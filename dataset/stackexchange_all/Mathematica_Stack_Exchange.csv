question,answer
front end - Usage of \[InvisibleApplication] and other related invisible characters,"
It is used in TraditionalForm output, e.g. here:
TraditionalForm[ Hypergeometric2F1[a,b,c,x] ]

Without \[InvisibleApplication] it would probably be hard for Mathematica to parse it back to 
InputForm. Probably it is used in more places internally.
In order to get rid of it:
Locate the file UnicodeCharacters.tr in /usr/local/Wolfram/Mathematica/8.0/SystemFiles/FrontEnd/TextResources (or the equivalent under Windows or MacOSX), make a backup of the file, open it and delete the line 
0xF76D         \[InvisibleApplication]         ($@$ ...

Then your cat can jump on the keyboard again.
"
"functions - What best practices or performance considerations are there for choosing between Cases, Position, Pick and Select?","
In my view, Cases and Position are in one camp (pattern-based functions used for general expression destructuring), while Select is in another: (more) special-purpose functions optimized to work on certain efficient data structures. 
As was mentioned already, both Cases and Select do generally unpack when used with packed arrays. What wasn't mentioned is that Select can easily be compiled, including compilation to C:
sel = Compile[{{lst, _Integer, 2}}, Select[lst, #[[2]] > 0 &], 
        CompilationTarget -> ""C"", RuntimeOptions -> ""Speed""];

In[98]:= (res3 = sel[test]);//Timing
Out[98]= {0.125,Null}

which gives an order of magnitude speed-up in the case at hand. Needless to say, Cases, being a general function using patterns, cannot be compiled and any attempt to do so will result in a callback to the main evaluator in the compiled code, which destroys the purpose.
Another difference is that Select can also work on sparse arrays, while Cases and Position can't.
OTOH, Cases and Position are more general in that they can work on arbitrary expressions (not necessarily packed or even regular arrays), and at an arbitrary level. If you happen to have an (even numerical) irregular nested list, where you can't utilize packing, Cases and Position may be able to do things Select can't (Select is limited to one level only). Performance-wise, Cases / Position can also be very efficient, if the test patterns are constructed properly (mostly syntactic patterns, with no Condition or PatternTest involved, and preferably not containing things like __, ___ etc as sub-parts).
There are instances when Cases (Position also, but not as much) are practially indispensable, and this is when you want to collect some information about the expression, while preventing its parts from evaluation. For example, getting all symbols involved in an expression expr, in unevaluated form, wrapped in HoldComplete (say), is as simple as this:
Cases[expr, s_Symbol :> HoldComplete[s], {0, Infinity}, Heads -> True]

and quite efficient as well. Generally, patterns and destructuring are very (perhaps most) powerful metaprogramming tools that Mathematica provides.
So, my final advice is this: when you have an expression with a fixed regular structure, or even better, numerical packed array, Select or other more precise operations (Pick etc) may be advantageous, and also more natural. When you have some general (perhaps symbolic) expression, and want to get some non-trivial information from it, Cases, Position and other pattern-based functions may be a natural choice.
"
cdf format - How can I embed a Manipulate (or other interactive graphics) in my website using CDF?,"
UPDATE
See: Why does Wolfram Research no longer support the CDF plugin?
Then: Web Delivery: Cloud
Also: Wolfram Notebook Embedder
LEGACY
This is just to update everyone on this topic. Wolfram Research released detailed blog and video tutorial ""CDF Embedding in a Nutshell"". It shows how to use built-in Mathematica wizard to deploy CDF online into HTML pages and Word Press blogs. URL:
http://blog.wolfram.com/2012/02/22/mathematica-qa-series-cdf-embedding-in-a-nutshell/
"
topology - Generating a topological space diagram for an n-element set,"
I suspect this is a fundamentally difficult problem, because as you pointed out, it boils down to drawing hypergraphs which, it seems, Mathematica does not have built in support for.
It isn't hard though, to automatically generate some kind of visualization of topologies.
I used the elegant topologyQ function proposed by kguler over at the stackoverflow question you linked to:
topologyQ[x_List] := Intersection[x, #] === # &[
Union[{Union @@ x}, Intersection @@@ Rest@#, Union @@@ #] &@
Subsets@x]

And then a little bit of (substantially less elegant) code I wrote myself:
RandomTopoTable[n_] := 
Module[{Sets = 
 Reverse[Sort[
  RandomSample[#, RandomChoice[Range[Length[#]]]] &[
   Subsets[Range[n]]]]], 
GenerateRow = 
 Function[{set}, {#, Background -> If[MemberQ[set, #], Red, White],
     Frame -> True} & /@ Range[n]]}, 
{If[topologyQ[Sets] && MemberQ[Sets, Range[n]],
  Style[""GOOD"", Darker[Green]], Style[""BAD"", Red]], 
  Grid[({Range[n]}~Join~((Item @@@ # &) /@ (GenerateRow /@ Sets))), 
  Frame -> All, Background -> {Lighter[Gray], None}]}];

Table[Column[RandomTopoTable[3]], {20}]

And this is the output for n=3, but it works for other choices of n too:

This is presenting a random sample of the subsets of the subsets of original set, e.g. a random selection of ""potential topologies"".
"
graphics - Is there a way to have Plot draw points on a function where the function is undefined as circles as in textbooks?,"
By using Exclusions and ExclusionsStyle like this
Plot[1/Sin[π x], {x, -3, 3},
  Exclusions -> Sin[π x] == 0, 
  ExclusionsStyle -> {Thin, Directive[Red, PointSize[0.02]]}
]

you can define the location of the discontinuities and the style for poles and discontinuity boundaries, respectively.

Also the Wolfram Blog, March 2011 has more examples on this topic.
"
"symbolic - How to symbolically do matrix ""Block Inversion""?","
Mathematica does not support this directly. You can do things of this sort using an external package called NCAlgebra.
http://math.ucsd.edu/~ncalg/
The relevant documentation may be found at
http://math.ucsd.edu/~ncalg/DOWNLOAD2010/DOCUMENTATION/html/NCBIGDOCch4.html#x8-510004.4
In particular have a look at ""4.4.8 NCLDUDecomposition[aMatrix, Options]""
Using this package, you would find the block inverse of the example matrix using:
c=0;    
inverse = NCInverse[matrix]  
(* Out[] = {{inv[a], -inv[a] ** b ** inv[d]}, {0, inv[d]}} *)

Here inv[a] represents the general inverse of the a block of the matrix and the ** represents non-commutative (i.e. matrix) multiplication. This approach works for larger (3x3, 4x4, etc) square block matrices as well.
"
numerics - Can Mathematica propose an exact value based on an approximate one?,"
I can offer a round-about method.
First compute the numerical approximation. I obtain, to high precision,
In[24]:= N[Sum[1/(2*n!), {n, 0, 100}], 100]

Out[24]= 1.\
3591409142295226176801437356763312488786235468499797874834838138620383\
15176773797285691089262583214

Now paste that into a Wolfram|Alpha query, accessed by clicking on the '+' sign at upper left of a fresh input cell. This gives, among other things, possible closed forms.
To the best of my knowledge, the heuristic methods used by W|A for this task are not directly exposed in any other way in Mathematica proper.
"
reference request - Where can I find examples of good Mathematica programming practice?,"
Here's a collection of resources that I started on Mathgroup (a collection of Mathematica learning resources) and updated here at Stack Overflow. As this site is dedicated to Mathematica it makes more sense to maintain it here. This represents a huge amount of information; of course it's not exhaustive so feel free to improve it! Also, don't hesitate to share it and suggest other interesting links! Remember, you can always search the online Documentation Center of Mathematica, that is identical to the built-in help of the latest software version.
Links to more advanced aspects of the program that you can start to appreciate once you understand the basics are provided in separate answers (below) as this post became too large.

Tips and Tricks
Advanced evaluation, patterns and neat algorithms

Introduction

If you're just beginning try to have a look at these videos.
Mathematica Basics, Elementary Programming in Mathematica
Hands-on Start to Mathematica
Several introductory videos by Jon McLoone
and many other video introductions and tutorials from the official Wolfram website 
An elementary introduction to the Wolfram language
Fast introduction for programmers 
Is it necessary to have a prior computational background or is it possible to learn Mathematica as a first programming language? 
What are the most common pitfalls awaiting new users? 
How To-s: full solutions for particular tasks from the online documentation  
Easy-to-understand animations explaining common Mathematica functions
Sal Mangano's videos for using pure functions, Part and patterns
Introductory videos of various applications of Mathematica
What is the best Mathematica tutorial for young people? 

Basic advices for people new to Mathematica
Functional style
Avoid iterative programming using loops like For or Do, use instead functional programming functions Map, Scan, MapThread, Fold, FoldList, ... and pure functions. This makes the code cleaner and faster.  

Functional Programming, Functional Programming: Quick Start 
Pure functions
What does # mean in Mathematica? 
Alternatives to procedural loops and iterating over lists in Mathematica 
An example: Programming a numerical method in the functional style 
How to understand the usage of Inner and Outer figuratively? 

Transpose and dimensions

Something not easy to guess alone at the beginning: if you have x={1,2} and y={3,4},
doing Transpose[{x,y}] or {x,y}ESC tr ESC in the front end will produce {{1,3},{2,4}} (format compatible with ListPlot). This animation helps understand why.
You can also use the second argument of Transpose to reorder the indices of a multidimensional list.
Don't forget to regularly control the output of the lists you generate using Dimensions.

Get familiar with shorthand syntax (@, &, ##, /@, /., etc.)

Operator Input Forms
when is f@g not the same as f[g]? 

Programming easily

Getting help: Execute ?Map for example for a short description of a function, or press F1 on a function name for more details and examples about it. You can solve many problems by adapting examples to your needs.  
Auto-completion: Start typing the name of a function and (in Mathematica 9+) select from the pop-up auto-completion menu, or press Ctrl+k to get a list of functions which names start with what has already been entered. Once the name of the function is written completely press Ctrl+Shift+k (on Mac, Cmd+k) to get a list of its arguments.
Function templates: In Mathematica 9, after typing a function name, press Ctrl+Shift+k (on Mac, Cmd+Shift+k) and click on the desired form from the pop-up menu to insert a template with named placeholders for the arguments. 
Other useful shortcuts are described in the post Using the Mathematica front-end efficiently for editing notebooks.
Use palettes in the Palettes menu especially when you're beginning.
In Mathematica 8, use the natural input capability of Wolfram Alpha, for example type ""= graph 2 x + 1 between 0 and 3"" without the quotes and see the command associated with the result.

Tutorials

An elementary introduction to the Wolfram language, by Stephen Wolfram
Fast introduction for programmers 
Fundamentals of Mathematica Programming (by Richard Gaylord, great tutorial for an overview of the logic behind Mathematica: patterns)
Video tutorial also available    
Introduction to Mathematica (by Thomas Hahn, another succinct overview of Mathematica)  
Tutorial Collection by WRI (lots of extra documentation and examples, available as free PDFs, also available and up-to-date in Help > Virtual Book in Mathematica). 
Programming Paradigms via Mathematica (A First Course) 
Mathematica Tutorial: A New Resource for Developers 
Wolfram's Mathematica 101 
http://bmia.bmt.tue.nl/Software/Downloads/Campus/TrainingMathematicaEnglish.zip
http://bmia.bmt.tue.nl/Software/Mathematica/Tutorials/index.html 
A problem centered approach 
A beginner's guide to Mathematica 
http://math.sduhsd.net/MathematiClub/tutorials.htm 
http://www.austincc.edu/mmcguff/mathematica/ 
http://www.mtholyoke.edu/courses/hnichols/phys303/ 
http://www.apam.columbia.edu/courses/ap1601y/ (Introduction to Computational Mathematics and Physics)  
http://ftp.physics.uwa.edu.au/pub/MATH2200/2012/Lectures/ (Applied Mathematics)
http://ftp.physics.uwa.edu.au/pub/MATH2200/2009/Lectures (path for some lectures in pdf) 
http://en.wikibooks.org/wiki/Mathematica 
http://www.cs.purdue.edu/homes/ayg/CS590C/www/mathematica/math.html (Basic tutorial)   
https://stackoverflow.com/questions/4430998/mathematica-what-is-symbolic-programming  (What is symbolic programming)   
http://www.cer.ethz.ch/resec/people/tsteger/Econ_Model_Math_1.pdf 
http://www.physics.umd.edu/enp/jjkelly (An introduction to Mathematica as well as some physics courses)   
Do you know of any web-based university course that is entirely Mathematica based? 
http://homepage.cem.itesm.mx/jose.luis.gomez/data/mathematica (Tutorials in Spanish)
Mathematica programming (some examples of the various programming paradigms that can be used in Mathematica)

FAQ

http://12000.org/my_notes/faq/mma_notes/MMA.htm  (FAQ)  
https://stackoverflow.com/questions/tagged/mathematica?sort=faq&pagesize=15  (FAQ on Stack Overflow)  
https://mathematica.stackexchange.com/questions?sort=faq (FAQ on this site)   
http://library.wolfram.com/conferences/conference98/Lichtblau/SymbolicFAQ.nb (Symbolic FAQ)  

Books

Stephen Wolfram's The Mathematica Book (online, version 5.2), available for free  
Mathematica programming: an advanced introduction (online) by Leonid Shifrin, available for free
Tutorial Collection by WRI (lots of extra documentation and examples, available as free pdfs, also available and up-to-date in Help > Virtual Book in Mathematica). 
Mathematica Cookbook by Sal Mangano (O'Reilly, 2010)
Mathematica in Action by Stan Wagon (Springer, 2010)
Mathematica: A Problem-Centered Approach by Roozbeh Hazrat (Springer, 2010)
Mathematica Navigator by Heikki Ruskeepaa (Academic Press, 2009)
The Mathematica GuideBooks (for Programming, Numerics, Graphics, Symbolics) by Michael Trott (Springer, 2004-2005)  
An introduction to programming with Mathematica by Paul R. Wellin, Richard J. Gaylord and Samuel N. Kamin (Cambridge University Press, 2005); contains an example of Domain Specific Language (DSL) creation.
Mastering Mathematica by John W. Gray (Academic Press, 1997)
Programming in Mathematica by Roman Maeder (Addison-Wesley Professional, 1997)
Programming with Mathematica®: An Introduction by Paul Wellin (Cambridge University Press, 2013)  
Power Programming With Mathematica: The Kernel, by David B. Wagner (Mcgraw-Hill, 1997), out of print but scanned copy available here.  
http://blog.wolfram.com/2014/01/10/read-up-on-mathematica-in-many-subjects 

Wolfram Websites
Learn 

http://www.wolfram.com/broadcast/ 
http://www.wolfram.com/training/courses (Online video courses, most are free)
http://www.wolfram.com/training/special-event/ (Links to videos of past conferences)  
Slides of seminars 
http://www.youtube.com/user/WolframResearch 
An elementary introduction to the Wolfram language
Fast introduction for programmers
Data drop quick reference 

Examples 

http://demonstrations.wolfram.com
How To-s 
http://www.wolfram.com/mathematica/new-in-8
http://www.wolfram.com/mathematica/new-in-9
http://www.wolfram.com/mathematica/new-in-10/
http://www.wolfram.com/mathematica/new-in-11/
http://www.wolfram.com/training/special-event/new-in-mathematica-10/ 
A plot gallery for Mathematica 9 
http://www.wolfram.com/language/ 

Resources 

http://www.wolfram.com/mathematica/resources 
http://library.wolfram.com/ (Great amount of resources here) 
http://support.wolfram.com/kb/topic/mathematica (Knowledge base)    
http://www.mathematica-journal.com 
Help
Help > Virtual Book 
http://www.wolfram.com/support/learn/ 
http://www.wolfram.com/books/ 
http://reference.wolfram.com

Blogs 

http://community.wolfram.com 
http://blog.wolfram.com 
http://blog.wolframalpha.com 
http://blog.stephenwolfram.com 
http://twitter.com/#!/mathematicatip 

Other related sites 

http://www.mathematica25.com
SMP
http://blog.stephenwolfram.com/2013/06/there-was-a-time-before-mathematica
http://blog.stephenwolfram.com/data/uploads/2013/06/SMPHandbook.pdf 
http://www.wolframalpha.com 
Wolfram Science: the official site of Stephen Wolfram's New Kind of Science
NKS forum
Lecture notes from NKS summer schools
Programs from the notes
Demonstrations 
http://computerbasedmath.org/ 
http://education.wolfram.com (Some interactive basic math courses, useful for curious young people)  
http://www.wolfram.com/webresources.html  (other Mathematica related sites)  

Virtual conferences 

http://www.wolfram.com/events/virtual-conference/spring-2013 
http://www.wolfram.com/events/virtual-conference/2012 
http://www.wolfram.com/events/virtual-conference/2011 

Mathematica one-liner competition

http://www.wolfram.com/events/techconf2010/competition.html
http://www.wolfram.com/events/technology-conference/2011/one-liners.html 
http://www.wolfram.com/training/special-event/mathematica-experts-live-one-liner-competition-2012 

Wolfram technology conferences

http://www.wolfram.com/events/technology-conference/2016 
2015, http://www.wolfram.com/events/technology-conference/2015
2014, http://www.wolfram.com/events/technology-conference/2014 
2013, http://www.wolfram.com/events/technology-conference/2013 
2012, http://www.wolfram.com/events/technology-conference/2012 
2011, http://www.wolfram.com/events/technology-conference/2011 
2010, http://www.wolfram.com/events/techconf2010 
2009, 2007, 2006, 2005, 2004, 2003, 2001, 1999, 1998, 1997, 1994, 1992 
http://library.wolfram.com/infocenter/Conferences/ 

"
"plotting - RegionPlot is producing odd gaps, even for simple functions. Is there an option to prevent this?","
Just increase the number of PlotPoints
RegionPlot[x^2 < y && y < x^4, {x, -3, 3}, {y, 0, 3}, 
  PlotPoints -> 100]


"
parallelization - How to run mathlink external commands in parallel?,"
First I'd like to mention that I am currently using LibraryLink, and that LibraryFunctions can be shared with parallel kernels with DistributeDefinitions.  When using Parallelize, this happens automatically.  (I'm assuming that you have local parallel kernels.  For remote ones, see here.)
For MathLink programs, this will not work.  Let's try it:
First, let's launch the kernels:
In[6]:= LaunchKernels[]

Then install the addtwo example into the main kernel:
In[7]:= SetDirectory[$InstallationDirectory <> 
   ""/SystemFiles/Links/MathLink/DeveloperKit/"" <> $SystemID <> 
   ""/PrebuiltExamples/""];

In[8]:= link = Install[""addtwo""]    
Out[8]= LinkObject[""addtwo"", 23, 11]

It will not work in parallel kernels even after distribution the definitions because the connection exists only between addtwo and the main kernel:
In[9]:= DistributeDefinitions[AddTwo]    
Out[9]= AddTwo

In[10]:= ParallelEvaluate[Print@AddTwo[2, 2]]

(kernel 2) LinkObject::linkn: Argument LinkObject[addtwo,23,11] in LinkWrite[LinkObject[addtwo,23,11],CallPacket[0,{2,2}]] has an invalid LinkObject number; the link may be closed.

(kernel 1) LinkObject::linkn: Argument LinkObject[addtwo,23,11] in LinkWrite[LinkObject[addtwo,23,11],CallPacket[0,{2,2}]] has an invalid LinkObject number; the link may be closed.

(kernel 2) $Failed

(kernel 1) $Failed

Out[10]= {Null, Null}

Now lets install it into each parallel kernel:
In[11]:= ParallelEvaluate[Install[""addtwo""]]    
Out[11]= {LinkObject[""addtwo"", 6, 6], LinkObject[""addtwo"", 6, 6]}

In[12]:= ParallelEvaluate[Print@AddTwo[2, 2]]

(kernel 1) 4

(kernel 2) 4

Out[12]= {Null, Null}

As you can see, now it works in each of them, but the addtwo process will also exist in three copies (on a two-core machine). Note: you will have to run ParallelNeeds[] if you load any packages required by the sub kernels.
I must note that unlike with LibraryLink, I have no practical experience with this.

Caveat:  This problem didn't come up in my tests, but I think it may be possible that the symbol AddTwo will get auto-synchronized between the kernels, so they might lose the connection to their own addtwo process.  This could be avoided by placing the AddTwo symbol into a different context than Global ` (see here and here), but unfortunately you won't have control over this unless you are writing your MathLink programs yourself.
"
performance tuning - File-backed lists/variables for handling large data,"
Preamble
I spent some time and designed and implemented a tiny framework to deal with this problem, over the last two days. Here is what I've got. The main ideas will involve implementing a simple key-value store in Mathematica based on a file system, heavy use and automatic generation of UpValues, some OOP - inspired ideas, Compress, and a few other things. Those who know my posts, I have to warn that this is going to be an unusually long one.
The problem and ideas behind the solution

Let me describe the limitations of my system right away. Since the general problem is tough, I consider a very simplified version, but one which can be useful in its own right, and which can serve as a good starting point for future developments. The problem is how to file-back a large ragged numerical list, whose sublists are possibly packed, but generally of different lengths. Let me tell from the start that since I can not use .mx files to avoid platform-dependence, the performance of this won't be stellar. This is a clear speed/memory trade-off situation, and the performance will be merely average. Perhaps, one could make a few tweaks. The overall design was more of my concern here, and I hope I've got a few things right in that department.
Let us say we have a large list already constructed in  memory in Mathematica, call it testList. Its elements are lists themselves. What I will do is traverse it element by element. For a given element (sub-list), we will analyze how much memory it occupies, and if this amount exceeds a certain threshold that we specify, we will create a key-value pair for it. The key will be some dummy generated symbol, and the value will be a file name for a file where we will save a contents of this element. We will actually Compress the element first, and save the compressed data.
Low-level OOP-style data exchange API
EDIT
Since using .mx files is so much faster, I added some switch functions which will allow one to switch between using usual files and .mx files:
ClearAll[$fileNameFunction,fileName, $importFunction,import, $exportFunction, 
  export,  $compressFunction, $uncompressFunction]

$fileNameFunction = fileName;
$importFunction  = import;
$exportFunction = export;
$compressFunction = Compress;
$uncompressFunction = Uncompress;

fileName[dir_, hash_] := 
   FileNameJoin[{dir, StringJoin[""data"", ToString[hash], "".dat""]}];
mxFileName[dir_, hash_] := 
   FileNameJoin[{dir, StringJoin[""data"", ToString[hash], "".mx""]}];
import =  
   Function[fname, Import[fname, ""String""]];
export = 
   Function[{fname, compressedValue}, 
      Export[fname, compressedValue, ""String""]];
mxImport = 
   Function[fname, Block[{data}, Get[fname]; data]];
mxExport = 
   Function[{fname, compressedValue}, 
       Block[{data = compressedValue}, DumpSave[fname, data]]];

In addition, compression / uncompression we will also be able to switch on and off. Note also that other functions down the page have been modified accordingly.
END EDIT
As a second component, we need some high-level structure, which will represent the ""skeleton"" of the original list, and which will manage the on-demand data fetching and saving. As such a structure, I will use just a single symbol, say s. Here is the function which implements the management (the large one):    
ClearAll[definePartAPI];
definePartAPI[s_Symbol, part_Integer, dir_String] :=
 LetL[{sym = Unique[], hash = Hash[sym], 
     fname = $fileNameFunction[dir, hash]
   },
   sym := sym =  $uncompressFunction@$importFunction[fname];
   s /: HoldPattern[Part[s, part]] := sym;

   (* Release memory and renew for next reuse *)
   s /: releasePart[s, part] :=
       Replace[Hold[$uncompressFunction@$importFunction[fname]], 
          Hold[def_] :> (ClearAll[sym]; sym := sym = def)];

   (* Check if on disk *)
   s /: savedOnDisk[s, part] := FileExistsQ[fname];

   (* remove from disk *)
   s /: removePartOnDisk[s, part] := DeleteFile[fname];

   (* save new on disk *)
   s /: savePartOnDisk[s, part, value_] :=
      $exportFunction[fname, $compressFunction @value];

   (* Set a given part to a new value *)
   If[! TrueQ[setPartDefined[s]],
     s /: setPart[s, pt_, value_] :=
       Module[{},
         savePartOnDisk[s, pt, value];
         releasePart[s, pt];
         value
       ];
     s /: setPartDefined[s] = True;
   ];
(* Release the API for this part. Irreversible *)
s /: releaseAPI[s, part] := Remove[sym];
];

How it works
Let me now explain what happens here. First, LetL is a sequentially-binding version of With, which I will display in a minute. It allows to avoid nested With statements. The parameters of the function are the main top-level symbol s, the part index, and the directory where our key-value store will be located. Basically, in OO terms, this function creates an instance of a class, with these methods: Part (part extraction), releasePart (releasing the memory occupied by the part, and getting ready to extract it from file again, savedOnDisk - checks is the part has been backed into a file, removePartOnDisk - deletes the backing file for the part,  savePartOnDisk - save the part contents to a file, and releaseAPI - needed to release resources at the end.
All this is implemented via UpValues for s. In particular, the Part is overloaded, so now when I call s[[part]], it will look and feel like I extracted the part of s (not true of course, but very convenient). The content of the part is stored in the generated symbol sym, which is unique for a given part. Notice that the definition is lazy and self-uncompressing. This is a similar technique to one I used in this answer. Upon the first call, sym loads the content from file and uncompresses it, and then assigns it to itself. All subsequent calls will be constant time, with the content of the part stored in sym.  Note also that when I call releasePart, I remove the direct part content from sym, feed it to the garbage collector, and reconstruct back the lazy definition for sym. This is my mechanism to be able to release part content when no longer needed, but also be able to load it back again on demand. 
There are two important points to note regarding Compress. One is that it does not unpack packed arrays. Another is that it is cross-platform. Both are huge wins for us. Note that, essentially, for each part I create an instance of a class, where sym plays a role of instance variable. Note also that I use the Hash of the name of sym, to construct the file name. There are two flaws with this approach actually. One is that there in principle can be hash collisions, and currently I don't handle them at all. Another is that the symbols sym are unique only within a single session, while, as we'll see, I will be exporting their definitions. Both problems are surmountable, but for the sake of simplicity, I ignore them for now. So, the above code represents the low-level data-exchange API on the level of a single list's part.
Here is the code for LetL macro:
(* A macro to bind sequentially. Generates nested With at run-time *)
ClearAll[LetL];
SetAttributes[LetL, HoldAll];
LetL /: Verbatim[SetDelayed][lhs_, rhs : HoldPattern[LetL[{__}, _]]] :=  
  Block[{With},
    Attributes[With] = {HoldAll};
    lhs := Evaluate[rhs]];
LetL[{}, expr_] := expr;
LetL[{head_}, expr_] := With[{head}, expr];
LetL[{head_, tail__}, expr_] :=
  Block[{With}, Attributes[With] = {HoldAll};
   With[{head}, Evaluate[LetL[{tail}, expr]]]];

The details of how it works are explained in much detail  here.
Higher-level interface: the list-building function
This is the main function used in list-building. Its name pretty much tells what it does - it extends the list with one more element. This, however, does not cost us a performance penalty, since our ""list"" is faked - it is a symbol s which pretends to be a list but in fact is not (it is more like a hash-table filled with class instances).
ClearAll[appendTo];
Options[appendTo] = {
   ElementSizeLimit :> $elementSizeLimit,
   DestinationDirectory :> $destinationDirectory
 };
appendTo[s_Symbol, value_, opts : OptionsPattern[]] :=
  LetL[{len = Length[s], part = len + 1,
     dir = OptionValue[DestinationDirectory],
     blim = OptionValue[ElementSizeLimit]
    },
    definePartAPI[s, part, dir];
    s /: Length[s] = part;
    If[ByteCount[value] > blim,
       definePartAPI[s, part, dir];
       savePartOnDisk[s, part, value];
       releasePart[s, part],
       (* else *)
       With[{compressed = $compressFunction @value}, 
         s /: Part[s, part] := 
            (s /: Part[s, part] = $uncompressFunction@compressed);
         s /: Part[s, part, parts___] := Part[s, part][[parts]];
  ]]];

As you can see from this code, not all parts of the list are backed by files. Those which are below the threshold in terms of size, are merely compressed and also assigned to s via UpValues and overloaded Part, but are not on the disk. The code of this function is pretty self-explanatory, so I will move on.
Integration with the system and initialization
The following function (partially) integrates my construction with some commands that we all love. This will help to better masquerade our symbol s so that in many respects it now behaves as an ordinary list.
ClearAll[initList];
initList[s_Symbol] :=
  Module[{},
   ClearAll[s];
   (* Set a new value for part, including update on disk *)
   s /: Length[s] = 0;
   s /: HoldPattern[Take[s, {n_}]] := s[[n]];
   s /: HoldPattern[Take[s, n_]] := Take[s, {1, n}];
   s /: HoldPattern[Take[s, {m_, n_}]] := Table[s[[i]], {i, m, n}];
   s /: HoldPattern[Drop[s, {n_}]] := Drop[s, {n, n}];
   s /: HoldPattern[Drop[s, n_]] := 
      Table[s[[i]], {i, n + 1, Length[s]}];
   s /: HoldPattern[Drop[s, {m_, n_}]] :=
        Table[s[[i]], {i, Range[m - 1] ~~ Join ~~ Range[n + 1, Length[s]]}];
   s /: Map[f_, s] := Table[f[s[[i]]], {i, Length[s]}];
   s /: HoldPattern[First[s]] := s[[1]];
   s /: HoldPattern[Last[s]] := s[[Length[s]]];
   s /: HoldPattern[Rest[s]] := Drop[s, 1];
   s /: HoldPattern[Most[s]] := Take[s, {1, Length[s] - 1}];
   s /: Position[s, patt_] :=
      If[# === {}, {}, First@#] &@
        Reap[Do[If[MatchQ[s[[i]], patt], Sow[{i}]], {i, Length[s]}]][[2]]
  ];

The above code probably does not need any comments.
Settings
There are a few settings I use, basically defaults for the directory and the size threshold.
ClearAll[releasePart, savedOnDisk, removePartOnDisk, removePartOnDisk,
   savePartOnDisk, releaseAPI]
$destinationDirectory = $TemporaryDirectory ;
$elementSizeLimit = 50000;

Higher-level and management-level functions
The following functions realize higher-level API which is actually what the end user is supposed to work with.
ClearAll[appendList];
appendList[s_Symbol, l_List, opts : OptionsPattern[]] :=
   Do[appendTo[s, l[[i]], opts], {i, 1, Length[l]}];

ClearAll[removeStorage];
removeStorage[s_Symbol] :=
   Do[If[savedOnDisk[s, i], removePartOnDisk[s, i]], {i, Length[s]}];

ClearAll[releaseAllMemory];
releaseAllMemory[s_Symbol] :=
   Do[releasePart[s, i], {i, Length[s]}];

The last several functions are concerned with disk management, and storing the main structure / definitions on disk. The point is that in the process of creating our key-value store, we generated lots of UpValues for s, and all those private symbols sym for each part, must also be saved together with s, if we want to fully reconstruct the environment on a fresh kernel.
This will find the dependencies of the main symbol s. We only use UpValues, so this is quite straightforward.
(* Our current system only has one-step dependencies*)
ClearAll[getDependencies];
getDependencies[s_Symbol] :=
 Thread[
   Prepend[
     Union@Cases[UpValues[s],
     sym_Symbol /; Context[sym] =!= ""System`"" :> HoldComplete[sym],
     {0, Infinity}, Heads -> True],
   HoldComplete[s]
  ],
  HoldComplete] 

This generates a file name. It is important that the extension for the main file is .m (Mathematica package) - will come to that later.
ClearAll[getMainListFileName];
Options[getMainListFileName] = {
   DestinationDirectory :> $destinationDirectory,
   ListFileName -> Automatic
 };
getMainListFileName[s_Symbol, opts : OptionsPattern[]] :=
  LetL[{fn = OptionValue[ListFileName],
    fname = If[fn === Automatic, ToString[s] <> "".m"", fn],
    fullfname = FileNameJoin[{OptionValue[ DestinationDirectory], fname}]},
   fullfname];

This function saves the main symbol s and those on which it depends (definitions) in a plain .m format to the disk.
ClearAll[storeMainList];
storeMainList[s_Symbol, opts : OptionsPattern[]] :=
  LetL[{filteredOpts  = 
      Sequence @@ FilterRules[{opts}, Options[getMainListFileName]],
      fname  = getMainListFileName[s, filteredOpts]},
    releaseAllMemory[s];
    If[FileExistsQ[fname], DeleteFile[fname]];
    Replace[getDependencies[s],
       HoldComplete[syms_] :> Save[fname , Unevaluated[syms]]]];

A call to releaseAllMemory is important, since it converts all possibly expanded definitions of sym-s for various parts back to lazy form, and in that form they will be saved.
This function does the inverse: it loads the environment, on a fresh kernel:
ClearAll[retrieveMainList];
retrieveMainList[s_Symbol, opts : OptionsPattern[]] :=
  LetL[{filteredOpts  = 
      Sequence @@ FilterRules[{opts}, Options[getMainListFileName]],
      fname  = getMainListFileName[s, filteredOpts],
      imported =  Import[fname , ""HeldExpressions""]
     },
    ReleaseHold[imported /.
       {TagSet -> TagSetDelayed, UpSet -> UpSetDelayed}
       ] /; imported =!= $Failed;
    ];

 retrieveMainList[___] := $Failed;

There are a few subtleties here. The problem is that Save converts delayed UpValue definitions (made with TagSetDelayed or UpSetDelayed), into immediate ones (which looks like a bug to me, but anyways). Therefore, I have to load the package in unevaluated form and do back replacements manually, before I allow it to run.
The last function here will completely remove all the generated files from the file system:
ClearAll[deleteListComplete];
deleteListComplete[s_Symbol, opts : OptionsPattern[]] :=
 LetL[{filteredOpts  = 
    Sequence @@ FilterRules[{opts}, Options[getMainListFileName]],
    fname  = getMainListFileName[s, filteredOpts]},
    removeStorage[s];
    If[FileExistsQ[fname], DeleteFile[fname]];
    Do[releaseAPI[s, i], {i, Length[s]}];
    ClearAll[s]]; 

This completes the current version of the system, and now we are ready to start using it.
Examples and benchmarks
Initialization
The following may be considered as a quick guide to the usage.
$HistoryLength = 0

We first generated a reasonably small piece of data, to have something to play with:
smallTest = RandomInteger[100, #] & /@ RandomInteger[{10000, 20000}, 300];

I will chose our top-level symbol to have a name test. Before we start anything, we must initialize it:
initList[test]

Convertin a list
We now convert our list into our key-value structure: 
In[83]:= appendList[test,smallTest,DestinationDirectory:>""C:\\Temp\\LargeData""];//Timing
Out[83]= {2.906,Null}

This was about 18Mb:
In[84]:= ByteCount[smallTest]
Out[84]= 18193688

And we generated about 230 files:
In[87]:= FileNames[""*.dat"",{""C:\\Temp\\LargeData""}]//Short
Out[87]//Short= {C:\Temp\LargeData\data530106946.dat,<<234>>,
      C:\Temp\LargeData\data530554672.dat}

Details and tests...
Note that I intentionally chose a high enough threshold so that not all parts of smallTest ended up in files, some were assigned in-memory only:
In[95]:= Length[test]
Out[95]= 300

In[97]:= Position[Table[savedOnDisk[test,i],{i,Length[test]}],False]//Short
Out[97]//Short= {{3},{5},{7},{33},{34},{35},{39},<<50>>,{277},{280},{287},{290},{298},{299},{300}}

Let us now test that our file-backed system keeps the right results. We pick some random positions:
In[99]:= randomPos = RandomSample[Range[Length[test]],20]
Out[99]= {287,214,9,294,32,263,12,141,282,85,213,108,22,197,77,67,41,286,146,38}

And test:
In[100]:= test[[#]]==smallTest[[#]]&/@randomPos//Timing
Out[100]= {0.203, {True,True,True,True,True,True,True,True,True,True,
True,True,True,True,True,True,True,True,True,True}}

Note that the second time the test is instant, since memoization is now at work, and there's no need to uncompress again:
In[101]:= test[[#]]==smallTest[[#]]&/@randomPos//Timing
Out[101]= {0.,{True,True,True,True,True,True,True,True,True,True,True,
True,True,True,True,True,True,True,True,True}}

Another test:
In[102]:= Take[test, {10, 20}] == Take[smallTest, {10, 20}]
Out[102]= True

Adding new elements
Let us append some elements to our list now:
appendTo[test, Range[10000]]

We check the length:
In[105]:= Length[test]
Out[105]= 301

We can also test directly:
In[116]:= test[[301]]//Short
Out[116]//Short= {1,2,3,4,5,6,7,8,9,10,<<9980>>,9991,9992,
9993,9994,9995,9996,9997,9998,9999,10000}

In[117]:= Last@test//Short
Out[117]//Short= {1,2,3,4,5,6,7,8,9,10,<<9980>>,9991,9992,
 9993,9994,9995,9996,9997,9998,9999,10000}

We can append wholesale as well:
In[118]:= appendList[test, Partition[Range[10000, 60000], 10000]]

In[119]:= Length[test]
Out[119]= 306

Memory management
I will now illustrate memory management: we will force it to load from disk and uncompress all parts:
In[120]:= MemoryInUse[]
Out[120]= 49040104

In[121]:= Take[test, {1, Length[test]}];

In[122]:= MemoryInUse[]
Out[122]= 64273408

We now release all memory, and return to lazy self-uncompressing definitions.
In[123]:= releaseAllMemory[test];

In[124]:= MemoryInUse[]
Out[124]= 49079560

Saving and reconstructing the environment
Let us now save our environment:
In[125]:= 
storeMainList[test, DestinationDirectory :> ""C:\\Temp\\LargeData""] // AbsoluteTiming

Out[125]= {1.1015625, Null}

We now quit the kernel:
Quit

and now try to reconstruct it back:
In[126]:= 
retrieveMainList[test, 
   DestinationDirectory :> ""C:\\Temp\\LargeData""] // AbsoluteTiming

Out[126]= {1.2294922, Null}

We can see that we are in business:
In[127]:= Length[test]
Out[127]= 306

In[128]:= test[[301]]//Short
Out[128]//Short= {1,2,3,4,5,6,7,8,9,10,<<9980>>,9991,9992,9993,
9994,9995,9996,9997,9998,9999,10000}

Removing the key-value store - uninstall
Finally, this will remove all the files from the system completely:
In[129]:= deleteListComplete[test,DestinationDirectory:>""C:\\Temp\\LargeData""]//Timing
Out[129]= {0.031,Null}

Larger tests
I will throw in a few larger tests, which are still kind of toy tests, but a bit more representative. We start with this:
In[130]:= MemoryInUse[]
Out[130]= 44668800

Now we create a reasonably large dataset:
In[131]:= mediumTest = RandomInteger[100,#]&/@RandomInteger[{100000,200000},1000];
In[132]:= ByteCount[mediumTest]

This tells how large
Out[132]= 607800752
In[133]:= initList[test]

It takes slightly more than a minute to convert it to our data store:
In[134]:= 
appendList[test, mediumTest, 
   DestinationDirectory :> ""C:\\Temp\\LargeData"",
   ElementSizeLimit:>20000]; //Timing
Out[134]= {73.906,Null}

The memory consumption is just amazing (the lack of it!):
In[135]:= MemoryInUse[]
Out[135]= 657753176

This is pretty much what the initial memory use was plus the memory occupied by mediumTest - our construction takes almost no memory because everything is cached and lazy.
Here we extract some element (which is not that small):
In[136]:= test[[10]]//Short//Timing
Out[136]= {0.047,{1,19,82,24,54,12,25,5,11,4,74,7,75,
   <<176964>>,93,5,12,25,97,89,56,59,46,35,95,1,49}}

All the next times, this will be instantly for this particular element, until we decide to release the cache. We take some more now:
In[137]:= Take[test,{10,30}]//Short//Timing
Out[137]= {0.5,{<<1>>}}

In[138]:= ByteCount[Take[test,{10,30}]]
Out[138]= 13765152

We now take about a third of the total data set - it takes several seconds:
In[139]:= (chunk = Take[test,{1,300}]);//Timing
Out[139]= {6.75,Null}

In[140]:= ByteCount[chunk]
Out[140]= 180658600

Need for speed: Turning on .mx files
If we sacrifice being cross-platform for speed, we get 10-40x speedup by using .mx files, and in this regime I'll be hard-pressed to see any database solution beating this in terms of performance. Here are the same benchmarks as before, done with .mx files.
First, switch to .mx:
$fileNameFunction = mxFileName;
$importFunction  = mxImport ;
$exportFunction = mxExport ;
$compressFunction = Identity;
$uncompressFunction = Identity;

Note also that I disabled compressing, for maximal speed. The benchmarks:
In[57]:= MemoryInUse[]
Out[57]= 18638744

In[58]:= mediumTest = RandomInteger[100,#]&/@RandomInteger[{100000,200000},1000];

In[59]:= ByteCount[mediumTest]
Out[59]= 594434920

In[60]:= initList[test]

In[61]:= appendList[test,mediumTest,DestinationDirectory:>""C:\\Temp\\LargeData""];//Timing
Out[61]= {14.797,Null}

In[62]:= MemoryInUse[]
Out[62]= 618252872

Extraction of a singe list element (including loading from disk) is now instantly:
In[63]:= test[[10]]//Short//Timing
Out[63]= {0.,{7,17,36,41,54,62,49,78,63,62,84,83,14,42,42,
    <<184520>>,83,0,64,25,86,84,89,17,71,94,84,3,6,23,38}}

Extracting 20 elements is also pretty fast:
In[64]:= Take[test,{10,30}];//Timing
Out[64]= {0.047,Null}

In[65]:= ByteCount[Take[test,{10,30}]]//AbsoluteTiming
Out[65]= {0.,12279632}

We now extract about 300 elements, with the total size af about 180Mb:
In[66]:= (chunk = Take[test,{1,300}]);//AbsoluteTiming
Out[66]= {0.3281250,Null}

In[67]:= ByteCount[chunk]
Out[67]= 178392632

To my mind, this is blazing fast. 
Summary and conclusions
I presented here a tiny but complete implementation of a key-value store, which may make it possible to work with large files which don't fit in memory, notably lists. From the technical viewpoint, this is by far the most serious application of UpValues I have ever written. I think the simplicity of the code illustrates the power of UpValues well. They also made it possible to have nice syntactic sugar, and be able to use the familiar commands such as Part, Take, etc.
The implementation has many flaws, and it is still not clear to me whether it is efficient enough to be useful, but I think this may represent a good starting point. 
EDIT 
As it turns out, using .mx files gives a huge speedup (which is not unexpected of course). If speed is absolutely crucial, one can use .mx files for all computations and only use normal files to import from or export to another computer. I plan to build a layer which would automate that, but so far, this can be done manually, based on the single-part API in the code above. 
END EDIT 
All ideas, suggestions etc - most welcome!
"
image processing - ImageAlign doesn't always work correctly,"
The subimage may be too small:
ImageCorrespondingPoints[mandrill, eye]

returns
{{}, {}}

When you take more of the image (e.g., replace ""91"" by ""191""), Mathematica finds some corresponding points and ImageAlign works.
""Too small"" probably depends on the nature of the two images as well as their sizes.  The docs state that ImageCorrespondingPoints uses ImageKeyPoints which in turn is said to use the SURF method to find keypoints.  Indeed,
ImageKeypoints[eye]

returns an empty list.  If you increase the ""91"" to ""100"", a single keypoint is obtained, a pair of corresponding points is found, and ImageAlign succeeds.
"
curated data - Is it possible to invoke the OEIS from Mathematica?,"
There is a Mathematica package exactly for this at the OEIS wiki.
Somewhat related: there's also a package for formatting data into the OEIS format.
WolframAlpha also has some of this information, though I'm not sure how to get the $n^{\mathrm{th}}$ term of the sequence.
In[1] := WolframAlpha[""A004001"", {{""TermsPod:IntegerSequence"", 1}, ""ComputableData""}]

Out[1] = {1, 1, 2, 2, 3, 4, 4, 4, 5, 6, 7, 7, 8, 8, 8, 8, 9, 10, 11,
          12, 12, 13, 14, 14, 15}

Or:
In[1] := WolframAlpha[""A018900"", {{""Continuation"", 1}, ""ComputableData""}]

Out[1] = {3, 5, 6, 9, 10, 12, 17, 18, 20, 24, 33, 34, 36, 40, 48, 65, 66, 68, 72}

"
polynomials - Is there a way to Collect[] for more than one symbol?,"
Well, I am more inclined to try something that leverages Mathematica ""knowledge"" of polynomials.
In fact, in Mathematica 7 and 8, you can collect by $x-y$. However, it only works if $(x-y)$ is explicitly apparent in the form of the argument seen by the Collect function.
So, this works:
Collect[a (x - y)^3 + b (x - y)^2 + c (x - y) + d, x - y]

But, this doesn't:
Collect[Expand[a (x - y)^3 + b (x - y)^2 + c (x - y) + d], x - y]

I would use PolynomialReduce but I don't have an automated way for doing what you need.
Nevertheless it looks promising as the following does return {a, b, c, d}:
Flatten[
    PolynomialReduce[
        d + c x + b x^2 + a x^3 - c y - 2 b x y - 3 a x^2 y
             + b y^2 + 3 a x y^2 - a y^3,
        Table[(x - y)^i, {i, 3, 1, -1}],
        {x, y}
    ]
]

But I can use this approach for other factorizations.
For example, consider the following expansion Expand[z (x - y)^6 + w (x - y)^4 + t (x - y)^2 + s]. Using this expansion I am able to retrieve the coefficients in terms
of powers of x^2 - 2 x y + y^2:
Flatten[
    PolynomialReduce[
    s + t x^2 + w x^4 - 2 t x y - 4 w x^3 y + t y^2 + 6 w x^2 y^2 - 
        4 w x y^3 + w y^4 + x^6 z - 6 x^5 y z + 15 x^4 y^2 z - 
        20 x^3 y^3 z + 15 x^2 y^4 z - 6 x y^5 z + y^6 z, 
    Table[(x^2 - 2 x y + y^2)^i, {i, 3, 1, -1}],
    {x, y}
    ]
]

"
plotting - How to create regular (planar) graphs?,"
My friend C.P and I worked out these solutions. The 1st is C.P.s' Here we go. 
First things to know:
1) New Graph[] and related functionality in v8.0.4 is powerful in the sense that it does not only create an image but also stores all the information, including vertex coordinates, in that Graph[] object.
2) There is a GridGraph[...] function that makes exactly what it is named for 
Now starting from GridGraph[...] you can simply add or remove edges to it to get your diagrams. 
g[m_, n_] := 
 GridGraph[{m, n}, VertexSize -> 0.3, VertexStyle -> White, 
  EdgeStyle -> Black]

edges[m_, n_] := 
 Flatten[Table[
   If[Mod[j, m] != 0 && (j + m + 1 <= n*m), 
    UndirectedEdge[j + m + 1, j], {}], {j, 1, n*m}]]

altg[m_, n_] := EdgeAdd[g[m, n], edges[m, n]]

altg[7, 5]


The rest of your diagrams can follow in the same manner. Another way would be to figure out
the formula for construction of adjacency matrix for your diagrams. Then just use AdjacencyGraph[...].
But probably the easiest way to solve this (not necessarily efficient) is to understand the visual connection between your vertices. Then connect elements of an array exactly in this way and flatten the array. You should get creative with vertex coordinates though.
mat[m_, n_] := Flatten@Table[{
    If[i < m, a[i, j] \[UndirectedEdge] a[i + 1, j], {}],
    If[j < n, a[i, j] \[UndirectedEdge] a[i, j + 1], {}],
    If[i < m && j < n, a[i, j] \[UndirectedEdge] a[i + 1, j + 1], {}]
    }, {i, m}, {j, n}]

g[m_, n_] := 
 Graph[mat[m, n], 
  VertexCoordinates -> 
   Thread[Sort[VertexList[Graph[mat[m, n]]]] -> 
     Flatten[Table[{i, j}, {i, m}, {j, n}], 1]], VertexSize -> 0.4, 
  VertexStyle -> White]

g[7, 5]



===================     UPDATE     ===================

I just realized that we have some beautiful built in data for this type of things.
SetProperty[GraphData[{""KingsTour"", {10, 10}}], {VertexSize -> 0.4, 
VertexStyle -> White, EdgeStyle -> Black}]


SetProperty[GraphData[{""KnightsTour"", {10, 10}}], {VertexSize -> 0.4, 
VertexStyle -> White, EdgeStyle -> Black}]


"
How to use Union on list of lists without sorting them first?,"
Sorting of sub-lists seems unavoidable since this is what brings them to a ""canonical form"" in this problem. If you don't care about the order of your resulting sub-lists, you could used DeleteDuplicates in place of Union though - this should be faster for large lists.
"
graphics3d - Texture mapping and resizing a sphere primitive in Mathematica,"
You could use a combination of Translate and Scale. Suppose the radii and centres of the circles are given by
radii = RandomReal[{.1, .6}, 8];
centres = RandomReal[{-2, 2}, {8, 3}];

Then using the original sphere
image = ExampleData[{""ColorTexture"", ""GiraffeFur""}];
sphere = SphericalPlot3D[1, {theta, 0, Pi}, {phi, 0, 2 Pi}, Mesh -> None, 
  TextureCoordinateFunction -> ({#5, 1 - #4} &), 
  PlotStyle -> Directive[Texture[image]], Lighting -> ""Neutral"", 
  Axes -> False, Boxed -> False];

You could do for example
Graphics3D[MapThread[Translate[Scale[sphere[[1]], #1], #2] &, {radii, centres}]]

Which produces something like this

"
recursion - How can I implement dynamic programming for a function with more than one argument?,"
Yes, there is, although the speed-up is not as dramatic as for 1D memoization:
ClearAll[CharlierC];
CharlierC[0, a_, x_] := 1;
CharlierC[1, a_, x_] := x - a;
CharlierC[n_Integer, a_, x_] :=
  Module[{al, xl},
    Set @@ Hold[CharlierC[n, al_, xl_],          
        Expand[(xl - al - n + 1) CharlierC[n - 1, al, xl] - 
             al (n - 1) CharlierC[n - 2, al, xl]
        ]];
    CharlierC[n, a, x]
];

(Thanks to @Mike Bantegui for pointing out the wastefulness of Simplify, which has now been removed).
What you memoize here are function definitions.Expand is used to not accumulate the complexity too fast. The idea is that I first create a new pattern-based definition, using a number of tricks to fool the scoping variable - renaming mechanism but localize pattern variables, and then evaluate this definition.
For example:
In[249]:= CharlierC[20,a,x];//Timing
Out[249]= {0.063,Null}

In[250]:= CharlierC[25,a,x];//Timing
Out[250]= {0.078,Null}

While with clear definitions:
In[260]:= CharlierC[25,a,x];//Timing
Out[260]= {0.094,Null}

Here are a first few generated definitions:
In[262]:= Take[DownValues[CharlierC],4]
Out[262]= 
{HoldPattern[CharlierC[0,a_,x_]]:>1,
 HoldPattern[CharlierC[1,a_,x_]]:>x-a,
 HoldPattern[CharlierC[2,al$4106_,xl$4106_]]:>
      al$4106^2-xl$4106-2 al$4106 xl$4106+xl$4106^2,
 HoldPattern[CharlierC[3,al$4105_,xl$4105_]]:>
   -al$4105^3+2 xl$4105+3 al$4105 xl$4105+3 al$4105^2 xl$4105
       -3 xl$4105^2-3 al$4105 xl$4105^2+xl$4105^3}

"
formatting - Best way to give presentations with Mathematica,"
You can create SlideShows using Mathematica and run it to demonstrate presentation.
Main advantage of using such Slideshow over Powerpoint / PDF is that you can play dynamic content. 

This Link gives further details on how to create
http://reference.wolfram.com/mathematica/howto/CreateASlideShow.html
This screencast gives detailed steps on how to create slideshows
http://www.wolfram.com/broadcast/screencasts/howtocreateaslideshow/?w=800&h=600
This notebook has some cool tips
http://library.wolfram.com/infocenter/TechNotes/5299/Tips.nb?file_id=5035

With CDF format available with Mathematica now , Presentation can be saved in cdf format and can be presented using any browser in which CDF Player is installed
Quick tips for Inpatients ! 

Create Slide Show File -> New -> Slide Show
Open Slide Show Palette Palettes -> Slide Show
Run Slide Show View Environment -> SlideShow
Run in Full Screen Mode Presentation Size -> Full Screen

"
How can I get Overlay to position graphics according to coordinates?,"
Can you use Show? It produces the same thing as your first plot:
Graphics1 = Graphics[{Red, Disk[{0, 0}, 3, {0, Pi/4}]}];  
graphics2 = Graphics[{Blue, Disk[{0, 0}, 10, {0, Pi/2}]}];  
Show[{graphics2, graphics1}]


If you want to add other options, it works as well:
Show[{graphics2, graphics1}, PlotRange->{{-10, +10}, {-10, +10}}]


You should note that Show is order dependent. It draws it in the order that's specified
"
assignment - Clearing a specific definition,"
You can use Unset for this, like so:
a[b_, c_] =.

=. works with UpValues too (the full form of this has TagUnset):
a /: Subscript[a,2] =.

You need to use the same pattern in Unset that you used in the definition.  Get this using Information (i.e. ?a).
"
cdf format - What are the exact guidelines for what is allowed in a CDF?,"
Sal there is a security problem when you embed CDFs that is analogous to when you open a CDF from an untrusted directory. So though a CDF may work on your desktop you may/will run into problems when embedded. Many causes of this including bugs in how things get screened. For example I had a case where a tick function with down values triggered a security issue whereas an equivalent tick function without down values did not (Wolfram advised that it was down values that were causing that particular problem although in the case in question it shouldn't have caused a problem. I'm told that particular bug/problem has been fixed in current builds but until a new version of Mma is released you may want to try replacing functions with pure functions and see what happens).
For other instances where the grey boxes appear there appears to be no way around this without an Mma build that allows higher level security signing. However you will note the difference between an embedded CDF and one that opens in a webpage in fullscreen and displays the dynamic content warning, i.e. the button that you press to allow dynamic content to be considered safe. So one way around some, but not all, of these problems is described here
Change
cdf.embed(""http://path.to/myCDF.cdf"", 500, 600);

to 
cdf.embed(""http://path.to/myCDF.cdf"", 500, 600,{fullscreen:'true'});

"
"assignment - How can I randomly generate a unique, unused symbol?","
Unique will do precisely this.  Try for example Unique[x], which returns a symbol with a name similar to x$123.
Here I should mention the Temporary attribute as well, which, when associated with a symbol, causes that symbol to be removed from the system when it's no longer referenced.  This is occasionally useful when you need Unique.
But whenever you do something like this, the question comes up: why can't you just use localization (Module/Block)?
"
front end - Creating custom notation,"
You may wish to use the Notation package.
It lets you do these things fairly easily. I'd copy and paste some examples but they don't really copy and paste well. Read through the tutorials and you'll see some examples of how to do this.
You may also be interested in the Vector Analysis package.
"
performance tuning - Choosing among different function definitions without sacrificing speed,"
What I'd do (this is just one way of doing it out of many) is to make functions F and G local and generate them at run-time:
FFromFile[filename_] := FFromFile[filename] = Module[{ ...}, ...]
FAnalytic[a_, b_, c_] := a^2 + b^2 + c^2;
GenerateData[phi_, opts : OptionsPattern[]] :=
  Module[{F, G},
   If[OptionValue[Model] === ""File"",
     F[a_, b_, c_] := FFromFile[OptionValue[Source]][a, b, c],
     (* else *)
     F[a_, b_, c_] := FAnalytic[a, b, c]
   ];
   G[d_, e_, f_, phiLocal_] :=
     Block[{g, h, i},
       (*do a bunch of calculations to figure out g and h*)
       i = F[g, h, 5];
       (*do more calculations involving i*)
     ];
   NIntegrate[G[x, y, z, phi, opts], {x, 2, 10}, {y, 0, x}, {z, 0, 3},
     Method -> ""QuasiMonteCarlo"",  PrecisionGoal -> 3]];

"
export - How can I ensure graphics exported in WMF format don't have text-spacing problems?,"
I can only guess that the following could be a work-around for you (I don't have Windows). Define the following wrapper function for Export:
outlinedExport[name_, gr_, opts : OptionsPattern[]] := 
 Export[name, 
  First@ImportString[ExportString[gr, ""PDF""], ""PDF"", 
    ""TextMode"" -> ""Outlines""], opts]

On my Mac, I cannot export to WMF so I'll have to trust that it will work the same way it does with SVG which I did try. Assuming your graphics object is g, you would do something like this:
outlinedExport[""output.wmf"", g, ImageSize -> 600]

There is no need to embed any fonts because they have all been replaced by outlined paths (again, not sure if Mathematica on Windows does this properly). The downside is that the file size increases, but the upside is that you'll never have any font headaches again.
"
"assignment - What is the distinction between DownValues, UpValues, SubValues, and OwnValues?","
In Mathematica, all functions are really just patterns, and there are different kinds of those.
Let's start with OwnValues, which is the pattern type of a variable as you know it from other programming languages. The symbol having the OwnValue has, as the name suggests, intrinsic, ""own"", value.
 In[1] := a = 2; OwnValues[a]
Out[1] := {HoldPattern[a] :> 2}


A DownValue is defined when the variable itself does not have a meaning, but can get one when combined with the proper arguments. This is the case for the most function definitions
f[x_] := x^2

This defines a pattern for f specifying that each time f[...] is encountered, it is to be replaced by ...^2. This pattern is meaningless if there is a lonely f,
 In[2] := f
Out[2] := f

However, when encountered with an argument downwards (i.e. down the internal structure of the command you entered), the pattern applies,
 In[3] := f[b]
Out[3] := b^2

You can see the generated rule using
 In[4] := DownValues[f]
Out[4] := {HoldPattern[f[x_]] :> x^2}


The next type of pattern concerns UpValues. Sometimes, it's convenient not to associate the rule to the outermost symbol. For example, you may want to have a symbol whose value is 2 when it has a subscript of 1, for example to define a special case in a sequence. This would be entered as follows:
c /: Subscript[c, 1] := 2

If the symbol c is encountered, neither of the discussed patterns apply. c on its own has no own hence no OwnValue, and looking down the command tree of c when seeing Subscript[c,1] yields nothing, since c is already on an outermost branch. An UpValue solves this problem: a symbol having an UpValue defines a pattern where not only the children, but also the parents are to be investigated, i.e. Mathematica has to look up the command tree to see whether the pattern is to be applied.
 In[5] := UpValues[c]
Out[5] := {HoldPattern[Subscript[c, 1]] :> 2}


The last command is SubValues, which is used for definitions of the type
d[e][f] = x;

This defines neither an OwnValue nor a DownValue for d, since it does not really define the value for the atomic object d itself, but for d[e], which is a composite. Read the definition above as (d[e])[f]=x.
 In[6] := SubValues[d]
Out[6] := {HoldPattern[d[e][f]] :> x}

(Intuitively, an OwnValue for d[e] is created, however calling for this results in an error, i.e. OwnValues[d[e]] creates Argument d[e] at position 1 is expected to be a symbol.)
"
dynamic - What causes Manipulate to stop evaluating expressions?,"
Please try this. I prefer to remove all unneeded dynamics from the code by making the Manipulate use a Trigger so that I see better what is the dynamic object in all of these things, and added TrackedSymbols on only the trigger variable, and moved globals into the Manipulate as I do not like to see globals. (you can also use Module inside Manipulate if you want). 
Not seeing any hangups any more. The Trigger is probably what you want to use for this type of simulation setup. 
Manipulate[
 {r, v, a} = Step[r, v, a, dt];

 Grid[{
   {Show[{Graphics@Circle[{0, 0}, 1], 
      Graphics[{PointSize[Large], Red, Point[r]}]}]},
   {r, Norm@r}
   }
  ],

 Control[{{dt, 0.005, ""dt:""}, 0.00001, 1, 0.00001, 
   ControlType -> Trigger, DisplayAllSteps -> True, 
   ImageSize -> Small, AnimationRate -> Automatic}],

 {{r, {1, 0}}, None},
 {{v, {0, 1}}, None},
 {{a, {-1, 0}}, None},
 TrackedSymbols :> {dt},
 Initialization :>
  {
   Step[r_, v_, a_, dt_] := Block[{nr, nv, na},
     nv = v + dt/2 a;
     nr = r + dt nv;
     na = -nr;
     nv = nv + dt/2 a;
     {nr, nv, na}
     ]
   }
 ]

"
performance tuning - How can I improve the speed of eigenvalue decompositions for large matrices?,"
Mathematica is every bit as fast as Matlab for these types of computations.  The source of the discrepancy arises from the fact that Timing keeps track of total time used by all processors when Mathematica distributes the computation across them.  We can examine a fair comparison using AbsoluteTiming, which is more comparable to Matlab's tic and toc.
Consider the following computed on my Macbook Pro:
t1 = First[Timing[Eigenvalues[RandomReal[{0, 1},
  {1000, 1000}]]]];
t2 = First[AbsoluteTiming[Eigenvalues[RandomReal[{0, 1},
  {1000, 1000}]]]];
{t1, t2}

{5.16576, 1.329784}
Again, the only difference is the use of Timing versus AbsoluteTiming.  You can watch the wall clock to convince yourself that the faster time is accurate.  Let's try this with with the OP's code:
timingsGood = With[{x = RandomReal[NormalDistribution[], {#, #}]}, 
  Eigenvalues[x]; // AbsoluteTiming // First] & /@ 
  Range[500, 5000, 500];
timingsBad = With[{x = RandomReal[NormalDistribution[], {#, #}]}, 
  Eigenvalues[x]; // Timing // First] & /@ 
  Range[500, 5000, 500];
Column[{timingsGood, timingsBad, timingsBad/timingsGood}]


Note that the (incorrect) Timing result is always consistently about three times longer than the (correct) AbsoluteTiming result, which accounts just about exactly for the OP's observations.
I ran a suite of numerical comparisons that I created several years ago.  Here are my results:

There are differences.  Matlab is notably faster at singular value, Cholesky, and QR factorizations.  Mathematica is slightly faster at sparse eigenvalue computations.  They seem to be generally quite close to one another.  There are a few other types of computations as well.  Symbolically, Mathematica is way faster than Matlab's symbolic toolbox.
"
graphics - Speeding up this fractal-generating code,"
Use these 3 components: compile, C, parallel computing.
Also to speed up coloring instead of ArrayPlot use
Graphics[Raster[Rescale[...], ColorFunction -> ""TemperatureMap""]]

In such cases Compile is essential. Compile to C with parallelization will speed it up even more, but you need to have a C compiler installed. Note difference for usage of C and parallelization may show for rather greater image resolution and more cores. 
mandelComp = 
  Compile[{{c, _Complex}}, 
   Module[{num = 1}, 
    FixedPoint[(num++; #^2 + c) &, 0, 99, 
     SameTest -> (Re[#]^2 + Im[#]^2 >= 4 &)]; num], 
   CompilationTarget -> ""C"", RuntimeAttributes -> {Listable}, 
   Parallelization -> True];

data = ParallelTable[
   a + I b, {a, -.715, -.61, .0001}, {b, -.5, -.4, .0001}];

Graphics[Raster[Rescale[mandelComp[data]], 
  ColorFunction -> ""TemperatureMap""], ImageSize -> 800, PlotRangePadding -> 0]


This is just a prototype - you can figure out a better coloring. Another way is to use LibraryFunction - we have Mandelbrot built in:
mlf = LibraryFunctionLoad[""demo_numerical"", ""mandelbrot"", {Complex}, 
   Integer];
n = 501; samples = 
 Table[mlf[x + I y], {y, -1.25, 1.25, 2.5/(n - 1)}, {x, -2., .5, 
   2.5/(n - 1)}];
colormap = 
  Function[If[# == 0, {0., 0., 0.},  Part[r, #]]] /. 
   r -> RandomReal[1, {1000, 3}];
Graphics[Raster[Map[colormap, samples, {2}]], ImageSize -> 512]


Now, if you have a proper NVIDIA graphics card you can do some GPU computing with CUDA or OpenCL. I use OpenCL here because I got the source (from documentation btw):
Needs[""OpenCLLink`""]

src = ""
  __kernel void mandelbrot_kernel(__global mint * set, float zoom, \
float bailout, mint width, mint height) {
     int xIndex = get_global_id(0);
     int yIndex = get_global_id(1);
     int ii;

     float x0 = zoom*(width/3 - xIndex);
     float y0 = zoom*(height/2 - yIndex);
     float tmp, x = 0, y = 0;
     float c;

     if (xIndex < width && yIndex < height) {
         for (ii = 0; (x*x+y*y <= bailout) && (ii < MAX_ITERATIONS); \
ii++) {
              tmp = x*x - y*y +x0;
              y = 2*x*y + y0;
              x = tmp;
          }
          c = ii - log(log(sqrt(x*x + y*y)))/log(2.0);
          if (ii == MAX_ITERATIONS) {
              set[3*(xIndex + yIndex*width)] = 0;
              set[3*(xIndex + yIndex*width) + 1] = 0;
              set[3*(xIndex + yIndex*width) + 2] = 0;
          } else {
              set[3*(xIndex + yIndex*width)] = ii*c/4 + 20;
              set[3*(xIndex + yIndex*width) + 1] = ii*c/4;
              set[3*(xIndex + yIndex*width) + 2] = ii*c/4 + 5;
          }
      }
  }
  "";

MandelbrotSet = 
  OpenCLFunctionLoad[src, 
   ""mandelbrot_kernel"", {{_Integer, _, ""Output""}, ""Float"", 
    ""Float"", _Integer, _Integer}, {16, 16}, 
   ""Defines"" -> {""MAX_ITERATIONS"" -> 100}];

width = 2048;
height = 1024;
mem = OpenCLMemoryAllocate[Integer, {height, width, 3}];

res = MandelbrotSet[mem, 0.0017, 8.0, width, height, {width, height}];

Image[OpenCLMemoryGet[First[res]], ""Byte""]


References:
Fractals CDF paper
Compile to C
LibraryFunction 
OpenCL 
Demonstrations
"
Manipulate evaluation sequence,"
According to my previous experiences and this post, the sequence goes like this (please feel free to correct me in this post):

From the documentation: 

Manipulate generates a DynamicModule object, with the variables u, v, etc. specified as local. 

That is, first Manipulate wraps its result into DynamicModule, then...
...gives unique names to local variables (as it is a scoping construct).
Next, the body of Manipulate is evaluated in standard order.
The output cell is created by evaluating the result of the DynamicModule (or the Manipulate).
If there was any Initialization :> init inside Manipulate, it is now evaluated ""when the result is first displayed in a particular session"".
If there is any Deinitialization :> deinit inside Manipulate and the dynamic output cannot be displayed any more, deinit is evaluated.

Contraintuitively, Initialization is called almost ultimately which caused me some frustration over time.
To understand how to load a package with your dynamic content by Needs, see my answer here.
"
programming - Continuous evaluation of complex calculations,"
There have been several good examples of nice interactive visualizations in the answers so far.
Your question was a very general one, so I will mention the intended general solution: Monitor.
For example, this combines very nicely with NDSolve's StepMonitor along with a ProgressIndicator:
In[13]:= Monitor[
 NDSolve[{D[u[t, x], {t, 2}] == D[u[t, x], {x, 2}] + Sin[u[t, x]], 
   u[0, x] == E^-x^2, Derivative[1, 0][u][0, x] == 0, 
   u[t, -10] == u[t, 10]}, u, {t, 0, 100}, {x, -10, 10}, 
  StepMonitor :> (sol = u[t, x]; time = t)], 
 Column[{Plot[sol, {x, -10, 10}, PlotRange -> {0, 8}, 
    Filling -> Axis], ProgressIndicator[time, {0, 100}]}]
 ]

It looks like this while it is evaluating:

(This is a modified version of an example in the documentation for StepMonitor.)
Using Monitor[..., ProgressIndicator[...]] is a very useful idiom. I guess I use it several times per week. (With a bit of extra code you can monitor e.g. ParallelTable this way too: https://stackoverflow.com/questions/7352461/monitoring-progress-of-a-parallel-computation-in-mathematica/7376332#7376332.)
"
Difficulties in creating strict and robust equivalence between two symbols using the Notation package,"
You appear to be looking for the functionality of $PreRead:
$PreRead = # /. ""beta"" -> ""\[Beta]"" &;


"
list manipulation - Flatten command: matrix as second argument,"
One convenient way to think of Flatten with the second argument is that it performs something like Transpose for ragged (irregular) lists. Here is a simple example:
In[63]:=  Flatten[{{1,2,3},{4,5},{6,7},{8,9,10}},{{2},{1}}]
Out[63]= {{1,4,6,8},{2,5,7,9},{3,10}}

What happens is that elements which constituted level 1 in the original list are now constituents at level 2 in the result, and vice versa. This is exactly what Transpose does, but done for irregular lists. Note however, that some information about positions is lost here, so we can not directly inverse the operation:
In[65]:= Flatten[{{1,4,6,8},{2,5,7,9},{3,10}},{{2},{1}}]
Out[65]= {{1,2,3},{4,5,10},{6,7},{8,9}}

To have it reversed correctly, we'd have to do something like this:
In[67]:= Flatten/@Flatten[{{1,4,6,8},{2,5,7,9},{3,{},{},10}},{{2},{1}}]
Out[67]= {{1,2,3},{4,5},{6,7},{8,9,10}}

A more interesting example is when we have deeper nesting:
In[68]:= Flatten[{{{1,2,3},{4,5}},{{6,7},{8,9,10}}},{{2},{1},{3}}]
Out[68]= {{{1,2,3},{6,7}},{{4,5},{8,9,10}}}

Here again, we can see that Flatten effectively worked like (generalized) Transpose, interchanging pieces at the first 2 levels. The following will be harder to understand:
In[69]:=  Flatten[{{{1, 2, 3}, {4, 5}}, {{6, 7}, {8, 9,  10}}}, {{3}, {1}, {2}}]
Out[69]= {{{1, 4}, {6, 8}}, {{2, 5}, {7, 9}}, {{3}, {10}}}

The following image illustrates this generalized transpose:

We may do it in two consecutive steps:
In[72]:=  step1 = Flatten[{{{1,2,3},{4,5}},{{6,7},{8,9,10}}},{{1},{3},{2}}]
Out[72]= {{{1,4},{2,5},{3}},{{6,8},{7,9},{10}}}

In[73]:= step2 =  Flatten[step1,{{2},{1},{3}}]
Out[73]= {{{1,4},{6,8}},{{2,5},{7,9}},{{3},{10}}}

Since the permutation {3,1,2} can be obtained as {1,3,2} followed by {2,1,3}. Another way to see how it works is to use numbers which indicate the position in the list structure:
Flatten[{{{111, 112, 113}, {121, 122}}, {{211, 212}, {221, 222, 223}}}, {{3}, {1}, {2}}]
(*
==> {{{111, 121}, {211, 221}}, {{112, 122}, {212, 222}}, {{113}, {223}}}
*)

From this, one can see that in the outermost list (first level), the third index (corresponding the third level of the original list) grows, in each member list (second level) the first element grows per element (corresponding to the first level of the original list), and finally in the innermost (third level) lists, the second index grows, corresponding to the second level in the original list. Generally, if the k-th element of the list passed as second element is {n}, growing the k-th index in the resulting list structure corresponds to increasing the n-th index in the original structure.
Finally, one can combine several levels to effectively flatten the sub-levels, like so:
In[74]:=  Flatten[{{{1,2,3},{4,5}},{{6,7},{8,9,10}}},{{2},{1,3}}]
Out[74]= {{1,2,3,6,7},{4,5,8,9,10}}

"
output formatting - Can the Notation function support complex structures on its left hand side?,"
So (I guess that) the problem occurs because
Notation[LHS \[DoubleLongLeftRightArrow] RHS] converts the LHS into boxes,
where OverBar[x] is OverscriptBox[x,""_""].
It then interprets the underscore as a Blank (_), which it tries to match up with a pattern on the RHS.  
I'm sure that I've used the Notation package with OverBars before and have not had troubles with it. But then again, maybe not.
Anyway, you can forget about the Notation package for this since you can easily use the underlying box mechanism to implement the notation that you want:
MakeBoxes[afstarbar, form_] := InterpretationBox[
    OverscriptBox[SuperscriptBox[""af"", ""*""], ""_""], afstarbar]

"
persistence - Saving Mathematica kernel state?,"
While it is true that you can not save a full state of the kernel, in some cases it may be enough for your purposes to save all symbols' definitions in some context(s), such as Global` (or whatever other contexts are of interest to you). This can be done via DumpSave, like
DumpSave[""state.mx"", ""Global`""]

The .mx file generated by DumpSave will be platform-specific though. By using Get at some later point, you can reconstruct the values stored in symbols in those contexts you saved:
Get[""state.mx""]

As stated already by @ruebenko, this will not generally fully reconstruct the kernel state. But if you manage to correctly account for all symbols (defined by you) which affect your computations, and depending on the circumstances, this may be enough for many practical purposes.
"
plotting - Plot Option Precedence while combining Plots with Show[],"
First a little background:
All of Mathematica's plotting functions produce a Graphics expression (or Graphics3D, but let's talk about Graphics now).  The Graphics expression is simply a representation of what you see in the graphic.  You can look at it by converting the output cell to InputForm (Ctrl-Shift-I).  For example, Plot will produce Graphics with Lines in it.
Some of the options to plotting functions are passed on directly to Graphics an affect its appearance (how its contents get rendered).  An example is Axes.  Some others control what the plotting function will put into the graphics.  Examples are PlotStyle or PlotMarkers.  These are specific to (and different for) each plotting function.
How Show works:
It combines several Graphics expressions into one.  The returned Graphics expression will inherit its options from the first one passed to Show.  In Show you can override some Graphics options directly, but of course this will only override options for Graphics, and not the plotting functions that produced the graphics (as those have already finished running by the time Show sees their output).
So 
Show[ListPlot[... , Op1], Plot[... , Op2], Op3] 

is equivalent to 
Show[ListPlot[... , Op3, Op1], Plot[...]]

or to
Show[ListPlot[...], Plot[...], Op3, Op1]

but this is only valid for ListPlot options that are also Graphics options.  It is not valid for PlotMarkers.
Also note that if the same option is specified several times in the same Graphics, the first one takes precedence. (Thanks J. M.!)
"
"function construction - which is better, using Assert[] or manual checks on arguments and other computations?","
Like in other programming languages, such as C or Java, assertions are used to catch errors in the logic of your code. With discipline, you can also use exceptions for a similar purpose (see e.g. this discussion for an example).
Using patterns and returning a function unevaluated is useful in different types of situations. The linked above answer also discusses when which is more appropriate. Very roughly, there are 3 different situations:

You want to pre-emptively catch certain errors in your logic, since you know that certain things definitely can not normally happen. At the same time, these checks can not be easily reduced to input argument checks. And, finally, the error, if occurs, is purely in your logic, and otherwise things are within your control. Then, use assertions. I would not use assertions to filter out unwanted input - this is what pattern-checks in function definitions are for. Using asserts in their place would typically make code clumsier, more fragile and less readable.
Your function can not move further with its computations, since either wrong arguments were supplied or something beyond your control happened (file not found on disk say). Then, return $Failed or use exceptions (but be sure to use tagged exceptions and catch them in the outer - public- functions). 
The function does not know what to do with the input, but there is a chance that the input may evaluate to something meaningful at some later point.  Then, returning unevaluated may make more sense.

Generally, functions which do not return anything and whose results are some performed actions, tend to be candidates for 1. or 2., while functions returning expressions are more often candidates for 3. But these are just general guidelines, and one has to develop the intuition to know when to follow these rules and when to break them. 
"
Change syntax from other programs to mathematica syntax,"
There is support for TeX files built in to the Import function. For example:
NotebookPut[Import[""http://www.math.wisc.edu/computing/tex/sample.tex""]]

Will load the sample TeX file located at that URL into a Mathematica notebook. You can of course replace the URL with a path to a file on your computer.
The TeX file is imported with ""structure"" intact (I suppose we'd expect this from Mathematica), so you can play around with how exactly it is formatted.
As for other computer algebra systems, it would surprise me if there was an easy way to translate syntax in general--but you can use StringReplace for simple syntax modifications, as in this example:
ToExpression[StringReplace[""Sin(x)+Cos(y)"", {""("" -> ""["", "")"" -> ""]""}]]

"
programming - Sum over n variables,"
You can write a few helper functions to help you. The following can probably be streamlined...
vars[s_String, n_Integer?Positive] := Table[Symbol[s <> ToString[i]], {i, 1, n}]
vars[sym_Symbol, num_] := vars[SymbolName[sym], num]

nestedRange[vars_List, min_, max_] /; min <= max := 
 Transpose@{vars, ConstantArray[min, Length[vars]], Append[Rest@vars, max]}

nestedSum[f_, vars:{__Symbol}, min_, max_] /; min <= max := 
 With[{r = Sequence @@ Reverse@nestedRange[vars, min, max]}, Sum[f, r]]
nestedSum[f_, {var:(_String|_Symbol), num_Integer?Positive}, 
 min_, max_] /; min <= max := nestedSum[f, vars[var, num], min, max]

Then, for example 
nestedSum[f[a, b, c], {a, b, c}, 0, Infinity] // TraditionalForm

produces 
A larger sum is
In[]:= nestedSum[Total@vars[i, 4], {i, 4}, 1, 20] // Timing
Out[]= {0.016001, 371910}

which can be compared with evaluating the same thing using Boole
In[]:= v = vars[i, 4];
       With[{r = Sequence@@Table[{n, 1, 20}, {n, v}]}, 
            Sum[Boole[LessEqual@@v] Total@v, r]] // Timing
Out[]= {0.056003, 371910}

"
graphics - ListPlot: Plotting large data fast,"
Many posters already suggested good answers. I am just adding some explanation behind this behavior. Also, I have to warn that this is my understanding, and I couldn't find any reference. So, please take it with grain of salt. I am more than happy to stand corrected, if found wrong.
Problem
It is a rendering issue. And it is in fact Windows' GDI+ related issue (and probably Apple too). I tried my best, but couldn't find related Microsoft KB (which I know there is...).
Anyway, this is what is roughly happening. If you have lines defined by Line[{pt1, pt2, ...}], system graphics API treat it as a single path (with multiple segment). Now, in a single path case, the API, especially the rasterizer is trying to see whether each pixel is intersected by multiple segments. The reason? Because of the opacity. Compare these two images (very exaggerated, but the idea is there).
pts = {{0, 0}, {1, 1}, {1, 0}, {0, 1}};

{Graphics[{Thickness[.1], Opacity[.3], Line[{{0, 0}, {1, 1}, {1, 0}, {0, 1}}]}],
 Graphics[{Thickness[.1], Opacity[.3], Line[Partition[pts, 2, 1]]}]}


If you don't treat the self-intersection, what you end up getting is something like the second result (transparency accumulated in self-intersection points). Which is very bad for many cases. Now it shouldn't be a problem when opacity is 1, but unfortunately if you use anti-aliasing, then you are in effect introducing a different opacity, this should be dealt. This is no problem with multi-path case (like the second image), since in that case, you can just accumulate pixel values at each pixel.
To prove it, compare the following point configuration and speed difference:

The same number of points, but the rendering of the second one is much faster.
Now, back to our problem. When we are using ListLinePlot without any options (or just PlotRange->All), the process is very close to what Leonid's myListPlot is doing. Which means that it will generate a long chain of Line[{pt1, pt2, ...}] and the self-intersection routine will kick in. If you see the original result closely, you will see that in fact, the resulting graphics has a lot of self-intersection in pixel-res space (it does computation on pixel-level).
Solutions
In fact, Mr.Thomas already got his own answers.

Turing off anti-aliasing (by Style[..., AntiAliasing->False]). This way, the rasterizer spend a lot less time processing intersections, thus much much faster.
Sub-sampling. There are multiple ways, MaxPlotPoints is one, Thomas' code is another, and much more.
Cheating by making multiple paths:

Well, this solution isn't going to give you super boost. Just in case you absolutely need anti-aliasing, and also need to use all the points. Look at a part of my first example:
Line[Partition[pts, 2, 1]]

You will see that we are essentially turning Line[{pt1, pt2, pt3, pt4, ...}] into Line[{{{pt1, pt2}}, {{pt2, pt3}}, {{pt3, pt4}}, ...}]. As long as the opacity remains 1, the result should be about the same (except JoinedForm, but in our case it is no concern). The benefit of the second form is that now it is not considered to be a single path. So, the rasterizer will think that it is multiple-path, and no self-intersection treatment.
I modified Lenoid's myListPlot a bit so that it does this task.
ClearAll[myListPlot2];
Options[myListPlot2] = {AspectRatio -> GoldenRatio^(-1), Axes -> True,
    AxesOrigin -> {0, 0}, PlotRange -> {All, All}, 
   PlotRangeClipping -> True, 
   PlotRangePadding -> {Automatic, Automatic}};

myListPlot2[pts_List, opts : OptionsPattern[]] :=
 Module[{pts1, pts2},
  pts1 = Developer`ToPackedArray@
    Transpose[{N@Range[Length[pts]], pts}];
  pts2 = Partition[pts1, 2, 1];
  Graphics[{{{}, {}, {Hue[0.67, 0.6, 0.6], Line[pts2]}}}, 
   FilterRules[{opts, Options[myListPlot]}, Options[Graphics]]]]

Now, time to prove the theory. With the same data set rv, here is the timing comparison between myListPlot and myListPlot2 (myListPlot is faster than ListLinePlot so it is enough).

Well, about twice as fast. Frankly, it is not that practical, just theoretical interest :)
Addendum
Szabolcs found some bundling going on at 500 (Not sure it is Windows specific or number is exactly that, but bundling is true), which makes me experimenting with different segmenting--instead of just 2, partitioning it at 3, 4, ... etc. And I got all different speed result (getting faster, then slower again). If you use Partition it drops the tail (and I personally am still learning all complex syntax, so...), but it shouldn't make that much of difference, in my opinion.
So, the problem is probably not just affected by the self-intersection, but also the bundling. It gets more interesting / complex :)
"
options - How to find out which method Mathematica selected?,"
I think you can actually see (most of) what Mathematica is doing by using Trace[..., TraceInternal -> True].
For example, 
Select[Flatten[
  Trace[NDSolve[y'[x] == x && y[0] == 0, y, {x, 0, 6}], 
   TraceInternal -> True]], ! FreeQ[#, Method | NDSolve`MethodData] &]

shows the DE was evaluated using NDSolve`LSODA and Newton's method. (I think)
And
Select[Flatten[
  Trace[NDSolve[{Derivative[1][x][t]^2 + x[t]^2 == 1, x[0] == 1/2}, 
    x, {t, 0, 10 Pi}, SolveDelayed -> True], 
   TraceInternal -> True]], ! FreeQ[#, Method | NDSolve`MethodData] &]

used NDSolve`IDA.

As an aside, here's something I just learnt from Trott's Mathematica guidebook for numerics, to see all of the methods and suboptions for NDSolve 
{#, First /@ #2} & @@@ 
 Select[{#, Options[#]} & /@ (ToExpression /@ 
   DeleteCases[Names[""NDSolve`*""],(* PDE method only *) ""NDSolve`MethodOfLines""]), 
   (Last[#] =!= {}) &]

"
"interactive - Get a ""step-by-step"" evaluation in Mathematica","
For differentiation at least, old versions of Mathematica had a demonstration function called WalkD[] that holds your hand and shows what is done at each stage up until the final answer.
In general, however...

You should realize at the outset that while knowing about the
  internals of Mathematica may be of intellectual interest, it is
  usually much less important in practice than you might at first
  suppose.
Indeed, one of the main points of Mathematica is that it provides an
  environment where you can perform mathematical and other operations
  without having to think in detail about how these operations are
  actually carried out inside your computer. 
...
Particularly in more advanced applications of Mathematica, it may
  sometimes seem worthwhile to try to analyze internal algorithms in
  order to predict which way of doing a given computation will be the
  most efficient. And there are indeed occasionally major improvements
  that you will be able to make in specific computations as a result of
  such analyses.
But most often the analyses will not be worthwhile. For the internals
  of Mathematica are quite complicated, and even given a basic
  description of the algorithm used for a particular purpose, it is
  usually extremely difficult to reach a reliable conclusion about how
  the detailed implementation of this algorithm will actually behave in
  particular circumstances.
A typical problem is that Mathematica has many internal
  optimizations, and the efficiency of a computation can be greatly
  affected by whether the details of the computation do or do not allow
  a given internal optimization to be used.

Put another way: how Mathematica does things doesn't necessarily correspond to ""manual"" methods.

Here's my modest attempt to (somewhat) modernize WalkD[]:
Format[d[f_, x_], TraditionalForm] := DisplayForm[RowBox[{FractionBox[""\[DifferentialD]"",
                                                  RowBox[{""\[DifferentialD]"", x}]], f}]];

SpecificRules = {d[(f_)[u___, x_, v___], x_] /;
                 FreeQ[{u}, x] && FreeQ[{v}, x] :> D[f[u, x, v], x],
                 d[(a_)^(x_), x_] :> D[a^x, x] /; FreeQ[a, x]};

ConstantRule = d[c_, x_] :> 0 /; FreeQ[c, x];

LinearityRule = {d[f_ + g_, x_] :> d[f, x] + d[g, x],
                 d[c_ f_, x_] :> c d[f, x] /; FreeQ[c, x]};

PowerRule = {d[x_, x_] :> 1, d[(x_)^(a_), x_] :> a*x^(a - 1) /; FreeQ[a, x]};

ProductRule = d[f_ g_, x_] :> d[f, x] g + f d[g, x];

QuotientRule = d[(f_)/(g_), x_] :> (d[f, x]*g - f*d[g, x])/g^2;

InverseFunctionRule = d[InverseFunction[f_][x_], x_] :>
                      1/f'[InverseFunction[f][x]];

ChainRule = {d[(f_)^(a_), x_] :> a*f^(a - 1)*d[f, x] /; FreeQ[a, x],
             d[(a_)^(f_), x_] :> Log[a]*a^f*d[f, x] /; FreeQ[a, x],
             d[(f_)[g__], x_] /; ! FreeQ[{g}, x] :>
             (Derivative[##][f][g] & @@@ IdentityMatrix[Length[{g}]]).(d[#, x] & /@ {g}),
             d[(f_)^(g_), x_] :> f^g*d[g*Log[f], x]};

$RuleNames = {""Specific Rules"", ""Constant Rule"", ""Linearity Rule"", ""Power Rule"",
              ""Product Rule"", ""Quotient Rule"", ""Inverse Function Rule"", ""Chain Rule""};

displayStart[expr_] := CellPrint[
  Cell[BoxData[MakeBoxes[HoldForm[expr], TraditionalForm]], ""Output"", 
   Evaluatable -> False, CellMargins -> {{Inherited, Inherited}, {10, 10}}, 
   CellFrame -> False, CellEditDuplicate -> False]]

displayDerivative[expr_, k_Integer] := CellPrint[
  Cell[BoxData[TooltipBox[RowBox[{InterpretationBox[""="", Sequence[]], ""  "", 
       MakeBoxes[HoldForm[expr], TraditionalForm]}], $RuleNames[[k]], 
     LabelStyle -> ""TextStyling""]], ""Output"", Evaluatable -> False, 
   CellMargins -> {{Inherited, Inherited}, {10, 10}}, 
   CellFrame -> False, CellEditDuplicate -> False]]

WalkD[f_, x_] := Module[{derivative, oldderivative, k}, 
        derivative = d[f, x]; displayStart[derivative];
        While[! FreeQ[derivative, d],
            oldderivative = derivative; k = 0;
            While[oldderivative == derivative,
                      k++;
                      derivative = derivative /. 
                              ToExpression[StringReplace[$RuleNames[[k]], "" "" -> """"]]];
            displayDerivative[derivative, k]];
        D[f, x]]

I've tried to make the formatting of the derivative look a bit more traditional, as well as having the differentiation rule used be a tooltip instead of an explicitly generated cell (thus combining the best features of WalkD[] and RunD[]); you'll only see the name of the differentiation rule used if you mouseover the corresponding expression.

"
implementation details - How to check for Mathematica’s definition of XY?,"
Since there are two parts to your question. I will address the one directly dealing with Binomial.
For the purposes of discrete mathematics, the binomial is defined through its generating function:
$$
   (1+x)^{\alpha} = \sum_{m=0}^\infty \binom{\alpha}{m} x^m
$$
It makes evaluations of sums using generating functions much easier if the sum were to run over all integers. So it is natural, in this context, to set $\binom{\alpha}{m} = 0$, $\forall m \in \mathbb{Z}_{< 0}$. 
And this convention is indeed adopted in two books you link to, at the expense of breaking the symmetry $\binom{\alpha}{m} = \binom{\alpha}{\alpha-m}$, as explicitly emphasized in ""Concrete Mathematics"".
In Mathematica, Binomial[z,w] is a defined over $\mathbb{C} \times \mathbb{C}$, and the aforementioned symmetry holds almost everywhere, justifying automatic evaluation
In[62]:= Binomial[n, n - 3]

Out[62]= 1/6 (-2 + n) (-1 + n) n

But the symbolic polynomial above does not give zero for $n \in \mathbb{Z}_{\leqslant -1}$, so we have an inconsistency.
In order to fix all the sums for $c^r_n$ one may use Boole (also known as Iverson bracket). In fact it seems that this particular sum requires Boole even in version 7:

"
front end - How to force neat linewrapping in Print?,"
The option ImageSize with the value Scaled should give better results, and it will adapt to the size of the notebook window. You will still need to define the value of Scaled to allow for likely widths of the label in the first column.
Print[""test line 1...............: "", {1, 2, 3}, ""\n"", 
  ""test line 2...............: "", 
  Pane[Table[""testestestestestestestestest"", {10}], 
   ImageSize -> Scaled[0.5]], ""\n"", 
  ""test line 3...............: "", {1, 2, 3}];


I agree that Grid is a better option here. But if you stick with Print, for example because you want to keep this output as a side effect of evaluation, you might also want to consider wrapping that long table output in TableForm.
"
plotting - Using ListPointPlot3D to simulate 2D plots moving in time,"
Thanks to all for the answers. After looking more into this, I think I found a method that works for me. I thought I describe it here. 
The idea is to use ListPlot3D with DataRange->All. But to use this, I needed to modify my data structure a little to make each entry in the list as {x,time,u(x,t)}. Not a big problem for me to do that. The following diagram shows the data structure used

Here is an animation of some made up function in time, showing the 3D view of the solution in time with the normal 2D view on the side. Below that I post the example code which generated this:

Code: (just for illustration of the method)
Make up the data:
f1 = .05;
f2 = .2;
simulationTime = 20;
u = Table[
       Table[{x,t,Exp[-.01 t] Cos[f1 t x] Sin[ f2 t x]},{x,-2 Pi,2 Pi,.2}], 
       {t, 0, simulationTime, .1}
    ];

Do the animation:
Grid[{
  {
   Animate[ListPlot3D[u[[1 ;; i]],
     AxesLabel -> {""x"", ""time"", ""u(x,t)""},
     PlotLabel -> Row[{""u(x,t) at time "", u[[i]][[1, 2]], "" sec""}],
     MaxPlotPoints -> 10,
     PlotRange -> {{-2 Pi, 2 Pi}, {0, simulationTime}, {-1, 1}},
     DataRange -> All,
     PerformanceGoal -> ""Quality"",
     Mesh -> Automatic
     ], {i, 2, Length[u], 1}
    ]
   ,
   Animate[ListPlot[u[[i, All, {1, 3}]],
     AxesLabel -> {""x"", Row[{""u(x) at time "", u[[i]][[1, 2]], "" sec""}]},
     PlotRange -> {{-2 Pi, 2 Pi}, {-1, 1}},
     Joined -> True,
     Mesh -> All
     ], {i, 2, Length[u], 1}
    ]
   }
  }]

Note:
Just an implementation note. I have been testing the above method in my main demo, and so far, it is working well. But since I need to save in memory each frame to get this method to work (each time I plot, I plot all the frames from t0 to current time, so I need to keep them all in memory), what I did is the following:

Pre-allocate using Table the slots for as many frames I need.
Do not generate a frame for each time step, as it will consume too much memory, and the demo will become too slow very quickly. So what I do is make one frame each $n$ time steps, where $n$ is something I am trying to decide a good value for, as it depends on the length of the simulation and the size of the grid and such. I try to make it show not less than 100 or so frames for the whole simulation time each time. This way, it runs fast, and the memory usage for this is kept low. 
In MATLAB, I did this differently, since MATLAB has a command called holdon. 
I wish Mathematica had such a command; it would make life so much easier. This command works like this: One can make a plot to the graphic window, and then say holdon which means the next plot to the same window will not erase what is on the window but add to it whatever is being plotted. So, when I did this same simulation in MATLAB, I did not have to keep track myself of all the frames, but only the current one. This made the simulation much simpler, as me, the user did not need to manage and keep lots of frames in my own buffer, all the time and then re-plot them all each time.

So in summary, this is how the simulation works in Mathematica:
allocate array for simulation frames
LOOP
    time = time + delt
    generate solution 
    IF need to generate new plot  --- do this every N steps to save memory
      add current frame to buffer    
      plot frames 1..current    
    END IF
END LOOP

In MATLAB, I would do
LOOP
    time = time + delt
    generate solution    
    Plot current frame
    holdon
END LOOP

You can see it makes the simulation simpler as everything is pushed to the graphics buffer instead of user having to manage it.
I hope future version of Mathematica will add such a feature to its graphics, as I like the way graphics look in Mathematica more. If there is a trick to do now in Mathematica, I'd love to know about it.

Update:
I've implemented the above method for showing the solution of few simple PDE's in a demo I am writing. I think it helps in the visualization of the solution, but the problem is that it takes a lot of memory as I have to save many frames, but still, it seems to work OK.
Here is one example, an animation of the solution of the convection-diffusion 1D PDE (diffusion with drift). In the 2D plot, the red curve is the initial condition, and the blue is the current concentration.  Then the 3D view of the same solution.
 
I think Mathematica is really nice for doing simulations with (It just needs faster rendering. I think that is the slowest part. Hard to get very high FPS from it, but may be I am still not doing something the right way somewhere.
"
import - Importing videos in Mathematica,"
64-bit Windows only

Note for Mathematica 11.3: There is a potential conflict between MathMF and the built-in MediaTools package. See here for details and here for an example of how to use MediaTools in place of MathMF.

 

Note for Mathematica version 10: The Wolfram Library has been updated in version 10 and you will need to recompile the MathMF DLL. This is most easily accomplished by evaluating ""MathMF""//FindLibrary//DeleteFile prior to loading the package.

Link to package on GitHub
I have written a package called MathMF which uses a LibraryLink DLL to do frame-by-frame video import and export with Windows Media Foundation. It should be able to read a reasonable variety of movie files, including AVI, WMV and MP4. Exporting is currently limited to WMV and MP4 formats (AVI encoding is not natively supported by Media Foundation)
Here is the sort of code you can write with it. The code first opens a video file for reading, and creates a new video file for writing to. It then runs a loop in which each frame is sequentially read from the input stream, processed in Mathematica and then written to the output stream. So Mathematica is effectively being used as a video filter.
{duration, framerate, width, height} =
 MFInitSourceReader[""C:\\Users\\Simon\\Desktop\\test1.wmv""];

MFInitSinkWriter[""C:\\Users\\Simon\\Desktop\\filtered.wmv"", 
 width, height, ""FrameRate"" -> framerate]

While[
  (image = MFGrabFrame[""RealImage""]) =!= EndOfFile,
  MFSendFrame @ GradientFilter[image, 2]
  ] ~Monitor~ image

MFFinaliseSink[]

The package can be downloaded from the GitHub link at the top of this post, it is too large to include in full here.
The package includes the library source code, and on first use will attempt to compile the library locally. I believe the compilation should work if you have Visual Studio 2010 or later installed, and probably won't work if you use a different compiler. There is a pre-built DLL available if the compilation fails (see the readme on GitHub for more details)
I hope some people find this useful, it has been hovering in my mind as something to try to do for quite some time, hindered mainly by my total lack of experience with C++ and COM programming.
"
How to find out the (current) free memory on the system?,"
You might be able to use JLink along with some undocumented behaviour of the Java class java.lang.management.ManagementFactory to get the information you seek:
Needs[""JLink`""]
InstallJava[];
LoadJavaClass[""java.lang.management.ManagementFactory""];
JavaBlock[
  {#, java`lang`management`ManagementFactory`getOperatingSystemMXBean[]@#[]} & /@
  { getName
  , getArch
  , getVersion
  , getCommittedVirtualMemorySize
  , getFreePhysicalMemorySize
  , getFreeSwapSpaceSize
  , getTotalPhysicalMemorySize
  , getTotalSwapSpaceSize
  , getProcessCpuTime
  , getAvailableProcessors
  , getSystemLoadAverage
  } // Grid
]

This works on Windows 7 (Mathematica 8, 64-bit):
Out[368]= getName                        Windows Vista
          getArch                        amd64
          getVersion                     6.1
          getCommittedVirtualMemorySize  102449152
          getFreePhysicalMemorySize      5997510656
          getFreeSwapSpaceSize           14498115584
          getTotalPhysicalMemorySize     8587284480
          getTotalSwapSpaceSize          17172676608
          getProcessCpuTime              6068438900
          getAvailableProcessors         4
          getSystemLoadAverage           -1.

I don't have Mac or Linux boxes to hand at the moment to test whether it works there as well.
"
front end - What are the most common (usual) ways to make palettes with non-trivial functionality?,"
All palette state (i.e., variables which affect the palette and should be remembered between sessions) should be vectored through the palette's TaggingRules option, and its initialization should be done in the palette's NotebookDynamicExpression option.  That, plus context isolation of any kernel functions you need to define should solve all of the points you raise, excepting the documentation issue.
An example palette which demonstrates these principles:
CreatePalette[
 Column[{Button[""Print opener state"", 
    MyPalette`Private`DoSomething[
     ""The opener is "" <> 
      If[CurrentValue[EvaluationNotebook[], {TaggingRules, ""opener""}],
        ""open"", ""closed""]]],
   OpenerView[{""Group of buttons"", Column[{Button[1], Button[2]}]}, 
    Dynamic[CurrentValue[
      EvaluationNotebook[], {TaggingRules, ""opener""}, False]]]}],
 NotebookDynamicExpression :> 
  Refresh[MyPalette`Private`DoSomething[MyPalette`Private`x_] := 
    Print[MyPalette`Private`x], None]]


Let's hit the items raised in this code one by one...

The palette uses a kernel-defined function which is in NotebookDynamicExpression. The code is wrapped in Refresh[_,None] to ensure that it evaluates once only when the notebook is opened. The code is context isolated by hand. Note that Begin and End won't work here, although they would work inside of a package, or if you wrapped the code in ToExpression (e.g., Begin[""foo`""];ToExpression[""code""];End[]).
A palette-wide state variable is stored in the palette's TaggingRules, which can be accessed by using CurrentValue[EvaluationNotebook[],{TaggingRules,""opener""}]. Because ""opener"" is a string, no symbols are introduced into any context.
State variables will typically need to be initialized. I could do that in various standard ways, but I used the undocumented third argument to CurrentValue which sets it to False if it doesn't already have a value.
Once the palette is installed, the TaggingRules setting will persist between instances of the palette, even if you quit Mathematica. Mathematica automatically serializes an installed palette's TaggingRules settings when you close it by storing the value into the global option PalettesMenuSettings.
If you have multiple versions of the palette open, they'll each operate using independent state variables because the state variable is attached to the palette notebook. If multiple versions of the palette are installed under different names then the PalettesMenuSettings trick will store the TaggingRules separately.

"
How do you efficiently return all of a List but one element?,"
You can use Most[list] to do this if you want to drop last element, Rest[list] to drop the first element, and Delete[list, n] to drop the $n^\mathrm{th}$ element.
I verified that none of these unpack packed arrays, so performance should be good.  Drop and Take don't unpack either, so the performance of those should be similar too, at least for packed arrays.
"
How to find the position of elements in a list satisfying criteria,"
Position[{2, 4, 6, 8, 10}, _?(# > 7 &)] does the job. Apply Flatten[] if need be.

As noted by Dan in a comment alluding to Brett's answer, using the level-specification argument of Position[] might sometimes be needed, if the numbers are not Reals, Rationals or Integers.
"
notebooks - How to avoid spaces between numbers when displaying TagBox(es),"
Why not use ToBoxes (or MakeBoxes) to construct boxes, instead of doing it yourself?
DisplayForm[
 ToBoxes[Row[List[0, 1, Superscript[2, 3], Superscript[1, 2], a]]]]


"
graphics - Transparent textures don't show,"
Go into the option inspector, and try the different settings for Graphics Options > RenderingOptions > ""Graphics3DRenderingEngine and see if that has any effect.
Edit This option can be set on a per-graphic basis, say by using Style:
AbsoluteTiming[
   Rasterize[
    Style[Graphics3D[{Opacity[0.1], 
       Sphere[{0, 0, 0}, #] & /@ Range[20]}, ImageSize -> 200], 
     RenderingOptions -> {""Graphics3DRenderingEngine"" -> #}]]] & /@
{""BSPTree"", ""HardwareDepthBuffer""}


"
list manipulation - What is the most efficient way to add rows and columns to a matrix?,"
ArrayFlatten is much faster than combination of Join and Transpose:
m = RandomVariate[NormalDistribution[], {1000, 1000}];
v = RandomVariate[NormalDistribution[], 1000];

Check that ArrayFlatten gives the same output:
(* In[54]:=*) ArrayFlatten[{{Transpose[{v}], m}}] == 
 Transpose[Join[{v}, Transpose[m]]]

(* Out[54]= True *)

(* In[57]:= *) ArrayFlatten[{{Transpose[{v}], m}}] == 
 MapThread[Prepend, {m, v}]

(* Out[57]= True *)

See the timing:
(* In[55]:= *) Do[
  ArrayFlatten[{{Transpose[{v}], m}}], {10^3}] // AbsoluteTiming

(* Out[55]= {4.330433, Null} *)

(* In[58]:= *) Do[MapThread[Prepend, {m, v}], {10^3}] // AbsoluteTiming

(* Out[58]= {11.766177, Null} *)

(* In[56]:= *) Do[
  Transpose[Join[{v}, Transpose[m]]], {10^3}] // AbsoluteTiming

(* Out[56]= {16.700670, Null} *)

"
performance tuning - Is there an NDSolve`ProcessEquations analog for NIntegrate?,"
NIntegrate performs a certain symbolic processing of the integrand to detect discontinuities, singularities, to determine the method to choose and so on. 
If you know the integrand pretty well, the way to reduce the overhead is to set the method explicitly, set its SymbolicProcessing suboption to 0 (to allow to time spent on the preprocessing), and to add points of discontinuities to the path explicitly.
This can make a significant difference in timing:
In[66]:= Do[
  NIntegrate[Piecewise[{{x^2, x <= 1}}, 1/1 + x], {x, 0, 1, 2}, 
   Method -> {""GaussKronrodRule"", 
     ""SymbolicProcessing"" -> 0}], {10^3}] // AbsoluteTiming

Out[66]= {1.542154, Null}

In[67]:= Do[
  NIntegrate[
   Piecewise[{{x^2, x <= 1}}, 1/1 + x], {x, 0, 
    2}], {10^3}] // AbsoluteTiming

Out[67]= {15.063506, Null}

"
evaluation - How can I test properties of a symbol from the string name without the symbol completely evaluating,"
I usually use 
ToExpression[""symbol"",  InputForm, ValueQ]

ToExpression will wrap the result in its 3rd argument before evaluating it.

Generally, all functions that extract parts (Extract, Level, etc.) have such an argument.  This is useful when extracting parts of held expressions.  ToExpression acts on strings or boxes, but both the problem with evaluation control and the solution is the same.  I thought this was worth mentioning here.
"
graphics - Antialiasing in 3D - Mathmatica Stack Exchang,"
This needs specific support from your graphics card.  My own graphics card is very old, and does not support it, so the slider does nothing on my machine.

But the good news is that there are workarounds, and I even made an antialiasing palette (code at the end of the post -- evaluate it, pop out the palette, and if you prefer, save it using Palettes -> Install Palette...).
This is the core antialiasing function I use:
antialias[g_, n_: 3] := 
  ImageResize[Rasterize[g, ""Image"", ImageResolution -> n 72], Scaled[1/n]]

It simply renders a large image, and it downscales it.  The results can be better than with a better graphics card's built-in antialiasing, so it's worth a look even if you have a good graphics card.
Problems with this method:

Fonts can be blurrier than what you'd like
With a high scaling factor, it may expose bugs in your graphics driver, and show some unusual results (I had problems with opacity in more complex graphics)
Tick marks don't scale properly (I think this is a bug), so they are barely visible on the antialiased version.


This is the palette code.  Usage: select a 3D graphic and press the button.  It'll insert an antialiased image below.
Begin[""AA`""];

PaletteNotebook[DynamicModule[
  {n = 3},
  Column[{
    SetterBar[
     Dynamic[n], {2 -> ""2\[Times]"", 3 -> ""3\[Times]"", 
      4 -> ""4\[Times]"", 6 -> ""6\[Times]""}, Appearance -> ""Palette""],
    Tooltip[
     Button[""Antialias"", antialiasSelection[SelectedNotebook[], n], 
      Appearance -> ""Palette""], 
     ""Antialias selected graphics using the chosen scaling factor.\nA single 2D or 3D graphics box must be selected.""]
    }],
  Initialization :> (
    antialias[g_, n_Integer: 3] := 
     ImageResize[Rasterize[g, ""Image"", ImageResolution -> n 72], 
      Scaled[1/n]];

    antialiasSelection[doc_, n_] := Module[{selection, result},
      selection = NotebookRead[doc];
      If[MatchQ[selection, _GraphicsBox | _Graphics3DBox],
       result = 
        ToBoxes@Image[antialias[ToExpression[selection], n], 
          Magnification -> 1];
       SelectionMove[doc, After, Cell];
       NotebookWrite[doc, result],

       Beep[]
       ]
      ]
    )
  ],
 TooltipBoxOptions -> {TooltipDelay -> Automatic}, 
 WindowTitle -> ""Antialiasing""
 ]

End[];


Demonstration:
 
"
Image levels: how to alter 'exposure' of dark and light areas?,"
Two things. 
First, a minor point: if you rewrite your compiled function as
tweakC = Compile[{{pixel, _Real, 1}},
  Module[{m},
   m = Mean[pixel];
   Which[
    m <= 0.3, pixel*1.5,
    m >= 0.85, pixel*0.8,
    True, pixel]
   ]
  ]

then the ImageApply bit is 20 times faster (due to not having to use external calls). It's also a bit cleaner.
If you have v8 and a C compiler, you can speed it up by another factor of 2 by using CompilationTarget->""C"".
Second, and more important, is that your tone curve looks like this:

the jumps at .35 and .8 lead to harsh transitions. So I thought I'd use a smoother curve which you can interactively manipulate (horrible code, but seems to do the job):
image1 = Image[
   ReliefPlot[
    Table[i - 3 Sin[i^2 + j^2], {i, -4, 4, .03}, {j, -4, 4, .03}]]];
DynamicModule[
 {pts = {{0, 0}, {.25, .25}, {.5, .5}, {.75, .75}, {1, 1}}}, Dynamic[];
 LocatorPane[
  Dynamic[pts],
  Dynamic[
   curve = InterpolatingPolynomial[pts, x];
   image2 = ImageAdjust[
     ImageApply[Function[{x}, Evaluate@curve], image1, 
      Interleaving -> False]];
   Dynamic[
    Plot[curve, {x, 0, 3}, PlotRange -> {{0, 1}, {0, 1}}]]
   ],
   LocatorAutoCreate -> True
  ]
 ]
GraphicsGrid[
 {{image1, Dynamic[image2]}}
 ]

it looks like this:

The idea is, you define a curve by moving the locators, and the image on the right bottom reflects that transformation. The whole thing is interactive. You may add more locators by alt-clicking on windows and linux, cmd-clicking on OS X.
Note that I have little understanding of Dynamic etc, so this is probably badly written in terms of dynamic interactivity.
"
graphics - Why is the Locator snapping back to the original coordinates? How can I prevent this?,"
It seems using an EventHandler to simulate a locator will be smooth on my computer ( press Shift instead of press mouse button to active the locator ):
p = {3, 3};
EventHandler[
 EventHandler[
  Graphics[Circle[{5, 5}, 5], Epilog -> Locator[Dynamic[p]], 
   Axes -> True, GridLines -> {{3}, {3}}],
  ""MouseMoved"" :> Null,
  PassEventsUp :> CurrentValue[""ShiftKey""]],
 ""MouseMoved"" :> (p = MousePosition[""Graphics""])
 ]
Dynamic[p]

Update:
I think it's the AlignmentGuidesEnabled feature which causes the snapping.
Here are another two examples which display the problem:

Putting the Locator in the ""main part"" of Graphics instead of in Epilog:
p = {3, 3};
Graphics[{Circle[{5, 5}, 5], Locator[Dynamic[p]]}, Axes -> True, 
 GridLines -> {{3}, {3}}]

On my computer, the snapping occurs near the borders of the Graphics but not near {3, 3} anymore.
Different Locator actions in one Graphics:
DynamicModule[{v1 = {2, 0}, v2 = {-1, 1}},
 Dynamic@Graphics[{
    Line[{{0, 0}, v1}],
    Locator[Dynamic[v1]],
    Locator[Dynamic[v2]]
    }, PlotRange -> 3, Frame -> True]]

On my computer (Windows 7 x64, Mathematica 8.0.4), the Locator v1 which linked to the Line moves smooth, but the Locator v2 remains snapping.

So it looks like the behavior of AlignmentGuidesEnabled. Use Ctrl+D open the ""Drawing Tools"" palette, there is a button at the bottom-left, toggle the AlignmentGuidesEnabled option off, the snapping will gone.
"
front end - How to work with characters from CJK Unified Ideographs Extension B correctly?,"
Reposting John Fultz’s comment above as a “community wiki” answer for everyone to improve:

Mathematica simply has no support for non-plane-0 characters. That it
  appears to temporarily work should not fool you into thinking that M--
  knows anything about such values. Those who saw the R&D keynote at the
  2011 Tech Conference may remember my relating the story of the pain we
  have experienced from the fact that we were extremely early adopters
  of Unicode, well before it was baked into OSes and the concept of
  Unicode planes had been fully developed. It affects every part of the
  system, and will be difficult and expensive to fix when we finally do
  fix it.

"
performance tuning - Adaptive sampling for slow to compute functions in 2D,"
Update: I described an alternative approach based on built in plotting functions in this answer.  That approach is not very practical here though because I need to be able to handle points at arbitrary positions while built in functions work with a rectangle-based mesh.  I am still looking for improvements.

I came up with this very naive approach and implementation (I know that the implementation is not optimal at all):
First let's define a test function (same one as in the question):
fun[{x_, y_}] := 1/(1 + Exp[10 (Norm[{x, y}] - 3)])

These functions will subdivide lines in the Delaunay triangulation of the points if 1. the points are further apart than a threshold (i.e. the resolution is controlled) and 2. the function values in the two points also differ by more than another threshold.
<< ComputationalGeometry`

makeLines[tri_] := Union[Sort /@ Flatten[Thread /@ tri, 1]]

subdivision[points_, values_, valueThreshold_, distanceThreshold_] :=
 Module[
  {tri, lines, linesToDivide},
  tri = DelaunayTriangulation[points];
  lines = makeLines[tri];
  linesToDivide = 
   Pick[lines, (Abs[values[[#1]] - values[[#2]]] > valueThreshold && 
        Norm[points[[#1]] - points[[#2]]] > distanceThreshold ) & @@@ lines];
  Mean /@ (linesToDivide /. n_Integer :> points[[n]])
  ]

Let's define an initial point grid to compute the function in:
points = Tuples[Range[0, 5, 1], 2];

We can iterate this function to add more and more points and recursively subdivide the grid (evaluate the following commands together repreatedly):
values = fun /@ N[points];
newpoints = subdivision[points, values, 0.1, 0.1];

ListDensityPlot[Flatten /@ Thread[{points, values}], 
 InterpolationOrder -> 0, Mesh -> All, ColorFunction -> ""MintColors"", 
 Epilog -> {PointSize[Large], Point[points], Red, Point[newpoints]}]

points = Join[points, newpoints];





The result after several iterations:
values = fun /@ N[points];
ListDensityPlot[Flatten /@ Thread[{points, values}], 
 InterpolationOrder -> 0, Mesh -> All, ColorFunction -> ""MintColors""]



Open question:  My aim is to minimize the number of points I need to compute while getting a precise approximation.  This is probably not the best subdivision method for it.  What are some easy-to-implement better methods?
I think ideally the decision for refining the grid should be made based on some sort of curvature.  Take for example the following function:
ContourPlot[Erf[1/(1 + 20 x^2) - y], {x, -3, 3}, {y, -3, 3}]


Using a valueThreshold of 0.3 and distanceThreshold of 0.1, and a starting grid with a spacing of 0.5 produces this:

Let's turn on interpolation (because I can't turn interpolation off in DensityPlot) and compare it with a DensityPlot made using similar options (PlotPoints -> 12, MaxRecursion -> 15):

The curvature-based DensityPlot (right) is clearly much better.  Furthermore, my method won't properly detect ""fjord-like"" structures (similar to the one in this example).  It tend to ""jump"" over them, this is why some artefacts are visible in the middle of the plot.

Thanks to @ruebenko for the hints and ideas he sent me!
"
graphics - How can I extract the maximum value from a Histogram?,"
As mentioned by others, use HistogramList.  You can even use the resulting information to generate the plot without recomputing the information:
{bins, heights} = HistogramList[returns, 300, ""PDF""];
maxFreq = Max[heights];
Histogram[returns, {bins}, heights &, 
 Epilog -> {{Thick, Darker[Green], 
    Line[{{μ, 0}, {μ, maxFreq + 2}}]}}]


"
How to export and import Graphs with additional data?,"
I think it must be an oversight in the graph export code (it also happens when exporting to graph formats other than Graphlet). If you use explicit labels in Mathematica, it gets exported properly, just the implicit VertexLabels -> ""Name"" does not.
Note that since the export formats do not have an equivalent of VertexLabels -> ""Name"", you'd expect the export/import cycle to yield explicit VertexLabels.
So, I guess you should submit a bug report to Wolfram Research.
In the meantime, the work around of using explicit labels should not be too onerous; e.g.,
Graph[{1 -> 2, 2 -> 3, 3 -> 1}, VertexLabels -> Table[i -> i, {i, 3}],
  VertexStyle -> Purple, VertexShapeFunction -> ""Diamond""]


This can be automated in Export by using something like
ExportGraph[file_String, g_Graph, opts___] :=
 If[Flatten[{PropertyValue[g, VertexLabels]}] === {""Name""},
  Export[file, SetProperty[g,
         VertexLabels -> Table[i -> i, {i, VertexList[g]}]], opts],
  Export[file, g, opts]]

"
performance tuning - How can I ensure that I am constructing patterns in the most efficient way possible?,"
Some pitfalls in pattern-construction
You should ask several questions:

Will your pattern involve frequent invocation of the evaluator (this happens if it contains Condition and / or PatternTest, and is tested many times). If yes, this will slow down the pattern-matcher.

Here is an example taken from this answer
randomString[]:=FromCharacterCode@RandomInteger[{97,122},5];
rstest = Table[randomString[],{1000000}];

In[102]:= MatchQ[rstest,{__String}]//Timing
Out[102]= {0.047,True}

In[103]:= MatchQ[rstest,{__?StringQ}]//Timing
Out[103]= {0.234,True} 


Will your pattern make the pattern-matcher perform many a-priori doomed matching attempts (and thus, underutilize the runs of the pattern-matcher)? If yes, this will slow it down a lot. Patterns with BlankSequence or BlankNullSequence are notorious for that, particularly in combination with ReplaceRepeated.

For example, this list sorting is very inefficient:
list//.{left___,x_,y_,right___}/;x>y:>{left,y,x,right}

However, there are cases where such patterns are very efficient as well, such as in this answer.

Will your pattern lead to excessive copying of parts? This happens also for patterns like x___, because the rule like {x_,y___}:>{y} will copy the entire sequence (array) y during the match. This is because lists are implemented as arrays in Mathematica.

As in example here, consider the following implementation of mergeSort, taken from my answer in this thread:
Clear[merge]; 
merge[x_List, y_List] := 
 Block[{merge}, 
   Flatten[merge[x, y] //. {
    merge[{a_, b___}, {c_, d___}] :> 
      If[a < c, 
         {a, merge[{b}, {c, d}]}, {c, merge[{a, b}, {d}]}
      ], 
      merge[{}, {a__}] :> {a}, 
      merge[{a__}, {}] :> {a}}]]  

This one is very slow. The detailed analysis is in the same answer I linked to, but here is the version based exclusively on ReplaceRepeated, but made efficient because it uses linked lists:
Clear[toLinkedList]; 
toLinkedList[x_List] := Fold[{#2, #1} &, {}, Reverse[x]]; 
Module[{h, lrev}, 
  mergeLinked[x_h, y_h] := 
    Last[{x, y, h[]} //. {
        {fst : h[hA_, tA_h], sec : h[hB_, tB_h], e_h} :> 
              If[hA > hB, {tA, sec, h[hA, e]}, {fst, tB, h[hB, e]}], 
        {fst : h[hA_, tA_h], h[], e_h} :> {tA, h[], h[hA, e]}, 
        {h[], sec : h[hB_, tB_h], e_h} :> {h[], tB, h[hB, e]}}]; 

  lrev[set_] := Last[h[set, h[]] //. h[h[hd_, tl_h], acc_h] :> h[tl, h[hd, acc]]]; 

  sort[lst_List] := 
     Flatten[Map[h[#, h[]] &, lst] //. 
         x_List :>       
           Flatten[{toLinkedList@x, {}} //.
            {{hd1_, {hd2_, tail_List}}, accum_List} :> 
               {tail, {accum, lrev@mergeLinked[hd1, hd2]}}], 
         Infinity, h]]; 

Just only due to the use of linked lists and resulting from them memory/run-time savings, this implementation recovers the correct n log n asymptotic complexity of the merge sort angorithm, even though ReplaceRepeated is used all over. The benchmarks can be found in the quoted post.

Does your pattern lead to accidental unpacking of packed arrays, even when that is not necessary? This can slow things down significantly. In this answer, I discussed some possible work-arounds to avoid such situtations.

Summary and recommendations:


Be careful with __ and ___
Be careful with ReplaceRepeated
Try to construct patterns such as to minimize failed pattern-matching attempts.
Avoid Condition and PatternTest whenever possible, and use syntactic patterns
Watch out for unpacking during the pattern-matcher
In place of __ and ___, try using linked lists when you can

"
Asynchronous evaluation: Is it possible?,"
By using the ideas of @Szabolcs, I've managed to write a convenient function which almost does what you want (edit: there is a better version of this function in the third edit, that does exactly what you want):
ClearAll[AsynchronousEvaluate];
SetAttributes[AsynchronousEvaluate, HoldAll];
AsynchronousEvaluate[exp_] := DynamicModule[{eval, display},
  display = EventHandler[
    eval= ParallelSubmit[exp],
    {""MouseClicked"" :> (display = WaitAll[eval])}];
  Parallel`Developer`QueueRun[];
  Dynamic[display]]

What this function does is put the expression you want to evaluate in the queue, and makes it run in the background. In the mean while it displays the EvaluationObject that the function ParallelSubmit outputs, and you are free to perform other operations in the same Mathematica notebook.
Once the evaluation of the expression is complete, all you have to do is click the EvaluationObject, and it will be replaced by the result.  
Of course it would be better if the EvaluationObject would be automatically replaced by the result when the evaluation finishes, but I don't know how to do that. If anyone thinks of way - feel free to edit my answer and add it (edit: I already found a way, see below).
Edit: By using $Pre = AsynchronousEvaluate; you can get Mathematica to automatically apply the function AsynchronousEvaluate to every expression you evaluate, saving you some time and making the notebook look neater.
Edit #2: Be careful when assigning a function to $Pre though, the only way to change it back is to restart Mathematica, since trying to evaluate $Pre=. will result in sending the command to one of the parallel kernels :)
Edit #3: OK here it is, the same function, only now it automatically replaces the EvaluationObject by the result when the evaluation finishes. In order for it to work you need to have a scheduled task running in the background:
qRunTask = CreateScheduledTask[Parallel`Developer`QueueRun[]];
StartScheduledTask[qRunTask];

Keeping the default interval of one second for the scheduled task seems reasonable. Now the AsynchronousEvaluate function:
ClearAll[AsynchronousEvaluate];
SetAttributes[AsynchronousEvaluate, HoldAll];
AsynchronousEvaluate[exp_] := DynamicModule[{eval,display},
display = eval = ParallelSubmit[exp];
Dynamic[
  If[MatchQ[eval[[4]],
    Parallel`Developer`finished[_]], display = eval[[4]][[1]]]; display]]

That's it!
If you're not using this function for a while, you can stop the scheduled task (though it doesn't cause any slow down in my experience):
StopScheduledTask[qRunTask];

Edit #4: I improved the function to fix a problem where the results did not persist after restarting Mathematica. Now they do.
"
How to combine images with the same dimensions in a grid?,"
What you're looking for is ImageAssemble:
c1 = Import[""http://i.stack.imgur.com/2SRcD.png""];
c2 = Import[""http://i.stack.imgur.com/zL8id.png""];
ImageAssemble[{c1, c2}]


It can also assemble vertically and horizontally:
ImageAssemble[{{c1, c1}, {c2, c2}}]


"
image processing - Tuning ParallelMap when IO and computationally bound,"
In this case, you would want to favor Method->FinestGrained, not Method->CoarsestGrained.
FinestGrained is more useful when the workload has items that may take a very long time to process, or which may have wildly varying computation times.
CoarsestGrained is useful when the workload consists of many fast, easy to compute items. You don't want to have heavy synchronization and dispatch when you're adding 1 to 10^10 numbers, do you? 
I'll add some real examples shortly. But in general:

FinestGrained: Computation bound or varying completion time
CoarsestGrained: Fast computations. Really fast ones. Communication is expensive so you want to limit it.

You can really view it the two options as tradeoffs between TComm (cost of communication) vs TComp (cost of computation. In other words:
If[TComm > TComp,
    Method->""CoarsestGrained"",
    Method->""FinestGraned""]


If you want some more control over the grain, you can utilize Method->ItemsPerEvaluation->n. In this case, we hand out n items to each kernel when they come for work. You can use this to further tweak how fine Mathematica grains your calculations.
As a note, the default option of Method->Automatic (which is implicit any time you use Parallel*) performs load balancing we may be expensive to perform if your workload is better suited to fine or coarse grained.
Remember though -- Always measure!
"
front end - What is the most effective way to setup a Notebook with transparent background but solid contents?,"
On Mac this works (but apparently only with WindowFrame->""PopupMenu""):
SetOptions[InputNotebook[], Background -> Opacity[.75, Red], 
 WindowFrame -> ""PopupMenu""]

This is different than WindowOpacity.
"
evaluation - How to simplify expression and use HoldForm at the same time?,"
Why don't you use HoldForm only on the part that actually needs to be held? For example:
f[c_] := Module[{}, 
  c HoldForm[D[""u""[""x"", ""t""], {""x"", 2}]] == ""f""[""x"", ""t""]]


"
notebooks - Setting up TextStyle with initialization cells in Mathematica 6+,"
Just use SetOptions[Graphics, BaseStyle -> {...}].  For example
SetOptions[Graphics, BaseStyle -> {Large, Red, FontFamily -> ""Times"", Italic}];
Graphics[{Circle[], Text[""test""]}]


Note that the Text inherits its BaseStyle from the surrounding Graphics.
The Text function also takes a BaseStyle option, but for some reason it doesn't seem to do anything (in Mma v8.0.4) - this might be a bug. For example:
SetOptions[Text, BaseStyle -> {Large, ""Color"" -> Green}]
{Text[""test""], Text[""test""]//Graphics}


However explicit BaseStyle options passed to Text do work:
Graphics[{Circle[], Text[""test"", BaseStyle -> {Large, ""Color"" -> Green}]}]


"
output formatting - Easiest Way to Use ShowGroupOpener in Mathematica,"
Unless you want group openers for all groups -- which you probably don't, since that would put one at the very top level for the entire notebook -- then you can edit the notebook's style sheet, select the kind of cell (Section, Subsection, e.g.) for which you want the group opener, and then use the Option Inspector on that cell in the style sheet to include ShowGroupOpener.
You could do this either for a particular notebook by using the menu command Format > Edit StyleSheet or you could make a copy of a standard style sheet, modify that, and then select it as the style sheet for whatever notebooks you choose. (I'd advise against directly modifying any of the Wolfram-supplied style sheets.)
I can give a more detailed explanation if you like. 
"
Implementing local complements of graphs,"
For your two examples
g1 = {1 <-> 2, 2 <-> 3, 3 <-> 1}; g2 = {1 <-> 2, 2 <->3, 3 <-> 4, 4 <-> 1};

your function LocalComplement[_,_] gives the results:
EdgeList[LocalComplement[Graph[g1], 1]] (*  gives {1 <-> 2, 3 <-> 1} *)

and
EdgeList[LocalComplement[Graph[g2], 1]] (* gives {1 <-> 2, 2 <-> 3, 2 <-> 4, 
     3 <-> 4, 4 <-> 1}

which are both correct.
For pictures, using
 gplt:={Graph[#, VertexShapeFunction -> ""Name""], 
   Graph[EdgeList[LocalComplement[Graph[#], 1]],VertexShapeFunction -> ""Name""]} &

for the two examples,  I get
 gplt@g1  (* gives *)


and 
gplt@g2  (* gives *)


EDIT: Graph is introduced with version 8.0, and specific details of ""over 500"" fixes and improvements from V8.0 to V8.0.4 has not been released. Since your function works fine in V8.0.4 but gives incorrect results in V8.0, it is likely that you are seeing the effect of a bug that has been fixed in 8.0.4.  
"
front end - Is it possible to cause a notebook to be hidden when pressing the close button?,"
Not a perfect solution, but it works for some extent. It definitely needs some further foolproofing though.
nb = CreateDocument[{}, WindowTitle -> ""Log"", 
   WindowFrameElements -> {}, NotebookEventActions -> {
     ""WindowClose"" :> DialogReturn[],
     ""EscapeKeyDown"" :> (
       SetOptions[EvaluationNotebook[], Visible -> False];
       )}];

Button[""Show"", SetOptions[nb, Visible -> True]]

I used the hack Heike provided to remove the closebox from the window frame, since no matter how hard I tried to integrate the hiding functionality under ""WindowClose"" instead of ""ExcapeKeyDown"" without actually closing the window, it was always closed. Now the window is kept hidden if Esc is hit, and it is Alt+F4 that really terminates the window. If hidden, the provided ""Show"" button can be used to unhide the notebook.
"
front end - Move the cursor in a notebook using the keyboard,"
There are some known bugs where the caret can get, as you say, ""trapped"" when using the up/down arrow keys.  I.e., further presses of the up/down key at certain points in typesetting cells can just do nothing.  However, it has always been my experience that left/right arrow will continue to work, and that usually one or two presses will get you to a point that the up/down arrow keys begin working again.
Also, important to note, that you can traverse the notebook more quickly with the arrow keys by popping the selection out to the cell bracket.  You can, of course, select the cell bracket using the mouse, but you can also select it from the keyboard by repeatedly pressing Ctrl+period (or Cmd+period on Mac) to move the structured selection outwards until it hits the cell bracket.  At that point, using the up/down arrow keys will never get trapped, and it will also be very efficient if you're looking to skip through content cell by cell.
"
programming - Updating Wagon's FindAllCrossings2D[] function,"
Here is my latest code for this function, from Chapter 12 of the third edition of ""Mathematica in Action"". It is pretty short, but I will let you work out if it is faster or more robust than yours. Note the PlotPoints option for difficult cases.
FindRoots2D::usage = 
  ""FindRoots2D[funcs,{x,a,b},{y,c,d}] finds all nontangential solutions to
   {f=0, g=0} in the given rectangle.""; 

Options[FindRoots2D] = {PlotPoints -> Automatic, MaxRecursion -> Automatic}; 

FindRoots2D[funcs_, {x_, a_, b_}, {y_, c_, d_}, opts___] := Module[
  {fZero, seeds, signs, fy}, 
  fy = Compile[{x, y}, Evaluate[funcs[[2]]]]; 

  fZero = Cases[Normal[
     ContourPlot[
        funcs[[1]] == 0, 
        {x, a-(b-a)/97, b+(b-a)/103}, {y, c-(d-c)/98, d+(d-c)/102}, 
        Evaluate[FilterRules[{opts}, Options[ContourPlot]]]]], 
     Line[z_] :> z, Infinity]; 

  seeds = Flatten[(
     (signs = Sign[Apply[fy, #1, {1}]]; 
      #1[[1 + Flatten[Position[Rest[signs*RotateRight[signs]], -1]]]]) &
     ) /@ fZero, 1];
  If[seeds == {}, {}, 
     Select[
        Union[({x, y} /.
           FindRoot[{funcs[[1]], funcs[[2]]}, {x, #1[[1]]}, {y, #1[[2]]}, 
              Evaluate[FilterRules[{opts}, Options[FindRoot]]]] & ) /@ seeds, 
           SameTest -> (Norm[#1 - #2] < 10^(-6) & )], 
        a <= #1[[1]] <= b && c <= #1[[2]] <= d & ]]]

"
list manipulation - Efficient way to combine SparseArray objects?,"
ArrayFlatten[{{sa11, sa12}, {sa21, sa22}}] seems to be what you need. It automatically merges everything into one big SparseArray[].
"
algorithm - How to get actual triangles from DelaunayTriangulation[]?,"
It might be easier to use TriangularSurfacePlot3D to find the Delaunay triangulation of the points. For example, 
Needs[""ComputationalGeometry`""];
triangles[points_] := Module[{pl},
  pl = TriangularSurfacePlot[ArrayPad[points, {{0, 0}, {0, 1}}]];
  Cases[pl, Polygon[a_] :> Flatten[(Position[points, #[[{1, 2}]]] & /@ a)], 
    Infinity]]

Graphics[GraphicsComplex[points, {EdgeForm[Black], FaceForm[],    
  Polygon[triangles[points]]}]]

produces this:


If we use the approach in the original question, each valid triangle should appear exactly trice in the list, so a way to extract the triangles from the result of DelaunayTriangulation would be
Needs[""ComputationalGeometry`""];
triangles2[points_] := Module[{tr, triples},
  tr = DelaunayTriangulation[points];
  triples = Flatten[Function[{v, list},
      Switch[Length[list],
        (* account for nodes with connectivity 2 or less *)
        1, {},
        2, {Flatten[{v, list}]}, 
        _, {v, ##} & @@@ Partition[list, 2, 1, {1, 1}]
      ]
    ] @@@ tr, 1];
  Cases[GatherBy[triples, Sort], a_ /; Length[a] == 3 :> a[[1]]]]

Edit 
I've moved Needs[""ComputationalGeometry`""] outside of the function definition of triangles. As Szabolcs correctly remarked in his comments, putting Needs[""ComputationalGeometry`""] inside the definition will cause shadowing problems because of the creation of the symbol Global`DelaunayTriangulation
Edit 2
Apparently ListDensityPlot uses a Delaunay triangulation as well, and is much faster than TriangularSurfacePlot, so the first part of this answer could be made much more efficient by rewriting it according to
triangles1[points_] := Module[{pl},
  pl = ListDensityPlot[ArrayPad[points, {{0, 0}, {0, 1}}]];
  Cases[pl, Polygon[a_] :> a, Infinity][[1]]]

Note that since ListDensityPlot returns a GraphicsComplex and it keeps the order of the points the same, the index lists for the polygons can extracted directly from the plot without having to lookup the indices of the vertices in points.
"
evaluation - Reassign values to symbols,"
This seems to work:
a = 1; b = 2; c = 3; d = 4;
Scan[Function[p, p = 5, HoldAll], Hold[a, b, c, d]]

Now, try evaluating {a, b, c, d}.
Here's the version with slots:
Scan[Function[Null, # = 5, HoldAll], Hold[a, b, c, d]]

"
networking - How do you use ssh-keys instead of a password to run a remote-kernel over ssh?,"
Mathematica by default uses its own ssh implementation. You can see it in the dialog of the remote kernel configuration dialog in the advanced options: `java` -jar `mathssh`. As far as I know, you can safely replace that with the local ssh command (most likely /usr/bin/ssh). You have to select the ""Advanced Options"" radiobutton to do that (if you first add all the standard options, the rest of the command is already filled in correctly).
Edit: By default, Mathematica uses the launch command
`java` -jar ""`mathssh`"" user@hostname math -mathlink 
       -LinkMode Connect -LinkProtocol TCPIP -LinkName ""`linkname`"" 
       -LinkHost `ipaddress`

to invoke ssh, where user and hostname are filled in via text boxes above. To use the local ssh command, you need to change the above command to
ssh user@hostname ""math -mathlink -LinkMode Connect -LinkProtocol TCPIP 
                        -LinkName `linkname` -LinkHost `ipaddress`""

This appears to have one flaw, killing the remote kernel via the front-end no longer kills the processes on the remote server. So, that will have to be done by hand.
"
What are recommended guidelines for developing packages?,"
Part of what you are asking is of course a matter of taste and habits, but here are my 2 cents:
1) if you want Mathematica to find your package files with a Needs or Get their context names must agree with the hierarchy of directories and filenames. I don't see any good reasons to diverge from that standard convention. For complex packages with many files you will also typically have a Kernel-subdirectory with an init.m, but I think these things are relatively well documented.
2) My personal opinion is that using symbols for option names is asking for exactly these kind of problems. Obviously at least some of the WRI personnel thinks the same, since in later versions there are more and more options that accept strings as names and the new way to work with options also full supports this. If you are worried about cluttering your code with too many pairs of """", note that this will work alright:
Options[f] = {""Verbose"" -> False}

f[OptionsPattern[]] := (If[OptionValue[""Verbose""], 
   Print[""I'm so verbose!""]]; RandomReal[])

f[Verbose -> True]

or even:
f[someothercontext`Verbose -> True]

What you loose is the possibility to have a usage message bound to the option name, but as you have noticed if there are more than one function using the same option name, the usage message is of limited use anyway and the details must be explained in the documentation of the function, not the option. WRI has the same problem, obviously: At least I don't think that this usage is of very much help:
?Method

Method is an option for various algorithm-intensive functions that specifies what internal methods they should use.
3) Introducing sub-contexts is useful when things get more complex and parts of the whole can be split up in more or less independent parts. Of course giving these parts names that make it easy to recognize what they provide is a good idea, but I think that's so obvious that I doubt I fully understand that part of your question. If you want these parts to be loadable without the other parts, you must split them in different files, otherwise it's up to you from the technical viewpoint. From the code organization point of view I would think that if it makes sense to split your packages in separate contexts, it usually is also a good idea to split them into separate files. That becomes even more important if several people work on the various parts, but I feel there is not much Mathematica code written that way (except within WRI). Of course it's not necessary to include a Common.m, but as you have mentioned it's a good approach to collect all symbols that the various parts share into one common context/file, and Common.m (myPackage`Common`) is a common convention that is also used by WRI, so I'd stick with it. On the other hand I would consider it as a good design of your package when you don't need a Common.m, since then you obviously managed to really split your package in independent parts.
"
How to xport larg graphics? - Mathmatica Stack Exchang,"
First, some clarifications:

pure image size: pixels × pixels
Mathematica ImageSize: the distance x distance of the image, defined as a multiple of 1/72'', which is approximately 0.353 mm (1/72'' is called a printer's point)
printing size: distance × distance on the printing media
printer resolution (dpi): depends on printer characteristics; it's the number of small drops it can place in a linear inch; nowadays, above 1000 dpi; generally, due to the mechanical characteristics of the printer, it can put more points in a ""horizontal"" line than in a vertical line; some printers allow this value to be changed for ink economy. 
image resolution printing output (dpi): the amount of pixels defined on the image that will be placed in a 1 inch row or column, on the sheet of paper
Mathematica ImageResolution: a way to specify how many pixels to generate on the exported file, etc.

So, let's suppose you have a 1000 × 1000 pixels image file. What is the resolution of your image? If it is not shown, neither on the screen, nor on paper, it has no resolution (sure your image software can register in a file a specific value for the resolution, but this value has absolutely no impact on your image, see it as something like the date on a digital photograph.)
(I'm sure someone from the ""printing"" business would not agree with some of the words I used, but let's use this as my personal practical definition)
If you print that 1000 × 1000 pixels image on a 4"" × 4"" size paper, it will have a image resolution printing output of 1000/4""= 250 dpi. If you printed with a printer resolution of 2500 × 2500 dpi, then your printer placed 10 × 10 drops of ink to render each pixel of your digital image (this also allows for a correct color rendering from just 3 or 5 different ink recipients).
If you display the same 1000 × 1000 image on your screen, with a 100 % zoom (where each pixel of the image occupies exactly one pixel on your screen), most likely, your image will measure 1000/72"" (if you use a ruler), since most screens have a resolution of 72 dpi (recent laptops may have substantially higher resolution).
So, another important question is: What should be my image resolution printing output?
When printing, you should have an image resolution printing output adapted to the distance at which the image will be seen. It is common to say that someone with a 20/20 sight is able to distinguish 0.3 to 0.4 arc minutes at maximum. Considering the value 0.3, we could say that, for the printing to be perfect, the image resolution printing output, in dpi, should be (360/(0.3/60))/(2 d*Pi), where d stands for the distance of viewing (in inches).
Nevertheless, I'll add here my personal experience on printed results (where, for obvious reasons, things aren't so perfect as on perfectly geometrical displays): below 150 dpi, you will start to easily see the pixels on your printed support; above 300 dpi, only with very precise printers, and looking closely, will you see a difference to the same image at 300 dpi. Out of curiosity, these practical limits correspond on a perfect vision to a distance between 1 to 2 meters.
For your example, a 3' × 5' print, I think that 200 dpi image resolution printing output is more than enough, since it is probably a print that will be observed from a certain distance. Everyone farther than 1,5 m will be beyond physical capability to distinguish pixels; and I would add that up to 1/4th of this distance, the image will still be perfectly acceptable (after-all, we have been living pretty happy with 72/96 dpi displays up to not so long ago...)
This means you would need 3 × 12 × 200 by 5 × 12 × 200 = 7200 × 12000 pixels on your file.
How to generate this on Mathematica?
There are a lot of different ways. I will show you a couple of examples.
The following creates an image of 100 ""printer points"" (horizontal), meaning 100*1/72'', which corresponds to approximately 36 mm.
a = Plot[x^2, {x, 0, 1}, ImageSize -> 100]

Unfortunately, what that means is a little hard to understand, since the size that image will occupy on your screen is probably not 36 mm. It depends on the Magnification, the difference between your screen true resolution and what Mathematica reads of it (not always match), etc. Nevertheless, if you activate the ruler (Windows->Show Rules), you will see that it matches. So, think of it more like a meta information...
The following exports the previously generated image with the default value of ImageResolution, which is 72 dpi. This means that you jpg file will have (100*1/72'')*72 dpi = 100 horizontal pixels.
Export[""a.jpg"", a]

The following exports a 200 horizontal pixel size image (it changes your original option, defined on the Plot)
Export[""a.jpg"", a, ImageSize->200]

And with the following you specify the ImageResolution for the Export function. This is  probably what you are looking for.
Export[""a.jpg"", a, ImageResolution->200]

So, I recommend that you play around with ImageSize, to get a good looking image on your screen (the texts on the correct size, etc), and then Export it specifying the ImageResolution to get the 7200 × 12000 pixels file.
(See JPEG specifications to get it into a reasonable file size.)
"
How to represent and manipulate abstract indexed vector (or tensor) expressions?,"
On this wikipedia page you find a collection of Tensor software and Mathematica has the biggest section. 
The package Ricci, which username acl pointed out in his answer is there, and I personally have used xAct. It looks like this
http://img692.imageshack.us/img692/211/pic1ni.png
And yes, as you suggest in your question, for smaller computation in specific dimensions you can also work in components directly. For me, this usually looks something like this (only have a screenshot atm.).
http://img835.imageshack.us/img835/5023/bild4go.png
Although the expression $de_\mu$ makes me think the package variant is best suited for you.
"
programming - Creating Mathematica packages,"
Package creation is a large topic indeed. I will still attempt to give a minimal clarification of the encapsulation mechanism behind packages, since in my experience it pays off to understand it.
What constitutes a package
Basically, a piece of Mathematica code (usually containing a number of variable 
and function definitions), which is placed inside
Begin[someContext]

code

End[]

can be called a package. Usually, however, at least some more structure is present. In particular, to separate interface from implementation, the typical package looks like
BeginPackage[someContext]

public-functions-usage-messages 

Begin[""`Private`""]

code

End[]

EndPackage[]

Contexts and symbol names
The context here is a namespace. The convention is that context name is a string ending with ""`"". At any given moment, the value for the current working namespace is stored in the system variable $Context, and can also be queried by calling Context[]. Begin[""test`""] will simply add the current context to the context stack, and then change it to ""test`"", while End[] will exit the current context by making the previous one current. 
Every symbol must belong to some context. The system commands belong to the ""System`"" context, and the default working context for interactive FrontEnd sessions is ""Global`"". When mma code is parsed, the symbols are given their ""true"" (long) names, which contain both a symbol name and a context where the symbol is. For example, Map is really System`Map, and if I define a function f[x_]:=x^2 in the FE session, it will be Global`f. For any symbol, one can call Context[symbol] to determine the context where that symbol belongs. To ""export"" a symbol defined in a package, it is sufficient to simply use it in any way in the ""public"" part of the package, that is, before ""`Private`"" or other sub-contexts are entered. Usage messages is just one way to do it, one in principle could just write sym; and the sym would be created in the main package context just the same (although this practice is discouraged).
Every symbol can be referenced by its long name. Using the short name for a symbol is acceptable if the context where it belongs belongs to the list of contexts currently on the search path, stored in a variable $ContextPath. If there is more than one context on the $ContextPath, containing the symbol with the same short name, a symbol search ambiguity arises, which is called shadowing. This problem should be avoided, either by not loading packages with conflicting public (exported) symbols at the same time, or by referring to a symbol by its long name. I discussed this mechanics in slightly more detail in this post.
Contexts can be nested. In particular, the ""`Private`"" above is a sub-context of the main context someContext. When the package is loaded with Get or Needs,only its main context is added to the $ContextPath. Symbols created in sub-contexts are therefore inaccessible by their short names, which naturally creates the encapsulation mechanism. They can be accessed by their full long names however, which is occasionally handy for debugging.
Storing and loading packages
Packages are stored in files with "".m"" extension. It is recommended that the name of the package coincides with the name of the package context. For the system to find a package, it must be placed into some of the locations specified in the system variable $Path. As a quick alternative (useful at the development stage), $Path can be appended with the location of a directory that contains a package. 
When the Needs or Get command are called, the package is read into a current context. 
What is meant  by this is that the package is read, parsed and executed, so that the definitions it contains are added to the global rule base. Then, its context name is added to the current $ContextPath. This makes the public symbols in a package accessible within the current working context by their short names. If a package A is loaded by another package B, then generally the public symbols of A will not be accessible in the context C which loads B - if needed, the A package must generally be explicitly loaded into C. 
If the package has been loaded once during the work session, its functions can be accessed by their long names even if it is not currently on the $ContextPath. Typically, one would just call Needs again - if the package has been loaded already, Needs does not call Get but merely adds its context name to the $ContextPath. The internal variable $Packages contains a list of currently read in packages.
The case at hand
Here is how a package might look like:
BeginPackage[""SimpleArithmetic`""]

AddTwo::usage = ""AddTwo[a, b] returns a+b"";
AddThree::usage = ""AddThree[a, b, c] returns a+b+c"";
TimesTwo::usage = ""TimesTwo[a, b] returns a*b"";
TimesThree::usage = ""TimesThree[a, b, c] returns a*b*c"";

Begin[""`Private`""]

plus[args___] := Plus[args];
times[args___] := Times[args]

AddTwo[a_, b_] := plus[a, b];
AddThree[a_, b_, c_] := plus[a, b, c];
TimesTwo[a_, b_] := times[a, b];
TimesThree[a_, b_, c_] := times[a, b, c];

End[]
EndPackage[]

The functions AddTwo, AddThree, TimesTwo,TimesThree are public because these symbols were used in the public part of the package. Their long names would be then SimpleArithmetic`AddTwo, SimpleArithmetic`AddThree, SimpleArithmetic`TimesTwo, SimpleArithmetic`TimesThree. The functions plus and times are private to the package, since they are in the sub-context `Private`, which is not added to the ContextPath when the main package is loaded. Note that this is the only reason they are private. Should I call AppendTo[$ContextPath,SimpleArithmetic`Private`], and they'd become as ""public"" as the main functions (practice that should of course be discouraged by which should clarify the encapsulation mechanism).
With regards to splitting a package into several packages, this is a normal practice, but usually an individual mma package contains much more functionality than say a typical Java class, more like Java package. So, in the case at hand, I'd not split it until you get a much more functionality in it.
Of course, I only discussed here a very small subset of things related to packages. I will hopefully update this tutorial soon. An excellent reference for writing packages is a book of Roman Maeder ""Programming in Mathematica"". It is pretty old, but still one of the most (if not the most) useful accounts on the matter.   
"
"function construction - SetAttributes[f,Flat]: Why the order dependence?","
Ok, I'm going to try to explain my best conjuecture as to how this happens, and don't even try to answer why. 
There are three reasons for this behaviour:
SetDelayed left hand side evaluation
As others have mentioned, even though SetDelayed has attributes that indicate it holds the lhs, it does evaluate the head and the arguments of it, just not the expression as a whole.
How the Attribute Flat affects the final evaluation of the expression
Ok, so the evaluator is now trying to transform the expression (with head Flat) as a whole. It has already evaluated the head and arguments, or not, as it was supposed to. It has already flattened everything. It has already tried the UpValues, nothing fit.
Now it checks, in order, one DownValue at a time:
1* If it matches the expression as is, we're good. It applies the transformation rule.
2* If it doesn't, then it modifies the expression, gathering arguments. Tries combinations of head[prev__, head[some__], aft__] with args being different subsequences of arguments taken from expression. If some subexpression fits the pattern, it transforms it and restarts the process.
Example
In[27]:= ClearAll[f];
SetAttributes[f, {Flat, HoldAll}];
f[b, c] := 8;
f[a, b, c, d]

Out[30]= f[a, 8, d]

3* If it doesn't then IT TRIES TO MATCH THE EXPRESSION head[] WITH NO ARGUMENTS. If it succeeds, then IT PREPENDS THE UNEVALUATED TRANSFORMATION OF head[] TO THE EXPRESSION AND RESTARTS THE EVALUATION PROCESS
Some examples:
In[18]:= ClearAll[f1, f2, f3, f4];
SetAttributes[{f1, f2, f3, f4}, Flat];
f1[2, 2, 2, 2] := ""Yeahh"";
f1[2] = ""bo"";
f1[] := (Print[""here""]; 2);

f2[2] = ""bo"";
f2[2, 2, 2, 2] := ""Yeahh"";
f2[] := (Print[""here""]; 2);

f3[] := (Print[""here""]; 2);
f3[2, 2, 2, 2] := ""Yeahh"";
f3[2] = ""bo"";

f4[2, 2, 2, 2] := ""Yeahh"";
f4[] := (Print[""here""]; 2);
f4[2] = ""bo"";

In[32]:= Scan[Print[DownValues[#][[All, 1]]] &, {f1, f2, f3, f4}]

During evaluation of In[32]:= {HoldPattern[f1[2,2,2,2]],HoldPattern[f1[2]],HoldPattern[f1[]]}

During evaluation of In[32]:= {HoldPattern[f2[2]],HoldPattern[f2[2,2,2,2]],HoldPattern[f2[]]}

During evaluation of In[32]:= {HoldPattern[f3[]],HoldPattern[f3[2,2,2,2]],HoldPattern[f3[2]]}

During evaluation of In[32]:= {HoldPattern[f4[2,2,2,2]],HoldPattern[f4[]],HoldPattern[f4[2]]}

In[33]:= f1[2]
f2[2]
f4[2]

Out[33]= ""bo""

Out[34]= ""bo""

During evaluation of In[33]:= here

During evaluation of In[33]:= here

During evaluation of In[33]:= here

Out[35]= ""Yeahh""

So, in our case, when the expression f[n_Integer] fails to match the pattern f[x___Real], it evaluates f[] to get {}, and tries matching f[{}, f[n_Integer]], which doesn't match so it loops infinately.
If this is a case, then a good tip would be to always take care that all definitions of Flat symbols that match without arguments should go last...
How the order of setting attributes matter
Flat affects evaluation in 3 different moments:

After evaluating the arguments of an expression, it automatically
flattens it's head
Changes the pattern-matching (more on this later)
Changes what the evaluator does when an expression didn't match a DownValue

The 1.th and 2.th part seems to only care about Flat being set at the time of evaluation.
But 3., it seems that that peculiar behaviour (see 2* and 3* above) of the evaluator trying to match the no-arguments version is PER DOWNVALUE, and it seems to me that, at the time the DownValue is set, MMA records somewhere if Flat was or not set at the time.
So, the previous f3 example that looped infinitely wouldn't loop infinitely if the no argument version was defined while the Flat attribute wasn't set.
ClearAll[f3];
f3[] := (Print[""here""]; 2);
SetAttributes[{f1, f2, f3, f4}, Flat];
f3[2, 2, 2, 2] := ""Yeahh"";
f3[2] = ""bo"";

In[65]:= f3[2]

Out[65]= ""bo""

The previous f4 example would also differ. You don't even need to set the Flat attribute back up in the end for the behaviour to remain
In[66]:= ClearAll[f4];
SetAttributes[f4, Flat];
f4[2, 2, 2, 2] := ""Yeahh"";
ClearAttributes[f4, Flat];
f4[] := (Print[""here""]; 2);
SetAttributes[f4, Flat];
f4[2] = ""bo"";

In[73]:= f4[2]

Out[73]= ""bo""

The same actually applies to (see 2*) the evaluator testing the different combinations of gathered arguments... So
In[37]:= ClearAll[f];
SetAttributes[f, {Flat, HoldAll}];
f[b, c] := 8;
ClearAttributes[f, Flat];
f[e, g] := 9;
f[a, b, c, d]
f[a, e, g, d]

Out[42]= f[a, 8, d]

Out[43]= f[a, e, g, d]

Extra for less incompleteness
Flat also affects the pattern matcher.
When the pattern matcher finds itself comparing arguments of an expression whose head (let's call it head) has attribute Flat, it behaves differently: patterns of length one (_, r_, Conditions, PatternTests) trigger the pattern matcher to automatically wrap a head around the respective arguments of the expression so both the expression and the pattern have the same number of arguments (could also be a single argument, but it never leaves it as is. Don't know the purpose). In cases where more than one option is possible due to having __s as arguments, it just starts trying one way and if it doesn't match, tries the next).
In[47]:= ClearAll[f]; SetAttributes[f, {Flat, HoldAllComplete}];
         Cases[Hold@f[1], Hold@f[i_] :> Hold[i], {0}]
         Cases[Hold@f[1, 2, 3, 4], Hold@f[1, i_, 4] :> Hold[i], {0}]
         Cases[Hold@f[1, 2, 3, 4], Hold@f[i_, __] :> Hold[i], {0}]
         Cases[Hold@f[1, 2, 3, 4], 
            Hold@f[i_, j__ /; Length[{j}] === 2] :> Hold[i], {0}]

Out[48]= {Hold[f[1]]}

Out[49]= {Hold[f[2, 3]]}

Out[50]= {Hold[f[1]]}

Out[51]= {Hold[f[1, 2]]}

Conclusion
The problem is: Will the evaluation of f[n_Integer] in our definition of g trigger an infinite loop or not? It does evaluate because of the peculiar evaluation rules of Set functions.
f[n_Integer] doesn't match the only DownValue it has at the time: f[x___Real]. In the 2 cases that work, that DownValue wasn't defined while f had the attribute Flat, so it just returns unevaluated. However, in the third case, the DownValue was defined while the symbol had Flat. So after failing, it tries to evaluate f[], returning {} and now reevaluates the whole expression as f[{}, n_Integer]
"
performance tuning - How do you determine the optimal autocompilation length on your system,"
You should note that you are actually controlling the compiling and the array packing is just coupled to that and AFAIK can't be controlled independently (anymore). You can verify this with e.g. this uncompilable table body which generates the same result:
Developer`PackedArrayQ[Table[i /. x_ /; x > 300 :> RandomReal[], {i, 1, 251}]]
False

I would expect that the compiling dominates over the array packing concerning runtime overhead and thus that the dependence on the actual body of the table is much stronger than that of the system you are on. If that expectation isn't completely wrong an optimization with regards to the system might be rather useless. Here are examples to demonstrate this:
SetSystemOptions[""CompileOptions"" -> {""TableCompileLength"" -> \[Infinity]}];
uncompiled = Map[
   Function[x, Timing[Do[With[{y = RandomReal[]},
         Table[
          Abs[i - y]/(Exp@Sin[y*i]*i^2 + 1 - 0.5*(i + y)^23), {i, x}]
         ], {1000}];][[1]]],
   Range[1, 50]
   ];

SetSystemOptions[""CompileOptions"" -> {""TableCompileLength"" -> 1}];
compiled = Map[
   Function[x, Timing[Do[With[{y = RandomReal[]},
          Table[
           Abs[i - y]/(Exp@Sin[y*i]*i^2 + 1 - 0.5*(i + y)^23), {i, x}]
          ], {1000}];][[1]]],
    Range[1, 50]
   ];

ListLinePlot[{compiled, uncompiled}]


SetSystemOptions[""CompileOptions"" -> {""TableCompileLength"" -> \[Infinity]}];
uncompiled = Map[
    Function[x, Timing[Do[
        With[{y = RandomReal[]}, Table[i + y, {i, x}]],
        {5000}];][[1]]],
   Range[60, 180]
   ];

SetSystemOptions[""CompileOptions"" -> {""TableCompileLength"" -> 1}];
compiled = Map[
   Function[x, Timing[Do[
        With[{y = RandomReal[]}, Table[i + y, {i, x}]],
        {5000}];][[1]]],
   Range[60, 180]
  ];

ListLinePlot[{compiled, uncompiled}]


If you compare the two plots you will see that for these two cases the optimal compile length is very different.
To get most out of your system, you would need to adopt these settings to the problem at hand (and of course change them for another).
This of course assumes that you are talking about runtime efficiency, although array packing is just as well (or even in the first place) about memory efficiency.
"
packages - Strategies for avoiding and handling shadowing,"
When this is unavoidable, I just refer to full contexts.  This happens all the time when using Combinatorica, which defines Graph objects that conflict with V8's new built in Graph object.  Here's a sample session (presented as an image to show highlighting and such):

"
performance tuning - How to collect result continuously (interruptible calculation) when running parallel calculations?,"
Regarding using Sow instead of AppendTo, you may find this trick useful:
Last[Last[Reap[CheckAbort[Do[Pause[0.1]; Sow[x], {x, 30}], ignored]]]]

(Try running this and aborting it partway through. It runs for 3 seconds due to the Pause[0.1] commands.)
Do is used instead of Table, and the results are returned with Sow. The CheckAbort catches when you abort your computation partway through and does the useful tidying up (in this case, returning something, anything, to the enclosing Reap).
You can combine this with a version of Sow that always run on the master kernel:
SetSharedFunction[ParallelSow];
ParallelSow[expr_] := Sow[expr]

(Tangentially related blog post I did: http://blog.wolfram.com/2011/04/20/mathematica-qa-sow-reap-and-parallel-programming/)
Then you could use this parallelized version:
In[3]:= Last[
 Last[Reap[
   CheckAbort[ParallelDo[Pause[0.1]; ParallelSow[x], {x, 30}], 
    ignored]]]]

Out[3]= {6, 1, 7, 2, 8, 3, 9, 4, 10, 5, 16, 11, 17, 12, 18, 13, 19, \
14, 20, 15, 21, 26, 22, 27, 23, 28, 24, 29, 25, 30}

However, as you can see, the results come in in an unpredictable order so something slightly cleverer is in order. Here is one way (probably not the best but the first thing I thought of):
In[5]:= Catch[
 Last[Last[
   Reap[CheckAbort[
     Throw[ParallelTable[Pause[0.1]; ParallelSow[x], {x, 30}]], 
     ignored]]]]]

Out[5]= {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \
18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}

The Throw is used to jump outside the Reap if the ParallelTable finishes. (Getting messy!)
To be safe this should be wrapped up in a function and tags (a.k.a. the optional second argument) should be used on the Throw, Catch, Sow, Reap.
"
Constructing functions with variable number of output arguments,"
As you have mentioned there are other more standard ways to provide some variaty in your return value so I don't think that this is something that you should do. If you provide code using something like it you should have good reasons for doing so. Just being used to it because matlab has it probably is just not convincing enough. 
That said, it can be done along these lines:
ClearAll[f, ff]
f /: Set[arg_Symbol, f[x_]] := Block[{nargout = 1}, arg = ff[x]];
f /: Set[args_List, f[x_]] := Block[{nargout = Length[args]}, args = ff[x]];
f[arg_] /; FreeQ[Stack[], Set] := Block[{nargout = 1}, ff[arg]];
ff[x_] := (Table[x, {nargout}]);

you can now use it like this:
In[101]:= f[5]
Out[101]= {5}
In[102]:= a=f[5]
Out[102]= {5}
In[104]:= {a,b}=f[5]
Out[104]= {5,5}
In[105]:= {a,b,c}=f[5]
Out[105]= {5,5,5}

This is not tested well and could have many pitfalls. I see it rather as a proof of concept and probably something for your own convenience. So use with care, especially if you are uncertain about all the details (as I am: I can't remember I ever had the need to use Stack). 
Brett already found one pitfall. Actually that is a case where one could be argueing what the expected return value should be. If we fall back to the one argument case for everything that is not an explicit Set it is easy to solve, but I can see other problems already :-):
f[arg_] /; Not[MatchQ[Stack[],{___,Set,f,___}]]:=Block[{nargout=1},ff[arg]];

"
optics - Drawing graphics part by part,"
What you want is done by
Graphics[Table[Circle[{a, 1}, 1], {a, 1, 2}] ~Append~ Text[""It's finished"", {0, 0}]]


Here's another approach, with minimal changes to your code:
Graphics[
  {
     a = 1;
     Label[tag];
     If[a < 3,
        {Sow @ Circle[{a, 1}, 1], a = a + 1; Goto[tag];},
        {Sow @ Text[""It's finished"", {0, 0}]}]
  } // Reap // Last // Last
]

EDIT: I'm afraid I am not sure what that is supposed to look like, but does this
Manipulate[
 Graphics[
  {
   α = ArcSin[H/R];
   p = Sqrt[R^2 - H^2];
   {Red, Thick, Line[{{-2, H}, {p, H}}]},
   {Blue, Opacity[.5], Disk[{0, 0}, R, {0, Pi/2}]},
   If[
    H < R/n,
    {
     l = (R^2 n)/(Sqrt[R^2 - H^2] n - Sqrt[R^2 - H^2 n^2]);
     {Red, Thick, Line[{{p, H}, {l, 0}}]}
     },
    Last@Last@Reap[
       {
        novo = H;
        k = 2;
        Sow@Text[θ, {10, 5}], Text[α, {10, 7}], 
        Text[k, {10, 9}],
        Label[oznaka];
        s = R Cos[α] - novo/Tan[2 α];
        If[s <= R,
         Sow@{{Red, Thick, Line[{{p, novo}, {s, 0}}]}},
         {θ = (2 k + 1) α - k Pi;
          f = R Cos[θ];
          h = R Sin[θ];
          k = k + 1;
          Sow@Line[{{{p, novo}, {f, h}}}], novo = h;
          p = f;
          Goto[oznaka];}]}
       ]
    ]
   }
  ],
 {{H, 9.45991`, ""Vertikalna udaljenost upadne zrake""}, 0.0001, 
  R - 0.0001, 
  Appearance -> ""Labeled""}, {{n, 1.5, 
   ""Koeficijent prelamanja stakla""}, 1.001, 2, 
  Appearance -> ""Labeled""}, {{R, 10, ""Poluprecnik prizme""}, 0, 10, 
  Appearance -> ""Labeled""}]

work?

"
histograms - Elegantly pairing up mismatched lists,"
You can use InterpolationOrder for the plot itself to generate the same behavior. I'm assuming here you want the plot you posted in an easier way, not the data handling itself.
{bins, counts} = HistogramList[...];
ListLinePlot[
    {bins, Append[counts, 0]} // Transpose, 
    InterpolationOrder -> 0
]


(You may want to prepend one value to the finished list so that the histogram goes down to zero on the left side as well.)
"
configuration - what is the command to make Mathematica beep each time there is an error even for the same command?,"
Heike figured out what was going on. 
However, if you want a command that will make your Simplify[expr] beep everytime, you need to turn of the symbolic part of the cache using
SetSystemOptions[""CacheOptions"" -> {""Symbolic"" -> False}]

"
options - How can I work out which functions work with SetOptions?,"
I don't know the direct answer to the specific question on SetOptions, but if we look at the purpose of (re)setting options globally, I have some alternative suggestion. A need to set options globally means that you need some persistent configuration of options which you'd like to be applied many times, without extra effort on your side. This can be achieved by creating such option(s) configuration and then always passing options locally (explicitly). It is possible to create helper functions / macros, which would automate this process for you and make it look and feel (almost) as if you have set your options globally.
I have implemented a simplistic options configuration manager, and a lexically scoped construct withOptionConfiguration, which can be wrapped around your code containing a function call of interest. One can also implement dynamically-scoped environments, for which the option-passing will happen also for all code called from the code within a construct. To my mind, this will save a lot of hassle even if / when you get the exhaustive answer to your direct question, since with the approach I suggest, you don't have at all to remember which functions work with SetOptions and which don't.
"
numerics - Combined numerical minimization and maximization,"
This is a rather common issue that comes up with many numerical functions (FindRoot, NIntegrate, FindMaximum, NMaximize, etc.)  It is also explained in this Wolfram Knowledge Base article. Sometimes you want to pass these functions an expression that has a symbolic parameter, and compute the result for different values of that parameter.
Example:
fun[a_] := Block[{b}, b /. NMinimize[(a^2 + b)^2, {b}][[2]]]

This will work nicely if you call it with a numeric argument: fun[3].  But it will cause an error in NMinimize if you call it with a symbolic parameter: fun[a] (for obvious reasons).
The solution is:
Clear[fun]
fun[a_?NumericQ] := Block[{b}, b /. NMinimize[(a^2 + b)^2, {b}][[2]]]

NMaximize[fun[a], {a}]

(Be sure to evaluate Clear[...] to get rid of the previous definition of fun!)
This ensures that fun will only evaluate for numerical arguments, i.e. fun[a] won't evaluate inside NMaximize before NMaximize actually substitutes a number for a.
And this is also the answer to your specific question: make the inner NMinimize expression a separate function, and make sure it only evaluates for numerical arguments.

Requested edit
An important related point is: how can we match only numerical quantities using a pattern?  One might think of using _Real (as in the comment below).  The problem with this is that it will only match numbers whose Head is Real.  This excludes integers (such as 1,2,3), rationals (2/3, 4/5), constants (such as Pi or E), or expressions like Sqrt[2].
The only robust solution is using NumericQ[] (x_ ? NumericQ in a pattern).  NumericQ will return True for anything that gives a number when N[] is applied to it.
There's another related function, NumberQ[], which gives True only for objects with Integer, Rational, Real or Complex, but not for constant or expressions (Pi or Sin[3]).
"
programming - How do I evaluate only one step of an expression?,"
I believe I have found the solution I was seeking.  It returns the first step that transforms the entire expression, and it does so without further evaluation.  
The P = (P = part is to skip the untransformed expression.
SetAttributes[step, HoldAll]

step[expr_] :=
  Module[{P},
    P = (P = Return[#, TraceScan] &) &;
    TraceScan[P, expr, TraceDepth -> 1]
  ]

I hope that this function will be as helpful to others as I expect it will be to me.
"
options - How can I set Grid alignments using numbers?,"
It seems that the handling of the Alignment option is not consistent for all functions using it. Panel for instance seems to support numeric values for this option
Manipulate[
 Panel[""\[Times]"", ImageSize -> {100, 50}, Alignment -> {x, y}],
 {x, -1, 1},
 {y, -1, 1}
]

while with Grid this is not supported.
Knowing this, you could check functions you're interested in with something simple like
SetAttributes[AlignmentTest, HoldAll];
AlignmentTest[func_] := Row[{
   Manipulate[
    Append[func, Alignment -> {x, y}],
    {x, -1, 1},
    {y, -1, 1}
    ],
   Manipulate[
    Append[func, Alignment -> {x, y}],
    {x, {Left, Center, Right}},
    {y, {Bottom, Center, Top}}
    ]
   }]

You see that in many cases numeric values for the Alignment option can be used
AlignmentTest[
 Button[""Click Here"", Print[10!], ImageSize -> {100, 100}]]

AlignmentTest[
 Manipulate[Plot[Sin[x (1 + a x)], {x, 0, 6}], {a, 0, 2}, 
  ContentSize -> {500, 500}]]

AlignmentTest[
 Grid[{{""\[Times]"", ""\[Times]"", ""\[Times]""}, {""\[Times]"", ""\[Times]"", 
    ""\[Times]""}}, Frame -> All, ItemSize -> {10, 10}]]

AlignmentTest[Overlay[{Graphics[{Disk[]}], Slider2D[]}, All, 2]]

"
boolean computation - Prenex and Skolem normal forms,"
tutorial/RealPolynomialSystems claims ""Reduce, Resolve, and FindInstance always put real polynomial systems in the prenex normal form, with quantifier-free parts in the disjunctive normal form...""
For obtaining Skolem form from prenex, possibly could proceed as described at
http://demonstrations.wolfram.com/Skolemization/
or
http://mathworld.wolfram.com/SkolemFunction.html
Edit:
Also there is a non-System` context function of interest (I learned this via grep). I'll illustrate with the example provided in a comment.
ee = ForAll[x, P[x] \[Implies] Q[x]] \[Implies] (ForAll[x, P[x]] \[Implies] ForAll[x, Q[x]]);

We'll need to put into a normal for; conjunctive or disjunctive will suffice. I'll use LogicalExpand to get a dnf.
ff = LogicalExpand[ee]


Exists[x,  !Implies[P[x], Q[x]]] || Exists[x,  !P[x]] || ForAll[x, Q[x]]


Reduce`ToPrenexForm[ff]


Exists[{C[1], C[2]}, ForAll[{C[3]}, (P[C[1]] &&  !Q[C[1]]) ||  !P[C[2]] || Q[C[3]]]]


I've no idea whether this is the sort of result wanted. But it does seem to have all quantifiers at the front.
"
calculus and analysis - Implementing discrete and continuous Hilbert transforms,"
Here's a direct implementation of the formula
$$\mathcal H(u)(t) = \frac1{\pi} -\hspace{-1.1em}\int_{-\infty}^\infty \frac{u(\tau)}{t-\tau}\, \mathrm d\tau$$
hilbertTransform[f_, u_, t_] :=
       FullSimplify[Convolve[f, 1/u, u, t, PrincipalValue -> True]/π]

Try it out:
hilbertTransform[#, v, w] & /@ {Sin[v], Cos[v], 1/(1 + v^2), Sinc[v], DiracDelta[v]}
   {-Cos[w], Sin[w], w/(1 + w^2), (1 - Cos[w])/w, 1/(π w)}


For the discrete Hilbert transform, here is a Mathematica routine:
hilbert[data_?VectorQ] := Module[{fopts = FourierParameters -> {1, -1}, e, n},
   e = Boole[EvenQ[n = Length[data]]]; 
   Im[InverseFourier[Fourier[data, fopts] * 
                     PadRight[ArrayPad[ConstantArray[2, Quotient[n, 2] - e], {1, e}, 1], n],
                     fopts]]] /; And @@ Thread[Im[data] == 0]

(making everything completely analogous to FourierTransform[] and Fourier[]). The algorithm is based on the routine in Marple's paper, and is essentially the same algorithm used by the function hilbert() in MATLAB's Signal Processing Toolbox.
Examples:
hilbert[{1, -2, 1}]
   {1.73205, 0., -1.73205}

hilbert[{1, -2, 1, 2}]
   {2., 0., -2., 0.}

"
plotting - On coloring the faces of a surface differently with parameter-dependent colors,"
My friend C.H. enlightened me, that in current version of M. ColorFunction defines vertex colors which in turn define polygon colors. Because vertexes cannot have 2 different colors for different sides of a surface, so can’t polygons. 
I will show two solutions.
So here is one solution. We can extract images from ColorData:

and just use textures - if you want to call ParametricPlot3D only once. You can easily map different textures on different sides of a surface, use Specularity and Opacity with them.
ParametricPlot3D[{Cos[u] (3 + Cos[v]), Sin[u] (3 + Cos[v]), 
  Sin[v]}, {u, 0, 1.5}, {v, -3.5, 2}, 
 TextureCoordinateFunction -> ({#4, #5} &), 
 PlotStyle -> 
  Directive[Specularity[White, 50], 
   FaceForm[Texture[ColorData[""BrightBands"", ""Image""]], 
    Texture[ColorData[""DarkRainbow"", ""Image""]]]], Axes -> False, 
 Lighting -> ""Neutral"", Mesh -> None, Boxed -> False]



Another solution, as you mentioned, is to put 2 surfaces together. I really like it, it's light and zippy. I will mention it here for completeness of example. In M. we can make surface (its polygons) to be transparent if you look from one side and colored from the other with help of FaceForm[None , {}]. Clearly demonstrated below with Möbius strip:
ParametricPlot3D[{Cos[t] (3 + r Cos[t/2]), Sin[t] (3 + r Cos[t/2]), 
  r Sin[t/2]}, {r, -1.5, 1.5}, {t, 0, 2 Pi}, Mesh -> {10, 60}, 
 PlotStyle -> FaceForm[None, Orange], Boxed -> False]


You can also do things like PlotStyle -> FaceForm[None, Directive[Orange, Opacity[.5]]] We will uses this. Each graphics one surface’s side is effectively turned off, so shifting the two surfaces with respect to each other is not needed.
Show[
 ParametricPlot3D[{(2 + Cos[v]) Cos[u], (2 + Cos[v]) Sin[u], 
   Sin[v]}, {v, -Pi/1, Pi/1.5}, {u, 0, Pi/1.5}, Boxed -> False, 
  Axes -> False, Mesh -> False, 
  ColorFunction -> (ColorData[""DarkRainbow""][#5] &), 
  PlotPoints -> 30,
  PlotStyle -> FaceForm[{}, None] ],

 ParametricPlot3D[{(2 + Cos[v]) Cos[u], (2 + Cos[v]) Sin[u], 
   Sin[v]}, {v, -Pi/1, Pi/1.5}, {u, 0, Pi/1.5}, Boxed -> False, 
  Axes -> False, Mesh -> False, 
  ColorFunction -> (ColorData[""BrightBands""][#5] &), 
  PlotPoints -> 30,
  PlotStyle -> FaceForm[None, {}] ]
]


======================== Reply to 1st Comment ========================
Trimming anyhow color maps will work:
ParametricPlot3D[{Cos[u] (3 + Cos[v]), Sin[u] (3 + Cos[v]), 
  Sin[v]}, {u, 0, 1.5}, {v, -3.5, 2}, 
 TextureCoordinateFunction -> ({#4, #5} &), 
 PlotStyle -> 
  Directive[Specularity[White, 50], 
   FaceForm[
    Texture[ImageTake[
      ColorData[""BrightBands"", ""Image""], {0, 31}, {85, 250}]], 
    Texture[ImageTake[
      ColorData[""DarkRainbow"", ""Image""], {0, 31}, {85, 250}]]]], 
 Axes -> False, Lighting -> ""Neutral"", Mesh -> None, Boxed -> False]


"
syntax - Convenient string manipulation,"
I suggest an approach based on creating lexical and / or dynamic environments (custom scoping constructs if you wish), inside which the rules of our ""universe"" will be altered. I will illustrate with a dynamic environment:
ClearAll[withStringManipulations];
SetAttributes[withStringManipulations, HoldAll];
withStringManipulations[code_] :=
  Internal`InheritedBlock[{Take, Drop, Position, Join, Append, 
        Prepend, Length, Part, Plus},
   Unprotect[Take, Drop, Position, Join, Append, Prepend, Length, Part, Plus];
   Take[s_String, pos_] := StringTake[s, pos];
   Drop[s_String, pos_] := StringDrop[s, pos];
   HoldPattern[Part[s_String, n_]] := StringTake[s, {n, n}];
   Join[ss__String] := StringJoin[ss];
   Append[s_String, ss_String] := StringJoin[s, ss];
   Prepend[s_String, ss_String] := StringJoin[ss, s];
   Length[s_String] := StringLength[s];
   Plus = 
    Function[Null, 
      If[MatchQ[{##}, {__String}],
        StringJoin[##],
        (* else *)
        Module[{result, ov = OwnValues[Plus]},
          Unprotect[Plus];
          OwnValues[Plus] = {};
          result = Plus[##];
          OwnValues[Plus] = ov;
          Protect[Plus];
          result]]];
   Protect[Take, Drop, Position, Join, Append, Prepend, Length, Part, Plus];
   code
];

This is not a complete set of things you can do, just an example. Because I used Internal`InheritedBlock, the global versions of functions Part etc are never modified, so this is safe in the sense that it does not have system-wide effects. With Plus, I had to go through some pain, since it has an Orderless attribute and I did not want to alter that, but wanted to avoid sorting when arguments are strings.
Some examples:
In[31]:= withStringManipulations[""a""+""b""+""c""]
Out[31]= abc

In[32]:= withStringManipulations[1+2+3]
Out[32]= 6

In[34]:= withStringManipulations[With[{s = ""abc""},Table[s[[i]],{i,Length[s]}]]]//InputForm
Out[34]//InputForm=
 {""a"", ""b"", ""c""}

withStringManipulations[Append[""abc"",""d""]]
Out[37]= abcd

As I said, this is just an example to illustrate the idea. Anyone interested can create their own environments by setting their own rules. This is IMO a very cheap and powerful way to reuse the system functions' syntax to one's liking, without endangering the system. 
Be aware, however, that the above environment is dynamic (in terms of scoping), and so not suitable for example to create higher-order functions which would accept some arbitrary user's code (unless the user knows exactly what the consequences will be, but in practice you as a package-writer can not depend on the user much), since these functions (Part etc) will be also behaving differently in that code. It is also possible to create lexical environments, where the changes will only affect the code literally present inside the environment.
"
evaluation - Context unique to each group at a specified level,"
Now, with v9, I can undelete this answer :)
You could set a context dependent on a certain counter value. 
Add to your stylesheet, to the ""Input"" style, the following option
CellContext:>""Section""<>ToString@CurrentValue[{""CounterValue"", ""Section""}]<>""`""

and in my few tests you get a context dependent on the last section number. It can very probably be expanded to add a title counter and a notebook id
"
Functions with Options - Mathmatica Stack Exchang,"
The main change since that time seems to be that the modern way of using options is associated with  OptionsPattern[] -  OptionValue commands. A typical way of defining a function would be:
Options[f] = {FirstOption -> 1, SecondOption -> 2};
f[x_, y_, opts : OptionsPattern[]] :=
   Print[{x, y, OptionValue[FirstOption], OptionValue[SecondOption]}]

The OptionsPattern[] is a pattern which is similar to ___?OptionQ in its purpose, but has subtle differences, some of which are discussed in this question. In the same question, it is discussed what are the major differences and advantages / disadvantages of old and new approaches. You can still use the old way though. The OptionValue command is a rather magical function, which knows which function you are in, so that you often don't have to supply the function name explicitly. However, you can always do so, since OptionValue has forms with more arguments. What you can not do is to mix the two approaches: if you declare options as ___?OptionQ, then OptionValue won't work.
The second difference is that there is new built-in functions  FilterRules, which can be used to filter options. Previously, there was a package by Maeder called FilterOptions, which provided similar functionality, but was not in the widespread use, just because not everyone knew about it. The typical options filtering call looks like
g[x_, y_, opts : OptionsPattern[]] :=
   f[x, y, Sequence@@FilterRules[{opts}, Options[f]]]

Filtering options is a good practice, so this addition is quite useful.
If you wanted to pass options that belong to other functions (e.g. functions that are called inside your function g) you would do something like this, and it would work even if useQ was actually an option of the function p:
g[x_, y_, opts : OptionsPattern[{g, f, p, q}]] :=
  Module[
    {s = If[OptionValue[useQ], q[y, FilterRules[q]], p[x, FilterRules[p]]]},
    f[x, s, Sequence@@FilterRules[{opts}, Options[f]]] 
  ]

"
VertexSize doesn't scale with Graph layout?,"
Does the following do what you want?
WeightedGraph[edges_, weights_, options___]:=
  Block[{maxweight=Max[#[[2]]&/@weights]},
    Graph[edges,VertexSize->((#[[1]]->0.9*#[[2]]/maxweight)&/@weights),options]]

WeightedGraph[{1 \[UndirectedEdge] 2, 2 \[UndirectedEdge] 3,
               3 \[UndirectedEdge] 1, 3 \[UndirectedEdge] 4},
   (*weights:*) {1 -> 1.1, 2 -> 1.2, 3 -> 1.3, 4 -> 1.4}]


The second line is basically your Graph call, except that it uses WeightedGraph instead of Graph, and the weights don't have VertexSize-> in front of them.
"
syntax - Clear complains that a subscripted variable is not a symbol or a string?,"
Your code reveals exactly why Clear complains: Subscript[x, r] is not a Symbol nor a String. When you assign a value to it, you're setting a DownValue not an OwnValue; in other words, you're setting the value of a function not a variable. To use $x_r$ as a symbol, use the Notation` package's function, Symbolize. I'd recommend using it from the palette directly, as it has all of the intricacies already set up for you.  
"
graphics - Antialiasing option behaves weird (polygon edges visible in ContourPlot),"
I believe that forcing anti-aliasing renders the edges of the polygons with alpha transparency, and that where two of these adjoin there is a region that remains partially transparent, through which the background shows.  Example:
Style[plot, Antialiasing -> True, Background -> Magenta]


"
graphics - Inconsistent GraphicsRow behaviour,"
GraphicsRow puts both plots into one GraphicsBox, which means they have to be rendered together.  Since the DensityPlot contains VertexColors it has to be rendered (on some platforms) using the 3D graphics renderer, whose support for Antialiasing is highly hardware dependent.
ContourPlot output normally renders with a 2D graphics engine.  DensityPlot normally renders with a 3D graphics engine.  When you group the two together (via GraphicsRow in this case) it forces them both to render with the 3D graphics engine, and that causes the ContourPlot to have a slightly different appearance.
Take a look at this example, containing only the ContourPlot.  This code forces the ContourPlot to be drawn with a 2D renderer (in my case Quartz, since I'm using a Mac) in one window and a 3D renderer (OpenGL) in another window.  Observer the difference in appearance (at full size):
g = ListContourPlot[
   Table[Sin[i + j^2], {i, 0, 2, 0.05}, {j, 1.2, 2, 0.05}], 
   ColorFunction -> ColorData[""AvocadoColors""], Contours -> 10, 
   Mesh -> False, ImageSize -> 400];

CreateDocument[g, CacheGraphics -> False, 
  ""NotebookRenderingEngine"" -> ""Quartz""];

CreateDocument[g, CacheGraphics -> False, 
  ""NotebookRenderingEngine"" -> ""OpenGL""];


"
plotting - Using GraphHighlight interactively,"
The reason why it fails is because of GraphHighlight. If you're highlighting a single vertex, then it expects an atom and not a list. In other words, it needs to be something like GraphicsHighlight -> 1 instead of GraphicsHighlight -> {1}. However, this is not the case for edges, where even a single edge can be supplied wrapped in a list. 
So the culprit here is the {#2} in VertexShapeFunction -> (...), and all you need to do to fix it is remove the {}. The following code works.
DynamicModule[{selection = {}},
 Dynamic[Graph[{1 \[UndirectedEdge] 2, 2 \[UndirectedEdge] 3, 
    3 \[UndirectedEdge] 1}, PlotLabel -> selection,
   VertexShapeFunction -> (EventHandler[Disk[#1, .1], 
       ""MouseClicked"" :> (selection = #2;)] &),
   EdgeShapeFunction -> (EventHandler[Arrow[#1, .1], 
       ""MouseClicked"" :> (selection = #2;)] &), 
   GraphHighlight -> selection, GraphHighlightStyle -> ""Thick"", 
   ImageSize -> 200]]
 ]


"
remote access - Are later versions of the Front-End compatible with older Kernels?,"
The best thing to do is to test whether you can make the connection manually:
Start Mathematica on your local machine. 
On the toolbar, navigate to Evaluation ► Kernel Configuration Options.
Add a new kernel and configure it. In the dialog, click on Add ... and a Kernel Configuration dialog appears.
Enter an appropriate name for your remote kernel.
Under Basic Options, verify that Launch On is set to Local machine. Additionally, clear the field, Kernel program.
Click on the Advanced Options switch. In the text field called Arguments to MLOpen, enter:
-LinkMode Listen -LinkProtocol TCPIP

Click OK and open up a new Mathematica notebook.
On the toolbar, navigate to Evaluation ► Notebook's Kernel and click on the name of the kernel that you just created.
Evaluate the command:
$Version

inside the notebook. Instead of printing
Mathematica's version number, a message box appears:
MathLink Alert
Link created on:

After this message is a string of characters. This string of characters is a linkname. Record the linkname so that you can use it later, and click OK to close the dialog.
The title bar of the notebook should still say Running... at the top.
While, the local machine is still running that notebook, connect to the remote machine and launch the Mathematica kernel. Inside the kernel, run the command:
$ParentLink = LinkConnect[""linkname"", LinkProtocol->""TCPIP""]

Where ""linkname"" is the linkname you recorded earlier in quotation marks. For example, if the linkname you saw was:
port1@machine.domain.com,port2@machine.domain.com

You would run:
$ParentLink = LinkConnect[
                ""port1@machine.domain.com,port2@machine.domain.com"",
                LinkProtocol->""TCPIP""]

The notebook that is open on the local machine prints out the version of Mathematica you remotely connected to. This indicates that the local machine is successfully using the remote kernel.
"
curated data - Why is Neptune missing from AstronomicalData?,"
AstronomicalData was updated to remove Pluto, so you don't need to anymore.
In[27]:= AstronomicalData[""Planet""]

Out[27]= {""Mercury"", ""Venus"", ""Earth"", ""Mars"", ""Jupiter"", ""Saturn"", ""Uranus"", ""Neptune""}

"
Correct way to handle mysterious NaN` result from MathLink function,"
NaN (or Not-a-Number is used in floating point arithmetic to represent values that are undefined or unrepresentable, such as $0/0,\ \infty/\infty$, etc. Mathematica typically returns Indeterminate for these, but several other languages return NaN.
To work with NaNs, you must load the ComputerArithmetic package as <<ComputerArithmetic` prior to calling your external function. If you don't do so, then Mathematica will treat the NaNs like any other symbol (or perhaps with other, unknown consequences depending on the setup). Loading the package will give you the results as expected, and pattern matching is pretty straightforward too.

"
graphics - Visualizing Rubik's Graph,"
I am not sure this is what you need.  Please see if it helps.  The little cubes are clickable, but not rotatable.  We could put nicely formatted edge labels as well, but I didn't want to do that now as it would slow it down even more.
conf = solved;

Dynamic@Graph[
  Join[
   (conf -> twist[#, conf] &) /@ basic,
   (twist[#, conf] -> conf &) /@ inv /@ basic
   ],

  VertexShapeFunction -> (Inset[
      Button[Graphics3D[#2, Boxed -> False], conf = #2, 
       Appearance -> None], #1, {0.5, 0.5}, #3] &), VertexSize -> 1, 
  EdgeStyle -> Black]


For others than the OP reading this:
You need to download the source of the demonstration, copy everything from the Initialization :> ( ... ) section of the Manipulate, and evaluate it.  The code is very well written and very easy to work with.
"
programming - What's the purpose of the Unique function?,"
Probably the most common use of Unique is in situations when you need a large number of local variables (and sometimes a variable number of local variables) so using Module is either inconvenient or impossible. In that case you can use the construction:
vars= Table[Unique[x],{n}] or something of this kind. You can find a few examples in the archives of the MathGroup. One that I remember being quite pleased with myself can be found here:
http://mathforum.org/kb/thread.jspa?forumID=79&threadID=1185003&messageID=3868818
"
"functions - How to find range in which a number falls, from given list of numbers?","
Interpolation
I propose using Interpolation.
list = Prime ~Array~ 3000;
intf = Interpolation[
         {list, Range@Length@list}\[Transpose],
         InterpolationOrder -> 0
       ];

Then, for point x:
x = 12225.4;

Which[
 x < First@list , {-∞, First@list},
 x > Last@list  , {Last@list, ∞},
 True           , list[[#-1 ;; #]]& @ intf @ x
]


{12211, 12227}



This could all be done inside Interpolation as well:
intf2 =
  Interpolation[
    Join[
      {{First@list, {-∞, 2}}},
      Thread[{Rest@list, Partition[list, 2, 1]}],
      {{Last@list + 1, {Last@list, ∞}}}
    ],
    InterpolationOrder -> 0
  ];

intf2[12225.4]


{12211, 12227}



Ordering
The method above was written from the perspective of repeated searching within the same list, and as noted in the comments it is assumed that the input list is sorted and free of duplicates.
If these assumptions do not hold other methods become appealing.  After a review of others answers seeking inspiration, including those by kglr, celtschk and Leonid, I find Leonid's use of UnitStep to have great promise but his function is hobbled by the comparatively slow function Position.  We can replace it with a use of Ordering. 

This function requires a sorted list as input, but including the overhead of Sort I still find it faster than other methods I tried such as a separate application of Ordering in an earlier revision of this answer.
I use an explicit Subtract for performance.

Code:
seekOrdered[x_, list_] /; x < First @ list := {-∞, First @ list}

seekOrdered[x_, list_] /; x >= Last @ list := {Last @ list, ∞}

seekOrdered[x_, list_] := 
  list[[# ;; # + 1]] & @@ Ordering[UnitStep @ Subtract[x, list], -1]

Here are comparative timings including Leonid's getInterval, celtschk's function, and a variation of kglr's interval2 using Replace rather than ReplaceList to return a single interval (in the case of ambiguous matches) for somewhat better performance. (Credit to Ali Hashmi for noting this.)
The various functions I am comparing take slightly different interpretations of the end point behavior requested therefore output does not precisely match.  It should be possible to change the behavior of my function with a bit of tinkering should that be required for a particular application.
The other functions as I will be timing them:
getInterval[ints_List, num_] := 
  Position[UnitStep[ints - num], 1, 1, 
    1] /. {{{1}} -> {-Infinity, First@ints}, {} -> {Last@ints, Infinity}, {{n_}} :> 
     ints[[n - 1 ;; n]]};

celtsF[x_, list_List] := 
 Module[{pos = Last@Ordering@Ordering[Append[list, x]]}, 
  Which[pos == 1, {-Infinity, First@list}, 
   pos == Length[list] + 1, {Last@list, Infinity}, True, list[[{pos - 1, pos}]]]]

interval2fast[x_, list_List] := 
 Replace[#, {___, a_, x, b_, ___} :> {a, b}] &@
  Join[{-Infinity}, Sort[Join[list, {x}]], {Infinity}]

Benchmark 1:
list = Prime ~Array~ 3000;

xs = RandomInteger[{-100, 30000}, 5000];

interval2fast[#, list] & /@ xs;  // RepeatedTiming // First
getInterval[list, #] & /@ xs;    // RepeatedTiming // First
celtsF[#, list] & /@ xs;         // RepeatedTiming // First
seekOrdered[#, list] & /@ xs;    // RepeatedTiming // First


1.25
0.5890
0.224
0.114

With a packed input list:
list = Developer`ToPackedArray @ list;

(* other code the same *)


1.16
0.5370
0.129
0.0689

With Reals rather than Integers for the search elements:
xs = RandomReal[{-100, 30000}, 5000];

(* other code the same *)


1.54
0.5674
0.855
0.0981

With Reals rather than Integers for the list:
list = Sort @ RandomReal[27000, 3000];

(* other code the same *)


1.88
0.552
0.129
0.0895

Of course for this repeated application Interpolation is faster still:
intf2 /@ xs; // RepeatedTiming // First // Quiet


0.0112

"
sorting - How to generate Intervals from a given list?,"
Maybe
Partition[Sort@list, 2, 1]

giving

{{1, 3}, {3, 4}, {4, 5}, {5, 7}}

"
trigonometry - How to express trigonometric equation in terms of of given trigonometric function?,"
This is a new version of my answer in response to the edited question (the first version is here). 
It is based on the same idea, but the Weierstrass substitution rules are now generated by Mathematica (instead of entered by hand) and results with $\pm$ solutions are correctly returned.
First, generate the Weierstrass substitution rules
$TrigFns = {Sin, Cos, Tan, Csc, Sec, Cot};
(WRules = $TrigFns == (Through[$TrigFns[x]] /. x -> 2 ArcTan[t] // 
      TrigExpand // Together) // Thread)

Then, Partition[WRules /. Thread[$TrigFns -> Through[$TrigFns[x]]], 2] // TeXForm returns
$$
\begin{align}
 \sin (x)&=\frac{2 t}{t^2+1}\,, & \cos (x)&=\frac{1-t^2}{t^2+1}\,, \\
 \tan (x)&=-\frac{2 t}{t^2-1}\,, & \csc (x)&=\frac{t^2+1}{2 t}\,, \\
 \sec (x)&=\frac{-t^2-1}{t^2-1}\,, & \cot (x)&=\frac{1-t^2}{2 t} \ .
\end{align}
$$
Then, we invert the rules using 
invWRules = #[[1]] -> Solve[#, t, Reals] & /@ WRules

which we can finally use in the convert function:
convert[expr_, (trig : Alternatives@@$TrigFns)[x_]] := 
 Block[{temp, t},
  temp = expr /. x -> 2 ArcTan[t] // TrigExpand // Factor;    
  temp = temp /. (trig /. invWRules) // FullSimplify // Union;
  Or @@ temp /. trig -> HoldForm[trig][x] /. ConditionalExpression -> (#1 &)]

Note that the final line has HoldForm to prevent things like 1/Sin[x] automatically being rewritten as Csc[x], etc...
Here are some test cases - it is straight forward to check that the answers are correct (but don't forget to use RelaseHold):
In[6]:= convert[Sin[x], Cos[x]]
Out[6]= - Sqrt[1 - Cos[x]^2] || Sqrt[1 - Cos[x]^2]

In[7]:= convert[Sin[x]Cos[x], Tan[x]]
Out[7]= Tan[x]/(1 + Tan[x]^2)

In[8]:= convert[Sin[x]Cos[x], Cos[x]]
Out[8]= -Cos[x] Sqrt[1 - Cos[x]^2] || Cos[x] Sqrt[1 - Cos[x]^2]

In[9]:= convert[Sin[2x]Cos[x], Sin[x]]
Out[9]= -2 Sin[x] (-1 + Sin[x]^2)

In[10]:= convert[Sin[2x]Tan[x]^3, Cos[x]]
Out[10]= 2 (-2 + 1/Cos[x]^2 + Cos[x]^2)


A couple of quick thoughts about the above solution:

It assumes real arguments for the trig functions. It would be nice if it didn't do this and could be extended to hyperbolic trig and exponential functions.
When two solutions are given, it should return the domains of validity - or combine the appropriate terms using Abs[].
It should be extended to handle things like convert[Sin[x], Cos[2x]].

If anyone feels like implementing any of these things, please feel free!
"
performance tuning - Can a Trie be implemented efficiently?,"
UPDATE
Since version 10, we have Associations. Here is the modified code for trie building and querying, based on Associations. It is almost the same as the old code (which is below):
ClearAll[makeTreeAssoc];
makeTreeAssoc[wrds : {__String}] := Association@makeTreeAssoc[Characters[wrds]];
makeTreeAssoc[wrds_ /; MemberQ[wrds, {}]] := 
    Prepend[makeTreeAssoc[DeleteCases[wrds, {}]], {} -> {}];
makeTreeAssoc[wrds_] := 
   Reap[
     If[# =!= {}, Sow[Rest[#], First@#]] & /@ wrds, 
     _, 
     #1 -> Association@makeTreeAssoc[#2] &
   ][[2]]

You can see that the only difference is that Association is added to a couple of places, otherwise it's the same code. The lookup functions also are very similar:
ClearAll[getSubTreeAssoc];
getSubTreeAssoc[word_String, tree_] := Fold[Compose, tree, Characters[word]]

ClearAll[inTreeQAssoc];
inTreeQAssoc[word_String, tree_] := KeyExistsQ[getSubTreeAssoc[word, tree], {}]

The tests similar to the ones below (for entire dictionary) show that the lookup based on this trie (Associations - based) is about 3 times faster than the one based on rules, for a trie built from a dictionary. The new implementation of getWords is left as an exercise to the reader (in fact, that function could be optimized a lot, by storing entire words as leaves in the tree, so that one doesn't have to use StringJoin and combine the words).

A combination of rules and recursion is able to produce rather powerful solutions. Here is my take on it:
ClearAll[makeTree];
makeTree[wrds : {__String}] := makeTree[Characters[wrds]];
makeTree[wrds_ /; MemberQ[wrds, {}]] := 
     Prepend[makeTree[DeleteCases[wrds, {}]], {} -> {}];
makeTree[wrds_] := 
    Reap[If[# =!= {}, Sow[Rest[#], First@#]] & /@ 
       wrds, _, #1 -> makeTree[#2] &][[2]]

ClearAll[getSubTree];
getSubTree[word_String, tree_] := Fold[#2 /. #1 &, tree, Characters[word]]

ClearAll[inTreeQ];
inTreeQ[word_String, tree_] :=  MemberQ[getSubTree[word, tree], {} -> {}]

ClearAll[getWords];
getWords[start_String, tree_] :=
  Module[{wordStack = {}, charStack = {}, words},
    words[{} -> {}] :=
      wordStack = {wordStack, StringJoin[charStack]};
    words[sl_ -> ll_List] :=
      Module[{},
        charStack = {charStack, sl};
        words /@ ll;
        charStack = First@charStack;
      ];
    words[First@Fold[{#2 -> #1} &, getSubTree[start, tree], 
         Reverse@Characters[start]]
    ];
    ClearAll[words];
    Flatten@wordStack];

The last function serves to collect the words from a tree, by performing a depth-first tree traversal and maintaining the stack of accumulated characters and words. 
Here is a short example:
In[40]:= words = DictionaryLookup[""absc*""]
Out[40]= {abscess,abscessed,abscesses,abscessing,abscissa,abscissae,abscissas,
   abscission,abscond,absconded,absconder,absconders,absconding,absconds}

In[41]:= tree = makeTree[words]
Out[41]= {a->{b->{s->{c->{e->{s->{s->{{}->{},e->{d->{{}->{}},s->{{}->{}}},
      i->{n->{g->{{}->{}}}}}}},i->{s->{s->{a->{{}->{},e->{{}->{}},s->{{}->{}}},
        i->{o->{n->{{}->{}}}}}}},o->{n->{d->{{}->{},e->{d->{{}->{}},r->{{}->{},s->{{}->{}}}},
       i->{n->{g->{{}->{}}}},s->{{}->{}}}}}}}}}}

In[47]:= inTreeQ[#,tree]&/@words
Out[47]= {True,True,True,True,True,True,True,True,True,True,True,True,True,True}

In[48]:= inTreeQ[""absd"",tree] 
Out[48]= False

In[124]:= getWords[""absce"", tree]
Out[124]= {""abscess"", ""abscessed"", ""abscesses"", ""abscessing""}

I only constructed here a bare-bones tree, so you can only test whether or not the word is there, but not keep any other info. Here is a larger example:
In[125]:= allWords =  DictionaryLookup[""*""];

In[126]:= (allTree = makeTree[allWords]);//Timing
Out[126]= {5.375,Null}

In[127]:= And@@Map[inTreeQ[#,allTree]&,allWords]//Timing
Out[127]= {1.735,True}

In[128]:= getWords[""pro"",allTree]//Short//Timing
Out[128]= {0.015,{pro,proactive,proactively,probabilist,
    <<741>>,proximate,proximately,proximity,proxy}}

In[129]:= DictionaryLookup[""pro*""]//Short//Timing
Out[129]= {0.032,{pro,proactive,proactively,probabilist,<<741>>,
    proximate,proximately,proximity,proxy}}

I don't know which approach has been used for the built-in functionality, but the above implementation seems to be generally in the same calss for performance. The slowest part is due to the top-level tree-traversing code in getWords. It is slow because the top-level code is slow. One could speed it up considerably by hashing words to integers - then it can be Compiled. This is how I'd do that, if I were really concerned with speed.
EDIT
For a really nice application of a Trie data structure, where it allows us to achieve major speed-up (w.r.t. using DictionaryLookup, for example), see this post, where it was used it to implement an efficient Boggle solver.
"
performance tuning - Fastest square number test,"
Here's an idea similar to Carl Woll's that's a little faster:
sQ[n_] := FractionalPart@Sqrt[n + 0``1] == 0;
sQa = FractionalPart@Sqrt[# + 0``1] == 0 &; (* @Roman's suggestion *)

@Roman reports the pure function is 10% faster. I find on several runs of timeRun[] below, the variation in the timings cause them to overlap, with sQa sometimes timed slower than sQ. The median for sQa is around 5–6% faster. If I change AbsoluteTiming to Timing in timeRun[], sQ and sQa finish in a dead heat, ±2% of each other. Theoretically, I would expect pure functions to have less overhead, but it would be a small difference compared to the time Sqrt[n + 0``1] will take.  Maybe %5 is about right. It's difficult to time computations in a multiprocess environment like my laptop. The upshot is that sQa appears to be a bit faster.

Here are some timing runs similar to @fgrieu's:
timeRun[f_] := Module[{a, m},
  a = (2^1024 - 3^644)^2;
  m = (2^1024 - 3^644)^2 + 9;
  First@ AbsoluteTiming@ Do[f[n], {n, m - 200000, m}]
  ]

timeRun2[f_] :=
  First@ AbsoluteTiming[
   Do[
    f /@ (n^2 + {-2, -1, 0, 1, 2}),
    {n, 2^1357, 0, -Floor[2^1357/99]}]
   ];

Tests of a long sequence of consecutive integers about single large square number:
timeRun[sQ]
timeRun[SqQ]
timeRun[sqQ1]
timeRun[SquareQ2]
timeRun[SquareQ08]
(*
  0.626601  sQ
  0.789668  SqQ (@fgrieu)
  1.11774   sqQ1 (@CarlWoll)
  1.63489   SquareQ2 (@Mr.Wizard)
  3.39258   SquareQ08 (@KennyColnago)
*)

Tests of short sequences of consecutive integers about many small to large square numbers:
timeRun2[sQ] 
timeRun2[SqQ] 
timeRun2[sqQ1] 
timeRun2[SquareQ2] 
timeRun2[SquareQ08] 
(*
  0.002639   sQ
  0.003289   SqQ
  0.0039     sqQ1
  0.005791   SquareQ2
  0.01749    SquareQ08
*)

A test of just smaller numbers:
aa = 1; bb = 10^6;
AbsoluteTiming@Do[sQ@(n), {n, aa, bb}]
AbsoluteTiming@Do[SqQ@(n), {n, aa, bb}]
AbsoluteTiming@Do[sqQ1@(n), {n, aa, bb}]
AbsoluteTiming@Do[SquareQ2@(n), {n, aa, bb}]
AbsoluteTiming@Do[SquareQ08@(n), {n, aa, bb}]
(*
  {2.34658, Null}
  {3.2571,  Null}
  {3.18561, Null}
  {3.42899, Null}
  {3.25997, Null}
*)


If you want to verify its accuracy, you can test it against other solutions like this:
aa = 10^20 - 100; bb = aa + 10^3;
Table[sQ[n], {n, aa, bb}] === Table[IntegerQ@Sqrt[n], {n, aa, bb}]
(*  True  *)

aa = 1; bb = 10^6;
Table[sQ[n], {n, aa, bb}] === Table[IntegerQ@Sqrt[n], {n, aa, bb}]
(*  True  *)

"
numerics - How to guarantee that NDSolve correctly detects abrupt changes in parameters?,"
There is an (undocumented?) feature of NDSolve which is handy for exactly this purpose: You can add more than just the start and end of the integration interval and enforce that these points will be met. The result is like you would run NDSolve on each of the corresponding intervals with the starting conditions given by the end point of the previous interval. This would do what you want for your example: 
variation[x_?NumericQ] := Which[
   x < 10, 1, x < 15, 0, x < 15.1, 10, x < 20, 0, x < 30, 1, True,0
];
points = {};
ans = accumulation /. 
  Flatten[NDSolve[{accumulation'[x] == variation[x], 
     accumulation[0] == 0}, 
     accumulation, {x, 0, 10, 15, 15.1, 20, 30, 40}, 
     StepMonitor :> AppendTo[points, {x, accumulation[x]}]]];

Show[
 Plot[ans[x], {x, 0, 40}],
 ListPlot[points, PlotStyle -> Red]
]


"
"front end - Saving a notebook as PDF, preserving syntax highlighting","
The default style sheets set ShowSyntaxStyles -> False for the ""Printout"" environment.
You could change the notebook to use a style sheet that doesn't set this.  Probably the easiest way is to copy the definition from Default.nb, and modify it:
Cell[StyleData[All, ""Printout""],
 ShowSyntaxStyles->True]

"
debugging - Inspecting non-variable state from a breakpoint in Workbench,"
You can enter arbitrary expressions in the Expressions debugging view:

The function VariableValue must be used in such expressions in order to access any active variables.
If the Expressions view is not visible, you can open it from the Workbench main menu using Window / Show View... / Expressions.
"
output formatting - Converting a large floating-point number to a single-line string,"
Admittedly hackish, but you could use
numbers = RandomReal[10^10, 3]

ToString[ToString[#, CForm] & /@ numbers]

or
ToString[ToString[#, FortranForm] & /@ numbers]

It gives
{3.672422352722051e9, 8.491123505444411e9, 1.7587409493599138e9} 

Mathematica usually likes to wrap long lines.  This won't happen here because by default ToString uses PageWidth -> Infinity
"
notebooks - How to export to HTML and not lose Grid Frame in the generated HTML?,"
Following my comment on your question, if you add
table
{
border-collapse:collapse;
}
table, td, th
{
border:1px solid black;
}

at the beginning of the css file, you will get:

"
"parallelization - How can we implement ""Sleep Sort""?","
Here is an implementation that uses the scheduled tasks in version 8:
sleepSort[l_, t_:0.1] :=
  Scan[RunScheduledTask[Print[#];RemoveScheduledTask[$ScheduledTask], {t #}]&, l]

In a notebook environment, output will appear in the messages window.  The time interval is specified as the optional second argument, defaulting to 1/10th of a second (I'm impatient).  Don't set it too low, though -- the vagaries of the timing might produce results out of order.
"
document creation - Generating a table of contents,"

A bit of warning from the OP: this code locked-up my Mathematica session, so be sure to save everything before you try this. Update: Problem seems to be related to a problem MMA has with paginating a particular notebook of mine (see comments).

This code creates a separate TOC for a notebook saved at the location bookUrl. It works by iterating over all the cells in the book. If a cell is encountered whose type is in typeList, a tag is added to the cell and a line is written to the TOC notebook. We use CounterBox[""Page"", {bookUrl, tag}] to print the appropriate page number. 
Note that due to the nature of CounterBox, the page numbers are only shown in the TOC is the notebook of the book is open and ShowPageBreaks -> True is set, but you should be able to print the TOC to a pdf.
createToc[bookUrl_, typeList_] :=
  Module[{toc, book, createCell, counter, cell, type, tag},

    (*create TOC file and open book*)
    toc = CreateDocument[];
    book = NotebookOpen[bookUrl];
    SetOptions[book, ShowPageBreaks -> True];

    (* helper file for creating cell *)
    createCell[text_, tag_, level_] := Cell[BoxData[
         TagBox[GridBox[{{"""", text, CounterBox[""Page"", {bookUrl, tag}]}},  
           GridBoxAlignment -> {""Columns"" -> {Left, Left, Right}}, 
           GridBoxItemSize -> {""Columns"" -> {2 level - 1, 35 - 2 level, 5}}], 
          ""Grid""]], ""Text""];

    (* iterate over cells to set tags and write lines to TOC *)
    Scan[(counter[#] = 0) &, typeList];
    SelectionMove[book, Before, Notebook];
    SelectionMove[book, Next, Cell];
    While[(cell = NotebookRead[book]) =!= {},
      If[Length[cell] >= 2,
       type = cell[[2]];
       If[MemberQ[typeList, type],
        counter[type] += 1;
        tag = type <> ToString[counter[type]];
        SetOptions[NotebookSelection[book], 
         CellTags -> Union[Flatten[{Options[NotebookSelection[book], 
           CellTags][[1, 2]], tag}]]];
        SelectionMove[book, All, CellContents];
        NotebookWrite[toc, 
         createCell[NotebookRead[book], tag, 
          Position[typeList, type][[1, 1]]]]];
       SelectionMove[book, Next, Cell]]];
    SetSelectedNotebook[toc]];

To see the code in action, lets create a very simple document with 2 sections and 3 subsections on 3 pages
book = CreateDocument[];
NotebookWrite[book, Cell[""This is section 1"", ""Section""]];
NotebookWrite[book, Cell[""This is a subsection"", ""Subsection""]];
NotebookWrite[book, Cell[""This is some text"", ""Text""]];
NotebookWrite[book, 
  Cell[""Another section which begins on a new page"", ""Section"", 
   PageBreakAbove -> True]];
NotebookWrite[book, 
  Cell[""Subsection 2.1"", ""Subsection"", PageBreakBelow -> True]];
NotebookWrite[book, Cell[""Subsection 2.2"", ""Subsection""]];
bookUrl = ExpandFileName[""book1.nb""];
NotebookSave[book, bookUrl];

Then createToc[bookUrl, {""Section"", ""Subsection""}] creates something like this

"
numerics - How to use NDSolve to track equilibrium?,"
This approach finds equilibrium by checking that all derivatives up to the order of the differential equation are below a threshold. Following the template (defined below) suggested by the OP, here is an example for a damped harmonic oscillator:
Needs[""DifferentialEquations`InterpolatingFunctionAnatomy`""];

eqns1 = {a''[t] == Pi^2/2500 - (Pi^2*a[t])/2500 - 0.02*a'[t], 
         a[0] == 0., a'[0] == 0};

steps1 = {};    
sol1 = equilibriumNDSolve[eqns1, {a}, {t, 0, 1000}, a, 
                          equilibriumThreshold -> 1*^-5, 
                          equilibriumStepMonitor :> AppendTo[steps1, t]];

end1 = InterpolatingFunctionDomain[a /. sol1[[1]]][[1, 2]];
Plot[a[t] /. sol1, {t, 0, end1}, PlotRange -> {0, 2}, 
     Prolog -> {Thin, Dashed, Line[{{#, 0}, {#, 2}}] & /@ steps1[[1 ;; -1 ;; 2]]}, 
     PlotStyle -> Thick, AxesLabel -> {t, a[t]}]

stops early (t=656.59), giving

The dashed vertical lines show the step monitor times. That is a 2nd order differential equation. The OP's example is a first order differential equation:
eqns2 = {Derivative[1][a][t] == -a[t] - 0.2` a[t]^2 + 2.1` b[t], Derivative[1][b][t] == a[t] + 0.1` a[t]^2 - 1.1` b[t], a[0] == 0.5`, b[0] == 0.5`};

steps2 = {};
sol2 = equilibriumNDSolve[eqns2, {a, b}, {t, 0, 1000}, a + b, 
                          equilibriumThreshold -> 1*^-3, 
                          equilibriumStepMonitor :> AppendTo[steps2, t]];
end2 = InterpolatingFunctionDomain[a /. sol2[[1]]][[1, 2]];
Plot[Evaluate[{a[t], b[t]} /. sol2], {t, 0, end2}, PlotRange -> Automatic, 
     Prolog -> {Thin, Dashed, Line[{{#, 0}, {#, 1100}}] & /@ steps2}, 
     PlotStyle -> Thick, AxesLabel -> {t, Row[{a[t], "", "", b[t]}]}]

uses a threshold of 1*^-3, and stops at t=465.234:

Here is the definition of equilibriumNDSolve[]:
Clear[equilibriumNDSolve];
Options[equilibriumNDSolve] = {equilibriumThreshold :> 1*^-5, equilibriumStepMonitor -> None};
equilibriumNDSolve[eqns_, vars_, {t_, start_, finish_}, equilibriumexpr_, opts : OptionsPattern[]] := 
  Module[{threshold, order},
    threshold = OptionValue[equilibriumThreshold];
    order = Max[Cases[eqns, Derivative[n_][_][_] :> n, Infinity]];
    NDSolve[eqns, vars, {t, start, finish}, Method -> {""EventLocator"", 
      ""Event"" -> And @@ ((Distribute@Abs[Through[
         Distribute[Derivative[#][equilibriumexpr]][t], Plus]] <threshold) & /@    Range[order])}, 
      StepMonitor :> OptionValue[equilibriumStepMonitor]]]

The key part is the ""EventLocator"" method of NDSolve, as pointed out by Sjoerd and Szabolcs. 
The function expects the stopping criterion (equilibriumexpr) to involve at most the addition of the NDSolve variables (more complicated expressions do not work as-is). The transformation of equilibriumexpr into an Event is not clean (i.e., not easy to follow), and may not be robust, but it works for the two cases above.
"
front end - Programmatically copy code so that all output is commented out,"
This is inspired by Rolfs answer, but uses the ""Copy As Input"" functionality as the starting point. My impression is that using that approach will keep more of the original formatting (concerning linebreaks) but it still isn't perfect in that concern. To see the problems, I didn't change what it does to the its own code (it added some empty lines). 
Other differences are that it will look at the current selection instead of using all the content of the selected notebook. And it adds the spaces at the begining of each line so it will directly be recognized as code when pasted into the edit window. 
It can't handle correctly anything except input and output cells that have an In/Out tag, otherwise the splitting in input and output cells will not work (although I think it will create something that's not completely useless in those cases...). 
CreatePalette[
 Tooltip[
  Button[
   ""Copy for MSE"",
   FrontEndTokenExecute[SelectedNotebook[], ""CopySpecial"", 
    ""InputText""];
   Map[
    CreateDocument[TextCell[#, ""Text"", FontFamily -> ""Courier""]] &,
    Cases[
     NotebookGet[ClipboardNotebook[]],
     Cell[c_String, ___] :> ""    "" <> StringReplace[
        StringJoin[Riffle[
          StringReplace[

           StringTrim[
            StringSplit[
             c, (""In"" | ""Out"") ~~ ""["" ~~ DigitCharacter .. ~~ ""]""]], {

            StartOfString ~~ "":="" ~~ WhitespaceCharacter ~~ input__ :>
              input,

            StartOfString ~~ ""="" ~~ WhitespaceCharacter ~~ output__ :>
              ""(*\n==> "" <> output <> ""\n*)""
            }
           ],
          ""\n\n""
          ]],
        ""\n"" -> ""\n    ""
        ],
     Infinity
     ]
    ],
   Method -> ""Queued""
   ],
  ""Copy formatted for use in MSE""
  ],
   Saveable -> False
 ]

"
numerics - Strategies to avoid LessEqual::nord in NMinimize?,"
I think you have to do the same as in many such cases: protect your arguments to be strictly numerical:
f[a_?NumericQ, b_?NumericQ] := Abs[(a + I b)^(3/2)];

And  then no problems:
NMinimize[f[a,b],{a,b}]

(*
 ==>  {1.11868*10^-26,{a->3.9489*10^-18,b->3.07007*10^-18}}
*)

Edit:
The following function automatically packs the expression into a function with _?NumericQ pattern arguments:
NOptimize[optfunc_,expr_,vars_,options___]:=
  Module[{f,
          varlist=If[ListQ[vars],vars,{vars}],
          expression=If[ListQ[expr],First@expr,expr],
          conditions=If[ListQ[expr],Rest@expr,{}]},
    Evaluate[f@@(Pattern[#,_?NumericQ]&/@varlist)]=expression;
    optfunc[{f@@varlist}~Join~conditions,vars,options]]

It can be used as follows:
NOptimize[NMinimize, a^2, a, AccuracyGoal->0.01]
(*
--> {2.39829*10^-33,{a->4.89724*10^-17}}
*)

or with constraints:
NOptimize[NMinimize, {a^2, a>3}, a, AccuracyGoal->0.01]
(*
--> {9.,{a->3.}}
*)

The following shows that it indeed solves the problem with LessEqual::Nord:
NOptimize[NMinimize,Abs[(a+I b)^(3/2)],{a,b}]
(*
--> {9.06219*10^-27,{a->4.31982*10^-18,b->4.8223*10^-19}}
*)

"
numerics - What determines the value of $MaxNumber?,"
If you calculate  Log[2,Log[2,$MaxNumber]], you'll get 29.999999828017338886225739 which is remarkably close to 30. Therefore I conclude that Mathematica calculates with a 31-bit exponent (1 bit for the exponent's sign). Which means that if Mathematica uses the same ordering as IEEE floats (i.e. first sign bit, then exponent, then mantissa), the first 32 bits (i.e. exactly 4 bytes) of a Mathematica floating point number contain the sign and the exponent.
"
import - Operations on online files via public URL access,"
Here's one approach, though it's hard to say without knowing the site and what additional information you want for the files.
Import[""http://kaurov.com"", {""HTML"", ""Images""}]


There are several other items you can ask for (including what elements you can ask for!)
In[53]:= Import[""http://kaurov.com"", {""HTML"", ""Elements""}]

Out[53]= {""Data"", ""FullData"", ""Hyperlinks"", ""ImageLinks"", ""Images"",
""Plaintext"", ""Source"", ""Title"", ""XMLObject""}

In[54]:= Import[""http://kaurov.com"", {""HTML"", ""ImageLinks""}]

Out[54]= {""http://kaurov.com/wordpress/wp-content/uploads/2011/10/masterimagelfss.jpg"",            
   ...
   ""http://kaurov.com/wordpress/wp-content/uploads/2009/11/life-death-spinner.gif""}

"
graphics - How can I share objects with dynamic content with non-Mathematica users?,"
You do not need to export an applet to be able to share things with non-Mathematica users. If you save your stuff as a CDF then other non-Mathematica people will be able to use it both on their desktops or view it in webpages (if you choose to embed your CDFs in a webpage). You can do this via File > Deploy

See also ref/format/CDF in the documentation center and the How To that is linked at the bottom.
Also some additional things that may help you:
#1
#2
#3
"
mathlink or wstp - Is it possible to use C# LINQ from Mathematica using .NET/Link?,"
Yes, it is, but it's cumbersome (at least as of Mathematica 8). The hardest part is that you have to manually do a lot of the juggling required to work with .NET generics and extension methods.
For example, let's translate a straightforward solution to Project Euler's Problem #1 (""Add all the natural numbers below one thousand that are multiples of 3 or 5."") from LINQ:
Enumerable.Range(1, 999)
.Where(x => x % 5 == 0 || x % 3 == 0)
.Sum();

To .NET/Link:
(* Load stuff. *)
<< NETLink`;
InstallNET[];
LoadNETType[""System.Linq.Enumerable""];

(* Create our enumerable list of numbers. *)
numbers = Enumerable`Range[1,999];

(* Create the filter that we're going to apply. *)
enumerableType = GetTypeObject[LoadNETType[""System.Linq.Enumerable""]];
meths = enumerableType@GetMethods[];
whereMethod = First[Select[meths, #@Name == ""Where"" && Length[#@GetParameters[]] == 2&]];
intTypeParams = {GetTypeObject[LoadNETType[""System.Int32""]]};
intWhereMethod = whereMethod@MakeGenericMethod[intTypeParams];
divisibleByThreeOrFive[n_] := Or[Mod[n, 3] == 0, Mod[n, 5] == 0];
whereCondition = NETNewDelegate[""System.Func`2[System.Int32,System.Boolean]"", divisibleByThreeOrFive];

(* Apply the filter to the list. *)
filteredNumbers = intWhereMethod@Invoke[Null, {numbers, whereCondition}];

(* Pump all the results through the filter and Sum. *)
Enumerable`Sum[filteredNumbers]

"
string manipulation - What's a robust way to insert another extension into a filename?,"
Here's my non-regex solution (but it does use a ""String Pattern"", which is equivalent to regex). I think it is robust.
insertExtension[fn_String, piece_String] := 
 Module[{split = FileNameSplit[fn], temp},
  temp = Insert[StringSplit[Last[split], "".""], piece, 2];
  temp = StringJoin[Riffle[temp, "".""]];
  FileNameJoin[Append[Most[split], temp]]]

Test:
In[]:= insertExtension[""/home/me.em/dir.ab/nomnom.tar.gz"", ""123""]

Out[]= ""/home/me.em/dir.ab/nomnom.123.tar.gz""

"
Is it possible to import dates and times directly as AbsoluteTime and by pass DateLists?,"
The data in the file test.xls are

03/Jan/2000   45.46
  04/Jan/2000   43.92
  05/Jan/2000   44.38
  06/Jan/2000   42.9
  07/Jan/2000   43.46
  10/Jan/2000   43.78
  11/Jan/2000   42.65
  12/Jan/2000   41.26
  13/Jan/2000   42.04
  14/Jan/2000   43.78


An alternative approach is to exploit the fact that Office documents are zipped collections of XML files. So, 
Step 1: rename the source file by adding .zip to the file name: test.xlsx.zip.
Step 2: Import the appropriate xml file in the zip file, extract the data elements and re-format:
 Cases[Import[""C:\\ your directory \\test.xlsx.zip"", {""ZIP"", ""xl\\worksheets\\sheet1.xml""}], 
  XMLElement[""v"", {}, {value_}] :> value, Infinity] 
  // Partition[#, 2] &

This gives:

{{""36528"", ""45.46""}, {""36529"", ""43.92""}, {""36530"", ""44.38""}, {""36531"",
     ""42.9""}, {""36532"", ""43.46""}, {""36535"", ""43.78""}, {""36536"", 
    ""42.65""}, {""36537"", ""41.26""}, {""36538"", ""42.04""}, {""36539"", 
    ""43.78""}}

where the first entry in each sublist is Excel's DATEVALUE (serial date number that counts the number of days from 1/1/1900). 
Puzzle: I would expect that converting Excel's DATEVALUE to Mathematica's AbsoluteTime (number of seconds from 1/1/1900) would be as simple as multiplying the former by 24*60*60. But doing that with:
  excelDateValues = {""36528"", ""36529"", ""36530"", ""36531"", ""36532"", ""36535"", ""36536"", ""36537"", ""36538"", ""36539""}

and 
  DateList /@ (24*60*60*ToExpression@excelDateValues)

gives

{{2000, 1, 5, 0, 0, 0.}, {2000, 1, 6, 0, 0, 0.}, {2000, 1, 7, 0, 0, 0.}, 
  {2000, 1, 8, 0, 0, 0.}, {2000, 1, 9, 0, 0, 0.}, {2000, 1, 12,  0, 0, 0.}, 
  {2000, 1, 13, 0, 0, 0.}, {2000, 1, 14, 0, 0, 0.}, {2000, 1, 15, 0, 0, 0.}, 
  {2000, 1, 16, 0, 0, 0.}}


which is off by two days. Hopefully, there is a less naive approach to the get the right conversion factor to go from excel Datevalues to Mma AbsoluteTime so that a modified version of Cases[] above gives the desired result. 
Puzzle resolved:  Thanks to Mr.Wizard's reference, the historical background to the two-day discrepancy is explained beautifully in Joel Spolsky's great story  . So, unless your data does contain dates going back early 1900's for most cases just subtracting 2 from final output dates should be ok. But ... things can get more complicated considering possible excel date system settings and varying defaults accross OSs. (see XL 1900 and 1904 date systems)
EDIT: Import uses the filename extension if no format is provided as the second argument. For zip files it returns the filenames in the zipped archive. For the example case
   Import[""C:\\ your directory \\test.xlsx.zip""]

returns

 {""[Content_Types].xml"", ""_rels\\.rels"",""xl\\_rels\\workbook.xml.rels"", ""xl\\workbook.xml"", ""xl\\styles.xml"",  ""xl\\worksheets\\sheet1.xml"", ""xl\\theme\\theme1.xml"", ""customXml\\item1.xml"", ""customXml\\_rels\\item1.xml.rels"", ""customXml\\_rels\\item2.xml.rels"", ""docProps\\app.xml"", ""customXml\\itemProps2.xml"", ""customXml\\item2.xml"", ""customXml\\itemProps1.xml"", ""docProps\\core.xml""}


"
computational geometry - Intersecting graphics,"
How about RegionPlot?
RegionPlot[
  {
   (x - 0.2)^2 + y^2 < 0.5 && 0 < x < 1 && 0 < y < 1,
   (x - 0.2)^2 + y^2 < 0.5 && ! (0 < x < 1 && 0 < y < 1),
   ! ((x - 0.2)^2 + y^2 < 0.5) && 0 < x < 1 && 0 < y < 1
  }, 
   {x, -1, 1.5}, {y, -1, 1.5}, 
   PlotStyle -> {Red, Yellow, Blue}
]


EDIT in response to Szabolcs's comment:
PointInPoly[{x_, y_}, poly_List] := 
 Module[{i, j, c = False, npol = Length[poly]}, 
  For[i = 1; j = npol, i <= npol, j = i++, 
   If[((((poly[[i, 2]] <= y) && (y < 
             poly[[j, 2]])) || ((poly[[j, 2]] <= y) && (y < 
             poly[[i, 2]]))) && (x < (poly[[j, 1]] - 
             poly[[i, 1]])*(y - poly[[i, 2]])/(poly[[j, 2]] - 
              poly[[i, 2]]) + poly[[i, 1]])), c = ¬ c];];
  c]

(from an answer I gave in MathGroup)
RegionPlot[{
   PointInPoly[{x, y}, {{1, 3}, {3, 4}, {4, 7}, {5, -1}, {3, -3}}] && 
   PointInPoly[{x, y}, {{2, 2}, {3, 3}, {4, 2}, {0, 0}}], 
   PointInPoly[{x, y}, {{1, 3}, {3, 4}, {4, 7}, {5, -1}, {3, -3}}] &&
   ¬ PointInPoly[{x, y}, {{2, 2}, {3, 3}, {4, 2}, {0, 0}}],
   ¬ PointInPoly[{x, y}, {{1, 3}, {3, 4}, {4, 7}, {5, -1}, {3, -3}}] &&
   PointInPoly[{x, y}, {{2, 2}, {3, 3}, {4, 2}, {0, 0}}]}, 
  {x, 0, 6}, {y, -4, 8}, 
  PlotPoints -> 100, PlotStyle -> {Red, Yellow, Blue}
]


"
coding style - Placement of Condition /; expressions,"
I prefer the Condition to appear on the left-hand-side and outside the square brackets for several reasons.
Type signature
I often think of the condition as (part of) the analog of the signature in a typed language, so it should go on the left hand side.
Order of operations
I like that the elements of the function definition appear in the order in which I want them to happen:
f[x_] /; x > 0 := Sqrt[x]


Look for f[x_].
Check that x > 0.
Return Sqrt[x].
(Optional) Check any postcondition (see below).

Function contract
When an argument-checking definition of the form
f[else___] := Throw[""Error in f.""]

appears, a left-hand-side Condition often plays the role of a precondition in the sense of Design By Contract. A Condition can also appear on the right-hand-side and this plays the role of a postcondition:
f[x_] /; x > 0 := Sqrt[x] /; Sqrt[x] > 0

Consistency of appearance
I prefer f[x_] /; x > 0 to the alternative f[x_ /; x > 0] for consistency, because sometimes placing the Condition inside the square brackets is not possible, such as when the Condition depends on multiple arguments:
f[x_, y_] /; x > y := 1/(x - y)

Update: Rationale
I think Brett's preference of putting the Condition as close as possible to the quantity to which it applies is equally good so I want to explain why I ended up with my slightly different preference.
Basically I was writing a sequence of definitions like this, following Brett's guideline:
f[x_ /; c1[x], y_] := this
f[x_, y_ /; c2[y]] := that
f[x_, y_] /; c3[x, y] := other

Note that all of these define f[x, y]. So there are two things I didn't like about that:

The key difference between each LHS is the different conditions on x and y, and these are difficult to read quickly here because they all start at different places and are mixed in with f[x_, y_].
When a condition needs to change such that it suddenly starts or stops depending on x or y, I need to move it from inside the square brackets to outside or vice versa.

Now compare:
f[x_, y_] /; c1[x] := this
f[x_, y_] /; c2[y] := that
f[x_, y_] /; c3[x, y] := other

Of course, what would make even more sense would be to adhere to Brett's guideline except in special cases like above! Maybe I will try that now ...
"
list manipulation - Unexpected behavior from GatherBy in version 7,"
We can compare the results of the two forms of GatherBy for varying data set sizes:
RandomSeed[1];
ListPlot @ Table[
  RandomInteger[4,{n,3}] /.
  set_ :> { n
         , Boole @ SameQ[
             GatherBy[set, Sort]
           , GatherBy[set, (""x"";Sort@#)&]
           ]
       }
, {n, 1, 300}
]

The x-axis shows the set size and the y-axis shows 1 where the GatherBy results match and 0 where they do not.  The chart shows the set size on the x-axis and The results for Mathematica 7 show a problem when there are 100 or more elements:

Mathematica 8 does not show this problem:

Following @ruebenko's suggestion, let's take a look for a compiler option with the magic number 100:
Cases[""CompileOptions"" /. SystemOptions[], HoldPattern[_ -> 100]]


{FoldCompileLength->100, MapCompileLength->100, NestCompileLength->100}

Some experimentation demonstrates that MapCompileLength is the culprit:
SetSystemOptions[""CompileOptions"" -> ""FoldCompileLength"" -> 100];
SetSystemOptions[""CompileOptions"" -> ""MapCompileLength"" -> 50];
SetSystemOptions[""CompileOptions"" -> ""NestCompileLength"" -> 100];

Recreating the chart after reducing MapCompileLength to 50 produces:

It appears we have a compiler bug involving the compilation of an internal use of Map -- a bug that seems to be fixed in Mathematica 8.
Increasing MapCompileLength to Infinity appears to correct the problem.
"
programming - How do you set attributes on SubValues?,"
Your question really is about how to make attributes of f affect also the evaluation of other groups of elements, like y and z in f[x___][y___][z___]. To my knowledge, you can not do it other than using tricks like returning a pure function and the like. 
This is because, the only tool you have to intercept the stages of evaluation sequence when y and z are evaluated, is the fact the heads are evaluated first. So, anything you can do to divert the evaluation from its standard form (regarding y and z), must be related to evaluation of f[x], in particular substituting it by something like a pure function. Once you pass that stage of head evaluation, you have no more control of how y and z will be evaluated, as far as I know.   
Generally, I see only a few possibilities to imitate this: 

return a pure function with relevant attributes (as discussed in the linked answer)
return an auxiliary symbol with relevant attributes (similar to the first route)
play with evaluation stack. An example of this last possibility can be found in my answer here

Here is another example with Stack, closer to those used in the question:
ClearAll[f];
f := 
  With[{stack = Stack[_]},
   With[{fcallArgs =
      Cases[stack, HoldForm[f[x_][y_]] :>
         {ToString[Unevaluated[x]], ToString[Unevaluated[y]]}]},
      (First@fcallArgs &) & /; fcallArgs =!= {}]];

And:
In[34]:= f[1 + 2][3 + 4] // InputForm
Out[34]//InputForm=  {""1 + 2"", ""3 + 4""}

Perhaps, there are other ways I am not aware of. The general conclusion I made for myself from considering cases like this is that the extent to which one can manipulate evaluation sequence is large but limited, and once you run into a limitation like this, it is best to reconsider the design and find some other approach to the problem, since things will quickly get quite complex and go out of control.
"
interoperability - Interfacing Mathematica with MINE using JLink,"
You don't need JLink for this, because MINE program (Java version) seems to not be able to transmit the results by any data transfer protocol. Rather, you launch it from the command line, as a Java executable (jar file). It takes the name of the input data file as one of the command line parameters, and it writes its output into another file. 
I will illustrate the steps needed to run it from Mathematica on Win7, but they should be similar on other systems.
1.Download MINE.jar and an example file (say Spellman.csv), and save them in some directory. I saved them in a directory C:\Temp\MINE
2.Find out the location of the Java runtime coming with Mathematica. One way to do this is to run 
Needs[""JLink`""]
InstallJava[]

(* 
-->

LinkObject[""C:\Program Files\Wolfram Research\Mathematica\8.0\SystemFiles\Java\
Windows-x86-  64\bin\javaw"" -classpath ...""]

*)

3.Define these directories:
$MINEDir = ""C:\\Temp\\MINE"";
$JavaDir = ""C:\\Program Files\\Wolfram Research\\Mathematica\\8.0\\SystemFiles
\\Java\\Windows-x86-64\\bin"";

4.Set the current directory to be the one with Java installation:
SetDirectory[$JavaDir]

5.Run this command (for example - this corresponds to an example they show):
stringify[s__String] := StringJoin[""\"""", s, ""\""""]

Run@StringJoin[
  ""javaw -jar "",
  stringify@FileNameJoin[{$MINEDir, ""MINE.jar""}],
  "" "",
  stringify@FileNameJoin[{$MINEDir, ""Spellman.csv""}],
  "" 0 cv=0.7""
]

In practice, the string with parameters you will build dynamically, from the parameter values, of course. Since I don't have a good grasp on possible parameters and their values, I refrained from implementing this, but this is straightforward to do.  Note that stringify is only needed for Windows (probably), to prevent the Windows shell from mis-interpreting spaces. It should return 0 if executed correctly, and you should also see a command-line window popping up and floating for a second or two, that it takes to compute.
6.This shows the data files:
In[8]:= (dataFiles = FileNames[""*.csv"",{$MINEDir}])//InputForm
Out[8]//InputForm=
{""C:\\Temp\\MINE\\Spellman.csv"", 
 ""C:\\Temp\\MINE\\Spellman.csv,mv=0,cv=0.7,B=n^0.6,Results.csv""}

The first one is the original data set. The last one contains the results. It should be possible to automate the identification of which is which.
7.Import the results:
In[9]:= Import[""C:\\Temp\\MINE\\Spellman.csv,mv=0,cv=0.7,B=n^0.6,Results.csv""]//Short[#,3]&

Out[9]//Short= {{X var,Y var,MIC (strength),MIC-p^2 (nonlinearity),MAS (non-monotonicity),
MEV (functionality),MCN (complexity),Linear regression (p)},<<4380>>,{time,<<6>>,0.00775905}}

It should be possible to automate all that, this is just to show the basic steps. I must add that the program does not contain an awful lot of documentation, so figuring out the parameters etc may be not completely trivial.
"
coordinate transformation - Plotting an implicit polar equation,"
Since ContourPlot[] returns a GraphicsComplex, you could also replace the point list of the plot with g @@@ pointlist where g is the coordinate transformation. For example
f[r_, th_] := th^2 - (3 Pi/4)^2 Cos[r]
g[r_, th_] := {r Cos[th], r Sin[th]} 

pl = ContourPlot[f[r, th] == 0, {r, 0, 8 Pi}, {th, 0, 2 Pi}, PlotPoints -> 30];
pl[[1, 1]] = g @@@ pl[[1, 1]];

Show[pl, PlotRange -> All]

which produces

The advantage of this method is that it also works for coordinate transformations for which the inverse transformation is hard to find.
"
algebraic manipulation - How do I replace a variable in a polynomial?,"
The reason why the replacement doesn't work is that replacement rules are not mathematical replacements, but pure structural replacements. Therefore the replacement z^2->x just looks for occurrences of the pattern z^2 and replaces that with x. Now z^4 doesn't match that pattern.
Also note that rules operate on the internal form, which doesn't always match the displayed form. For example, one would expect a-2b /. 2b->c to result in a-c, but it actually results in a-2b again, because internally the expression reads Plus[a, Times[-2, b]] (you can see that by applying FullForm), while 2b is Times[2,b].
To do the replacement wanted, one has to use a method which is aware of the mathematics instead of just the structure. One possibility is
Solve[p==z^4+z^2+4 && x==z^2, {p}, {z}]

which means ""Solve the equations given for p while eliminating z"". The result then is
{{p->4+x+x^2}}

Note that the curly braces around z are mandatory because otherwise Mathematica interprets it as domain, resulting in an error message because z is of course no valid domain. Also note that the documentation page of Solve omits the possibility of giving a list of variables to eliminate as third argument (at least I didn't find it). However, you'll find it in a Mathematica tutorial on eliminating variables (but there they use the third argument without braces, which at least for me results in an error message, as written above).
"
functions - What are the use cases for different scoping constructs?,"
You will find a lot of information in this answer. I will add a few personal notes.
Module
Use Module when you want to localize variables inside your function's body, and those variables will potentially acquire and/or change their values during the computation.
Basic use
For example:
f[x_]:=Module[{y=x^2},y=y+x;{x,y}]

Here, a local mutable variable (symbol) y is local to the Module, and is, indeed, a symbol with a unique name. This is the closest you have in Mathematica to, say, local variables in C.
Advanced uses
Module also has advanced uses. One of them is to create closures - functions with a persistent state. My third post in this thread illustrates many cases of that and has further references. One example I will steal from there:  the following function will produce the next Fibonacci number on demand, and yet it will be as fast as the iterative loop implementation for generation of consecutive Fibonacci numbers (since Module is invoked only once, when the function is defined):
Module[{prev, prevprev, this}, 
   reset[] := (prev = 1; prevprev = 1); 
   reset[]; 
   nextFib[] := (this = prev + prevprev; prevprev = prev; prev = this)
];

 
reset[]; 
Table[nextFib[], {1000}]; // Timing 

(* 
  ---> {0.01, Null} 
*)

One problem with persistence created with Module-variables is that one should not generally serialize such state (definitions), for example by saving the state via Save or DumpSave. This is because, the uniqueness of names for Module-generated symbols is guaranteed only within a single Mathematica session.
Module also allows one to create local functions, which With does not (except pure functions). This is a very powerful capability. It is particularly useful for writing recursive functions, but not only. In the link mentioned above, there were examples of this. One problem with local functions created by Module is that these symbols won't be automatically garbage-collected when Module finishes (if they have DownValues, SubValues or UpValues. OwnValues are fine), and so may lead to memory leaks. To avoid that, one can Clear these symbols inside Module before returning the result.
With
Use With to define local constants, which can not be changed inside the body of your function.
Basic use
For example,
f[x_,y_]:=With[{sum = x+y},{sum *x, sum *y}]

It is instructive to trace the execution of f. You will notice that sum gets replaced by its value very early on, before the body starts evaluating. This is quite unlike Module, where variable entries get replaced by their values in the process of evaluation, just as it would normally happen were the variables global.
Advanced uses
On an advanced level, With can be used to inject some evaluated code deep into some expression which is otherwise unevaluated:
With[{x=5},Hold[Hold[x^2]]]

(*
    Hold[Hold[5^2]]
*)

and is thus an important meta-programming tool. There are lots of uses for this feature, in particular one can use this to inject code into Compile at run-time right before compilation. This can extend the capabilities / flexibility of Compile quite a bit. One example can be found in my answer to this question.
The semantics of With is similar to that of rule substitutions, but an important difference is that With cares about inner scoping constructs (during variable name collisions), while rules don't. Both behaviors can be useful in different situations.
Module vs With
Both of these are lexical scoping constructs, which means that they bind their variables to lexical their occurrences in the code. Technically, the major difference between them is that  you can not change the values of constants initialized in With, in the body of With, while you can change values of Module variables inside the body. On a deeper level, this is because With does not generate any new symbols. It does all the replacements before the body evaluates, and by that time no ""constant symbols"" are at all present, all of them replaced with their values. Module, OTOH, does generate temporary symbols (which are normal symbols with an attribute Temporary), which can store a mutable state.
Stylistically, it is better to use With if you know that your variables are in fact constants, i.e. they won't change during the code execution. Since With does not create extra (mutable) state, the code is cleaner. Also, you have more chances to catch an occasional erroneous attempt in the code to modify such a constant.
Performance-wise, With tends to be faster than Module, because it does not have to create new variables and then destroy them. This however usually only shows up for very light-weight functions. I would not base my preference of one over another on performance boosts.
Block
Basic use
Block localizes the value of the variable. In this example, a does not refer to i literally inside Block, but still uses the value set by Block.
a:=i
Block[{i=2},a]
{a,i}

Block therefore affects the evaluation stack, not just the literal occurrences of a symbol inside the code of its body. Its effects are much less local than those of lexical scoping constructs, which makes it much harder to debug programs which use Block extensively. It is not much different from using global variables, except that Blockguarantees that their values will be restored to their previous values once the execution exits Block (which is often a big deal). Even so, this non-transparent and non-local manipulation of the variable values is one reason to avoid using Block where With and / or Module can be used. But there are more (see below).
In practice, my advice would be to avoid using Block unless you know quite well why you need it. It is more error-prone to use it for variable localization than With or Module, because it does not prevent variable name collisions, and those will be quite hard to debug. One of the reasons people suggest to use Block is that they claim it is faster. While it is true, my opinion is that the speed advantage is minimal while the risk is high. I elaborated on this point here, where at the bottom there is also an idiom which allows one to have the best of both worlds. In addition to these reasons, as noted by @Albert Retey, using Block with the Dynamic - related functionality may lead to nasty surprises, and errors resulting from that may also be quite non-local and hard to find.
One valid use of Block is to temporarily redefine some global system settings / variables. One of the most common such use cases is when we want to temporarily change the value of $RecursionLimit or $IterationLimit variables. Note however that while using Block[{$IterationLimit = Infinity}, ...] is generally okay, using  Block[{$RecursionLimit = Infinity}, ...] is not, since the stack space is limited and if it gets exhausted, the kernel will crash. A detailed discussion of this topic and how to make functions tail-recursive in Mathematica, can be found e.g. in my answer to this question.
It is quite interesting that the same ability of Block can be used to significantly extend the control the user has over namespaces/symbol encapsulation. For example, if you want to load a package, but not add its context to the $ContextPath (may be, to avoid shadowing problems), all you have to do is
Block[{$ContextPath}, Needs[Your-package]]

As another example, some package you want to load modifies some other function (say, System`SomeFunction), and you want to prevent that without changing the code of the package. Then, you use something like
Block[{SomeFunction}, Needs[That-package]]

which ensures that all those modifications did not affect actual definitions for SomeFunction  - see this answer for an example of this.
Advanced uses
Block is a very powerful metaprogramming device, because you can make every symbol (including system functions) temporarily ""forget"" what it is (its definitions and other global properties), and this may allow one to change the order of evaluation of an expression involving that symbol(s) in non-trivial ways, which may be hard to achieve by other means of evaluation control (this won't work on Locked symbols). There are many examples of this at work, one which comes to mind now is the LetL macro from my answer to this question.
Another more advanced use of Block is to ensure that all used variables would be restored to their initial values, even in the case of Abort or exception happening somewhere inside the body of Block. In other words, it can be used to ensure that the system will not find itself in an illegal state in the case of sudden failure. If you wrap your critical (global) variables in Block, it will guarantee you this.
A related use of Block is when we want to be sure that some symbols will be cleared at the end. This question and answers there represent good examples of using Block for this purpose.
Variable name conflicts
In nested scoping constructs, it may happen that they define variables with the same names. Such conflicts are typically resolved in favor of the inner scoping construct. The documentation contains more details.
Block vs Module/With
So, Block implements dynamic scoping, meaning that it binds variables in time rather than in space. One can say that a variable localized by Block will have its value during the time this Block executes (unless further redefined inside of it, of course). I tried to outline the differences between Block and With/Module (dynamic vs lexical scoping) in this  answer.
Some conclusions

For most common purposes of variable localization, use Module
For local constants, use With
Do not ordinarily use Block for introducing local variables
All of the scoping constructs under discussion have advanced uses. For Module this is mostly creating and encapsulating non-trivial state (persistent or not). For With, this is mostly injecting inside unevaluated expressions. For Block, there are several advanced uses, but all of them are, well, advanced. I'd be worried if I found myself using Block a lot, but there are cases when it is indispensable.

"
graphics - Undocumented form for FilledCurve[],"
The first element in the triples seems to indicate the type of curve used for the segment where 0 indicates a Line, 1 a BezierCurve, and 3 a BSplineCurve. I haven't figured out yet what 2 does.
Edit: When the first element of the triple is 2, the segment will be a BezierCurve similar to option 1 except that with option 2, an extra control point is added to the list to make sure that the current segment is tangential to the previous segment.
The second digit indicates how many points to use for the segment, and the last digit the SplineDegree. To convert the FilledCurve to a list of Graphics primitives, you could therefore do something like
conversion[curve_] :=
   Module[{ff},

       ff[i_, pts_, deg_] :=
           Switch[i,
               0, Line[Rest[pts]],
               1, BezierCurve[Rest[pts], SplineDegree -> deg],
               2, BezierCurve[
                   Join[{pts[[2]], 2 pts[[2]] - pts[[1]]}, Drop[pts, 2]], 
                   SplineDegree -> deg],
               3, BSplineCurve[Rest[pts], SplineDegree -> deg]
               ];

       Function[{segments, pts},
               MapThread[ff,
                   {
                       segments[[All, 1]],
                       pts[[Range @@ (#1 - {1, 0})]] & /@
                           Partition[Accumulate[segments[[All, 2]]], 2, 1, {-1, -1}, 1],
                       segments[[All, 3]]
                       }
                   ]
               ] @@@ Transpose[List @@ curve]
       ]

Then for the example in the original post, 
curve = FilledCurve[{{{1, 4, 3}, {1, 3, 3}, {1, 3, 3}, {1, 3, 3}}}, 
  {{{10.9614, 7.40213}, {10.9614, 10.2686}, {8.51663, 12.3137}, 
   {5.79394, 12.3137}, {3.05663, 12.3137}, {0.641063, 10.2686}, 
   {0.641063, 7.40213}, {0.641063, 4.53319}, {3.05663, 2.48813}, 
   {5.79394, 2.48813}, {8.53125, 2.48813}, {10.9614, 4.51856}, 
   {10.9614, 7.40213}}}];
curve2 = conversion[curve]

gives
{BezierCurve[{{10.9614, 7.40213}, {10.9614, 10.2686}, {8.51663, 
    12.3137}, {5.79394, 12.3137}}, SplineDegree -> 3], 
 BezierCurve[{{5.79394, 12.3137}, {3.05663, 12.3137}, {0.641063, 
    10.2686}, {0.641063, 7.40213}}, SplineDegree -> 3], 
 BezierCurve[{{0.641063, 7.40213}, {0.641063, 4.53319}, {3.05663, 
    2.48813}, {5.79394, 2.48813}}, SplineDegree -> 3], 
 BezierCurve[{{5.79394, 2.48813}, {8.53125, 2.48813}, {10.9614, 
    4.51856}, {10.9614, 7.40213}}, SplineDegree -> 3]}

and Graphics[curve2] produces

"
notebooks - How can I set a fixed cell height?,"
The cell dimensions are set by the option CellSize -> {width, height} which can be found in the category Cell Options > Inline Cell Options of the options inspector. One way to get there is to right-click on a cell bracket and select Properties near the bottom of the pop-up menu.
Edit
This is what the cell looks like in my version of Mathematica (8.0.1 on OS X) after setting CellSize -> {Automatic, 50} of the output cell in the options inspector. The little blue square attached to the bottom of the bracket of the output cell is the resize handle. 

"
equation solving - Figuring when the minute and hour hand coincide on a clock,"
I don't think it's necessary to use all the apparatus of Solve or Reduce here.
When you think about it, at one o'clock, the hour hand is on the 1, which corresponds to five minutes. So the hands meet a little after five past one. The solution is therefore that $m = 60  (\frac{h}{11})$. Someone else might show how this can be solved explicitly.
Here is a short piece of code that finds the correct times and formats them nicely as ""HH:MM:ss.    
DateString[{2012, 1, 23, #, 60. (# )/11}, {""Hour12"", "":"", ""Minute"", 
"":"", ""Second""}] & /@ Range[0, 11]


{""12:00:00"", ""01:05:27"", ""02:10:54"", ""03:16:21"", ""04:21:49"",
  ""05:27:16"", ""06:32:43"", ""07:38:10"", ""08:43:38"", ""09:49:05"",
  ""10:54:32"", ""12:00:00""}

Edit to include equation solving approach
To do this in a more complex situation that actually involves Solve, something along these lines would work:
soln = m /. First@Solve[30 h - 11 m /2 == 0, m, Reals]


(60 h)/11

All the solutions are actually in the correct domain of $m$ when $h \in\{1,...,11\}$, but here is what you would need to do to check this.
times = Select[Table[{h, N@soln}, {h, 0, 11}], 0 .<= #[[2]] <= 60. &]

Convert to date strings:
strings = DateString[Join[{2012, 1, 23}, #], {""Hour12"", "":"", ""Minute""}] & /@ 
  times


{""12:00"", ""01:05"", ""02:10"", ""03:16"", ""04:21"", ""05:27"", ""06:32"",
  ""07:38"",
  ""08:43"", ""09:49"", ""10:54"", ""12:00""}

Convert to the necessary angle units.
degrees = {1, -6 Degree}*# & /@ times


{{0, 0.}, {1, -0.571199}, {2, -1.1424}, {3, -1.7136}, {4, -2.28479},
  {5, -2.85599}, {6, -3.42719}, {7, -3.99839}, {8, -4.56959},
  {9, -5.14079}, {10, -5.71199}, {11, -6.28319}}

 Graphics[{Circle[{0, 0}, 0.85], 
  MapThread[
   Text[#1, {Cos[#2 + Pi/2], Sin[#3 + Pi/2]}] &, {strings, 
    degrees[[All, 2]], degrees[[All, 2]]}]}, ImageSize -> 250]


"
list manipulation - Why don't * and ^ work as I expected on matrices?,"
Matrices in Mathematica are nothing but a specific type of list of lists — specifically, a two dimensional list of lists.
* is the short form for the Times function, which threads over lists elementwise, and this is what you'd use if you wanted to take the Hadamard product of two matrices. So when you say A*B, you're actually saying Times[A, B].
. on the other hand, is short form for Dot, which lets you take the usual matrix products. So A.B is equivalent to Dot[A, B]. Both of these are different and it just boils down to understanding and remembering the short forms and the functions they represent.
If you're coming from a language like MATLAB, you might be confused at first, because * and ^ indeed do behave the way you described in that language. Although one should familiarize themselves with each language's differences, this might help you in remembering it — * and ^ behave exactly like .* and .^ respectively in MATLAB, in that they operate element wise.
Whether it is intuitive or not depends on your personal preferences (and experience with other languages). In the same vein, you could also ask why Infix is ~, when MATLAB treats it as the not operator or throwaway variable, depending on how you use it :)
"
programming - Distributing PlusMinus consistently,"
Here's my shot, haven't tested it much yet, but it's pretty weird.
Flattens out in NumericFunctions, I thought that made sense.
ClearAll[PlusMinus];
Module[{PlusMinusList},
 SetAttributes[PlusMinus, {Flat, OneIdentity, NumericFunction}];
 SetAttributes[PlusMinusList, {Flat, OneIdentity}];
 PlusMinus[a_] := PlusMinusList[a, -a];
 PlusMinus[a_, b_] := PlusMinusList[a + b, a - b];
 PlusMinusList /: 
  h_Symbol?(MemberQ[Attributes[#], NumericFunction] &)[b___, 
   pm_PlusMinusList, a___] := 
  Block[{PlusMinusList}, h[b, #, a] & /@ pm];
 PlusMinusList[exp___] := {exp} /; Length@Stack[] === 4;
 PlusMinusList /: 
  h_?(Head[#] =!= Symbol || ! 
        MemberQ[Attributes[#], NumericFunction] &)[bef___, 
   PlusMinusList[pm___], aft___] := 
  h[bef, {pm}, aft];
 ]

The idea is that it splits the results not in a regular List but in a PlusMinusList, which flattens itself out. With UpValues, it distributes over NumericFunctions. Then I put a couple of weird definitions to turn the PlusMinusList into a List in two cases: when it's already in the highest level of the stack, and when it is wrapped up by a non numeric function.
But I'm already seing that it doesn't Flatten properly nested PlusMinus because it doens't have the NumericFunction Attribute
EDIT
I added the attribute NumericFunction to PlusMinus, and removed the condition ""/; h =!= PlusMinusList;"" which I think serves no purpose. Also added a line to consider the single argument case PlusMinus[x]
"
programming - How can you give a Module a context and have its local variables and Modules belong to that context?,"
Here is an idea:
SetAttributes[account, HoldAll ]

makeAccount[ initBalance_ ] :=
 Module[ { balance = initBalance },
  account[ balance ]
  ]

account /: balance[ account[ bal_ ] ] := bal

account /: deposit[ account[ bal_ ], newBal_ ] := ( bal += newBal )

account /: withdraw[ account[ bal_ ], amount_ ] := ( bal -= amount ) /; 
  amount <= bal
account /: withdraw[ account[ bal_ ], amount_ ] := 
 Print[ ""Save some cash first"" ] /; amount > bal

Format[ acc_account  /; ValueQ[ balance[ acc ] ] ] := ""-account-""

Then use this as:
a1 = makeAccount[100]
a2 = makeAccount[150]

balance[a1]

100
deposit[a1, 100]

200
balance[a1]

200
balance[a2]

150
This works because of the unique symbol:
FullForm[a1]

Edit:
Here is a version without SetAttributes
makeAccount1[ initBalance_ ] :=

 Module[ { balance = initBalance , withdraw, deposit, amount, 
   dispatch},

  withdraw[ amount_ ] :=
   Module[ {},
    If[ balance >= amount,
     balance -= amount; balance,
     Print[ ""Insufficient funds"" ] 
     ]
    ];

  deposit[ amount_ ] :=
   Module[ {},
    balance += amount; 
    balance
    ];

  amount[ amount_ ] :=
   Module[ {},
    balance
    ];

  dispatch[m_] :=
   Which[
    StringMatchQ[ m, ""withdraw"" ], withdraw,
    StringMatchQ[ m, ""deposit"" ], deposit,
    StringMatchQ[ m, ""amount"" ], amount,
    (* else *)
    True, Print[""Unknown request -- MAKE_ACCOUNT "", m]
    ];

  Return[ dispatch ];
  ]

Use as follows:
acc = makeAccount1[ 100 ] 
acc2 = makeAccount1[ 200 ] 

dispatch$99
dispatch$100
acc[  ""withdraw"" ][ 10 ]

90
acc2[ ""withdraw"" ][ 60 ]

140
acc2[""amount""][]

140
"
performance tuning - Function that caches when it returns unevaluated,"
The following definition of f uses an auxiliary symbol to cache all results, whether they meet the required condition or not:
longCalculation[x_] := (Print[""calculating value for "", x]; x)

Module[{cache}
, m:cache[x_] := m = longCalculation[x]
; f[x_] := Module[{r = cache[x]}, r /; r < 8]
]

Here is a sample use:
In[61]:= f /@ Mod[2Range[20], 10]
During evaluation of In[61]:= calculating value for 2
During evaluation of In[61]:= calculating value for 4
During evaluation of In[61]:= calculating value for 6
During evaluation of In[61]:= calculating value for 8
During evaluation of In[61]:= calculating value for 0
Out[61]= {2,4,6,f[8],0,2,4,6,f[8],0,2,4,6,f[8],0,2,4,6,f[8],0}

"
programming - Is it possible to use Begin and End inside a Manipulate?,"
Short answer: yes, it is possible.
The problem is that parsing is done line-by-line only for the top-level code. For code inside some head(s), it is first parsed as a whole. Therefore, your f is parsed to Global`f, and this is why that symbol is used. Here is what you can do, schematically:
DynamicModule[{x = 5},
 With[{def = MakeBoxes[f[y_] := y^2 + 1;], ff = MakeBoxes[f]},
   Block[{$ContextPath},
     BeginPackage[""obj`""];
     ReleaseHold[MakeExpression@ff];
     Begin[""`Private`""];
     ReleaseHold[MakeExpression@def];
     End[];
     EndPackage[]]
 ];
 {x, Date[], obj`f[1]}]

What we do here is to delay the parsing (or, more precisely, the last stage of it)  of our definition until run-time, converting it first to boxes and thus preventing its premature parsing. I used a similar technique in my answer in this thread. We could have converted to strings, but I prefer boxes as being still ""on this side of Mathematica"".
Note that a side effect of this code is that a symbol f is still created in the context which is current when the code executes (Global` here). If you want to avoid that, you could insert Remove[f]  before Block. I went all the way to use `Private` sub-context, to avoid polluting the current context with some auxiliary symbols created during assignments.
You can also automate this code with some meta-programming.
"
equation solving - Why is FindInstance finding non-instances?,"
Your understanding of Exists is wrong. Maybe the best way to explain Exists is by an example:
FindInstance[Exists[y,x==y^2], x, Reals]
(*
--> {{x -> 0}}
*)

This means you seek values of $x$ for which there exists a value for $y$ whose square equals $x$. Obviously $x=0$ is such a value because for $y=0$, we have $x=y^2$. However, $x=-1$ would not be such a value because there's no real number whose square is $-1$. Note especially that in the first argument of Exists, there are variables whose values you don't seek for ($y$ in my example).
To solve your problem, just remove the Exists:
FindInstance[x > 1 && y > 1 && x > Sqrt[x + y], {x, y}]
(*
--> {{x -> 2, y -> 3/2}}
*)

"
number theory - Why does Mathematica claim there is no even prime?,"
Note: I am not particularly knowledgable in the field of this question, so what I write below may well be wrong.
I don't know whether or not this should be considered a bug, but to my mind this is an instance of a clash of programming and mathematical functionality. To put it differently, predicates (functions ending with Q) seem to be a wrong match for things like FindInstance or Resolve, because of their evaluation semantics. Functions suitable for mathematical transformations tend to return unevaluated when they don't know what to do, which gives the outer functions a chance to further transform them as expressions. OTOH, predicates will always return False immediately when they can not establish the the condition they check is True. 
By using Trace[Exists[n,EvenQ[n]&&PrimeQ[n]]//Resolve, TraceInternal->True], one can see that at some point, both EvenQ and PrimeQ evaluate to False, and this is the reason for the result. Moreover, even a simpler request 
Exists[n,EvenQ[n]]//Resolve
(*  
  -->  False
*)

However, this will work:
FindInstance[IntegerPart[n/2]*2==n && n>1 &&n<4 ,n,Integers]

(* 
 --> {{n->2}}
*)

I wasn't able to make the original request work (I tried using Divisors, but no luck). But my point is that recasting the condition as a set of equations and/or inequalities may increase the chances of success here, because their evaluation semantics is that of the mathematical rather than programming functionality. The borderline seems to be quite blurred, but I think it is there.
"
packages - Future-proofing access to packed array tools,"
I don't think that Developer` is going to go away; there is too much (also internal) stuff depending on it. What I do at the beginning of a package:
pack = Developer`ToPackedArray;
packedQ = Developer`PackedArrayQ;

then only use those; if anything changes then it's only one place I need to change it. On the other hand a re-factoring: of Developer`ToPackagedArray is not the end of the world.
Concerning moving this to the kernel: unlikely. It has not been done in the past (for probably good reasons), why should it happen now. I don't think there is generally a way to classify stability of packages; if it is in the kernel, it is more stable than if it is in a package that you have to explicitly load.
"
How to generate random directed acyclic graphs?,"
Note that @halmir's solution does the same thing as described below, but much more concisely. I recommend using that approach.

The idea is that the graph is acyclic if and only if if there exists a vertex ordering which makes the adjacency matrix lower triangular¹. It's easy to see that if the adjacency matrix is lower triangular, then vertex $i$ can only be pointing to vertex $j$ if $i<j$.
So let's generate a matrix which has zeros and ones uniformly distributed under the diagonal:
vertexCount = 10;
edgeCount = 30;

elems = RandomSample@
  PadRight[ConstantArray[1, edgeCount], 
   vertexCount (vertexCount - 1)/2]

adjacencyMatrix = 
  Take[
    FoldList[RotateLeft, elems, Range[0, vertexCount - 2]],
    All,
    vertexCount
  ] ~LowerTriangularize~ -1

(Thanks to @Mr.Wizard for the code that fills the triangular matrix!)

graph = AdjacencyGraph[adjacencyMatrix]

AcyclicGraphQ[graph]

(* ==> True *)

LayeredGraphPlot will show you the acyclic structure in a ""convincing"" way:


You did not say it explicitly, but I assume you need a connected graph.  Unfortunately I have no algorithm that gives you a connected one, but you can keep generating them until you find a connected one by accident (brute force).  If the connectance is very low, and you get very few connected ones, you can try generating graphs with a slightly higher vertex count than the required one until the largest connected component has the required vertex count.

Packed into a function for convenience:
randomDAG[vertexCount_, edgeCount_] /; 
  edgeCount < vertexCount (vertexCount - 1)/2 :=
 Module[
   {elems, adjacencyMatrix},
   elems = RandomSample@
     PadRight[ConstantArray[1, edgeCount], vertexCount (vertexCount - 1)/2];
   adjacencyMatrix = 
     Take[
       FoldList[RotateLeft, elems, Range[0, vertexCount - 2]],
       All,
       vertexCount
     ] ~LowerTriangularize~ -1;
   AdjacencyGraph[adjacencyMatrix]
 ]


¹ You can find the ordering that makes the adjacency matrix triangular using a topological sort.
"
Is the communication protocol underlying MathLink user-customizable?,"
Seems entirely possible. I'd start by writing a stub for each end whose entire purpose is to echo MathLink traffic over your custom channel. Without doing any measurement, my first guess would be that you should use the existing shared memory protocol for the stub to connect to the MathLink peer on either end.
As I think about it more, the stubs don't really even need to understand the MathLink protocol at all. If you use TCP/IP on either end, and you have a way to tunnel TCP/IP over your custom channel (a la SSH port forwarding), you're all set and don't have to write any code.
"
"mathlink or wstp - Connecting to and disconnecting from a continuously running kernel, on demand","
Why MathLink or webMathematica? (both quite time-consuming once you do something nontrivial)
Keep it simple:
On Windows: Use Remote Desktop to connect to your server (where you started the FrontEnd, starting the parallel calculation).
On Linux: Use TightVNC or NX or some such.
"
import - Plotting data with exponentials,"
You should be able to use ReadList on the string contents of each sublist. Here I'm just creating a small list containing three elements identical to the one you provided. The result can be plotted using ListPlot for example.
In[20]:= in = {{""   7.9080000e+01   1.9283193e+04""}, 
               {""   7.9080000e+01   1.9283193e+04""}, 
               {""   7.9080000e+01   1.9283193e+04""}};

In[22]:= Table[ReadList[StringToStream@First[i], Number], {i, in}]

Out[22]= {{79.08, 19283.2}, {79.08, 19283.2}, {79.08, 19283.2}}

EDIT: 
Due to the comments I should point out that this Table is going to produce an array that is not packed.  This means that the evaluator isn't aware ahead of time that all of the values are a particular type (namely real in this case) and so it is going to lean toward more general methods and is going to consume more memory to store the table. 
As the documentation for Developer`ToPackedArray points out, using Developer`ToPackedArray will not change results generated by Mathematica, but can enhance speed of execution and reduce memory usage.
In order to pack the result we can simply use ruebenko's suggestion placing Developer`ToPackedArray@ in front of our Table.
TESTING EDIT:
I decided to test whether ImportString proposed by Mr. Wizard or the ReadList approach might be faster. In fairness I separated the ExportString out presuming that the string would already be saved somewhere for importing.  It appears that ReadList is much faster at least for the fabricated example I've created here.  I'd be curious to see if this is true for 500's data.
In[21]:= data = Table[""   7.9080000e+01   1.9283193e+04"", {5000}];

In[22]:= Export[""numbers.txt"", data];

In[23]:= in = Partition[ReadList[StringToStream@Import[""numbers.txt"", 
              ""Plaintext""], Record], 1];

In[24]:= (andyr = Table[ReadList[StringToStream@First[i], Number]
                   , {i, in}]); // AbsoluteTiming

Out[24]= {0.0780015, Null}

In[25]:= str = ExportString[in, ""Table""];

In[26]:= (mrwiz = ImportString[str, ""Table""]); // AbsoluteTiming

Out[26]= {4.1340795, Null}

In[27]:= andyr === mrwiz

Out[27]= True

I should also point out that this comparison is only fair if we assume that the data is already in memory.  If not, the cost for Importing should be factored in to the ReadList approach.
"
"plotting - 1 Plot, 2 Scale/Axis","
This can be done with Overlay if the ImagePadding and the horizontal range for each plot is the same. For example,
plot1 = ListLinePlot[
    Accumulate[RandomReal[{0, 1}, {100}]],
    PlotStyle -> Blue,
    ImagePadding -> 25,
    Frame -> {True, True, True, False},
    FrameStyle -> {Automatic, Blue, Automatic, Automatic}
]


plot2 = ListLinePlot[
    Accumulate[RandomReal[{0, 100}, {100}]],
    PlotStyle -> Red,
    ImagePadding -> 25,
    Axes -> False,
    Frame -> {False, False, False, True},
    FrameTicks -> {{None, All}, {None, None}},
    FrameStyle -> {Automatic, Automatic, Automatic, Red}
]


Overlay[{plot1, plot2}]


Edit: Cleared up which axis is which using FrameStyle.
"
export - How to embed fonts when exporting Mathematica graphics as PDF,"
What Verbeia said in her answer is not entirely correct — Mathematica indeed does embed the font, regardless of whether a particular font weight/slant exists or not. The real culprits are the PDF viewers on Macs, which do not use the base font if the specified weight is not available. It took some digging around to get to the reason though. The clues that led to my reasoning are as follows:

Mathematica knows what font it used when you re-import
This was the first clue. Executing Import[""~/Desktop/Graphics.PDF""] will correctly display the graphics in Papyrus font, albeit without the bold option (which, as Verbeia noted, doesn't exist in all fonts). So the information had to be in the file somewhere.

The binary file shows Papyrus embedded in it
Opening the pdf in vim under hex mode, you find the font info embedded in it. What you see in the readable text on the right is the full copyright info, which they'd have to include only if it were embedded.

It opens correctly on linux systems
Papyrus is not a font that comes installed by default with linux systems. The above file opens with the correct font (but not weight) on RHEL 6 and Ubuntu 11.10, which can only mean that the font is embedded in the pdf. Below is a screenshot in RHEL 6, with the same file opened in Adobe reader (left) and evince (right). 

Hey, it opens perfectly in Adobe Reader!
Below is a screenshot of the same file opened in Adobe reader (left) and Preview.app (right). You can see that Adobe sure does know which font to use.


So you can see here that the problem is most likely with the PDF viewers on macs (other than Adobe reader). My guess is that they don't stay true to Adobe's specifications, and instead rely on OSX's Quartz framework for rendering the file, which is why you don't see the right font. 
Either that, or they don't like the fact that Mathematica uses PDF v1.4 to export its files. v1.4 is pretty old (2001), and it is worth mentioning (since you're embedding non-standard fonts) that PDF v1.4 does not support embedding ""Open Type"" fonts. That was introduced only in v1.6, and if you're working with such fonts, you might want to keep this in mind.
"
functions - Error checking and trapping techniques with Throw and Catch,"
I have answered almost exactly this question (somewhat more general one, if we interpret this one as being concerned only with Throw and Catch)  here. Since you asked a more narrow one, I feel it may be appropriate to borrow a part of my answer, to have it here.
The method

This method is IMO almost never appropriate for the top-level functions that are exposed to the user. Mathematica exceptions are not checked (in the sense of say checked exceptions in Java), and mma is not strongly typed, so there is no good language-supported way to tell the user that in some event exception may be thrown. However, it may be very useful for inner functions in a package. Here is a toy example:
ClearAll[ff, gg, hh, failTag];
hh::fail = ""The function failed. The failure occured in function `1` "";

ff[x_Integer] := x^2 + 1;
ff[args___] := Throw[$Failed, failTag[ff]];

gg[x_?EvenQ] := x/2;
gg[args___] := Throw[$Failed, failTag[gg]];

hh[args__] :=
  Module[{result},
   Catch[result = 
     gg[ff[args]], _failTag, (Message[hh::fail, Style[First@#2, Red]];
      #1) &]];

and some example of use:
In[219]:= hh[1]
Out[219]= 1

In[220]:= hh[2]
During evaluation of In[220]:= hh::fail: The function failed.
The failure occured in function gg 
Out[220]= $Failed

In[221]:= hh[1,3]
During evaluation of In[221]:= hh::fail: The function failed. 
The failure occured in function ff 
Out[221]= $Failed

It is important to never use a single-argument Throw - always use exception tags. I would go even further and say that in my opinion, the possibility to use Throw without a tag is a defect of the language.
I found this technique very useful, because when used consistently, it allows to locate the source of error very quickly. This is especially useful when using the code after a few months, when you no longer remember all details.
Meta-programming and automation

You may have noticed that lots of error-checking code is repetitive (boilerplate code). A natural thing to do seems to try automating the process of making error-checking definitions. I will give one example to illustrate the power of mma meta-programming by automating the error-checking for a toy example with internal exceptions discussed above.
Here are the functions that will automate the process:
General::interr = 
 ""The function `1` failed due to an internal error. The failure occured in function `2`"";

ClearAll[setConsistencyChecks];
Attributes[setConsistencyChecks] = {Listable};
setConsistencyChecks[function_Symbol, failTag_] :=
    function[___] := Throw[$Failed, failTag[function]];


ClearAll[catchInternalError];
Attributes[catchInternalError] = {HoldAll};
catchInternalError[code_, f_, failTag_] :=
  Catch[code, _failTag,
    Function[{value, tag},
      Message[General::interr , Style[f, Red], Style[First@tag, Red]];
      value]]; 

This is how our previous example would be re-written:
ClearAll[ff, gg, hh];
Module[{failTag},
  ff[x_Integer] := x^2 + 1;
  gg[x_?EvenQ] := x/2;
  hh[args__] := catchInternalError[gg[ff[args]], hh, failTag];
  setConsistencyChecks[{ff, gg}, failTag]
];

You can see that it is now much more compact, and we can focus on the logic, rather than be distracted by the error-checking or other book-keeping details. The added advantage is that we could use the Module- generated symbol as a tag, thus encapsulating it (not exposing to the top level). Here are the test cases:
In[34]:= hh[1]
Out[34]= 1

In[35]:= hh[2]

During evaluation of In[35]:= General::interr: The function hh failed 
    due to an internal error. The failure occured in function gg
Out[35]= $Failed

In[36]:= hh[1,3]

During evaluation of In[36]:= General::interr: The function hh failed 
    due to an internal error. The failure occured in function ff
Out[36]= $Failed

Many error-checking and error-reporting tasks may be automated in a similar fashion. For a more complete discussion of the error-checking, see the original answer I linked to.
Applicability

Now, why would you choose exceptions over, say, returning $Failed, or perhaps, some custom return codes which can be analyzed? One good reason to use exceptions is when you have long chain of function calls. Without exceptions,  we would need to  propagate $Failed or some other error codes through the entire chain of functions until we reach one which is in a position to make decision and / or execute some recovery code. This may add a lot of needless complexity to the code.
Another good reason is that since Mathematica is a functional programming language and emphasizes immutable code, functions normally don't have much state. Therefore, abrupt jump within an execution stack, which is what exception is, does not usually lead to system getting into an invalid state. In other world, most functions we write in Mathematica don't require any clean-up code to be executed when exception is thrown.
Yet another feature of this error-checking method, which I consider good, is that it takes a zero-tolerance approach to errors. If you use it consistently, any error inside the code will lead to a program failure, during the development stage. This makes code self-testing to a large degree. A similar effect can be achieved with assertions. If you are disciplined enough, it is best not to use exceptions in places where assertions  can and should be used. However, the two methods can complement each other, because you can only use assertions on rather specific conditions, while exceptions can be used as catch-all ones, and can also catch cases you missed when designing the assertions.
In some cases, returning $Failed is still more appropriate. In particular, this is so when there is a well-defined procedure of what to do on failure, and the chain of function calls from the place where error happens to the actual error-handling function is not long.
"
graphics - Character edge finding,"
I think there is a neat solution. We have curios function ListCurvePathPlot:
pic = Thinning@Binarize[GradientFilter[Rasterize[Style[""\[Euro]"", 
FontFamily -> ""Times""], ImageSize -> 200] // Image, 1]];

pdata = Position[ImageData[pic], 1];

lcp = ListCurvePathPlot[pdata]


Now this is of course Graphics containing Line with set of points 
lcp[[1, 1, 3, 2]]


So of course we can do something like 
Graphics3D[Table[{Orange, Opacity[.5],Polygon[(#~Join~{10 n})&
/@ lcp[[1, 1, 3, 2, 1]]]}, {n, 10}], Boxed -> False]


I think it works nicely with ""8"" and Polygon:
pic = Thinning@Binarize[GradientFilter[
Rasterize[Style[""8"", FontFamily -> ""Times""], ImageSize -> 500] //Image, 1]]; 
pdata = Position[ImageData[pic], 1]; lcp = ListCurvePathPlot[pdata]


And you can do polygons 1-by-1 extraction:
Graphics3D[{{Orange, Thick, Polygon[(#~Join~{0}) & /@ lcp[[1, 1, 3, 2, 1]]]},
  {Red, Thick, Polygon[(#~Join~{1}) & /@ lcp[[1, 1, 3, 3, 1]]]},
  {Blue, Thick, Polygon[(#~Join~{200}) & /@ lcp[[1, 1, 3, 4, 1]]]}}]


=> To smooth the curve set ImageSize -> ""larger number"" in your pic = code.
=> To thin the curve to 1 pixel wide use Thinning:
 Row@{Thinning[#], Identity[#]} &@Binarize[GradientFilter[
 Rasterize[Style[""\[Euro]"", FontFamily -> ""Times""], 
 ImageSize -> 200] // Image, 1]]


You can do curve extraction more efficiently with Mathematica. A simple example would be
text = First[
   First[ImportString[
     ExportString[
      Style[""\[Euro] 9 M-8 "", Italic, FontSize -> 24, 
       FontFamily -> ""Times""], ""PDF""], ""PDF"", 
     ""TextMode"" -> ""Outlines""]]];

Graphics[{EdgeForm[Black], FaceForm[], text}]


"
graphics - How can all those tiny polygons generated by RegionPlot be joined into a single FilledCurve?,"
You could start by extracting the Line primitives from the normalized GraphicsComplex:
a=36;

g=RegionPlot[Mod[Sqrt[x^2+y^2]-7/2 ArcTan[x,y]+Sin[x]+Cos[y],Pi]<Pi/2,
 {x,-a,a},{y,-a,a},PlotPoints->100];

lines=Cases[Normal[g], _Line, Infinity];

The lines can then be directly included in a FilledCurve:
Graphics[{
  EdgeForm@Directive[Black, Thickness[Medium]], 
  FaceForm@Directive[Opacity[1/2], Orange], 
  FilledCurve[List /@ lines]
}]


This renders noticeably faster even within Mathematica (for example during resizing).
The structure of the FilledCurve must follow the FilledCurve[{{Line[...]}, {Line[...]}, ...}] pattern in order for the holes to show correctly.  Each line must be included in a separate sublist.

If each Line is included in a separate FilledCurve, then the holes will be missing:
Graphics[FilledCurve/@lines]


If we use the FilledCurve[{Line[...], Line[...], ...}] structure, the lines will be effectively concatenated into one continuous line, causing artefacts:
Graphics[FilledCurve[lines]]


"
output formatting - Printing a string in a Mathematica script,"
Another option is to set FormatType -> OutputForm on the $Output stream:
SetOptions[ $Output, FormatType -> OutputForm ];
Print[""Hello""];

Or call OutputForm on the string itself:
Print[ OutputForm[""Hello""] ];

"
dynamic - Usage Examples for DynamicWrapper,"
Suppose we have a Graphics object which depends on some parameters and a controller with which we want to control these parameters. This could be done easily enough using the second argument of Dynamic, for example
gr[pts_, col_, radius_] := Graphics[{col, Disk[#, radius] & /@ pts}, 
   PlotRange -> {{0, 3}, {0, 3}}, ImageSize -> 200];

contrl = {1, radius};
col = Blue; radius = .1;
pts = RandomReal[3, {10, 2}];

Grid[{{Dynamic[Framed[gr[pts, col, radius]]], 
  Slider2D[Dynamic[cntrl, 
   (cntrl = #; col = Blend[{Red, Blue}, cntrl[[1]]]; radius = cntrl[[2]])&]]
}}]

However, suppose that we also want a switch which switches the coupling between the controller and the plot on and off. With DynamicWrapper this can be done by doing something like this
Grid[{{Dynamic[Framed[gr[pts, col, radius]]], 
  Slider2D[Dynamic[cntrl]], 
  Toggler[""Off"", {DynamicWrapper[""On"", 
      col = Blend[{Red, Blue}, cntrl[[1]]]; radius = cntrl[[2]]], 
     ""Off""}]
 }}]


By clicking on the label of the slider you can then toggle between coupling or no coupling. The same effect can be achieved without using DynamicWrapper for example
DynamicModule[{state = ""Off""}, 
  Grid[{{Dynamic[Framed[gr[pts, col, radius]]], 
    Labeled[Slider2D[Dynamic[cntrl,(cntrl = #; 
         If[state === ""On"", col = Blend[{Red, Blue}, cntrl[[1]]]; 
         radius = cntrl[[2]]]) &]], 
     Toggler[Dynamic[state], {""On"", ""Off""}], Top]
  }}]
]

but imho the DynamicWrapper solution is more elegant in this case.
"
programming - How to close the front end so I can clear all Global variables?,"
From your description you seem to have an open window containing Dynamic content, which is what prevents some variables being cleared by simply quitting the kernel (or rather they get redefined again). 
So why don't you just close all windows containing any Manipulates or Dynamic and then use Quit[] (or Quit Kernel from the Evaluation menu) ? 
The only menu command to quit the Front End is the ""Quit Mathematica"" menu item in the Mathematica menu, which will indeed work (in a rather radical way) until you reopen the same notebooks that caused the problem to start with. 
"
packages - Why is JLink loaded every time I start Mathematica?,"
As far as I know, JLink is used at least in PacletManager`, for operations like loading data on demand etc. The documentation system also uses Java. Perhaps, other uses as well. I don't think that Java is used a lot for the core language though. 
This code can make it a bit more quantitative:
allNames = Flatten[Names[#<>""*""]&/@Contexts[]];
Quiet@Select[
  Select[allNames,!StringMatchQ[Context[#],""JLink`""~~___]&],
  MemberQ[
    Union@Cases[
             ToExpression[#,InputForm,DownValues],
             s_Symbol/;!MatchQ[Unevaluated[s],HoldPattern[Symbol[_]]]:>Context[s],
             Infinity,
             Heads->True
    ],
    c_String/;StringMatchQ[c,""JLink`""~~___]
  ]&
]//Short[#,5]&

Out[59]//Short= {com`wolfram`documentationsearch`DocumentationSearcher`closeSearcher,
com`wolfram`documentationsearch`DocumentationSearcher`closeSearchers,
com`wolfram`documentationsearch`DocumentationSearcher`getParser,   
 <<291>>,PacletManager`Utils`Private`DumpPacletSites, Assert,SystemInformation}

And this is only in contexts that were loaded in my session, plus probably the ReadProtected functions were not searched, and I only looked at DownValues. Some of these names are names for symbols that JLink generates to map to Java classes, but others are true Mathematica functions. So, I think one can safely say that Mathematica critically depends on Java.
"
deployment - How to install packages?,"
Note: This answer was originally written with package authors in mind, aiming to provide a user-friendly way to distribute packages and provide installation instructions. If your aim is user convenience, today you should be using paclets instead.

I think that the menu item File -> Install... is very convenient, even for power users.  The only problem is that there is no uninstall option.  However, if the package consists of a single file, upgrading is easy: the old file will be overwritten with the new file.
You can write some simple instructions for users:

Open the .m file you sent them
Choose File -> Install...
Choose Type -> Package, Source -> (the open notebook), Install Name -> SomePackage
Load the package by evaluating <<SomePackage` .

The only thing that can go wrong is that they mistype the install name.
The Install... menu item will put the package into
FileNameJoin[{$UserBaseDirectory, ""Applications""}]

which on Windows is
%appdata%\Mathematica\Applications

(Press Win-R and type the above to get to that directory.)
When necessary, the package file can be deleted from that directory.
This is the usual way I install and upgrade palettes myself.

Putting packages into the Mathematica installation directory is not really advantageous because they will get lost when Mathematica is upgraded (for example, from 8.0.1 to 8.0.4).  Instead they can be put into $BaseDirectory/Application (for all users) or $UserBaseDirectory/Application (for the current user).  This is what the Install... menu item does.

It seems that the Install... menu item can deal with multi-file packages too.  ""Type of Item to Install"" should be set to ""Applications"", ""Source"" -> ""From File..."" and the package files need to be inside an archive (.zip file).  I have not used this personally, so I have no experience with it (e.g. about what happens on upgrade).

@AlbertRetey noted below that the Wolfram Player Pro does not have this menu item at all.  The only way to install packages into it is to do it manually or create a script that does it.
"
mathlink or wstp - Specifying the ports used by LinkCreate or LinkLaunch,"
If you want to use port forwarding, you'll need to know that for every MathLink connection, two different ports are used.  The full syntax for TCPIP link names looks like this:
LinkCreate[""8000@1.2.3.4,8001@1.2.3.4"", LinkProtocol -> ""TCPIP""]

8000 and 8001 are the port numbers while 1.2.3.4 is your IP address.  You can pass only a single port number to LinkCreate as the link name: in this case it will return a LinkObject containing the full name and the other port will be automatically selected.

However, if you want to use SSH port forwarding, I strongly recommend using the Remote Kernel Strategies package.  It will save you a lot of trouble.  For example, it will automatically forward ports for all three links that Mathematica needs for Front End - Kernel communication ($ParentLink, MathLink`$PreemptiveLink and MathLink`$ServiceLink).  The other two links are created by the kernel when the front end connects to it by executing the code in the file SystemFiles/FrontEnd/TextResources/GetFEKernelInit.tr.
Please see the presentation I linked to for more information on how the connection is made and why three links are needed.
"
Code Golf: Least Common Multiple,"
I am not sure how this compares in terms of length but it does not throw errors and isn't even obfuscated:
lcm[ls__] := 
 Fold[Denominator[Together[Unique[x]/#1 + Unique[x]/#2]] &, 
  First[{ls}], Rest[{ls}]

Just to check it works:
f = RandomInteger[{1, 100}, 200];

lcm @@ f == LCM @@ f


True


"
programming - Using NETLink.MathKernel.Compute() for graphics results fails with GraphPlot[],"
I think your problem is that Graph will actually not evaluate to a Graphics but only be rendered as something like that by the FrontEnd. You could look at ToBoxes[yourgraph] to learn some details and try to extract something that can be transfered to .NET. I don't have any experience with NETLink, but I remember that at least older versions of JLink would return graphics as rastered images anyway, so a more simple approach could be to use 
Rasterize[GraphPlot[{1 -> 2, 2 -> 1, 3 -> 1, 3 -> 2, 4 -> 1, 4 -> 2, 4 -> 4}]]

You might want to finetune this with the options of Rasterize to meet your needs.
"
front end - How to Keep Input Cells Hidden After Evaluating Notebook,"
AutoCollapse[] function
Please try this code, based on Sasha's adaption of my own answer to this question.
AutoCollapse[] := (
  If[$FrontEnd =!= $Failed, 
   SelectionMove[EvaluationNotebook[], All, GeneratedCell];
   FrontEndTokenExecute[""SelectionCloseUnselectedCells""]])

Then in a new cell:
2 + 2
AutoCollapse[]

Always place AutoCollapse[] as the last line of an Input cell.
Stylesheets
To get the behavior without having to include AutoCollapse[] in each cell you can use Stylesheets and CellEpilog.  For example to create an InputHidden style use menu Format > Edit Stylesheet... and then add a Cell with the following code (use Ctrl+Shift+E to edit Cell code):
Cell[StyleData[""InputHidden"", StyleDefinitions -> StyleData[""Input""]],
 CellEpilog :> (SelectionMove[EvaluationNotebook[], All, GeneratedCell]; 
   FrontEndTokenExecute[""SelectionCloseUnselectedCells""]),
 MenuSortingValue -> 1510
 , MenuCommandKey -> ""8""
]


This creates a new style that behaves like Input but which auto-collapses when evaluated.  MenuCommandKey -> ""8"" lets it be quickly applied using Alt+8; change or remove this line as desired.

I may be reading more into your question than is there.  As Heike points you can close the input cells manually by deselecting menu Cell > Cell Properties > Open but I assumed you knew this already and provided the soluition(?) above.  If all you need is a hidden cell that generates output, use the menu.  If you need something a little more flexible that automatically hides after you make your changes I hope you will find the methods above useful.
"
programming - How to eliminate the need to double evaluate a Manipulate so that a Module in its Initialization section works?,"
Still not sure whether this is what you intended, but if you keep initialization stuff within the Initialization things seem to behave well:
Manipulate[x;
 get[obj],
 Button[""run"", x++],
 {x, None},
 {{obj, None}, None},
 TrackedSymbols :> {x},
 Initialization :> (
   makeObj[] := Module[{obj, u},
     init[obj] ^:= u = {1, 2, 3};
     get[obj] ^:= {obj, u, Date[]};
     obj
     ];
   obj = makeObj[];
   init[obj];
   )
 ]

I have seen that Faysal Aberkane has given an explanation what goes wrong in the first place. I just had prepared a piece of code which shows you in which order the various parts are evaluated, so I thought I'll share it, although it doesn't add anything new:
Manipulate[
 WriteString[$Output, ""body\n""];
 x,
 Button[""run"", x++],
 {x, None},
 {{obj, Print[""var. init""]}, None},
 TrackedSymbols :> {x},
 Initialization :> {
   Print[""Initialization option""]
   }
 ]

Here is another try which only uses frontend owned variables:
Manipulate[x;
 ""init""[obj];
 ""get""[obj],
 Button[""run"", x++],
 {x, None},
 {u, None},
 {obj, None},
 TrackedSymbols :> {x},
 Initialization :> (
   obj =.;
   ""init""[obj] ^:= u = {1, 2, 3};
   ""get""[obj] ^:= {obj, Hold[u], u, Date[]};
   )
 ]

"
plotting - I'd like to display field lines for a point charge in 3 dimensions,"
This is something I have used for my classes. Over time, I've tried to make it more and more user friendly, but that's also made it a little longish. I'll post the complete set of functions, with apologies if it's a bit unwieldy...
As you'll see, I found it does indeed work better in my use cases if I normalize the field, so that we advance along the field lines in more balanced steps. The hardest part in applying these functions is to choose the appropriate seed points.
fieldSolve::usage = 
  ""fieldSolve[f,x,x0,\!\(\*SubscriptBox[\(t\), \(max\)]\)] \
symbolically takes a vector field f with respect to the vector \
variable x, and then finds a vector curve r[t] starting at the point \
x0 satisfying the equation dr/dt=\[Alpha] f[r[t]] for \
t=0...\!\(\*SubscriptBox[\(t\), \(max\)]\). Here \[Alpha]=1/|f[r[t]]| \
for normalization. To get verbose output add debug=True to the \
parameter list."";

fieldSolve[field_, varlist_, xi0_, tmax_, debug_: False] := Module[
  {xiVec, equationSet, t},
  If[Length[varlist] != Length[xi0], 
   Print[""Number of variables must equal number of initial conditions\
\nUSAGE:\n"" <> fieldSolve::usage]; Abort[]];
  xiVec = Through[varlist[t]];
  (* Below, Simplify[equationSet] would cost extra time 
    and doesn't help with the numerical solution, so   don't try to simplify. *)

  equationSet = Join[
    Thread[
     Map[D[#, t] &, xiVec] == 
      Normalize[field /. Thread[varlist -> xiVec]]
     ],
    Thread[
     (xiVec /. t -> 0) == xi0
     ]
    ];
  If[debug, 
   Print[Row[{""Numerically solving the system of equations\n\n"", 
      TraditionalForm[(Simplify[equationSet] /. t -> ""t"") // 
        TableForm]}]]];
  (* This is where the differential equation is solved. 
  The Quiet[] command suppresses warning messages because numerical precision isn't crucial for our plotting purposes: *)

  Map[Head, First[xiVec /.
     Quiet[NDSolve[
       equationSet,
       xiVec,
       {t, 0, tmax}
       ]]], 2]
  ]   

fieldLinePlot[field_, varList_, seedList_, opts : OptionsPattern[]] :=
   Module[{sols, localVars, var, localField, plotOptions, 
    tubeFunction, tubePlotStyle, postProcess = {}}, 
   plotOptions = FilterRules[{opts}, Options[ParametricPlot3D]];
   tubeFunction = OptionValue[""TubeFunction""];
   If[tubeFunction =!= None,
    tubePlotStyle = Cases[OptionValue[PlotStyle], Except[_Tube]];
    plotOptions = 
     FilterRules[plotOptions, 
      Except[{PlotStyle, ColorFunction, ColorFunctionScaling}]];
    postProcess = 
     Line[x_] :> 
      Join[tubePlotStyle, {CapForm[""Butt""], 
        Tube[x, tubeFunction @@@ x]}]
    ];
   If[Length[seedList[[1, 1]]] != Length[varList], 
    Print[""Number of variables must equal number of initial \
conditions\nUSAGE:\n"" <> fieldLinePlot::usage]; Abort[]];
   localVars = Array[var, Length[varList]];
   localField = 
    ReleaseHold[
     Hold[field] /. 
      Thread[Map[HoldPattern, Unevaluated[varList]] -> localVars]];
   (*Assume that each element of seedList specifies a point AND the \
length of the field line:*)Show[
    ParallelTable[
     ParametricPlot3D[
         Evaluate[
          Through[#[t]]], {t, #[[1, 1, 1, 1]], #[[1, 1, 1, 2]]}, 
         Evaluate@Apply[Sequence, plotOptions]
         ] &[fieldSolve[
        localField, localVars, seedList[[i, 1]], seedList[[i, 2]]
        ]
       ] /. postProcess, {i, Length[seedList]}
     ]
    ]
   ];

Options[fieldLinePlot] = 
  Append[Options[ParametricPlot3D], ""TubeFunction"" -> None];

SyntaxInformation[fieldLinePlot] = {""LocalVariables"" -> {""Solve"", {2, 2}}, 
   ""ArgumentsPattern"" -> {_, _, _, OptionsPattern[]}};

SetAttributes[fieldSolve, HoldAll];

The main function is fieldLinePlot, but I split it into two functions to be more modular. Also, the problem of where to start drawing the field lines is treated separately because it depends a lot on the particular application.
fieldSolve[f,x,x0,Subscript[t, max]] symbolically takes a vector field f with respect to the vector variable x, and then finds a vector curve r[t] starting at the point x0 satisfying the equation dr/dt = α f[r[t]] for t=0...tmax. Here α = 1/|f[r[t]]| for normalization. To get verbose output add debug=True to the parameter list.
fieldLinePlot[field,varlist,seedList] plots 3D field lines of a vector field (first argument) that depends on the symbolic variables in varlist. The starting points for these variables are provided in seedList.
Each element of seedList={{p1, T1},{p2, T2}...} is a tuple where pi is the starting point of the $i^\mathrm{th}$ field line and Ti is the length of that field line in both directions from Pi.
Here are some examples:
1) Coulomb field of two opposite charges at $\vec{r} = \vec{0}$ and $\vec{r} = (1, 1, 1)$:
Look at the form of seedList to see how the field line starting points and lengths are specified.
seedList = 
  With[{vertices = .1 N[PolyhedronData[""Icosahedron""][[1, 1]]]}, 
   Join[Map[{#, 2} &, vertices], 
    Map[{# + {1, 1, 1}, -2} &, vertices]]];

Show[fieldLinePlot[{x, y, z}/
    Norm[{x, y, z}]^3 - ({x, y, z} - {1, 1, 1})/
    Norm[{x, y, z} - {1, 1, 1}]^3, {x, y, z}, seedList, 
  PlotStyle -> {Orange, Specularity[White, 16], Tube[.01]}, 
  PlotRange -> All, Boxed -> False, Axes -> None], 
 Background -> Black]


2) Magnetic field of an infinite straight wire:
With[{seedList = Table[{{x, 0, 0}, 6.5}, {x, .1, 1, .1}]
  },
 Show[fieldLinePlot[{-y, x, 0}/(x^2 + y^2), {x, y, z}, 
   seedList, PlotStyle -> {Orange, Specularity[White, 16], Tube[.01]},
    PlotRange -> All, Boxed -> False, Axes -> None], 
  Graphics3D@Tube[{{0, 0, -.5}, {0, 0, .5}}], Background -> Black]]



Edit: added variable line thickness to represent field strength
The field lines can be given a color that scales with the field strength (the norm of the vector field along the lines), by specifying a ColorFunction in fieldLinePlot. For example, if the vector field has been defined as a function f2 of variables x,y,z, then you could add the option ColorFunctionScaling -> False, ColorFunction -> Function[{x,y,z,u}, Quiet@Hue[Clip[ Norm[f2[x,y,z]],{0,20}]/20]] as I mention in the comment section.
In this new edit, I added the ability to encode the field strength in the thickness of the field lines instead. This required adding a new option ""TubeFunction"" which works similarly to ColorFunction. It is a function of the three coordinates x,y,z and returns the radius of the tube representing the field line at that point. To calculate this radius in the examples below, I take the (unscaled) value of the field and get its Norm. Then I scale and constrain it to a reasonable range so that the thickness variations of the field lines don't look too grotesque:
3) Same Coulomb field as above, but with varying field line thickness
f2[x_, y_,z_] := {x, y, z}/Norm[{x, y, z}]^3 - ({x, y, z} - {1, 1, 1})/
   Norm[{x, y, z} - {1, 1, 1}]^3

seedList = 
  With[{vertices = .1 N[PolyhedronData[""Icosahedron""][[1, 1]]]}, 
   Join[Map[{#, 2} &, vertices], 
    Map[{# + {1, 1, 1}, -2} &, vertices]]];

fieldLinePlot[f2[x, y, z], {x, y, z}, seedList, 
 PlotStyle -> {Orange, Specularity[White, 16]}, PlotRange -> All, 
 Boxed -> False, Axes -> None, 
 ""TubeFunction"" -> 
  Function[{x, y, z}, Quiet[Clip[Norm[f2[x, y, z]], {2, 40}]/200]], 
 Background -> Black]


4) Same magnetic field as above, this time with varying line thickness
f3[x_, y_, z_] := {-y, x, 0}/(x^2 + y^2)

With[{seedList = Table[{{x, 0, 0}, 6.5}, {x, .1, 1, .1}]}, 
 Show[fieldLinePlot[f3[x, y, z], {x, y, z}, seedList, 
   PlotStyle -> {Cyan, Specularity[White, 16]}, PlotRange -> All, 
   Boxed -> False, Axes -> None, 
   ""TubeFunction"" -> 
    Function[{x, y, z}, Quiet[Clip[Norm[f3[x, y, z]], {1, 40}]/200]]],
   Graphics3D@Tube[{{0, 0, -.5}, {0, 0, .5}}], Background -> Black]]


"
"What is the purpose of tags like :Name:, :Context:, etc. in packages?","
Old versions of Mathematica featured the package Utilities`Package`. This had the function Annotation[] that read those commented lines in packages so that one could see those annotations without having to explicitly open those packages in the front end.
Needs[""Utilities`Package`""]

Annotation[""Statistics`NonlinearFit`""]
{""Title"", ""Context"", ""Name"", ""Author"", ""Summary"", ""Copyright"", ""Package Version"", ""Mathematica Version"", ""History"", ""Keywords"", ""Sources"", ""Discussion"", ""Warning"", ""Example"", ""Example"", ""Example""}

Annotation[""Statistics`NonlinearFit`"", ""Mathematica Version""]
{""(* :Mathematica Version: 5.0 *)""}

If you want to still use this function, it's available here. I would say those specific delimiters allowed the package to pick out annotations instead of code comments.
"
graphics - Ideas on how to improve the rendering of the letter B in this 3D region plot?,"
The reason the B appears incorrectly is not because of the shape of G, but rather because the horizontal length of G is less than the vertical length of B, resulting in B being decapitated. Here's how the letters look at present when one is laid on top of the other at 90º:

Notice that in the actual GEB logo, they use a squarish font, which solves this problem. So a possible solution, in the absence of a square font, is to set the aspect ratio of each of the letter shapes to 1, so that they sit well with each other. 
Here is a solution that uses Vitaliy's solution for extracting the outlines from letters.
letter[s_String] := ImageData@ Binarize@Graphics[{EdgeForm[None], FaceForm[Black], 
     First[First[ImportString[ExportString[Style[s, FontSize -> 24], ""PDF""], 
        ""PDF"", ""TextMode"" -> ""Outlines""]]]}, AspectRatio -> 1, ImageSize -> 100]

Now you can see that the shapes now line up correctly:

Proceeding with your RegionPlot3D code, but with slight modifications, 
{g, e, b} = letter /@ {""G"", ""E"", ""B""};
RegionPlot3D[
 g[[Round[i], Round[j]]] == 0 && e[[Round[i], Round[k]]] == 0 && 
  b[[Round[j], Round[k]]] == 0, {i, 1, 100}, {j, 1, 100}, {k, 1, 100}]

we get a nice and pretty GEB logo that reproduces the B and all the other letters correctly.



"
programming - Functions vs. patterns,"
square = Function[x, x^2];
square1 = #^2 &;
square2[x_] := x^2;

DownValues[square]
DownValues[square1]
DownValues[square2]

{}
{}
{HoldPattern[square2[x_]] :> x^2}

Two differences that immediately come to mind are that:
1) functions with down values won't autocompile when you use them in Table, Map, Nest etc. so therefore are less efficient when used that way. e.g.
data = RandomReal[{0, 10}, {10000}];

Timing[Developer`PackedArrayQ[Map[square, data]]]
Timing[Developer`PackedArrayQ[tmp1 = Map[square1, data]]]
Timing[Developer`PackedArrayQ[tmp2 = Map[square2, data]]]

{0.001404, True}
{0.001498, True}
{0.022324, False}

despite tmp1 being packed and tmp2 being unpacked they are equal
tmp1==tmp2
True

but using the pure function gives you a packed list which means faster evaluations and less memory for storage:
N@ByteCount[tmp2]/ByteCount[tmp1]
3.49456

This example used Map but you would observe the same thing with Table, Nest, Fold and so on. As to why this is the case (@Davids question) the only answer I have is the circular one that autocompilation using functions with down values hasn't been implemented. I haven't found out what the difficulties are in implementing this, i.e. whether it hasn't been done because it can't be or because it just hasn't been. Someone else may know and can comment.
2) functions with down values may (in all likelihood will) cause a security warning when present in an embedded CDF.
I'm sure others will be able to expand on this and add many more differences.
"
performance tuning - With versus Function,"
To my mind, the differences are significant if obscure. The very big difference in evaluation was described already by @Sal. Here are several more subtle ones, which may however bite you. So, functions go first. 
Functions

Can be in two forms, Function[x,x^2] or Function[#^2] (the last is equivalent to #^2&), which are not always equivalent. Differences:

Functions with named arguments are scoping constructs, and as such, perform variable collision resolution by renaming variables in inner scoping constructs, if needed. Functions with Slot-s are not quite (are in some respects but not others. Example of the difference is below), and because of that have some  speed advantage.
Functions with named arguments represent a leaky functional abstraction (see at the bottom of that answer). This matters because you can never be sure that you won't run into trouble when passing such a function as an argument. Functions with slots are ok, but can not always be nested.
Functions with slots have a form which takes arbitrary number of arguments, such as Function[Null, Plus[##]]. Functions with named arguments don't have such form.
Functions with slots can be made recursive, which can be a very powerful tool in some cases.

Functions with slots, not being full - fledged scoping constructs,  have the substitution semantics similar to replacement rules, in that they won't care about inner scoping constructs and possible name collisions.

Example:
With[{x=a},x+#]&[x]

(*
  ==> 2 a
*)

but
Function[{inj},With[{x=a},x+inj]][x]

(*
   ==>  a+x
*)

(we could have used Module or another Function in place of With here). Which behavior is preferred depends on the situation, but more often than not the former one is used not intentionally and leads to subtle bugs. In any case, one should be aware of this. 

As mentioned, Function - s with slots can take arbitrary number of arguments
Functions can carry attributes. For example, this function will sort its arguments: Function[Null, {##}, Orderless]
Because functions can carry attributes, they can hold arguments passed to them, for example: Function[expr,Head[Unevaluated[expr]],HoldAll], and also inject unevaluated arguments in their body. Functions with slots can do that for an arbitrary number of arguments as well, here is an example
Because of their SubValue - looking form of invokation: Function[x,x^2][y], and the fact that SubValues can not be forced to hold outer groups of arguments, Function call semantics for Function-s with Hold-arguments can not be easily emulated by other means. This tells us that Function-s are very special objects, for which probably an exception was made in the main evaluation sequence semantics.
Because Function-s can carry Hold-attributes, they can implement pass-by-reference semantics. In particular, they can change values of variables passed to them: a=1; Function[x,x=2,HoldAll][a];a.
Because of their evaluation semantics (elaborated by @Sal), Function-s can be used to implement currying.

With
Ok, now time for With:

With is always a scoping construct. This means it cares about inner scoping constructs and renames their variables in cases of conflicts. This is a good feature most of the time, but when it is not, there are ways to disable renaming
With normally does evaluate the r.h.sides of its variable declarations. I recently learned (from @Szabolcs) that there is a syntax which will keep them unevaluated: With[{a := Print[1]}, Hold[a]], but it is undocumented and it is not clear if it is reliable.
By its nature, With will always require a fixed number of arguments
With can not normally change the values of its ""variables"" (constants really), unless again an undocumented form of it is used: a=1;With[{b := a}, b = 3];a.
In principle, the core With functionality  is nothing special in the sense that it can be emulated with a top-level code.
With can be used as a r.h.s. of delayed rules. This usage allows it to share variables between its body and condition, e.g. x_:>With[{y=x^2},{x,y}/;y<10]. This is a powerful feature, and one variation  of it (Trott-Strzebonski technique, a reference to the original source and some explanation can be found  e.g. here) is a particularly powerful device in rule-based programming. This is a language feature, and can not be easily emulated (well, perhaps unless one uses RuleCondition) . Function-s can not be used in a similar fashion. 

Some conclusions
While Function and With have somewhat similar semantics regarding the way they bind their variables, these construct are different. Even within Function-s themselves, functions with slots are substantially different from functions with named arguments, the main difference being that the former is not really a full-fledged scoping contsruct (more of a macro, as was also noted in other answers), while the latter is.  
Returing to With vs Function, viewed as injecting devices - the sets of such use cases for both do have a significant overlap. In other words, in many such cases they can be used interchangeably. However, my personal inclanation is to mostly use With as an injecting device, while I use Function for such purposes in relatively special circumstances. One should also keep in mind differences outlined above, sometimes those effects can lead to subtle errors.
Finally, from the viewpoint of a programming paradigms, With plays well both with functional programming and with rules, while Function plays well with functional programming constructs, so With seems to have somewhat wider domain of applicability.
"
numerics - Using Mathematica to help to determine the consistency of and numerically solve systems of non-linear equations,"
Your system is very large and what you're asking is quite general. So I guess only collection of general tips or links can help for now. If you provide a more specific smaller example - it would be easier to address. Generally there is an extensive documentation with many examples on ""Constrained Optimization"":

Read sectioned online
Download PDF

An example of a flexible approachs to a solution of a nonlinear system was already posted here:
Updating Wagon's FindAllCrossings2D[] function
List of some relevant interactive Demonstrations with free source code that solve a nonlinear system:

Hertzian Contact Stress 
Semenov's Algorithm for Solving Systems of Nonlinear Equations
Iterations of Newton's Method for Two Nonlinear Equations

"
Does there exist any way to add type annotations?,"
You could use UpValues:
mylist = {""Alice"", ""Bob"", ""Carol""};
numlist = {1, 2, 5, 3};

SetAttributes[NETType, HoldAll]

NETType[mylist] ^:= String
NETType[numlist] ^:= Integer

{NETType[mylist], NETType[numlist]}

(* Returns:
{String, Integer}
*)

Of course, this does not perform any checks that the elements in the list actually are of the type claimed.
"
plotting - Visualizing 3×3 spectrahedra,"
If the desire is to not have a surface appear when the region hits the boundary of the plot range, you could use something like:
Show[RegionPlot3D[Evaluate[cons], {x, -3, 3}, {y, -3, 3}, {z, -3, 3}, 
  PlotRangePadding -> None, Mesh -> 5, PlotStyle -> Opacity[.7], 
  PlotPoints -> 10], PlotRange -> 2.9]

to truncate the plot range to an area inside the boundary.

"
reference request - What is the best Mathematica tutorial for young people?,"
Mathematica is the best tutorial. It is a discovery tool - just start from something that he knows a bit already and you both take one little step at a time. Just try things.

1st Thing - Try this Link => Hands-on Start to Mathematica
I personally would recommend engaging with him in a project of making an application and submitting it to the Wolfram Demonstrations Project. 

http://demonstrations.wolfram.com/
Check out stuff for kids: Link => Especially this
It could be something simple, but because it is interactive - he may find it fun to play with. I suggest you guys design and make a game. When teens have precise goals it is easier to set them on track especially if it is fun. You can also look through demonstrations and try to figure out how they work. Taking thinks apart - kids like that ;-)

There are many videos here:

http://www.wolfram.com/broadcast/

But, again, Mathematica is the tutorial itself. It has some magic called ""free form linguistic input"". Basically you type in plane English and it gives you back the code or data. This is very cool for kids and teens. They can see how a concept is getting turned into code. You can find a few examples here:

Link => Virtual talk video
Link => Virtual talk notebook
This maybe a little bit adult level, but you can find some tricks how to teach him.

I generally recommend all talks here - videos & notebooks:

http://www.wolfram.com/events/virtual-conference/2011/presentations/

Mathematica Documentation is full of neat examples.
If he does not have Mathematica he can try using Wolfram|Alpha - it is free:

http://www.wolframalpha.com/
I very much like the idea of teaching programming to children. Below are a standard references for students:
M10: A Student's First Course in Mathematica
Wolfram Education Portal
"
graphics - $\LaTeX$ and Mathematica,"
There are a few different parts to your question. I'll just answer the part about using psfragand pdflatex.
There's a package called pstool that automates the whole process of using psfrag with pdflatex.
For example, here's a graphics created in Mathematica 8
plot = Plot[Sin[Exp[x]], {x, -Pi, Pi}, AxesLabel -> {""e"", ""s""}]
Export[NotebookDirectory[] <> ""plot.eps"", plot]


Note the use of the single character names for the axes. This was discussed in the stackexchange question 
Mathematica 8.0 and psfrag.
You can use psfrag on this image and compile straight to pdf using the following latex file
\documentclass{article}  
\usepackage{pstool}
\begin{document}
\psfragfig{plot}{%
	\psfrag{e}{$\epsilon$}
	\psfrag{s}{$\Sigma$}}  
\end{document} 

Compile it using pdflatex --shell-escape filename.tex. You can optionally include a file plot.tex in the same directory which can contain all the psfrag code for plot.eps so that your main .tex file is tidier and the plot is more portable.
Here's a screenshot of the graphics in the pdf file:

"
front end - Revert FullForm-ed text to prettyprinted,"
The fastest method keystroke-wise that I have found is:

Create new empty cell
Press Ctrl+Shift+E to get Cell[BoxData[""""], ""Input""]
Paste your expression into that one replacing the """" inside of BoxData.
Press Ctrl+Shift+E again.

Alternatively, plaste your expression into this and evaluate:
FrontEndExecute@FrontEnd`CellPrint[
  (* expression here *)
]

"
front end - Fontsize is too small,"
I might as well post my comment to Szabolcs as an answer. As Szabolcs noted, the default screen resolution in Mathematica is set to 72 dpi which might not agree with the actual resolution. 
You can change the screen resolution in the Option Inspector which can be found in the Format menu.  Set ""Show option values"" to ""Global preferences"" to change Front End settings permanently or set it to ""Selected Notebook"" to apply them to only the current notebook.  Then just search for ScreenResolution in the search box. The relevant option is the one called ""ScreenResolution"" with quotation marks. You can also find it via Formatting Options > Font Options > FontProperties > ""ScreenResolution"". It's set to 72 by default as Szabolcs figured out. 
By the way, I found that on OS X at least, to change a value in the option inspector I need to click on the value and hover over the selection with my mouse cursor for a few seconds until it goes into edit mode, but it might be different on Windows. 

You can try out using the system dpi temporarily by evaluating:
SetOptions[$FrontEndSession, FontProperties -> {""ScreenResolution"" -> Automatic}]

(This will revert to the previous value after the Front End is closed.)
You do this for the current notebook using
SetOptions[EvaluationNotebook[], 
     FontProperties -> {""ScreenResolution"" -> Automatic}]


Alternatively, If it's just the ""Text"" style that is too small, you could change the default text font in the style sheet you're using. In order to do this, go to Format > Edit Stylesheet... and type Text in the text field. Select the newly created cell, change the size in Format > Size to whatever you want, and close the stylesheet editor. All text cells in your notebook should now use the updated font size by default.
"
graphics - Tile image on specific location without space between them,"
One can in fact use the (once documented) third argument of Rectangle[] to tile images. Here's an example I cooked up:
imgs = {ExampleData[{""TestImage"", ""Clock""}], 
   ExampleData[{""TestImage"", ""Elaine""}], 
   ExampleData[{""TestImage"", ""JellyBeans""}], 
   ExampleData[{""TestImage"", ""Lena""}], 
   ExampleData[{""TestImage"", ""Mandrill""}], 
   ExampleData[{""TestImage"", ""Peppers""}], 
   ExampleData[{""TestImage"", ""Splash""}], 
   ExampleData[{""TestImage"", ""Tiffany""}], 
   ExampleData[{""TestImage"", ""U2""}]};

mat = Partition[RandomSample[Range[9]], 3];
Graphics[Table[Rectangle[{j, k}, {j + 1, k + 1}, imgs[[mat[[j + 1, k + 1]]]]],
               {j, 0, 2}, {k, 0, 2}]]


The idea is that, you have nine images to distribute on a 3×3 grid; you thus partition some permutation of the numbers $1$ to $9$ in groups of three (that is, mat), have the indices of Table[] map to a corresponding entry of mat, and then that entry of mat has a corresponding index in the list imgs. The extension to any number of images to be arranged in a grid should be straightforward.
"
"front end - Create shortcut in Mathematica for ""Equal Symbol Aligned Math Cell""","
With a little help from
http://web.ift.uib.no/~szhorvat/mmatricks.php
I came up with (having no idea why I could not use F3, on Windows, but F4 works) :
Item[KeyEvent[""F4""], FrontEndExecute[FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],
    Cell[TextData[Cell[BoxData[FormBox[GridBox[{{GridBox[{{""\[Placeholder]""}},
    GridBoxAlignment->{""Columns"" -> {{""=""}}}]}},
    GridBoxItemSize->{""Columns"" -> {{Scaled[0.96]}}}], TraditionalForm]]]], ""Text""], After]; 
    FrontEnd`NotebookFind[FrontEnd`InputNotebook[], ""\[Placeholder]"", Previous,CellContents]]]

which I inserted at the end of KeyEventTranslations.tr
Maybe it is a good idea to make a backup-copy of your KeyEventTranslations.tr, and remember:
the copy should not end with .tr
"
linear algebra - How to enter matrices in block matrix format?,"
You're looking for ArrayFlatten. For your example matrices,
 R = ArrayFlatten[ {{A, {t}\[Transpose]},{0, 1}} ]
 (*
 => {{1, 0, 0, 1}, {0, 0, 1, 1}, {0, -1, 0, 1}, {0, 0, 0, 1}}
 *)

The construct {t}\[Transpose] is necessary for ArrayFlatten to treat t as a column matrix. 

Then to find $\boldsymbol{R}^{-1}$, you run 
Inverse[R]
(* 
=> {{1, 0, 0, -1}, {0, 0, -1, 1}, {0, 1, 0, -1}, {0, 0, 0, 1}}
*)

"
version 8 - Typography messed up in prints,"
First, I cannot reproduce your issue on Mathematica 8.0.1.0 on 64-bit Linux (CentOS 5.8). But I compare what you obtain and what I see, and I think I have an idea.

The notebook does not specifically require fonts, and as such, the font for e.g. your title cell is system-dependent. On my Mac, it uses a bold Helvetica in size 36, while on my Linux box it substitutes it by a Nimbus Sans L. As the latter is a free Helvetica substitute, it works fine even though it does not strictly have the same metrics. When exported to PDF, the font used is ""Helvetica-Bold"", which is not embedded because it's a standard PDF font.
In your case, the display font substitution is what is going wrong. Compare your display (top) and print (bottom) versions:


You can see the display font is not a good substitute for Helvetica: the characters are different (see the endings of the s and a) and it's definitely wider. I suspect this difference in metrics is where the awful character positioning is coming from.
So, why is your display font not Helvetica or a substitute? If you have a decent substitute installed, I don't know why Mathematica isn't using it, but font handling in X11 is a hairy topic. Maybe you'll get better results at debugging this on AskUbuntu.
And what can you do to fix it? Well, if it's a problem of fonts missing from you system, try installing Freefont if you haven't already (package ttf-freefont), or MS Core fonts (package ttf-mscorefonts-installer). If it's an X11 issue, then I'm afraid I can't help more…


Edit. I actually have another suggestion for a workaround: have you tried other fonts on your system (non-default fonts) to see if it works better?
"
front end - How to work around Column cutting off a pixel row from images?,"
This seems to be due to a small rounding issue on Windows.
Here is a test Manipulate:
Manipulate[
 matrix = ArrayFlatten[Table[DiamondMatrix[size], {x}, {y}]];
 image = Image[matrix /. {0 -> {0, 0, 0}, 1 -> {255, 255, 255}},
  ""Byte"", ColorSpace -> ""RGB"", Interleaving -> True];
 Column[{""test"", Image[image, Magnification -> 1], ""test""}],
 {size, 1, 20, 1},
 {x, 1, 20, 1},
 {y, 1, 20, 1}
]

Under certain settings the top row of pixels in the image is cut off:

"
"output formatting - Way to improve ""show me this decimal number to M places, don't use scientific notation""?","
You can express any fraction/number to arbitrary decimal places by using a backtick followed by number of digits required. For example:
In[1]:= 4/3`20
Out[1]= 1.3333333333333333333

This is the same as N[4/3, 20]. Now combine this with AccountingForm, which never uses scientific notation to get the output that you desire.
AccountingForm[1/998001`2994]
Out[2]//AccountingForm= 0.0000010020030040050060070080090100110120130140...

However, be aware that AccountingForm uses parentheses for negative numbers:
AccountingForm[-1/998001`2994]
Out[3]//AccountingForm= (0.00000100200300400500600700800901001101201301401501601....


Daniel Lichtblau has a good point that although using `instead of N might be shorter in this case, in general, it might not give the same result — for example, compare the digits of Log[2`50] and N[Log[2],50]. You'll see that they differ in the last couple of digits. However, for small use cases, the difference might be insignificant.
"
sparse arrays - Efficient by-element updates to SparseArrays,"
If you need a batch update, then the answer is in my comment you linked. If you need element-by-element, then there are two cases: 

Most of values you update are non-zero (or, generally, not equal to default element). In this case, I believe the answer of @Mr. Wizard is optimal, and you should expect  update of a single element to be constant time.
Most (or at least a sizable fraction) of these elements are initially zero (or, default element). Then, you are out of luck. I gave a brief answer to a similar request in this thread. Basically, SparseArray object keeps lists of non-zero elements and their positions in packed arrays. Therefore, a transition from zero to non-zero for an element requires insertion in the middle of them, which is O(n) operation, where n is the current number of non-zero elements. So, this is the same situation as building a list with Append, and it will lead to a quadratic complexity. 

This tidbit is not well-known, so I'd like to emphasize it again: element-by-element update for the SparseArray generally has complexity ~ updates * nzero, where updates is the number of updates, and  nzero is the final non-zero elements.
If you can organize your elements into batches which can be updated at the same time, you win big. Then, I suggest that you use the function I described in the cited answer. A main obstacle in a batch approach would be if you need the current state of your array to be used for something, say matrix multiplication, in between single element updates. If this is not the case, I think you should be able to use the batch update method.
"
programming - How can I speed up SQL queries in Mathematica?,"
Adding a database index is very important when SELECTing data from a big table. Once you add the index, MySQL will take care of keeping it updated. The disadvantage of indices is that your database now takes more space in your HD and that your INSERTs are now slower.
Note that you created a multiple-column index that speeds up you SELECTs when you lookup by:

ticker, whichprice and date
ticker and whichprice
ticker

If you do a SELECTs by whichprice or date or (whichprice and date) will still be slow. 
Lastly, if this is a read-only table you could use the MyISAM storage engine and maybe even move to MariaDB (a mysql fork) for better performance.
"
evaluation - How to create symbols from strings and set values for them?,"
One solution is to use the third argument of ToExpression:
With minimal modification, a working version of your code would look like this:
Table[
  ToExpression[
  mmsignalnames[[i]], 
  InputForm, 
  Function[name, 
    name = Extract[ToExpression[celfilenames[[i]]], mmammindices[[j]]],
    HoldAll]],
 {i, Length[mmsignalnames]}, {j, Length[mmammindices]}]

(Untested because I don't have your data;  but see below for the main idea and a small demonstration.)
The core of the method is this:
ToExpression[""a"", InputForm, Function[name, name = 1, HoldAll]]

ToExpression will wrap the result into its third argument before evaluating it.  We can make the third argument a function that sets a value to the symbol (in this simple example it always sets the value to 1).  HoldAll is needed to make sure the symbol won't evaluate when it is passed to the function.

You might find all the evaluation control I'm using here a bit confusing.  To learn how to work with unevaluated expressions, I recommend reading

Working with Unevaluated Expressions by Robby Villegas

It is one of the best tutorials on the matter.

Finally, after answering your actual question, I'd like to suggest you use a hash table instead of symbols:
Instead of creating symbols from the strings ""a"", ""b"", ""c"", ..., and assigning to them, you could assign to myTable[""a""], myTable[""b""], ...  This will make programmatic access to this data trivial.  You won't need to bother with evaluation control nearly as much.  And more importantly, you can avoid accidental name collisions with existing symbols.  Here's an example:
(myTable[#] = 1) & /@ {""a"", ""b"", ""c""}

"
graphics - How can I specify the arrowhead size in printers points?,"
You could create a custom arrowhead using Offset coordinates, which are in terms of printer's points:
arrow = Graphics[
   Polygon[{{0, 0}, Offset[{-10, 5}, {0, 0}], Offset[{-5, 0}, {0, 0}],
      Offset[{-10, -5}, {0, 0}]}]];

Table[Graphics[{Arrowheads[{{0.1, 1, arrow}}], 
   Arrow[{{0, 0}, {1, 1}}]}, ImageSize -> s], {s, Range[25, 150, 25]}]


"
graphics - Plot Ellipse based on EigenSystem,"
You can use Rotate to draw the ellipse too. Note that knowing the eigenvectors is the same as knowing the orientation of the ellipse, so there is no necessity to favour GeometricTransformation over Rotate. So, to orient your ellipse along the first eigenvector (corresponding to the largest eigenvalue), it is as simple as:
Graphics[Rotate[Disk[meanVec, eigVals], ArcTan @@ eigVecs[[1]]]]


where meanVec is the mean (here, I've taken it to be {0,0})

Going by your comment under rcollyer's answer, here's a example reproducing your desired figure with simple shifting (change the center of the disk) and rotation of the disk. This approach will be simpler to follow (as the transformations are spelled out), if you do not understand what GeometricTransformation does. Modifying rcollyer's module,
Module[{mat = #, avg = Mean@fixations, eigVals, eigVecs},
   {eigVals, eigVecs} = Eigensystem@mat;
   Graphics[{{Black, Disk[#, .5] & /@ fixations}, 
      {Directive[Opacity[0.1], Red, EdgeForm[Gray]], 
          Rotate[Disk[avg, eigVals/5], ArcTan @@ eigVecs[[1]]]}
   }]
]&@covMatrice


"
list manipulation - Flatten at a certain level,"
Ok, I will give it a shot, although what follows is mostly a guess, and I also may be wrong.
Why this does not work (a guess)
I think, what you ask can not be achieved with just Flatten. And the reason for this is that there seems to be no way for the syntax you propose to coexist with the syntax explained in the question you linked. So, the problem is, that while e.g. this code is ligitimate:
Flatten[{{{1, 2, 3}, {6, 7}}, {{4, 5}, {8, 9, 10}}, {11, 12}}, {1}]

(*
  ==>  {{{1, 2, 3}, {6, 7}}, {{4, 5}, {8, 9, 10}}, {11, 12}}
*)

the syntax we used there means not what you'd like it to be in this case. I can only guess that this design decision was motivated by considering this possibility to be easily implemented using Map (for those who need it), while the one that currently is there for this syntax to be less trivial and not easily replicated.
Making it work through custom environments
If you want to frequently use Flatten with the semantics you mentioned, I suggest to create a lexical or dynamic environment where you will replace the existing semantics with this one. Here is a dynamic environment which will do that:
ClearAll[withListableFlatten];
SetAttributes[withListableFlatten, HoldAll];
withListableFlatten[code_] :=
  Internal`InheritedBlock[{Flatten},
    Unprotect[Flatten];
    Flatten[lst_, levspec_List] := Map[Flatten, lst, levspec];
    Protect[Flatten];
    code];

and now:
withListableFlatten[
  Module[{
     test = {{{1, 2, 3}, {4, 5}, 11}, {{6, 7}, {8, 9, 10}, 12}},
     levSpec = {1}},
    Flatten[test, levSpec]
  ]]

(* 
  ==> {{1, 2, 3, 4, 5, 11}, {6, 7, 8, 9, 10, 12}}
*)

where I used Module to illustrate that the new syntax will take effect for an arbitrary code enclosed in this wrapper, and all the way down the execution stack in this code. A lexical environment will be much easier to write in this case:
ClearAll[withListableFlattenLex];
SetAttributes[withListableFlattenLex, HoldAll];
withListableFlattenLex[code_] :=
  ReleaseHold[
     Hold[code] /. HoldPattern[Flatten[l_, lev_]] :> 
         Map[Flatten, l, lev]]

and you can check that it will give the same result for the above example. The difference is that in this case, only the explicit entries of Flatten in code will be affected.
As a side note, a good thing about dynamic environments is that they can be easily combined / nested, with rather predictable behavior in terms of how they interact, because they change behavior at run-time only (which is a late stage). The bad thing about them is that they affect all the code down the execution stack, and this makes them less suitable for writing say higher-order functions, or any functions which accept arbitrary user's code. Lexical environments are safer in this respect, but so far Mathematica lacks a genuine macro system which would both be natural to use, and will make their composition easier.
"
How to create a group action table with Mathematica?,"
MMA v.8 provides support for (finite) Group Theory, however this answer will not make use of that functionality.
We shall use the ** (NonCommutativeMultiply) command present in MMA, which allows us to create semigroups quite easily. 
In a fresh MMA session:
Unprotect[NonCommutativeMultiply];
GroupAction[g_, s_] := (g ** #) & /@ s
1 is the identity:
g_ ** 1 := g
1 ** g_ := g
Elements relations
a ** a ** a := 1
b ** b := 1
b ** a ** a := a ** b
Then
G = {1, a, a ** a, b, b ** a, b ** a ** a}

S = Subsets[G, {3}]

Check some products:
a ** 1 ** b ** q
a ** 1 ** b ** b ** q
a ** 1 ** b ** a ** a ** b ** q
p ** a ** a ** a ** q
(p and q are generic group elemants) as you see MMA uses the associative (Flat) property of NonCommutativeMultiply to parse and simplify the expressions in all possible ways.
Now this is your table:
Table[GroupAction[g, s], {s, S}, {g, G}] // MatrixForm
Nicely formatted:
Grid[Prepend[Table[GroupAction[g, s], {s, S}, {g, G}], G], 
 Background -> {None, {Lighter[Blue, .9], {White, 
     Lighter[Blend[{Blue, Green}], .8]}}}]
If you are serious about Group Theory, you might want to check the functionalities offered by MMA v.8
"
"What are some useful, undocumented Mathematica functions?","

LongestCommonSequencePositions and LongestCommonSubsequencePositions  Their use is analogous to LongestCommon(Sub)sequence but they return the position of the first match instead.
Update: These are documented since 10.2.
ClipboardNotebook[] can be used to access the clipboard.  NotebookGet@ClipboardNotebook[] will give a Notebook expression with the current contents of the clipboard.  I use this for pre-processing data before it is pasted (e.g. in the table paste palette).  I am not sure if this can be used for copying at all---I use the Front End's Copy function directly for that (through FrontEndTokenExecute)
Update: Since version 8 we have some documented clipboard functions.
PolynomialForm[] allows changing the order in which polynomial terms are printed by setting the option TraditionalOrder -> True
In[1]:= PolynomialForm[1+x+x^2, TraditionalOrder->True]
Out[1]= x^2+x+1

POST request: In version 8 Import has experimental support for the POST HTTP request method.  Example usage for uploading an image to imgur:
Import[""http://api.imgur.com/2/upload"", ""XML"", 
       ""RequestMethod"" -> ""POST"", 
       ""RequestParameters"" -> {""key"" -> apikey, ""image"" -> image}]

(Of course you'll need to insert your API key and a properly encoded image, as shown in the answer I linked to above.)
Internal`Deflatten[] will reconstruct higher dimensional tensor from a flat list.  Example:
In[1]:= arr = {{1, 2}, {3, 4}}
Out[1]= {{1, 2}, {3, 4}}

In[2]:= flatArr = Flatten[arr]
Out[2]= {1, 2, 3, 4}

In[3]:= Internal`Deflatten[flatArr, Dimensions[arr]]
Out[3]= {{1, 2}, {3, 4}}

Warning: If the dimensions passed to it don't match the length of the flat array, this will crash the kernel!
Update: Version 9.0 introduced the documented equivalent ArrayReshape.



Image capture start/stop IMAQ`StartCamera[] and IMAQ`StopCamera[] start and stop the webcam.



Undocumented interesting contexts to dig through: Internal`, Experimental`, Language`, NotebookTools` (similar to what the AuthorTools package offers), IMAQ` (IMage AQcuisition)
There are lots of functions in these contexts, generally undocumented, but sometimes with self-explanatory names (e.g. Internal`RealValuedNumericQ seems obvious).  Note that these functions might change in later versions.  Some of the ones listed by ?Internal`* are even from old versions and no longer work in M- 8.
Some functions from Language` are described here.



SystemOptions[]  The functions to set and read these options are not undocumented, but the options themselves unfortunately are.

Experimental`SystemOptionsEditor[]  In version 8 this gives a GUI for viewing/setting system options.
""TableCompileLength"" (and other similar options from the ""CompileOptions"") section set the length of a Table above which it attempts to compile its argument.
Example: SystemOptions[""CompileOptions"" -> ""TableCompileLength""] will show that the default value is 250.
""SparseArrayOptions"" -> {""TreatRepeatedEntries"" -> 1}
Setting this option to 1 will cause repeated entries to be summed up when creating a sparse array.  See an example use and explanation here.
In[1]:= Normal@SparseArray[{2 -> 1, 4 -> 1}]
Out[1]= {0, 1, 0, 1}

In[2]:= Normal@SparseArray[{2 -> 1, 4 -> 1, 2 -> 1}]
Out[2]= {0, 1, 0, 1}

In[3]:= SetSystemOptions[""SparseArrayOptions"" -> {""TreatRepeatedEntries"" -> 1}]

In[4]:= Normal@SparseArray[{2 -> 1, 4 -> 1, 2 -> 1}]
Out[4]= {0, 2, 0, 1}




This MathGroup thread has some interesting information too.
"
How can one find undocumented options or option values in Mathematica?,"
One thing you can do is look for options which appear in a function's Options but do not have a ::usage message. Of course, some of the results actually are documented in the help, they just don't have a usage message. Here's a function to do it:
undoc[x_Symbol]:=Select[Options[x],!StringQ@MessageName[Evaluate@First@#,""usage""]&];
undoc[_] = {};

(* e.g. *)
undoc[Plot]
Out[3]= {Evaluated->Automatic,ImageSizeRaw->Automatic}

The following runs this function on all symbols in System context, and presents the results in a grid. Some functions (like Cell) have huge lists of options with no usage message, these ones I skip over (just printing out the function name) to save space.
Grid[Select[{#,undoc[Symbol[#]]}&/@Names[""System`*""],
Last@#=!={}&&(Length@Last@#<10||Print@First@#)&],Frame->All]


"
calculus and analysis - Series expansion of an inverse,"
Is InverseSeries what you are looking for?
InverseSeries[Series[ArcTan[Log[1 + x]/(1 + x)], {x, 0, 5}]]
(*
x+(3 x^2)/2+3 x^3+(149 x^4)/24+(68 x^5)/5+O[x]^6
*)

EDIT: looks reasonable:
Plot[{
  pl[x],
  invs
  },
 {x, -.3, .3},
 PlotStyle -> {{Dashed, Black}, Red}
 ]


Who knows what the radius of convergence is, though.
"
export - How well does Mathematica code exported to C compare to code directly written for C?,"
A lot depends on how you write your code in Mathematica. In my experience, the rule of thumb is that the generated code will be efficient if the code inside Compile more or less resembles the code I would write in plain C (and it is clear why). Idiomatic (high-level) Mathematica code tends to be immutable. At the same time, Compile can handle a number of higher-level functions, such as Transpose, Partition, Map, MapThread, etc.  Most of these functions return expressions, and even though these expressions are probably passed to the calling function, they must be created. For example, a call to ReplacePart which replaces a single part in a large array will necessarily lead to copying of that array. Thus, immutability generally implies creating copies.
So, if you write your code in this style and hand it to Compile, you have to keep in mind that lots of small (or large) memory allocations on the heap, and copying of lists (tensors) will be happening.
Since this is not apparent for someone who is used to high-level Mathematica programming, the slowdown this may incur may be surprising. See this and this answers for examples of problems coming from many small memory allocations and copying, as well as a speed-up one can get from switching from copying to in-place modifications.
As noted by @acl, one thing worth doing is to set the SystemOptions -> ""CompileOptions"" as
SetSystemOptions[ ""CompileOptions"" -> ""CompileReportExternal"" -> True]

in which case you will get warnings for calling external functions etc.
A good tool to get a ""high-level"" but precise view on the generated code is the CompilePrint function in the CompiledFunctionTools` package. It allows you to print the pseudocode version of the byte-code instructions generated by Compile. Things to watch for in the printout of CompilePrint function:

Calls to CopyTensor
Calls to MainEvaluate (callbacks to Mathematica, meaning that something could not be compiled down to C)

One not very widely known technique of writing even large Compile-d functions and combining them from pieces so that there is no performance penalty, is based on inlining. I consider this answer very illustrative in this respect - I actually posted it to showcase the technique. You can also see this answer and a discussion in the comments below, for another example of how this technique may be applied.  
In summary - if you want your code to be as fast as possible, think about ""critical"" places and write those in ""low-level"" style (loops, assignments, etc) - the more it will resemble C the more chances you have for a speed-up (for an example of a function written in such a style and being consequently very fast, see the seqposC function from this answer). You will have to go against Mathematica ideology and use a lot of in-place modifications. Then your code can be just as fast as hand-written one. Usually, there are just a few places in the program where this matters (inner loops, etc) - in the rest of it you can use higher-level functions as well.
"
plotting - Centering date labels over the year in a DateListPlot,"
Here is a much simpler solution than Szabolcs's or Mike's. I've directly addressed your second bonus question and this can be easily extended to the first case. The following generates tick marks for the x-axis and incorporates your needs as per yours and Mike's comments below:

The quarter label is centered mid quarter
The year label is centered mid year

It is a wee bit wasteful in that I generate ticks for all months and then set the ones I don't want to be transparent. Of course, you can build upon the logic and generate/not generate for specific months/dates, but I'll let you decide if its worth it. 
xTicks[data_] := Module[{monthStr, date, color},
    monthStr[m_] := Which[
        MemberQ[{2, 5, 8, 11}, m], DateString[# + {0, 1, 0}, ""MonthNameInitial""] &, 
        m == 7, DateString[#, {""\n"", ""Year""}] &, True, """" &
    ];

    color[m_] := If[MemberQ[{4, 7, 10, 1}, m], Black, Transparent];
    date[m_] := If[MemberQ[{2, 5, 8, 11}, m], 15, 1];

    Table[MapAt[monthStr[m], {{y, m, date[m]}, {y, m, date[m]}, {0.0125, 0}, color[m]}, 2], 
        {y, Min[data[[All, 1, 1]]], Max[data[[All, 1, 1]]]}, {m, 1, 12}] ~Flatten~ 1
]

and now plot your FinancialData with ticks generated with the above as:
aapl = FinancialData[""AAPL"", {2008}];
DateListPlot[#, Joined -> True, FrameTicks -> {xTicks[#], Automatic, False, False}, 
    GridLines -> False]& @ aapl


"
formatting - Outline Numbering for Mathematica Section/Subsection Cells,"
This question might help. 
In short, to get an automatically numbered section or subsection you could edit the CellFrameLabels or the CellDingbat option of the relevant style definitions. 

Open a new notebook, add a section cell, and select Edit Stylesheet... in the Format menu 
Choose Section from the drop down menu in the stylesheet editor and select the newly created cell 
Check Show Expression in the Cell menu which 
Add either the option CellFrameLabels-> {{spec, None}, {None, None}} or CellDingbat -> spec somewhere after the first argument where spec is the specifications for the section number. 
Uncheck Show Expression. Sections in the should then be numbered automatically
You can install the updated stylesheet by pressing the Install Stylesheet... button in the stylesheet editor

In its simplest form the number specification would be something like 
 Cell[TextData[{ CounterBox[""Section""]}]]

for a section or
Cell[TextData[{ CounterBox[""Section""], ""."", CounterBox[""Subsection""]}]]

for a subsection, but you can add your own styling to the numbering. For example for a notebook using the default stylesheet you could set the style definition of Section to something like
Cell[StyleData[""Section""],
  CellFrameLabels->{{
    Cell[TextData[{CounterBox[""Section""], "" ""}],
    CellFrame -> {{0, 0}, {0, 1}}, 
    CellFrameMargins -> 4, 
    CellSize -> {30, Automatic}, 
    TextAlignment -> Right], 
   None}, {None, None}},
  CellFrameLabelMargins->0
]

Which would produce sections like this

"
programming - How to make GraphicsGrid with content tight inside it?,"
I prefer Framed. To improve labels just wrap TraditionalForm around it:
TraditionalForm@Framed[title]


If you have many cells and if the whole point is to make a tight grid and have nice labels, you could improve labels in Grid, rather then improving spacing in GraphicsGrid:
TraditionalForm[Grid[{{title}, {title}}, Frame -> All]]


GraphicsGrid is to handle graphics. Just for the sake of completeness you could simply Rasterize your formula to Graphics to make GraphicsGrid work:
GraphicsGrid[{{Rasterize@TraditionalForm[title]}}, Frame -> All]


"
Functional style using lazy lists?,"
A ""lazy list"", ""functional style"" solution to this problem might look something like this:
sIntegers[] ~sMap~ Prime ~sFilter~ palindromicQ ~sTake~ 400 // sList

No such notation is built into Mathematica.  However, creating such notations is Mathematica's strong suit.  Let's do it.
First, we need to define the notion of a ""stream"".  Streams are inherently lazy, so let's use HoldAll:
SetAttributes[stream, {HoldAll}]

A stream can be empty:
sEmptyQ[stream[]] := True

... or it can be non-empty, having two elements:
sEmptyQ[stream[_, _]] = False;

The first element of the stream is called the ""head"":
sHead[stream[h_, _]] := h

The remaining elements of the stream are called the ""tail"":
sTail[stream[_, t_]] := t

Armed with these definitions, we can now express an infinite stream of integers thus:
sIntegers[n_:1] :=
  With[{nn = n+1}, stream[n, sIntegers[nn]]]

sIntegers[] // sEmptyQ                 (* False *)
sIntegers[] // sHead                   (* 1 *)
sIntegers[] // sTail // sHead          (* 2 *)
sIntegers[] // sTail // sTail // sHead (* 3 *)

Infinite streams are difficult to display in a notebook.  Let's introduce sTake which truncates a stream to a fixed length:
sTake[s_stream, 0] := stream[]
sTake[s_stream, n_] /; n > 0 :=
  With[{nn = n-1}, stream[sHead[s], sTake[sTail[s], nn]]]

Let's also introduce sList, which converts a (finite) stream into a list:
sList[s_stream] :=
  Module[{tag}
  , Reap[
      NestWhile[(Sow[sHead[#], tag]; sTail[#])&, s, !sEmptyQ[#]&]
    , tag
    ][[2]] /. {l_} :> l
  ]

Now we can inspect an integer stream directly:
sIntegers[] ~sTake~ 10 // sList
(* {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} *)

sMap applies a function to every element of a stream:
sMap[stream[], _] := stream[]
sMap[s_stream, fn_] := stream[fn[sHead[s]], sMap[sTail[s], fn]]

sIntegers[] ~sMap~ Prime ~sTake~ 10 // sList
(* {2, 3, 5, 7, 11, 13, 17, 19, 23, 29} *)

sFilter selects elements from a stream that satisfy a given filter predicate:
sFilter[s_, pred_] :=
  NestWhile[sTail, s, (!sEmptyQ[#] && !pred[sHead[#]])&] /.
    stream[h_, t_] :> stream[h, sFilter[t, pred]]

sIntegers[] ~sFilter~ OddQ ~sTake~ 15 // sList
(* {1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29} *)

We now have almost all of the pieces in place to address the original problem.  All that is missing is a predicate that detects palindromic numbers:
palindromicQ[n_] := IntegerDigits[n] /. d_ :> d === Reverse[d]

palindromicQ[123] (* False *)
palindromicQ[121] (* True *)

Now, we can solve the problem:
sIntegers[] ~sMap~ Prime ~sFilter~ palindromicQ ~sTake~ 400 // sList

(* {2,3,5,7,11,101, ... ,3528253,3541453,3553553,3558553,3563653,3569653} *)

The stream facility we have defined here is very basic.  It lacks error checking, and further consideration should be given to optimization.  However, it demonstrates the power of Mathematica's symbolic programming paradigm.
The following listing gives the complete set of definitions:
ClearAll[stream]
SetAttributes[stream, {HoldAll, Protected}]

sEmptyError[] := (Message[stream::empty]; Abort[])
stream::empty = ""Attempt to access beyond the end of a stream."";

ClearAll[sEmptyQ, sHead, sTail, sTake, sList, sMap, sFilter, sIntegers]

sEmptyQ[stream[]] := True
sEmptyQ[stream[_, _]] = False;

sHead[stream[]] := sEmptyError[]
sHead[stream[h_, _]] := h

sTail[stream[]] := sEmptyError[]
sTail[stream[_, t_]] := t

sTake[s_stream, 0] := stream[]
sTake[s_stream, n_] /; n > 0 :=
  With[{nn = n-1}, stream[sHead[s], sTake[sTail[s], nn]]]

sList[s_stream] :=
  Module[{tag}
  , Reap[
      NestWhile[(Sow[sHead[#], tag]; sTail[#])&, s, !sEmptyQ[#]&]
    , tag
    ][[2]] /. {l_} :> l
  ]

sMap[stream[], _] := stream[]
sMap[s_stream, fn_] := stream[fn[sHead[s]], sMap[sTail[s], fn]]

sFilter[s_, pred_] :=
  NestWhile[sTail, s, (!sEmptyQ[#] && !pred[sHead[#]])&] /.
    stream[h_, t_] :> stream[h, sFilter[t, pred]]

sIntegers[n_:1] :=
  With[{nn = n+1}, stream[n, sIntegers[nn]]]



palindromicQ[n_] := IntegerDigits[n] /. d_ :> d === Reverse[d]

"
"interoperability - Are there any ""RLink"" like projects, which enable the interaction between R and Mathematica?","
Erich Neuwirth on MathGroup mentioned a solution for Windows (free for non-commercial applications) that you can download here.
Here is his example with small updates from Sasha and Mark Fisher. After downloading the R instalation and DCOM server stuff I tried it and it seems to work just fine.
Needs[""NETLink`""]
myR = CreateCOMObject[""StatConnectorSrv.StatConnector""]
myR@Init[""R""]
myR@SetSymbol[""xxx"", 12321]
result1 = myR@GetSymbol[""xxx""]
myR@EvaluateNoReturn[""randmat<-matrix(rnorm(100),10)""]
rmat = myR@GetSymbol[""randmat""]
result2 = myR@Evaluate[""solve(matrix(1:4,2))""]

(*
==> NETLink`Objects`NETObject$3810539581$1070974657101825
*)

(*
==> 12321
*)

(*
==> {{-0.2729702674, 1.803861976, 0.5813040979, 0.1600081953, 
  0.7538751951, 0.3923246778, 1.240256949, 2.143071289, -0.2112634412,
   0.9417189228}, {-0.1815065752, 0.6340400316, 
  0.6235181836, -0.1729713552, -0.965223049, -0.8076688634, 
  0.6125102682, 0.8043927759, 
  0.2623272614, -0.7300377248}, {-0.1573784247, 
  1.745921499, -1.223295754, 
  0.7508255497, -1.437158433, -0.5431748169, 
  0.5224185732, -0.006148655396, -0.5381351892, -0.1264029232}, \
{-0.2285349193, 0.5978044841, 
  0.7099844671, -0.830220449, -0.5994523393, -0.1600179795, 
  0.2957343203, -0.2560352574, 
  1.45552903, -0.9763608981}, {-0.5509826168, 0.4205191323, 
  2.021672968, 0.4834619721, -0.6738896365, -1.782509979, 0.515151609,
   0.6698301759, -1.914440159, 0.1741606405}, {1.199489342, 
  1.397342011, -0.08762926484, 0.3572575699, 0.1415520058, 
  0.2384566775, -0.598134357, -0.199506724, -0.4849505361, 
  0.1238990228}, {0.55417032, 
  0.4911786903, -0.2432415953, -1.270176719, 
  0.3143047255, -0.3256634613, 0.9347990095, 
  0.6459510591, -0.924018154, 1.091294398}, {-0.5705422396, 
  0.1740525789, -0.7607604118, -0.4584603394, -2.602648464, \
-0.08879130709, 1.550124853, 0.4472847015, 0.1335582644, 
  0.07635818615}, {1.301494963, 1.106258178, 
  0.3354845242, -1.45468913, -0.3581930843, 
  1.187368824, -0.1503588385, 0.1511637701, 2.236312191, 
  1.067101554}, {0.04525815419, 0.1181913247, 
  1.588764281, -0.7367518216, -1.79115224, -3.891936361, 2.463525431, 
  2.721622641, 0.8049086131, -0.1488657311}}
*)

(*
==> {{-2., 1.5}, {1., -0.5}}
*)

myR@Close[]

"
performance tuning - Internal`Bag inside Compile,"
I am somewhat reluctant to offer this as an answer since it is inherently difficult to comprehensively address questions on undocumented functionality. Nonetheless, the following observations do constitute partial answers to points raised in the question and are likely to be of value to anyone trying to write practical compiled code using Bags. However, caution is always highly advisable when using undocumented functions in a new way, and this is no less true for Bags.
The type of Bags

As far as the Mathematica virtual machine is concerned, Bags are a numeric type, occupying a scalar Integer, Real, or Complex register, and can contain only scalars or other Bags. They can be created empty, using the trick described in the question, or pre-stuffed:

with a scalar, using Internal`Bag[val] (where val is a scalar of the desired type)
with several scalars, using Internal`Bag[tens, lvl], where tens is a full-rank tensor of the desired numeric type and lvl is a level specification analogous to the second argument of Flatten. For compiled code, lvl $\ge$ ArrayDepth[tens], as Bags cannot directly contain tensors.

Internal`StuffBag can only be used to insert values of the same type as the register the Bag occupies, a type castable to that type without loss of information (e.g. Integer to Real, or Real to Complex), or another Bag. Tensors can be inserted after being flattened appropriately using the third argument of StuffBag, which behaves in the same way as the second argument of Bag as described above. Attempts to stuff other items (e.g. un-flattened tensors or values of non-castable types) into a Bag will compile into MainEvaluate calls; however, sharing Bags between the Mathematica interpreter and virtual machine has not been fully implemented as of Mathematica 8, so these calls will not work as expected. As this is relatively easy to do by mistake and there will not necessarily be any indication that it has happened, it is important to check that the compiled bytecode is free of such calls.

Example:
cf = Compile[{},
 Module[{b = Internal`Bag[{1, 2, 3}, 1]},
  Internal`StuffBag[b, {{4, 5, 6}, {7, 8, 9}}, 2];
  Internal`BagPart[b, All]
 ]
]

cf[] gives:
{1, 2, 3, 4, 5, 6, 7, 8, 9}

Nested Bags
These are created simply by stuffing one Bag into another, and do not have any special type associated with them except the types of the registers containing the pieces. In particular, there is no ""nested Bag type"". Per the casting rules given above, it is theoretically possible to stuff Integer Bags into a Real Bag and later extract them into Integer registers (for example). However, this technique is not to be recommended as the result depends on the virtual machine version; for instance, the following code is compiled into identical bytecode in versions 5.2, 7, and 8, but gives different results:
cf2 = Compile[{},
 Module[{
    br = Internal`Bag@Most[{0.}],
    parts = Most[{0.}],
    bi = Internal`Bag@Most[{0}]
   },
  Internal`StuffBag[bi, Range[10], 1];
  Internal`StuffBag[br, bi];
  parts = Internal`BagPart[br, All];
  Internal`BagPart[First[parts], All]
 ]
]

The result from versions 5.2 and 7:
{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

The result from version 8:
{1.}

Stuffing Bags of mixed Real and Integer types into a Real Bag produces even less useful results, since pointer casts are performed by Internal`BagPart without regard to the original type of each constituent Bag, resulting in corrupted numerical values. However, nesting bags works correctly in all versions provided that the inner and outer bags are of identical types. It is also possible to stuff a bag into itself to create a circular reference, although the practical value of this is probably quite limited.
Miscellaneous

Calling Internal`BagPart with a part specification other than All will crash Mathematica kernels prior to version 8.
Internal`Bag accepts a third argument, which should be a positive machine integer. The purpose of this argument is not clear, but in any case it cannot be used in compiled code.

"
variable definitions - How do I clear all user defined symbols?,"
Maybe this ?
ClearAll[""Global`*""]

"
symbols - Is there a way to separate variables between multiple notebooks?,"
May be this, I have not tried it, but it sounds like this is what you are looking for (if I understood you correctly):
Evaluation menu -> Notebook's Default Context -> Unique to This Notebook.

So, you do the above for each notebook.
I found this in the daily Mathematica tip webpage: http://twitter.com/mathematicatip
Update
If you want to do it programatically from within a notebook, run SetOptions[EvaluationNotebook[], CellContext -> Notebook].
Update 2
To set this automatically for all new notebooks, open the Options Inspector (Ctrl/Command+Shift+O), and change the scope to ""Global Preferences."" Then, the option CellContext is found under Cell Options -> Evaluation Options. Change it to ""Notebook.""
"
performance tuning - MaxSteps and Computing time issue for Solving Differential equation in Mathematica,"
NDSolve uses adaptive methods to obtain a good solution.  It dynamically changes the step size during integration.
I recommend you take a look at the Advanced Numerical Differential Equation Solving tutorial (ODE section), which has a very detailed description of how NDSolve work, what methods are available, and how you can tweak them.
You can start with 
NDSolve[..., Method -> {""FixedStep"", Method -> ""ExplicitEuler""}, StartingStepSize ->  ... ]

to figure out what is going on (this will likely not give you a precise solution though).  There's a good chance that your differential equation is very troublesome to solve, so automatic method selection will not work well.  In this case you'll need to study the methods available, and make a suitable choice yourself.
"
plotting - ListPlot InterpolationOrder->0 datapoint centered,"
This uses Nearest to build a NearestFunction (nf) for your testdata. This is like InterpolationOrder -> 0 except that it is centered because it does as the name implies: gives the nearest value.
testdata = {{1, 3}, {3, 4}, {4, 3}, {5, 8}, {7, 6}, {9, 4}};

nf = Nearest[Rule @@@ testdata];

{min, max} = {Min@# - 1, Max@# + 1} &@testdata[[All, 1]];

Plot[ nf[x], {x, min, max},
  AxesOrigin -> {0, 0},
  Epilog -> {PointSize[Large], Point[testdata]}
]


"
probability or statistics - Simultaneously fitting multiple datasets,"
This is an extension of Heike's answer to address the question of error estimates. I'll follow the book Data Analysis: A Bayesian Tutorial by D.S. Sivia and J. Skilling (Oxford University Press).
Basically, any error estimate depends on the basic assumptions you make. The previous answers implicitly assume uniform normally distributed noise: $\epsilon \sim  N(0, \sigma)$. If you know $\sigma$ the error estimate is straightforward.
With the same definitions:
data1 = Table[{x, RandomReal[{-.1, .1}] + f[x, 1, 1, 1]}, {x, -4, 6, 0.25}];
data2 = Table[{x, RandomReal[{-.1, .1}] + f[x, .5, 1, 2]}, {x, -8, 10, 0.5}];
f[x_, amplitude_, centroid_, sigma_] := amplitude Exp[-((x - centroid)^2/sigma^2)]

Add the variables:
vars = {mu, au1, s1, au2, s2};

The variance of the error is (analytically, from the definition above):
noiseVariance = Integrate [x^2, {x, -0.1, 0.1}];

The log-likelihood of the model is: 
logModel = -Total[ (data1[[All, 2]] - (f[#, au1, mu, s1] & /@ 
       data1[[All, 1]]) )^2 /noiseVariance]/2 - 
             Total[ (data2[[All, 2]] - (f[#, au2, mu, s2] & /@ 
       data2[[All, 1]]) )^2 /noiseVariance]/2;

Optimize the log-likelihood (note the change of sign leading to a maximization instead of minimization)
fit = FindMaximum[logModel, vars]

The fit will be the same, as the variance estimation doesn't affect the maximum,  so I won't repeat it here.
For the error estimates, the covariance matrix is found as minus the inverse of the hessian of the log-likelihood function, so (DA p.50): 
$$
\sigma_{ij}^2 = -[\nabla \nabla L]^{-1}_{ij}
$$
hessianL = D[logModel {vars, 2}];
parameterStdDeviations =  Sqrt[- Diagonal@Inverse@hessianL];
{vars,  #1 \[PlusMinus] #2 & @@@ ({vars /. fit[[2]], 
   parameterStdDeviations}\[Transpose]) }\[Transpose] // TableForm

If $\sigma$ is unknown the analysis is slightly trickier, but the results are easily implemented. If the error is additive guassian noise of unknown variance the correct estimator is (DA p. 67): 
$$
s^2 = \frac{1}{N-1} \sum_{k=1}^N (data_k - f[x_k; model])^2
$$
estimatedVariance1 = Total[(data1[[All, 2]] - (f[#, au1, mu, s1] & /@ 
       data1[[All, 1]]) )^2] / (Length@data2 - 1);
estimatedVariance2 = Total[(data2[[All, 2]] - (f[#, au2, mu, s2] & /@ 
       data2[[All, 1]]) )^2] / (Length@data2 - 1); 

As stated above the magnitude of the variance won't affect our point estimates in the model, so we can use the same code above, and just inject the newly estimated variance into the log-likelihood function. This seems to be equivalent to the default behaviour of NonlinearModelFit.
As you seem to indicate that you are fitting spectra from a counting experiment, you might have better performance if you assume Poisson counting noise instead, then the variance for each channel is estimated as the number of counts in that channel:
$$
\sigma^2_k \approx data_k
$$
You might also want to consider adding a background model (a constant background is a simple extension of the above), depending on the noise level.  
"
variable definitions - Subscripts,"
This is because only symbols can be localized by Module.   It is not about assignment, but localization.
Subscript[a, 1] is not a symbol, but a compound expression, so:
Module[{Subscript[a, 1] = ""x""}, 0] (* <-- not allowed *)

Module[{}, Subscript[a, 1] = ""x""]  (* <-- allowed but not localized *)

I agree that the error you got may be a bit confusing.
A somewhat ugly workaround is Module[{Subscript}, Subscript[a, 1] = ""x""] or you may try to use the Notation` package to create symbol names with subscripts in them.  A word of warning though: in some cases, Module variables that have DownValues do not get destroyed when the Module finishes evaluating.  For more information, see the end of the Module section in this answer by Leonid Shifrin, and the comments on that answer.
"
undocumented - Bags and non-standard evaluation,"
This is not related to evaluation. Internal`Bag, like many other special types, is an atomic object.  You can verify this using AtomQ[x].  This is despite its InputForm suggesting a structure. 
This is no different from how Graph, Rational, Complex or SparseArray behave.  (Though for SparseArray, most list manipulation functions are implemented, so it's much more difficult to notice that it is atomic).

A similar example using Rational:
In[206]:= rats={1/2,2/3}
Out[206]= {1/2,2/3}

In[208]:= Head/@rats
Out[208]= {Rational,Rational}

In[209]:= Depth/@rats
Out[209]= {1,1}

In[210]:= FullForm[rats]
Out[210]//FullForm= List[Rational[1,2],Rational[2,3]]

"
How to solve this iteration in the functional programming way?,"
If I now understand your code this should do what you want.  I am using my own f function for concise repeatability.
f = Tr@ToCharacterCode@ToString@# &;

temp = {d -> {d}, c -> {c, d}, a -> {a, c, d}, b -> {b, d}};

rules = Fold[Append[#, #2[[1]] -> f@Replace[#2, #, {2}]] &, {}, temp]

temp = Replace[temp, rules, {3}]


{d -> 619, c -> 853, a -> 1085, b -> 851}

{d -> {619},
 c -> {853, 619},
 a -> {1085, 853, 619},
 b -> {851, 619}}



This is orders of magnitude faster than your original code on long rules lists because the complete rules list is not continually reprocessed:
f = Tr@ToCharacterCode@ToString@# &;

syms = RandomSample@Array[var, 1000];
dat = # -> {#, Sequence @@ RandomSample[syms, RandomInteger[5]]} & /@ syms;

(temp = dat;
  rules = {};
  Do[rules = Append[rules, temp[[i, 1]] -> f@temp[[i]]];
   r1 = temp = Replace[temp, rules, {3}];, {i, 
    Length@temp}]) // Timing // First


39.219


(temp = dat;
  rules = 
   Fold[Append[#, #2[[1]] -> f@Replace[#2, #, {2}]] &, {}, temp];
  r2 = temp = Replace[temp, rules, {3}]) // Timing // First


 0.14


r1 === r2


True


"
front end - Using DynamicModule variables outside the DynamicModule,"
What you want to do (make this piece of GUI resistant to kernel quits) can be achieved simply like this:
DynamicModule[
  {x = True, tag = Unique[StringJoin[""g"", ToString[
            $SessionID]]]}, CreateDocument[{""hello""},
     TaggingRules -> tag, Visible -> True];
   Checkbox[Dynamic[x,
       (x = #1; TrueQ[Select[Notebooks[],
                 CurrentValue[#1, TaggingRules] === tag & ] /.
               {b_NotebookObject} :> (CurrentValue[b,
                      Visible] =  ! CurrentValue[b,
                        Visible])]) & ]]]

The ""wormhole"" is a unique identitfier attached to TaggingRules.
"
functions - How to add an interpolating point to InterpolatingFunction?,"
When I told you that this was not possible, I was wrong.
My understanding is that you have points $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$ through which you construct an interpolating function $f$.  Now you need to add another point $(x_0, y_0)$, and construct a new interpolating function $f^*$ for which it is true that $f^*(x) = f(x)$ for all $x \in [x_1, x_n]$.  I thought it was not possible to keep the function value unchanged in the interval $[x_1, x_n]$ when using higher value interpolation, but this is not the case.  See below:
Let's make an interpolation function from cosine values between 0.1 and 1.0:
ifun = Interpolation@Table[{x, Cos[x]}, {x, .1, 1, .1}]

It looks like this:

The trick is that when we add an extra point at $x=0$, we need to keep all derivatives unchanged in $x = 0.1$ up to the order of interpolation.
You can get the order of interpolation like this:
ifun[""InterpolationOrder""]

(* ==> 3 *)

Let's get the derivative values in the first point:
derivs = Table[
  Derivative[i][ifun][ifun[""Grid""][[1, 1]]], 
  {i, 0, First@ifun[""InterpolationOrder""] - 1}]

(* ==> {0.995004, -0.0995897, -1.00396} *)

And inject them back into the function, while adding a new value $f(0) = 2$:
ifun2 = Interpolation@Join[
          {{{0}, 2},
           {ifun[""Grid""][[1]], Sequence @@ derivs}},
          Rest@Thread[{ifun[""Grid""], ifun[""ValuesOnGrid""]}]
        ]

Notice that the function is unchanged for all values greater than 0.1:
Plot[{ifun2[x], ifun[x]}, {x, 0, 1}, PlotRange -> All]


If you are wondering where I got this special API to InterpolatingFunction where we do things like ifun[""Grid""]: I simply looked into the DifferentialEquations`InterpolatingFunctionAnatomy` package that the other answers used.
"
replacement - Replace expressions with symbols,"
I'm not really clear on the scope of the question, but this might provide a start.
In[340]:= 
PolynomialReduce[1 - Cos[α], t[1] - π (1 - Cos[α]), 
  Cos[α]][[2]]

Out[340]= t[1]/π

--- edit ---
Here is your example. I change equations to expressions in effect by taking differences. I create a Groebner basis for the defining expressions; that might not be necessary in this example. I order variables so that the one to be eliminated, Cos[alpha-sub-max], is highest. Your Eliminate came close but I think you'd really need to use Cos[alpha...] instead of just the alpha.
In[348]:= 
vars = Join[{Cos[Subscript[α, max]]}, 
   Table[Subscript[t, i], {i, 1, 5}]];
polys = Table[
   Subscript[t, i] == Pi/i (1 - Cos[Subscript[α, max]]^i), {i, 
    1, 5}];
gb = GroebnerBasis[polys, vars];

Now we can use PolynomialReduce to rewrite the expression of interest, replacing wherever possible that cosine with variables lower in the term order.
In[351]:= 
PolynomialReduce[
  1/3*Pi*(Subscript[v, y]^2*Cos[Subscript[α, max]]^3 - 
     2*Subscript[v, z]^2*Cos[Subscript[α, max]]^3 - 
     3*Subscript[v, y]^2*Cos[Subscript[α, max]] + 
     2*Subscript[v, z]^2 + 2*Subscript[v, y]^2), gb, vars][[2]]

Out[351]= Subscript[t, 1]*Subscript[v, y]^2 - 
 Subscript[t, 3]*Subscript[v, y]^2 + 
   2*Subscript[t, 3]*Subscript[v, z]^2

--- end edit ---
--- edit 2 ---
I saw (but no longer can locate) a comment asking about situations where there are related variables such as Sin[Subscript[α, max]/2]. This poses two wrinkles. First is that one will need to work with the smallest fractional angle in order to have polynomial relations between all such angles that can be algebraically related. The second is that one must also add the obvious trig relations such as Sin[XXX]^2+Cos[XXX]^2-1 where XXX is this smallest fractional angle. (Actually I am not sure if this relation must be added, or if GroebnerBasis preprocessing will figure that out for you. Assume it must be added by hand and you won't go too far astray.)
--- end edit 2 ---
--- edit 3 ---
Elaborating on edit 2 using an example from a comment, we use more trig variables and relationship polynomials.
In[74]:= vars = 
  Join[{Sin[Subscript[α, max]/2], 
    Cos[Subscript[α, max]/2], Sin[Subscript[α, max]], 
    Cos[Subscript[α, max]]}, Table[Subscript[t, i], {i, 1, 5}]];
polys = Join[{Cos[Subscript[α, max]]^2 + 
     Sin[Subscript[α, max]]^2 - 1, 
    Cos[Subscript[α, max]/2]^2 + 
     Sin[Subscript[α, max]/2]^2 - 1, 
    Cos[Subscript[α, 
       max]] - (Cos[Subscript[α, max]/2]^2 - 
       Sin[Subscript[α, max]/2]^2), 
    Sin[Subscript[α, max]] - 
     2*Cos[Subscript[α, max]/2]*
      Sin[Subscript[α, max]/2]}, 
   Table[Subscript[t, i] - 
     Pi/i (1 - Cos[Subscript[α, max]]^i), {i, 1, 5}]];
gb = GroebnerBasis[polys, vars];

In[66]:= p1 = 
  4/3*k^2*Sin[Subscript[α, max]/2]^4*(3*Pi - t[1])*
   Subscript[v, y];

In[80]:= PolynomialReduce[p1, gb, vars][[2]]

Out[80]= -((2*(-3*k^2*Pi*Subscript[t, 1]*Subscript[v, y] + 
       3*k^2*Pi*Subscript[t, 2]*
              Subscript[v, y] + 
       k^2*Subscript[t, 1]*Subscript[v, y]*t[1] - 
            k^2*Subscript[t, 2]*Subscript[v, y]*t[1]))/(3*Pi))

Here is another requested example. In this case preprocessing with TrigExpand causes a multiple angle trig term to disappear, allowing the polynomial replacement to work to its fullest capability.
In[91]:= p2 = 
  1/6*k^2 Pi*(8 - 9*Cos[Subscript[α, max]] + 
     Cos[3*Subscript[α, max]])*Subscript[v, y];

In[92]:= PolynomialReduce[p2 // TrigExpand, gb, vars][[2]]

Out[92]= 2*(k^2*Subscript[t, 1]*Subscript[v, y] - 
   k^2*Subscript[t, 3]*Subscript[v, y])

--- end edit 3 ---
"
list manipulation - How to find rows that have maximum value?,"
With:
dat = {{10, b, 30}, {100, a, 40}, {1000, b, 10}, {1000, b, 70}, {100, b, 20}, {10, b, 70}};

Perhaps most directly:
Cases[dat, {_, _, Max@dat[[All, 3]]}]

More approaches:

Last @ SplitBy[SortBy[dat, {#[[3]] &}], #[[3]] &]
Pick[dat, #, Max@#] &@dat[[All, 3]]
Reap[Fold[(If[#2[[3]] >= #, Sow@#2]; #2[[3]]) &, dat]][[2, 1]]

Of these Pick appears to be concise and efficient, so it is my recommendation.
Edit: Position and Extract are three times as efficient as Pick on some data.  Using Transpose is slightly more efficient on packed rectangular data.

dat ~Extract~ Position[#, Max@#] & @ dat[[All, 3]]
dat ~Extract~ Position[#, Max@#] & @ Part[dat\[Transpose], 3]

Here are some timings performed in version 7:
SetAttributes[timeAvg, HoldFirst]
timeAvg[func_] := Do[If[# > 0.3, Return[#/5^i]] & @@ Timing@Do[func, {5^i}], {i, 0, 15}]

SeedRandom[1]
dat = RandomInteger[99999, {500000, 3}];

Cases[dat, {_, _, Max@dat[[All, 3]]}]                          // timeAvg
Last@SplitBy[SortBy[dat, {#[[3]] &}], #[[3]] &]                // timeAvg
Pick[dat, #, Max@#] &@dat[[All, 3]]                            // timeAvg
Reap[Fold[(If[#2[[3]] >= #, Sow@#2]; #2[[3]]) &, dat]][[2, 1]] // timeAvg
dat ~Extract~ Position[#, Max@#] &@dat[[All, 3]]               // timeAvg
dat ~Extract~ Position[#, Max@#] &@Part[dat\[Transpose], 3]    // timeAvg


0.1278
0.764
0.0904
0.904
0.02996
0.02496

(In actuality I restarted the Kernel between each individual timing line as otherwise each run gets slower, unfairly biasing the test toward the earlier lines.)
These can be further optimized by using faster position functions for numeric data.
Michael E2 recommended compiling (probably faster in versions after 7):
pos = Compile[{{list, _Real, 1}, {pat, _Real}}, Position[list, pat]];
dat ~Extract~ pos[#, Max@#] & @ Part[dat\[Transpose], 3] // timeAvg


0.01372

My favorite method is SparseArray properties:
spos = SparseArray[Unitize[#], Automatic, 1][""AdjacencyLists""] &;
dat[[spos[# - Max@#]]] & @ Part[dat\[Transpose], 3] // timeAvg


0.002872

This is now about 30X faster than Pick, my original recommendation.
"
front end - How do I add new menuitems to menus?,"
I've never seen that command before but this does work at least in version 7 on Windows:
FrontEndExecute[
 AddMenuCommands[
  ""BackgroundDialog"", {Delimiter, 
   Item[""L&inen"", Background -> RGBColor[0.980, 0.941, 0.902]], 
   Item[""A&liceBlue"", Background -> RGBColor[0.941, 0.973, 1.0]], 
   Item[""Min&tCream"", Background -> RGBColor[0.961, 1.0, 0.980]], 
   Item[""Lig&htYellow"", Background -> RGBColor[1.0, 1.0, 0.878]], 
   Item[""Smok&e"", Background -> RGBColor[0.961, 0.961, 0.961]], 
   Item[""Mi&styRose"", Background -> RGBColor[1.0, 0.894, 0.882]]}]]


That comes from this MathGroup post. (Now improved; see comments.)
Further reading tells us:

You can completely reset the menus using...
FrontEndExecute[FrontEnd`ResetMenusPacket[{Automatic}]]


"
curated data - Is there a Mathematica API for the functions.wolfram site?,"
Here is a shameless plug for my HTML parser posted here. The code is a bit long to reproduce here, the only change to it I'd do is to replace the function processPosList with this code:
processPosList::unmatched = ""Unmatched lists `1` enountered!"";
processPosList[{openlist_List, closelist_List}] := 
  Module[{opengroup, closegroup, poslist}, 
  {opengroup, closegroup} = groupPositions /@ {openlist, closelist};
   poslist = Transpose[Transpose[Sort[#]] & /@ {opengroup, closegroup}];
   If[UnsameQ @@ poslist[[1]], Return[(Message[
       processPosList::unmatched , {openlist, closelist}]; {})], 
   poslist = Transpose[{poslist[[1, 1]], Transpose /@ Transpose[poslist[[2]]]}]]];

which will issue a message when some parts can not be parsed instead of printing the details (as the original code does). I must warn that my parser for some reason can not fully parse the Wolfram Functions pages (either they are ill-formed or my parser contains bugs), but it will parse enough for our purposes. Here is a simple web-scraper based on it and on a few observations about the typical format of the page:
Clear[getForms];
getForms[url_String] := 
 Quiet@ Cases[postProcess@parseText[Import[url, ""Text""]],
     pContainer[attribContainer["" class='CitationInfo'""], x__String] :> 
        StringJoin@x, Infinity] //. 
       x_String :>  StringReplace[ x, {""&quot;"" | ""quot;"" :> ""\"""", ""&amp;"" :> """", 
             ""&lt;"" | ""&lt"" :> ""<"", ""&gt;"" | ""&gt"" :> "">"", ""\n"" :> "" ""}];


Clear[formsOk, getInputForm, getStandardForm, getRuleForm];
formsOk[forms_] := Length[forms] == 5;
getInputForm[forms_?formsOk] := ToExpression[forms[[1]], InputForm];
getStandardForm[forms_?formsOk] := ToExpression[First@ToExpression[forms[[2]]], StandardForm];
getRuleForm[forms_?formsOk] := ToExpression[First@ToExpression[forms[[4]]]];
getInputForm[__] = getStandardForm[__] = getRuleForm[__] = $Failed;

I can not say how fragile this is, probably rather fragile. Here is an example of use:
In[277]:= 
forms = getForms[""http://functions.wolfram.com/07.23.17.0084.01""];
Through[{getInputForm,getStandardForm,getRuleForm}[forms]]

Out[278]= {Hypergeometric2F1[a,b,-(1/2)+a+b,z]==((Sqrt[1-z]-Sqrt[-z])^(1-2 a) 
  Hypergeometric2F1[-1+2 a,-1+a+b,-2+2 a+2 b,2 z+2 Sqrt[-z+z^2]])/Sqrt[1-z]/;Re[z]>1/2,
  Hypergeometric2F1[a,b,-(1/2)+a+b,z]==((Sqrt[1-z]-Sqrt[-z])^(1-2 a) 
  Hypergeometric2F1[-1+2 a,-1+a+b,-2+2 a+2 b,2 z+2 Sqrt[-z+z^2]])/Sqrt[1-z]/;Re[z]>1/2,
  HoldPattern[Hypergeometric2F1[a_,b_,a_+b_-1/2,z_]]:>((Sqrt[1-z]-Sqrt[-z])^(1-2 a) 
  Hypergeometric2F1[2 a-1,a+b-1,2 a+2 b-2,2 Sqrt[z^2-z]+2 z])/Sqrt[1-z]/;Re[z]/2}

I tested on about 10 different formulas, and this worked fine, but of course this is not an extensive test, so most likely this will not always work.
"
"boolean computation - Are there ""All"" and ""Any"" functions in Mathematica?","
Both, And and Or should work for All and Any respectively. You may have to get creative in how you apply them, though. For instance,
And @@ {True, False, True}

works just like you would expect 
AllOf @ {True, False, True}

to without any additional work. Similarly,
Or @@ {False, True, False}

works like AnyOf.
"
How to import date (YYYY-MM-DD) data from a file?,"
Import[(* file *), ""Table"", ""DateStringFormat"" -> {""Year"", ""-"", ""Month"", ""-"", ""Day""}] seems to work...

As a test:
Export[""test.dat"",
       {{""2010-05-19"", 17}, {""2010-05-20"", 20}, {""2010-05-21"", 19}},
       ""FieldSeparators"" -> "" ""];

Import[""test.dat"", ""Table"",
       ""DateStringFormat"" -> {""Year"", ""-"", ""Month"", ""-"", ""Day""}]
{{{2010, 5, 19}, 17}, {{2010, 5, 20}, 20}, {{2010, 5, 21}, 19}}

"
programming - How to make TraditionalForm display the same in the Manipulate output as in a notebook?,"
This is just a matter of different style (font here). This will produce identical output to what you get outside of Manipulate: 
Manipulate[
    Style[
        TraditionalForm[-Derivative[2, 0][u][x, y] - Derivative[0, 2][u][x, y] == f[x, y]], 
        FontFamily -> ""Times""
    ], 
    {z, None}]

"
image processing - How to make a drop-shadow for a Graphics3D objects?,"
This produces a 2D shadow. If you meant a 3D shadow (on the x-y plane), see code below.
image = Rasterize[Graphics3D[Sphere[], Boxed -> False]];
shadow = Blur[RegionBinarize[ColorNegate[image], {{1, 1}}, 0.1], 20];

image = SetAlphaChannel[image, ColorNegate@Binarize[image, {1, 1}]];

Show[{shadow, image}]


The position of the shadow has to be fine tuned manually.
I also managed to construct it in 3D (rotatable), though I cannot make the bottom polygon transparent.
shadow = Blur[
   RegionBinarize[Graphics[Circle[], ImagePadding -> 60], {{1, 1}}, 
    0.1], 40];
shadow = SetAlphaChannel[shadow, ColorNegate@shadow];

Graphics3D[{
  Sphere[],
  EdgeForm@None, Opacity@.7, Texture@shadow, 
  Polygon[{{-1, -1, -2}, {1, -1, -2}, {1, 1, -2}, {-1, 
     1, -2}, {-1, -1, -2}}, 
   VertexTextureCoordinates -> {{0, 0}, {1, 0}, {1, 1}, {0, 1}}]
  }, Boxed -> False]


"
Finding a subsequence in a list,"
I asked the same question on StackOverflow recently, and the answer that is now my favourite came from Jan Pöschko (modified):
findSubsequence[list_, {ss__}] := 
  ReplaceList[list, {pre___, ss, ___} :> Length[{pre}] + 1]

This will find all positions of ss in list.  Example:
findSubsequence[Range[50] ~Mod~ 17, {4, 5, 6}]


{4, 21, 38}

Despite using patterns, this solution runs very quickly, even for packed arrays.  Please see the question I linked to for more possibilities.

A potentially useful generalization to other heads may be had with:
findSubsequence[list : h_[__], _[ss__]] :=
  ReplaceList[list, h[pre___, ss, ___] :> Length[{pre}] + 1]

Allowing such forms as:
x = Hold[1 + 1, 2 + 1, 3 + 1, 4 + 1, 2 + 1, 3 + 1, 1 + 1, 2 + 1, 3 + 1];

findSubsequence[x, Hold[2 + 1, 3 + 1]]


{2, 5, 8}

"
list manipulation - Combination and Permutation,"
Take all subsets of length 10, then for each one find all splits into two sets of five such that the first of the ten is in the first part of the split.
In[29]:= Timing[
 msets = Subsets[Range[12], {10}];
 m2 = Flatten[
   Map[With[{fst = First[#], subs = Subsets[Rest[#], {4}], mset = #}, 
      With[{s2 = Map[Join[{fst}, #] &, subs]}, 
       Map[{#, Complement[mset, #]} &, s2]]] &, msets], 1];]

Out[29]= {0.07799999999999985, Null}

In[30]:= Length[m2]

Out[30]= 8316

"
"plotting - Styling ticks, axes and other elements in a Plot of a step function","
For the arrow heads on the axes, use an Epilog inside the Plot with the Arrow function, or use the techniques described in this post: https://stackoverflow.com/questions/5844790/arrows-for-the-axes.
For the tick labeling, use for each item in the list of x-tick and y-tick locations not just the number but a list that includes the number and the corresponding label:
Ticks -> {{{-3, -3 Q}, {-2, -2 Q}, {-1, -Q}, {1, +Q}, {2, 2 Q}, {3, 
3 Q}}, {-3, -2, -1, 1, 2, 3}}

where I've done it just with the x-ticks. If you insist on having the ""+"" prefixes on the positive ones, you could change, say, {1,+Q} to:{1, TraditionalForm@HoldForm[+Q]} and similarly for the others.
Of course you could write a little function that you would do all that with the ticks simply by applying it to the list of x-tick numbers and the list of y-tick numbers.
By default, as you've seen, tick marks are drawn only to the positive side of the axis and at a predetermined length. To change that to get each tick mark crossing the axis, use an option third entry for each tick: a list {plen,nlen} giving (as a fraction of the image size, I believe) how far the tick mark should extend in the positive and negative direction from the axis. For example:
Ticks -> {{{-3, -3 Q, {0.01, 0.01}...

You didn't say exactly what features of the displayed graphic you couldn't satisfactorily reproduce in Mathematica, but perhaps the size of the text, including tick labels, is an issue. In that case, you could use the BaseStyle-> option to Plot if you wanted to uniformly change all the text sizes, fonts, weights, etc. If, however, you want different treatment of different text elements, then you could modify each one by a Style treatment, e.g.:
Ticks -> {{{-3, -Style[3 Q, 24, Red, Bold, FontFamily -> ""Papyrus""],...

(My system has that font installed; yours may not.)
"
plotting - Creating a data1 versus data2 plot?,"
Assuming the name of the table is data 
data =
  {
   {1, 2, 3, 4, 5, 6},
   {2, 3, 4, 5, 6, 7},
   {3, 4, 5, 6, 7, 8},
   {4, 5, 6, 7, 8, 9}
   };

The 3rd column would be data[[All,3]] and the 5th data[[All,3]]. All means: take all elements of the given index. Since we need to plot x against y we need a submatrix containing the 3rd and 5th column. Data[[All,{5,3}]] does that.
data[[All, {5, 3}]]

(*
==> {{5, 3}, {6, 4}, {7, 5}, {8, 6}}
*)

There are many plot functions in Mathematica. In this case, ListPlot or ListLinePlot are appropriate.
ListPlot[data[[All,{5,3}]]]


ListLinePlot[data[[All,{5,3}]]]


There are many, many options to tune those plots. I suggest looking up those in the extensive electronic documentation in the Help menu or by selecting a command and pressing F1 (Windows)
Things to look up:

Part ( [[...]] ) 
Manipulating Elements Of Lists
Getting Pieces Of Lists
The data visualization overview page and its descendants
The function visualization overview page and its descendants

"
"functions - sprintf() or close equivalent, or re-implementation?","
I've had a need for such a function several times, and I found this implementation of C-style *printf functions, by Vlad Seghete. To use it, all you need to do is extract the files to $UserBaseDirectory/MathPrintF/ and you're all set.
Here's an example once you've installed it:
<<MathPrintF`
sprintf[""%d %s %d %s, %s %s %s %s"", 
    Sequence @@ Riffle[{1, 2, ""red"", ""blue""}, {""fish""}, {2, -1, 2}]]

Out[1]= 1 fish 2 fish, red fish blue fish


Also note the following caveat in the README

Limited Functionality
While we tried to mimic the C-standard as much as possible, only certain
  features are implemented. These are mainly dictated by what we needed at
  the time. In particular %d, %f, %e, %E and %s with most of their options
  are implemented. 

"
graphics - How can I create a ColorFunction using Blend?,"
distance = {0.245, -0.235, 0.053, -0.048, -0.128, -0.007, -0.075, -0.067, -0.005, 0.082}

Show[Function[attributes, 
   Graphics[{Blend[{{-Max[Abs[distance]], Red}, {0, LightRed}, {0, 
        LightGreen}, {+Max[Abs[distance]], Green}}, 
      distance[[attributes]]], 
     Rectangle[{If[distance[[attributes]] < 0, 
        distance[[attributes]]*10, 0], 
       attributes - 1}, {If[distance[[attributes]] < 0, 0, 
        distance[[attributes]]*10], attributes}], 
     PlotRange -> {{-5, 5}, {0, 10}}}, 
    Epilog -> {White, Line[{{0, 0}, {0, 11}}]}]] /@ Range[10], 
 Frame -> True]


"
list manipulation - On generalizing Partition[] (with offsets) to sublists of unequal length,"
This is a complete re-write
This is the original solution which was done in haste but i will leave here. It works in limited cases:
multisegment[lst_List, scts_List, offset_List] := 
 Module[{acc, offs}, 
  offs = 1+Prepend[Accumulate[PadRight[offset, 
      1 + Ceiling[Length[lst]/Total[offset]], offset]], 0];
  acc = PadRight[scts, Length[offs],scts];
  acc = acc + offs - 1;
  Inner[Take[lst, {#1, #2}] &, offs, acc, List]
  ]

multisegment[Range[14], {4, 3}, {3, 1}]
{{1, 2, 3, 4}, {4, 5, 6}, {5, 6, 7, 8}, {8, 9, 10}, {9, 10, 11, 
  12}, {12, 13, 14}}

To solve this you note that the starting position (for Part or Take) of the list depends solely on the offset list:
{1,4,5,8,9,12}

The ""span to"" position is determined by adding the partition list
{4,3,4,3,4,3}

to the offset list (minus 1) to give
{4,6,8,10,12,14}

From there, proceed as before with Inner and use either Take or Part. So this becomes an exercise in generating the correct offset list. As earlier failed attempts have shown, this is dependent on both the total of the offsets and the length of the offsets (list).
But also you do not want your Take or ""span to"" range exceeding the length of your target list. I have taken the easy way out here but using DeleteCases. A more exact and possibly elegant, but maybe not faster (?), approach is to actually work this out based on the partition list.
multisegment[lst_List, scts_List, offset_List] := 
 Module[{fin, offs, len = Length[lst], tot = Total[offset], len2 = Length[offset]}, 
  offs = 1 + Prepend[Accumulate[
      PadRight[offset, Ceiling[len2*len/tot], offset]], 0];
  fin = PadRight[scts, Length[offs], scts] + offs - 1;
  fin = DeleteCases[Transpose[{offs, fin}], {_, x_ /; x > len}];
  Take[lst, #] & /@ fin]

 (* case for no offsets *)
 multisegment[lst_List, scts_List] := multisegment[lst, scts, scts]

I prefer to layout the code in steps rather than combine multiple steps into a one (or two) liner. Feel free to do that if you wish but I think this way makes it easier for people to check out what is happening.
Also a qualifier: checks and/or conditions should be added. you cannot have {0} for your partition or offset. Must be integers etc. as per Simon's comments.
Usage. First the base case of an uneven partition with no offset
multisegment[Range[14], {3, 4}]
{{1, 2, 3}, {4, 5, 6, 7}, {8, 9, 10}, {11, 12, 13, 14}}

now add an offset
multisegment[Range[14], {3, 4}, {1, 2}]
{{1, 2, 3}, {2, 3, 4, 5}, {4, 5, 6}, {5, 6, 7, 8}, {7, 8, 9}, {8, 9, 
  10, 11}, {10, 11, 12}, {11, 12, 13, 14}}

Examples that previously failed:
multisegment[Range[10], {5, 4}, {2, 3}]
{{1, 2, 3, 4, 5}, {3, 4, 5, 6}, {6, 7, 8, 9, 10}}

multisegment[Range[100], {5, 4}, {2, 3}]
{{1, 2, 3, 4, 5}, {3, 4, 5, 6}, {6, 7, 8, 9, 10}, {8, 9, 10, 11}, {11,
   12, 13, 14, 15}, {13, 14, 15, 16}, {16, 17, 18, 19, 20}, {18, 19, 
  20, 21}, {21, 22, 23, 24, 25}, {23, 24, 25, 26}, {26, 27, 28, 29, 
  30}, {28, 29, 30, 31}, {31, 32, 33, 34, 35}, {33, 34, 35, 36}, {36, 
  37, 38, 39, 40}, {38, 39, 40, 41}, {41, 42, 43, 44, 45}, {43, 44, 
  45, 46}, {46, 47, 48, 49, 50}, {48, 49, 50, 51}, {51, 52, 53, 54, 
  55}, {53, 54, 55, 56}, {56, 57, 58, 59, 60}, {58, 59, 60, 61}, {61, 
  62, 63, 64, 65}, {63, 64, 65, 66}, {66, 67, 68, 69, 70}, {68, 69, 
  70, 71}, {71, 72, 73, 74, 75}, {73, 74, 75, 76}, {76, 77, 78, 79, 
  80}, {78, 79, 80, 81}, {81, 82, 83, 84, 85}, {83, 84, 85, 86}, {86, 
  87, 88, 89, 90}, {88, 89, 90, 91}, {91, 92, 93, 94, 95}, {93, 94, 
  95, 96}, {96, 97, 98, 99, 100}}

Example showing it working with increasing offset list length
multisegment[Range[44], {3, 4}, {1, 3, 2}]
{{1, 2, 3}, {2, 3, 4, 5}, {5, 6, 7}, {7, 8, 9, 10}, {8, 9, 10}, {11, 
  12, 13, 14}, {13, 14, 15}, {14, 15, 16, 17}, {17, 18, 19}, {19, 20, 
  21, 22}, {20, 21, 22}, {23, 24, 25, 26}, {25, 26, 27}, {26, 27, 28, 
  29}, {29, 30, 31}, {31, 32, 33, 34}, {32, 33, 34}, {35, 36, 37, 
  38}, {37, 38, 39}, {38, 39, 40, 41}, {41, 42, 43}}

multisegment[Range[44], {3, 4}, {1, 3, 2, 4}]
{{1, 2, 3}, {2, 3, 4, 5}, {5, 6, 7}, {7, 8, 9, 10}, {11, 12, 13}, {12,
   13, 14, 15}, {15, 16, 17}, {17, 18, 19, 20}, {21, 22, 23}, {22, 23,
   24, 25}, {25, 26, 27}, {27, 28, 29, 30}, {31, 32, 33}, {32, 33, 34,
   35}, {35, 36, 37}, {37, 38, 39, 40}, {41, 42, 43}}

and so on, and so forth.
"
notebooks - How to find pieces of code responsible for syntax errors?,"
New answer
There was actually an old post on mathgroup, Strange Syntax problem,
that looks like it was exactly the same problem you're experiencing. 
A power/superscript being associated with the closing parenthesis instead of the whole parenthesized expression (see the box forms presented in my original answer below for more details).
Unfortunately, this problem was not resolved in the the mathgroup post.
The best I can suggest at the moment is to simply press the + button

to get the expanded form

This should help narrow down the problem. 
Note the Syntax::bktmcp warning is talking about non-matching brackets, yet in the visible expression, all brackets are properly matched. So, the problem lies in the underlying box expression.
Alternatively, if it is this particular problem, you could Show Expression, then search for the problematic code snippet SuperscriptBox["")"". 
Then you can modify the box structure directly.
This is normally easiest if you paste it into a new input cell so that the Extend Selection mechanism works.
Original answer
There is no ""hidden bad character"" in the cell that you posted. Rather, the box structure is crazy and can't be interpreted by Mathematica - I have trouble imagining how you managed to create it...
Here's your cell
Cell[BoxData[
 RowBox[{""("", 
  RowBox[{""k"", ""h""}], 
  SuperscriptBox["")"", ""2""]}]], ""Input""]

and here is how it should look
Cell[BoxData[
 SuperscriptBox[
  RowBox[{""("", 
   RowBox[{""k"", "" "", ""h""}], "")""}], ""2""]], ""Input""]

So, your question does not really a work with the example you provided.
However, a simple way to maybe clean your code (at least in this case) is to copy it as plain text or input text, both of which produce (k h)^2 when pasted.
"
programming - Struct equivalent in Mathematica?,"
Update:  Mathematica 10 has introduced Association, which can be used as a close equivalent of structs.
params = <| ""par1"" -> 1, ""par2"" -> 2 |>

params[""par1""]
(* ==> 1 *)

In version 10 pure functions can have named arguments, and can be effectively used as expression templates where the slots can be populated from an association.  This is similar to the technique I describe in the original version of this post (below the line).
#par1 + #par2 & [params]

will evaluate to 1 + 2 then to 3. 
That said, my personal workflow still fits better with the approach described below the line (withRules).  The reason for this is that I tend to build up calculations interactively and incrementally.  This means that I do not start by writing the equivalent of an expression template (which would require thinking ahead...).  Instead I start with all the values explicitly written out, and later I replace them with a global variable.  This global variable can be simply Unset, and given a local value using withRules, then eventually changed into a function argument.

Quoting the OP's comment:

Most of the work I do involves constructing mathematical models and
  then testing various scenarios against those models. I'd like to be
  able to populate a particular scenario and then pass that scenario to
  a model. I'd also like to be able to copy that scenario, modify one or
  more parameters, and then pass the new scenario to the model.

The requirement, as I understand, is to be able to pass many parameter values around in a structured way.  Lists of rules are convenient for this:
params = {par1 -> 1, par2 -> 2, par3 -> {x,y,z}}

They can be extracted like this:
par1 /. params

(* ==> 1 *)

Once I wrote a function for substituting such parameter lists into bigger pieces of code:
ClearAll[withRules]
SetAttributes[withRules, HoldAll]
withRules[rules_, expr_] :=
  First@PreemptProtect@Internal`InheritedBlock[
    {Rule, RuleDelayed},
    SetAttributes[{Rule, RuleDelayed}, HoldFirst];
    Hold[expr] /. rules
]

It can be used like this:
withRules[params,
  par1 + par2
]

(* ==> 3 *)

withRules can contain complex code inside, and all occurrences of par1, par2, etc. will be substituted with the values from the parameter list.
We can also write a function for easily modifying only a single parameter (from the whole list), and returning a new parameter list.  Here's a simple implementation:
setParam[paramList_, newRules_] :=
 DeleteDuplicates[Join[newRules, paramList], 
  First[#1] === First[#2] &]

Example usage:
setParam[params, {par2 -> 10}]

(* ==> {par2 -> 10, par1 -> 1, par3 -> {x, y, z}} *)

Another list which has a different value for par2 is returned.

If needed, this could be extended to support more complex, structured lists such as { par1 -> 1, group1 -> {par2x -> 10, par2y -> 20}}, much how like the built-in option-handling works.  

Addendum by celtschk:  It's possible to extract a value from a list of rules using OptionValue as well: OptionValue[params, par1].
"
syntax - Representing second derivatives with a double overdot,"
g[x_] := Overscript[x, ""..""]
Print[HoldForm[g[x]], "" == "", g[x]]

You could use AdjustmentBox to tweak the two dots, but maybe this is not necessary.
"
graphics - Is there an equivalent of FullGraphics for Graphics3D?,"
No solution with 3D return, but you can ""vectorize"" 3D graphics by using the good ole ImportString[ExportString[...]] trick which results in a (large) 2D Graphicsexpression:
g = Plot3D[Sin[x + y^2], {x, -3, 3}, {y, -2, 2}]


vectorized2D = ImportString[ExportString[g, ""PDF""], ""PDF""][[1]]


This is now  a Graphics expression that you can use to extract certain features:
Cases[vectorized2D, _JoinedCurve, Infinity] // Graphics


but finding the right patterns for the stuff you might want to work with could take some effort. Also you have to live with the fact that some appearances will change more or less dramatically.
"
custom notation - Can we use letter with a subscript as a variable in Mathematica?,"
Yes you can, with limitations.
You have at least three different ways to make an assignment to a subscripted symbol a0 :

make a rule for Subscript
make a rule for a
""symbolize"" a0 using the Notation package/palette

In each case below, when I write e.g. Subscript[a, 1] this can also be entered as a1 by typing a then Ctrl+_ then 1.
When you write:
Subscript[a, 1] = ""dog"";

You make an assignment to Subscript:
DownValues[Subscript]


{HoldPattern[a1] :> ""dog""}

You make a rule for a by using TagSet:
a /: Subscript[a, 2] = ""cat"";

UpValues[a]


{HoldPattern[a2] :> ""cat""}

If you use the Notation palette you mess with underlying Box forms behind the scenes, allowing for assignment to OwnValues:

Each of these can be cleared with either Unset or TagUnset:
Subscript[a, 1] =.

a /: Subscript[a, 2] =.


"
version 8 - Problem with EllipticE documentation,"
I just tried it with both Mathematica 7 and 8, and Mathematica 7 gives the result from the documentation, while Mathematica 8 indeed gives just EllipticE[z, m].
Therefore I conclude Wolfram modified Integrate but forgot to update this piece of documentation.
"
plotting - Is it possible to speed up ContourPlot on multi-core machines?,"
I second @Verbeia's suggestion: compute the function on a mesh of points and use ListContourPlot.  The disadvantage is that ListContourPlot has no adaptive sampling, so it'd be preferable if we could do our own adaptive sampling somehow.  Adaptive sampling can give you a much better result while needing to compute the function in far less points---and the problem here is indeed computation time.  So ContourPlot with its adaptive sampling might give a better result in less time on a single CPU than ListContourPlot will with a high resolution mesh computed on many CPUs.
Adaptive sampling is what I asked about (and solved) here:  Adaptive sampling for slow to compute functions in 2D
The method I implemented there is usable (I am using it for something very similar to what you describe) but it is not nearly as good as ContourPlot's own.  So one might still try to somehow make use of it.  I'm quoting one suggestion I received from Leonid Shifrin there (in a comment):

You probably can control the DensityPlot, although not directly. Since
  it calls your function, you can simply Sow the values until some
  criteria (which you define) is violated (or satisfied). Then, you stop
  via throwing an exception, and catching it in the outer function, but
  still inside Reap. Alternatively, you could just start fooling
  DensityPlot by supplying faked values (perhaps, interpolated, or
  whatever), and it will stop by itself, I guess. Not sure this will
  work for you, but it may be worth trying.

I have not tried to implement this before, but I think it could work if your function is sufficiently smooth (which mine is definitely not, but yours may be).
Here's a quick sample implementation of how it could work:
First, let's define a sample function to plot:
fun[{x_, y_}] := 1/(1 + Exp[10 (Norm[{x, y}] - 3)])

Let's divide both the $x$ and $y$ axes into 5 parts on the interval $[0,5]$ and generate a mesh of points:
initialDivision = Range[0, 5];

points = N@Tuples[initialDivision, {2}];

Calculate function values on the intial mesh.  This can be parallelized (just use ParallelMap)
values = fun /@ points;

This counter i will be used to control the maximal subdivisions in ContourPlot:
i = 0;

Now put the following code into a single cell, and evaluate it several times.  Each time a finer and finer approximation will be computed.  The points where function values have been computed will also be visualized.  Note that I fixed the plot points in ContourPlot to force it to use the same initial mesh that I used, and I also fixed the number of contours.
if = Interpolation@ArrayFlatten[{{points, List /@ values}}]

{plot, {newpoints}} = Reap[
   ContourPlot[if[x, y], {x, 0, 5}, {y, 0, 5}, 
    Contours -> Range[0, 1, .1], MaxRecursion -> (++i), 
    PlotPoints -> Length[initialDivision], 
    EvaluationMonitor :> Sow[{x, y}]]
   ];
plot

newpoints = Complement[newpoints, points];
newvalues = fun /@ newpoints;  (* <-- this can be parallelized *)
points = Join[points, newpoints];
values = Join[values, newvalues];

Graphics[Point[points]]

After a few iterations the contour plot and the point mesh will look like this (note that the code above only plots the contours for the previous step, not the current results):


After 3 iterations, this method has computed the function value in 3809 points for this particular function.
Let's compare this with a plain ContourPlot using the same parameters:
ContourPlot[fun[{x, y}], {x, 0, 5}, {y, 0, 5}, 
    PlotPoints -> 6, MaxRecursion -> 3]


The quality of the plot is about the same with a plain ContourPlot as well.
How many points did the plain CountoutPlot use?
Reap[ContourPlot[fun[{x, y}], {x, 0, 5}, {y, 0, 5}, PlotPoints -> 6, 
    MaxRecursion -> 3, EvaluationMonitor :> Sow[{x, y}]]][[2, 1]] // Length

(* ==> 3790 *)

It uses almost the same number of points, so if the bottleneck is computing f, the method I described is going to be almost as fast as ContourPlot on a single core, with the advantage that it is parallelizable for multiple cores.
The next step would be packaging this up into a self-contained function, but seeing how the quality improves step by step is also valuable as you can make decisions about when to stop calculating (and avoid excessive computation times).

I find it quite disappointing that all those nice and fast algorithms that plotting functions use (fast Voronoi cells, Delaunay trinagulation, adaptive sampling) are not directly accessible by users.  We either have to use hacks to access these algorithms or reimplement them.
"
graphics - 2D Gaussian distribution of squares coordinates,"
This reproduces the image decently. It works by sampling without replacement from all the positions, and randomly coloring them with a built-in color scheme. 
size = 41; 
amountCovered = 0.40;
noSquares = Floor[amountCovered*size^2];
tiles = Flatten[Table[{i, j}, {i, size}, {j, size}], 1];
probabilities = Flatten@GaussianMatrix[Floor[size/2]];
sample = RandomSample[probabilities -> tiles, noSquares];
colors = RandomInteger[21, noSquares];
mat = SparseArray[sample -> colors, {size, size}];
ArrayPlot[mat, Frame -> None, 
          ColorRules -> {0 -> RGBColor[{237, 233, 214}/255], 
                         x_ -> ColorData[54][x]}]


For black and white, just replace colors with 1, and remove the ColorRules rules:
mat = SparseArray[sample -> 1, {size, size}];
ArrayPlot[mat, Frame -> None] 


Choice of colors
Choosing randomly from a set of colors instead of the built in ColorData:
lesCouleurs = {RGBColor[0.4, 0.4, 1], RGBColor[1, 0.5, 0.5], RGBColor[0, 0, 0]}
colors = RandomInteger[Length@lesCouleurs, noSquares];
mat = SparseArray[sample -> colors, {size, size}];
ArrayPlot[mat, Frame -> None, 
          ColorRules -> {0 -> RGBColor[{237, 233, 214}/255], 
                          x_ :>  lesCouleurs[[x]]}]

N.B. I was lazy in using GaussianMatrix for computing the probabilities, so only odd sizes work as expected.
"
export - How do you get high resolution plots in applications using the Mathematica MathService?,"
Try this.
1) Open Automator and create a new Service.
2) In the search box, type ""Run Apple Script"" and drag the action into the workflow space on the right. 
3) Replace the sample script (changing MyName appropriately) with:
on run {input, parameters}
set inputResult to (input as string)
set cmd to "" -run 'Export[\""~/Desktop/test.pdf\"","" & input & ""];Exit[]'""
set mathPath to POSIX path of file ((path to application ""Mathematica"" as text) & ""Contents:MacOS:MathKernel"")


do shell script mathPath & cmd
set the clipboard to (alias ""Users:MyName:Desktop:test.pdf"") as «class furl»

tell application ""System Events""
keystroke ""v"" using {command down}
end tell

end run

4) Hit the hammer icon to verify the code, then save the file to give the service a name.
5) In TextEdit try something like 
Plot[Sin[x],{x,0,Pi},PlotStyle->{Dashed,Red},ImageSize->500]

or
Style[TraditionalForm[Integrate[Gamma[Pi x]y[x],{x,0,2}]],FontSize->48]

It will embed a high quality PDF, saving the temp file to the desktop.
"
programming - How to Text justify string that includes SubScriptBox in it?,"
You can also supply a Row to the TextCell where the elements in the row can be a mix of strings and other expressions, so you could split the whole text into string fragments and bits of maths like this
TextCell[Row[{""This is some text "",
  HoldForm[Subscript[a, b]], 
  "". This is more text""}], TextJustification -> 1]

To show that it works:
Panel[Style[TraditionalForm[Grid[{
    {""Boundary Conditions"", SpanFromLeft},
    {TextCell[
       Row[{""This is some text, this is some text, this is some text "", 
       HoldForm[Subscript[a, b]], "" this is more text.""}], 
      TextJustification -> 1], SpanFromLeft},
    {""West"", HoldForm[u = \[Alpha][y]], HoldForm[Subscript[u, n] = \[Alpha][y]]}},
   Frame -> All]],
  15, FontFamily -> ""Times""], 
 ImageSize -> 250]


"
front end - MouseAppearance and cursor problems,"
Heike's answer has a strong virtue of simplicity, but it has two downsides. It strips the Graph-specific context menus, and it causes the output to not evaluate as a Graph if copied back to input. Here's a version which preserves those properties:
StripGraphMouseAppearance[x_Graph] := 
 RawBoxes[ToBoxes[x, StandardForm] /. 
   TagBox[contents_, MouseAppearanceTag[""NetworkGraphics""]] :> 
    contents]

Now, simply apply StripGraphMouseAppearance whenever you want to strip the appearance in output.  E.g., the example in the question would be reformulated as:
StripGraphMouseAppearance[
 Graph[{1 <-> 2, 2 <-> 3, 3 <-> 1}, ImageSize -> 200, 
  EdgeShapeFunction -> ({Black, AbsoluteThickness@2, Arrowheads@.1, 
      Arrow[#1, .1]} &), 
  VertexShapeFunction :> ({Hue[.6, .2, .8], Disk[#1, .1]} &)]]

Basically, Graph typesets with the MouseAppearance built into it. My code looks for the box form of MouseAppearance and strips it out. One could conceivably rewrite MakeBoxes rules for Graph directly to do this, but doing so correctly would be a much more difficult exercise, as it would require reverse-engineering the rules we have now and carefully overriding them...and such a solution might not be stable across different Mathematica versions.
"
front end - How to pipe a stream to another notebook?,"
I am not sure that this is possible.  The $Output and $Messages variables hold the output stream to where the standard output (and the message output) from the kernel goes.  If you check these, you'll see that they're simply set to stdout.
If you remove ReadProtected from NotebookWrite, you'll see that it is passing data to the front end instead of writing to an output stream.
All this suggest that it's not possible to redirect an output stream to an arbitrary notebook.

Instead of using output streams to switch the output ""device"", I'd suggest switching the output function.  You could have a function write which can be set to write = Write[outputChannel, #]& or to write = NotebookWrite[nb, #]&.
If you already have a lot of code using Write then it would be inconvenient to rewrite it to use an alternative write function.  But you can temporarily redefine Write using a block:
Block[{ Write = NotebookWrite[nb, #2]& },

 .... (* code called here *)

]

If you need to temporarily redefine Write with something that itself uses Write, then you can use the trick described here to ""wrap"" it with extra code.

Note: As @Heike said below, NotebookWrite[nb, Cell[BoxData[ToBoxes[#2]], ""Output""]] & is better for writing into notebooks than the simple NotebookWrite[nb, #2]& I used above.
"
bugs - How to Write into multiple files?,"
This is a bug and fixed in the development version. Thanks for pointing it out.
"
formatting - Producing cleaner Mathematica output,"
Try using semi-colons to suppress normal output and then use Print to print what you want exactly:
a = 1+1;
b = 1+2;
Print[a,"", "",b];

which gives:
2, 3

"
front end - How to improve the typesetting of mathematical contents,"
To format all your output expressions as TraditionalForm, you can set the $Post variable as:
$Post = TraditionalForm;

Here's how it would look:
Sin[x]/Cos[x + y]^3 + Integrate[Log[x], {x, 1, 2}] // HoldForm


Without HoldForm:
Sin[x]/Cos[x + y]^3 + Integrate[Log[x], {x, 1, 2}]


To clear the definition for $Post (if you need to), just evaluate $Post =. You can add this to your init.m if you'd like to make this apply to all notebooks henceforth, but I wouldn't suggest doing that.
"
mathlink or wstp - Is it possible to set a timeout for LinkWrite[]?,"
Setting up MathLink connections between kernels acting as peers (as opposed to in a master-slave arrangement) is sparsely documented, and the critical function you need to make this work, i.e. LinkActivate, is undocumented altogether (although, if you clear its ReadProtected attribute, you will see that it is merely a synonym for LinkConnect, which itself is a version of LinkOpen). In fact, LinkRead and LinkWrite both work with message queues and are not inherently blocking operations, but the behaviour you see is the result of the MathLink connection not having been initialized properly before writing.
To initialize the connection correctly, modify your code as follows:
SetOptions[EvaluationNotebook[], Evaluator -> ""K2""]

link = LinkCreate[""alink""]

(* Evaluate only after calling LinkConnect/LinkActivate from K1 *)
LinkActivate[link]

(* No longer blocks *)
LinkWrite[link, ""boo""]

and
SetOptions[EvaluationNotebook[], Evaluator -> ""K1""]

(* Evaluate immediately after calling LinkCreate from K2. *)
link = LinkConnect[""alink""];
LinkActivate[link] (* this call is blocking! *)

LinkRead[link]

Why this is undocumented I do not know; to my knowledge the only place where this is described is the (rather specialist) book, MathLink: Network Programming with Mathematica by Chikara Miyaji and Paul Abbott. I discovered it when I was curious as to whether it was possible to write an MPI-style message-passing implementation in pure Mathematica. (The answer is yes; I posted some code on MathGroup here if you are interested.)
"
programming - Suppressing negative roots in Mathematica,"
One way is to use Refine to filter out only the positive root. For example:
assume = Z > 0 && a > 0 && n > 0;
int = Integrate[n^2*Radial[1, 0, r]*r^2, {r, 0, ∞}, Assumptions -> assume];
sol = Solve[int == 1, n];
If[Refine[(n /. #) > 0, assume], #, ## &[]] & /@ sol


I've changed N to n since the former is a built-in function. In general, it's good practice in Mathematica to never use single capital letters for variables or start functions with capital letters (since internal functions always start with uppercase). 
Another way of doing it is by passing the assumptions directly to Solve, and getting back only the roots that satisfy those assumptions. However, it has been my experience in the past, with more complicated inequalities, that both Solve and Reduce tend to choke when you try to impose the requirements of the roots inside it (i.e., it solves the general case faster than the specific), and it's simpler to filter out the general solution with Refine. 
For the sake of completeness, here's a solution with the constraints inside Solve and then further simplified using Simplify:
Solve[int == 1 && assume, n] // Simplify[#, Assumptions -> assume] &

"
string manipulation - How to express an integer number in English words?,"
Nested WolframAlpha approach, showing the intermediate steps:
numberString[a_, k_: 10] := 
 FixedPointList[
  StringReplace[#, 
    b : (DigitCharacter ..) :> 
     WolframAlpha[""spell "" <> b, {{""Result"", 1}, ""Plaintext""}]] &, a, 
  k]

numberString[""123456""]

(*
==> {""123456"", ""123 thousand and 456"", ""one hundred twenty-three \
thousand and four hundred fifty-six"", ""one hundred twenty-three \
thousand and four hundred fifty-six""}
*)

numberString[""123456789123456789123456789""]

(*
==> {""123456789123456789123456789"", ""123 septillion, 456 \
sextillion, 789 quintillion, 123 quadrillion, 456 trillion, 789 \
billion, 123 million, 456 thousand and 789"", ""one hundred \
twenty-three septillion, four hundred fifty-six sextillion, seven \
hundred eighty-nine quintillion, one hundred twenty-three \
quadrillion, four hundred fifty-six trillion, seven hundred \
eighty-nine billion, one hundred twenty-three million, four hundred \
fifty-six thousand and seven hundred eighty-nine"", ""one hundred \
twenty-three septillion, four hundred fifty-six sextillion, seven \
hundred eighty-nine quintillion, one hundred twenty-three \
quadrillion, four hundred fifty-six trillion, seven hundred \
eighty-nine billion, one hundred twenty-three million, four hundred \
fifty-six thousand and seven hundred eighty-nine""}
*)

"
performance tuning - Memoization of Rounded inputs,"
Since Dan's already taken my initial solution, here's another approach that additionally allows you to specify the precision:
f[x_, tol_] := f[Round[x, tol]]
f[x_] := f[x] = Total[Table[x, {100000}]]

"
formatting - bar and hat only apply to certain letters,"
You can use the menu Palettes -> Basic Math Assistant and click the overscript button:

Then you can type j, followed by the tab key, followed by ^.
It should be possible at this point to assign to this typesetting construct.
Also, in this same grid of buttons you will see a button with a black square and
a ^ already on top of it, which should save you one step. There is also a button
for the overbar construction.
"
palettes - Some windows go off display,"
Manual approach: evaluate Notebooks[], and locate the palette in the resulting list.  Then evaluate the following, with a suitable value of $i$ filled in:
SetOptions[Notebooks[][[i]], WindowMargins -> {{0, 0}, {0, 0}}]

"
list manipulation - Efficient way to count the number of zeros at the (right) end of a very large number,"
For general large integers n, I don't know if there's a better method than Min[IntegerExponent[n, 5], IntegerExponent[n, 2]]. Or more compactly, IntegerExponent[n, 10] or IntegerExponent[n].
"
compile - List of compilable functions,"
Yes, but this only exists in version 8 onwards and is undocumented:
Compile`CompilerFunctions[] // Sort

giving, for reference:
{Abs, AddTo, And, Append, AppendTo, Apply, ArcCos, ArcCosh, ArcCot, ArcCoth, ArcCsc,
 ArcCsch, ArcSec, ArcSech, ArcSin, ArcSinh, ArcTan, ArcTanh, Arg, Array, ArrayDepth,
 Internal`Bag, Internal`BagPart, BitAnd, BitNot, BitOr, BitXor, Block, BlockRandom, Boole,
 Break, Cases, Catch, Ceiling, Chop, Internal`CompileError, System`Private`CompileSymbol,
 Complement, ComposeList, CompoundExpression, Conjugate, ConjugateTranspose, Continue,
 Cos, Cosh, Cot, Coth, Count, Csc, Csch, Decrement, Delete, DeleteCases, Dimensions,
 Divide, DivideBy, Do, Dot, Drop, Equal, Erf, Erfc, EvenQ, Exp, Fibonacci, First,
 FixedPoint, FixedPointList, Flatten, NDSolve`FEM`FlattenAll, Floor, Fold, FoldList, For,
 FractionalPart, FreeQ, Compile`GetElement, Goto, Greater, GreaterEqual, Gudermannian,
 Haversine, If, Im, Implies, Increment, Inequality, Compile`InnerDo, Insert,
 IntegerDigits, IntegerPart, Intersection, InverseGudermannian, InverseHaversine,
 Compile`IteratorCount, Join, Label, Last, Length, Less, LessEqual, List, Log, Log10,
 Log2, LucasL, Map, MapAll, MapAt, MapIndexed, MapThread, NDSolve`FEM`MapThreadDot,
 MatrixQ, Max, MemberQ, Min, Minus, Mod, Compile`Mod1, Module, Most, N, Negative, Nest,
 NestList, NonNegative, Not, OddQ, Or, OrderedQ, Out, Outer, Part, Partition, Piecewise,
 Plus, Position, Positive, Power, PreDecrement, PreIncrement, Prepend, PrependTo, Product,
 Quotient, Random, RandomChoice, RandomComplex, RandomInteger, RandomReal, RandomSample,
 RandomVariate, Range, Re, ReplacePart, Rest, Return, Reverse, RotateLeft, RotateRight,
 Round, RuleCondition, SameQ, Scan, Sec, Sech, SeedRandom, Select, Set, SetDelayed,
 Compile`SetIterate, Sign, Sin, Sinc, Sinh, Sort, Sqrt, Internal`Square, Internal`StuffBag,
 Subtract, SubtractFrom, Sum, Switch, Table, Take, Tan, Tanh, TensorRank, Throw, Times,
 TimesBy, Tr, Transpose, Unequal, Union, Unitize, UnitStep, UnsameQ, VectorQ, Which,
 While, With, Xor}

As of Mathematica 10.0.2, there are also the following functions:
{Gamma, Indexed, LogGamma, LogisticSigmoid, Internal`ReciprocalSqrt}

As of Mathematica 11, there are also the following functions:
{Internal`Expm1, Internal`Log1p, Ramp}

As of Mathematica 11.2, there are also the following functions:
{RealAbs, RealSign}

About Tr:
Please note that Tr appears in this list, but cannot actually be compiled without a call to MainEvaluate[]. It is unclear if this is deliberate or a bug.

Edit: additional functions
I have just discovered the symbol Internal`CompileValues, which provides various definitions and function calls needed to compile further functions not in the list above. Using the following code,
Internal`CompileValues[]; (* to trigger auto-load *)
ClearAttributes[Internal`CompileValues, ReadProtected];
syms = DownValues[Internal`CompileValues] /. 
    HoldPattern[Verbatim[HoldPattern][Internal`CompileValues[sym_]] :> _] :>
        sym;
Complement[syms, Compile`CompilerFunctions[]]

we get some more compilable functions as follows:
{Accumulate, ConstantArray, Cross, Depth, Det, DiagonalMatrix,
Differences, NDSolve`FEM`FEMDot, NDSolve`FEM`FEMHold,
NDSolve`FEM`FEMInverse, NDSolve`FEM`FEMPart, NDSolve`FEM`FEMTDot,
NDSolve`FEM`FEMTotalTimes, NDSolve`FEM`FEMZeroMatrix, FromDigits,
Identity, IdentityMatrix, Inverse, LinearSolve, Mean, Median, Nand,
NestWhile, NestWhileList, Nor, Norm, Ordering, PadLeft, PadRight,
Permutations, Ratios, Signature, SquareWave, StandardDeviation,
Tally, Total, TrueQ, Variance}

Looking at the definition of Internal`CompileValues[sym] for sym in the list above will provide some additional information about how these functions are compiled. This can range from type information (for e.g. Inverse), through to an implementation in terms of lower-level functions (e.g. NestWhileList). One can presumably also make one's own implementations of non-compilable functions using this mechanism, giving Compile the ability to compile a wider range of functions than it usually would be able to.
As of Mathematica 10.3, there are also the following functions:
{DeleteDuplicates, Region`Mesh`SmallMatrixRank,
 Region`Mesh`SmallQRSolve, Region`Mesh`SmallSingularValues,
 Region`Mesh`SmallSingularValueSystem, Region`Mesh`SmallSVDSolve,
 NDSolve`SwitchingVariable}

As of Mathematica 11, there are also the following functions:
{NearestFunction, RegionDistanceFunction, RegionMemberFunction, RegionNearestFunction}


Edit 2: the meaning of the second list
In response to a recent question, I want to be clear that the presence of a function in the second list given above does not necessarily mean it can be compiled into a form free of MainEvaluate calls. If a top-level function is already highly optimized (as e.g. LinearSolve is), the purpose of Internal`CompileValues[func] may be solely to provide type information on the return value, assuming that this can be inferred from the types of the arguments or some other salient information. This mechanism allows more complex functions that call these highly-optimized top-level functions to be compiled more completely since there is no longer any question of what the return type may be and so further unnecessary MainEvaluate calls may be avoided. It does not imply that the use of MainEvaluate is unnecessary to call the function itself.
"
list manipulation - Bug in LengthWhile?,"
Looks like a bug in V8.0.0 that was fixed in V8.0.1.
Seems to be triggered in part when the argument is a packed array:
(* V8.0.0 *)
In[2]:= digits = Reverse@IntegerDigits[1000]; 

In[3]:= LengthWhile[digits, 0 === #&]

Out[3]= 0

In[4]:= LengthWhile[Developer`FromPackedArray[digits], 0 === #&]

Out[4]= 3

which would explain why it worked when you used Evaluate in Place.
"
programming - FE`symbols that remain in notebook internals even after removing them and SaveDefinitions->True issue,"
Please try evaluating this in a copy of the Notebook with all the dynamic objects first deleted, then save and examine the Notebook file:
SetOptions[EvaluationNotebook[],
  PrivateNotebookOptions->{""FileContents""->{""NotebookData""}, ""FileOutlineCache""->False}
]

"
performance tuning - Making sure that Timing[] isn't thrown off by caching,"
Completely restarting the kernel will of course work.  If we don't restart the kernel, then we need to clear all caches.
The caches used for symbolic and some numeric calculations can be cleared using ClearSystemCache[].  The documentation page of this function says:

ClearSystemCache can be useful in generating worst-case timing results
  independent of previous computations.

I do not know if there are any other caches as well, not affected by this.
"
parallelization - Is it safe to launch/close kernels in the middle of a parallel calculation?,"
Actually it's safe to add a kernel, but if you close the kernel the calculation is working with, the calculation will never finish! I once had this problem. But I think adding a kernel when you are calculating shouldn't affect your answer.
Hope my answer helps you.
"
streams - Why these (error) messages?,"
The documentation for $Messages clearly states:

$Messages gives the list of files and pipes to which message output is sent.

Therefore Block[{$Messages = {stream}}, ... ] is the correct syntax.
"
caching - Built-in Mathematica data: are they cached? how to speed up the loading?,"
Initializing is not the same as downloading:

I believe you are witnessing the data being unpacked for use.
"
Efficint imag Import - Mathmatica Stack Exchang,"
Make your filenames unambiguously parsable, e.g. by consistently using some delimeters like underscores or something. A typical file name can look like ""Electric_B_3.png"". EDIT  If you have no control over the file names, use string patterns as described by other answers, but in the long-term you may benefit from creating your own robust naming scheme END EDIT 
Then write a function that would parse a single file name,  something like:
fileNameParse[fname_String, delim_String: ""_""] :=
   StringSplit[FileBaseName[fname], delim]

Then, Map it on FileNames[""*.png"", {your-dir}]. 
Finally, apply your importOne on the level one:
importOne@@@Map[fileNameParse, FileNames[""*.png"", {your-dir}]]

Since you have the result of Map available as well, you can regroup them any way you want. You can, for example, Map a function {#, importOne@@#}&, rather than just using importOne@@@.... Then, you could use GatherBy or any other means to regroup and collect your images according to the parts of their filenames.
EDIT 
Here is a self-contained example ( I use text files, but this doesn't matter):
ClearAll[fileNameParse, fileNameMake, importOne, $dir];
fileNameParse[fname_String, delim_String: ""_""] :=
    StringSplit[FileBaseName[fname], delim];

fileNameMake[pieces_List, delim_String: ""_"", ext_String: "".txt""] :=
    StringJoin[Append[Riffle[pieces, ""_""], "".txt""]];

importOne[set_, cat_, num_, dir_: $dir] :=
    Import[FileNameJoin[{dir, fileNameMake[{set, cat, num}]}]];

We now create a temporary directory:
$dir = FileNameJoin[{$TemporaryDirectory, ""ImportTest""}];
If[! FileExistsQ[$dir], CreateDirectory[$dir]];

Create sample files:
MapIndexed[
   Export[#, ""Test"" <> ToString[#2], ""Text""] &,
   Flatten[
     Outer[
       FileNameJoin[{$dir, fileNameMake[{##}]}] &,
       {""Electric""}, {""A"", ""B"", ""C""}, {""1"", ""2"", ""3""}
     ]]];

import them:
imported = Map[{#, importOne @@ #} &,  fileNameParse /@ FileNames[""*.txt"", {$dir}]]

(* 
  ==>

     {{{""Electric"", ""A"", ""1""},  ""Test{1}""}, {{""Electric"", ""A"", ""2""}, ""Test{2}""}, 
      {{""Electric"", ""A"", ""3""},  ""Test{3}""}, {{""Electric"", ""B"", ""1""}, ""Test{4}""}, 
      {{""Electric"", ""B"", ""2""},  ""Test{5}""}, {{""Electric"", ""B"", ""3""},  ""Test{6}""}, 
      {{""Electric"", ""C"", ""1""},  ""Test{7}""}, {{""Electric"", ""C"", ""2""},  ""Test{8}""}, 
      {{""Electric"", ""C"", ""3""}, ""Test{9}""}
      }
*)

You can now, for example, group them according to whatever parts of their file names you wish:   
GatherBy[imported , #[[1, 2]] &][[1]]

(* 
 ==>

{{{""Electric"", ""A"", ""1""}, ""Test{1}""}, {{""Electric"", ""A"", ""2""}, ""Test{2}""}, 
   {{""Electric"", ""A"", ""3""}, ""Test{3}""}}

*)

"
probability or statistics - Which Distributions can be Compiled using RandomVariate,"
To my knowledge UniformDistribution and NormalDistribution are the only distributions that are directly compilable for RandomVariate.
Consider that sampling from a UniformDistribution is what RandomReal was originally designed to do.  This code is likely written deep down in C and so compiles without any special effort.  In order to hook up RandomVariate for uniforms Compile just needs to recognize that this is really just a call to RandomReal.
Now, sampling from a NormalDistribution is so common that it was considered worth the time investment to make it compilable.  Notice that the call to RandomVariate actually produces a call to RandomNormal which was almost certainly written for this purpose.
As for other distributions, special code would need to be written for each one in a similar fashion to RandomNormal for them to be ""supported"" by Compile. Since there are well over 100 of these, it would be a huge undertaking.  An argument could be made for doing this for a few distributions but who is to decide which ones are most important?
There is a sunny side. Most distributions have their own dedicated and highly optimized methods for random number generation. Often Compile is used under the hood when machine precision numbers are requested.
Because of this, even if they were directly compilable you probably wouldn't see much of a speed boost since the code is already optimized. 
Fortunately Compile can happily handle arrays of numbers.  I typically just rely on the optimized code used by RandomVariate to generate the numbers and subsequently pass them in as an argument to the compiled function.
Incidentally, everything I just said about RandomVariate is also true of distribution functions like PDF, CDF, etc. Obviously these are just pure functions (in the univariate case) and unless they are built with some exotic components they should compile assuming you evaluate them before putting them into your compiled function.
"
Plotting piecewise function with distinct colors in each section,"
Here's an alternative approach than Spartacus' answer. What he did is splitting up the piecewise function into many different functions valid in only a small domain; what I am doing here is directly plotting the piecewise function as given, while the coloring is done using ColorFunction.
I'll use the same function as Spartacus,
f = Piecewise[{{#^2, # <= 0}, {#, 0 < # <= 2}, {Log[#], 2 < #}}] &

Step by step to the result
Now let's create a ColorFunction that does the desired thing out of this. I'll do this using Part, i.e. double brackets [[ ]], which is not limited to lists only.
First, create a copy of f.
colorFunction = f;

Now we need to find out how many pieces there are in this function; for this we have to extract those into a list we can allpy Length to. Step by step:
colorFunction[[1]]


Piecewise[{{#1^2, #1 <= 0}, {#1, Inequality[0, Less, #1, LessEqual, 2]}, {Log[#1], 2 < #1}}, 0]


That's the full function body. By applying another [[1]], we can get the first argument of Piecewise:
colorFunction[[1, 1]]


{{#1^2, #1 <= 0}, {#1, 0 < #1 <= 2}, {Log[#1], 2 < #1}}


From this matrix-shaped list, we'd like to get the length, leaving us with
piecewiseParts = Length@colorFunction[[1,1]]

Alright! Now make some colors out of that. The default plot colors are stored in ColorData[1][x], where x=1,2,3,4... is the usual blue/magenta/yellowish/green and so on.
colors = ColorData[1][#] & /@ Range@piecewiseParts


{RGBColor[0.2472, 0.24, 0.6], RGBColor[0.6, 0.24, 0.442893], RGBColor[0.6, 0.547014, 0.24]}


Now we need to take these color directives and inject them into the original function (that is, the colorFunction copy I've made in the beginning), so that it replaces squares and logarithms by reds and blues. This is some more Part acrobatics:
colorFunction[[1, 1, All, 1]] = colors

Done! colorFunction is now identical to the original function f, only that the actual functions have been replaced by colors. It looks like this:
Piecewise[{{RGBColor[...], # <= 0}, {RGBColor[...], 0 < # <= 2}, {RGBColor[...], 2 < #}}] &

Now it's time to plot, see the completed code below.
The completed code
f = Piecewise[{{#^2, # <= 0}, {#, 0 < # <= 2}, {Log[#], 2 < #}}] &;

colorFunction = f;
piecewiseParts = Length@colorFunction[[1, 1]];
colors = ColorData[1][#] & /@ Range@piecewiseParts;
colorFunction[[1, 1, All, 1]] = colors;

Plot[
    f[x],
    {x, -2, 4},
    ColorFunction -> colorFunction, 
    ColorFunctionScaling -> False
]


(The option ColorFunctionScaling determines whether Mathematica scales the domain for the color function to $[0,1]$. Handy in some cases, not so much here, since our self-made colorFunction is constant in this domain.)
"
formatting - Removing In/Out Labels before printing,"
You can set this in a style sheet so that it is done once and you don't have to do it again:
Cell[StyleData[All, ""Printout""], ShowCellLabel -> False]

or can you programmatically add this private style to your notebook:
SetOptions[EvaluationNotebook[], 
 StyleDefinitions -> 
  Notebook[{Cell[StyleData[StyleDefinitions -> ""Default.nb""]], 
    Cell[StyleData[All, ""Printout""], ShowCellLabel -> False]},
   StyleDefinitions -> ""PrivateStylesheetFormatting.nb""]
 ]

If you are unfamiliar with editing style sheets that latter option is probably the best.
"
"character encoding - How to ""Copy as Unicode"" from a Notebook?","
Since a native method is not forthcoming, I shall post my file based circumvention, for Windows.
You will need to have this utility in the command path (it apparently is stock with Windows 7).
copyUnicode[expr_] := Run[""clip <"",
   Export[""$Clipboard.temp"", ToString[expr, InputForm],
          ""Text"", CharacterEncoding -> ""Unicode""] ];

Usage:
expr = \[Alpha]\[Beta] + Mod[\[Delta]\[CapitalPsi], 2\[InvisibleTimes]\[Rho]^2];

copyUnicode[expr]

This leaves the following text in the Windows Clipboard:

αβ + Mod[δΨ, 2*ρ^2]



Here is a version of the function that holds (does not evaluate) the expression:
SetAttributes[copyUnicode, HoldFirst]

copyUnicode[expr_, form_: InputForm] := 
  Run[""clip <"", 
   Export[""$Clipboard.temp"", ToString[Unevaluated@expr, form], ""Text"", 
    CharacterEncoding -> ""Unicode""]];

Now:
Plot[\[Alpha], {\[Alpha], 0, 10}] // copyUnicode

Puts in the Windows Clipboard:

Plot[α, {α, 0, 10}]


"
programming - Cleaning up a List of HTML Data to Render Usable Information,"
For the two strings in your first example, this seems to work 
ImportString[string, ""HTML""]

For the baseurl as in the original post, Import[baseUrl, ""Data""] gives something like
data = Import[baseUrl, ""Data""]
data[[2, ;; 4]]

{{""Item"", ""View Options""}, {
  1., ""1841-1869 (Province of Canada), number 195, 21 June 1845, page \
15"", ""GIF | PDF""}, {
  2., ""1841-1869 (Province of Canada), number 402, Extra, 16 May \
1849, page 4"", ""GIF | PDF""}, {
  3., ""1841-1869 (Province of Canada), number 405, 26 May 1849, page \
15"", ""GIF | PDF""}}

so it looks like data[[2, ;; ,2]] gives you the list you're after.
"
"linear algebra - NullSpace[_, Method->""OneStepRowReduction""] is sometimes wrong; how can I work out when this happens?","
$Version    
(*  ""10.4.1 for Mac OS X x86 (64-bit) (April 11, 2016)""  *)

Let m = <pastebin monster>.
ns1 = NullSpace[m];
ns2 = NullSpace[m, Method -> ""OneStepRowReduction""];
diff = ns1 - ns2;


RootReduce[diff]
(*  {{0, 0, 0, 0, 0, 0, 0, 0}}  *)

So they're equivalent in V10.4.1.
Update: Checking correctness
After many minutes, this returns the zero vector:
m.First@ns1 // RootReduce

And these all return a rank of 7:
MatrixRank[m]
MatrixRank[N[m]]
MatrixRank[N[m, 32]]

Finally, Dimensions[m] yields {880, 8}, all of which confirms the answer is correct.
"
random - Generate a new output using Manipulate,"
Do you actually need a Manipulate expression, or is this sufficient?
DynamicModule[{x = Null}, Column[{
   Button[""Shuffle Images"", 
    x = ImageAssemble[
      Partition[
       RandomSample[
        Flatten@{DarkBlueB, DarkBlueC, DarkBlueN, DarkBlueE}, 20], 5]]
    ],
   Dynamic[x]
}]]

"
front end - Can the position of Tooltips be changed?,"
Improvised Tooltip using Text and Mouseover
Here's one way to improvise a tooltip for graphics objects--in this case,
a list of points. It emulates a tooltip but does not leave a a drop shadow, and as István notes, has a few graphical shortcomings that make it less than ideal (clipping, under axes layer). Also, the code would need to be tweaked for objects displayed through functions other than Graphics.
[Edit: The present version makes use of Heike's suggestion to use the third parameter of Text for the offset. As Heike notes, ""The units of the third argument of Text are scaled with respect to the bounding box of the first argument where {0,0} corresponds to the centre, {-1,-1} to the lower left corner, {1,1} to the upper right corner etc.""]
Graphics[{PointSize[Medium], 
    Table[Mouseover[Point[p], {Point[p], 
        Text[Framed[p, Background -> LightYellow], p, {1.25, 2}]}], 
    {p, RandomReal[1, {10, 2}]}]}, Frame -> True, 
    PlotRange -> {{0, 1}, {0, 1}}, ImagePadding -> {{100, 10}, {50, 5}}]


"
front end - Invisible \[Conjugate] glyph in the linux frontend,"
You need to make a backup and then modify the UnicodeFontMapping.tr file:
FileNameJoin[{$InstallationDirectory, ""SystemFiles"", ""FrontEnd"", 
              ""TextResources"", ""UnicodeFontMapping.tr""}]

Look for the line
0xF3C8      N       6       0xad        # \[Conjugate]

and modify it to something like
0xF3C8      N       1       0x2a        # *


Thanks go to ragfield for providing this workaround on stackoverflow.

Aside: In February 2011, I contacted WRI tech support about two linux specific Mathematica 8 frontend bugs/regressions. The non-visible \[Conjugate] discussed above and the bad typesetting in fractions. Here's images showing the latter


The helpful tech support response was simply:

These are known problems with the FrontEnd on Linux, which our developers
  hope to address in a future release of Mathematica.

and that I'll be ""notified when the issues are resolved""...  

Back to the aside:
Both of the Linux front-end bugs mentioned in the previous aside have been fixed in the first version 9 release. 
"
parallelization - Silence debug output from Parallelize?,"
It is the Check function which is throwing the error. Try using:
ParallelDo[
 Do[Quiet@Check[{i[[1]], j[[1]], 
     FindGeometricTransform[i[[2]], j[[2]], 
      Transformation -> ""Translation""]}, {i[[1]], j[[1]], err}], {i, 
   files}],
 {j, files}]

If you leave off the Print command, it will silence all kernel outputs, and also speed up your computation (I'm sure other's could expound on this, but displaying outputs while running loops tends to slow things down). If you want to monitor the output of a parallel computation while it's running, check this SO post.

Edit Just realized that putting Quiet on Check kills the whole point of your computation. I think it would be best if you just do the calculation as a Table and extract the data at the end:
Quiet@ParallelTable[{i[[1]], j[[1]], 
    Quiet[FindGeometricTransform[i[[2]], j[[2]], 
      Transformation -> ""Translation""]]}, {i, files}, {j, files}];

I'm not completely sure why I need both of those Quiet commands, but it seems to need it.
"
sql - MySQL Connection Problem,"
In the past, years ago, I have had problems with the MySQL connection that were solved following Wolfram's tech support advice of updating the java connector to its latest version. This can be done by:

Download the connector from MySQL web page: http://www.mysql.com/downloads/connector/j/
Install it at  $InstallationDirectory->SystemFiles->Links->DatabaseLink->Java

My Mathematica 8 has version 5.1.13 installed and the latest available now at mysql.com is 5.1.18
You could try this, and save the original connector in a separate location just in case you need to revert.
BTW, Which platform and mysql version are you using?

After reading your comment I realized that what you need to do is to wrap your connection code inside a TimeConstrained command. In the past I have used this code to connect reliably to my database:
Needs[""DatabaseLink`""];
CloseSQLConnection[conn];
TimeConstrained[
    conn = OpenSQLConnection[JDBC[""mysql"",""localhost:3306/my_database_name""],
                             ""Username""->""login"",
                             ""Password""->""secret""],
    5,
    CloseSQLConnection[conn]
];

"
programming - Alternative to overloading Set,"
Reasons why adding rules to Set is a really bad idea
First, let me list the reasons why I think that adding rules to  Set globally is a very bad practice:

This is a hugely non-local system modification. We have no idea which parts of the system will be affected, but we can be sure that there will be many.
Set is a very frequently used command (see first point)
Set is fundamental to the system, and in some ways more low-level command than most others.
It could have been already overloaded internally for certain purposes. We may even break that internal code, and in this case, there would be absolutely no way to know,
We may degrade the performance, in unpredictable ways.

Some possible ways out
Now, here are some suggestions of what one could do.

Overload Set via UpValues, when you can. One example can be found here. It is  not always possible however, due to the limitation on the depth-1 UpValues search.
Define yout own custom assignment operator, like mySet, and use that. This is the option I use most frequently myself. A bit more typing and less syntactically pleasing, but saves a lot of hassle in the long term. Besides, custom assignment operators are a very powerful programming tool, because you can do some extra stuff along with making assignments.
Create local environments. These can be lexical or dynamic. I will illustrate with a dynamic environment, for a simple example of a type point, that will hold a list of 2-dimensional coordinates. Our goal is that if some variable var is of type point (i.e. holds an expression like point[{x,y}], then if I make an assignment like var = {3,4}, I should have now point[{3,4}] stored in var.

Here is the code:
ClearAll[withCustomSet];
SetAttributes[withCustomSet, HoldAll];
withCustomSet[code_] :=
   Internal`InheritedBlock[{Set},
     Unprotect[Set];
     Set[var_Symbol, {x_, y_}] /;
        MatchQ[HoldComplete[var] /. OwnValues[var], HoldComplete[_point]] :=
            var[[1]] = {x, y};
     Protect[Set];
     code];

Let us see:
a = b = point[{1,2}]

a = {3,4};
a

(*
   ==>{3,4}
*)

while
withCustomSet[b = {3,4}];
b

(*
   ==>  point[{3,4}]
*)

In practice, you can execute arbitrary code inside withCustomSet, and the new redefinition of Set will take effect all the way down the execution stack. This is powerful but at the same time dangerous, however, much less dangerous that an analogous but global redefinition.
A lexical environment is also easy to construct:
ClearAll[withCustomSetLex];
SetAttributes[withCustomSetLex, HoldAll];
withCustomSetLex[code_] :=
  Unevaluated[code] /.
     HoldPattern[
       Set[var_Symbol, {x_, y_}] /; 
           MatchQ[HoldComplete[var] /. OwnValues[var], HoldComplete[_point]]] :>
             (var[[1]] = {x, y});

You can test that it works fine with the same simple test as above. However, it will only affect the instances of Set explicitly present in the code inside it. OTOH, this is yet much safer, since the stack is not affected.
Summary

Don't ever add rules to Set globally, if you want predictable behavior from Mathematica
There are plenty of ways to go around this problem, so this is not that serious of a limitation, really.

EDIT
To address the specific question (added in the update): the lexical environment would look like
ClearAll[withCustomSetLex];
SetAttributes[withCustomSetLex, HoldAll];
withCustomSetLex[code_] :=
  Unevaluated[code] /. 
      HoldPattern[Set[symbol_[key_], value_]] :>  ObjectSet[symbol, key, value]

A dynamic environment is trivial to implement: replace the code I used above in between Unprotect[Set] and Protect[Set] with your code.
"
probability or statistics - Conditional T distribution,"
Try this:
bivTCond[x_, y_, ν_, ρ_] := 
 Evaluate @ PDF[MultivariateTDistribution[{{1, ρ}, {ρ, 1}}, ν], {x, y}]/
 Evaluate @ PDF[StudentTDistribution[0, 1, ν], x]

Plot[bivTCond[1, y, 3, 0.5], {y, -3, 3}]


"
Does Mathematica implement the fast Fourier transform?,"
Fourier[list] computes the discrete Fourier transform of list.  I assume it uses the FFT when it can.
"
algebraic manipulation - Expand modulus squared,"
Something like (ComplexExpand with all three arguments, Expand and a rule) :
rule = {Im[x_]^2 + Re[x_]^2 -> Abs[x]^2, f_ Re[x_] Re[y_] + f_ Im[x_] Im[y_] -> f Re[Conjugate[x] y]};

Expand[ComplexExpand[Abs[Subscript[z, 1] + Subscript[z, 2]]^2, {Subscript[z, 1],Subscript[z, 2]}, TargetFunctions -> {Re, Im}]] //. rule

Abs[Subscript[z, 1]]^2 + Abs[Subscript[z, 2]]^2 + Re[Conjugate[Subscript[z, 1]] Subscript[z, 2]]

Expand[ComplexExpand[Abs[Subscript[z, 1] + Subscript[z, 2] + Subscript[z, 3]]^2, {Subscript[z, 1], Subscript[z, 2], Subscript[z, 3]}, TargetFunctions -> {Re, Im}]] //. rule

Abs[Subscript[z, 1]]^2 + Abs[Subscript[z, 2]]^2 + Abs[Subscript[z, 3]]^2 + Re[Conjugate[Subscript[z, 1]] Subscript[z, 2]] + Re[Conjugate[Subscript[z, 1]] Subscript[z, 3]] + Re[Conjugate[Subscript[z, 2]] Subscript[z, 3]]

"
linear algebra - Discrete Convolution,"
You could use ListConvolve:
ListConvolve[a, b, {1, -1}, 0]

concerning the padding:
ArrayPad[b, 3, 0]

And you could use Partition for the second of your steps:
Partition[Range[Length[ArrayPad[b, 3, 0]]], 3, 1]

"
compile - How to use a matrix variable for a compiled function,"
Not only can Matrix be a PackedArray, it must be a PackedArray. However, it will be packed for you if necessary before the compiled code is called.
The following code is substantially faster than that given by acl above and does not require any post-processing of the output, but is still sub-optimal in terms of requiring CopyTensor calls and using a rather larger working set than one would think necessary. Perhaps these limitations can be lifted, but after a brief survey of possible implementations I didn't find a way better than this (though note that I didn't try anything with Internal`Bag).
clusterFind = Compile[{{inte, _Real, 0}, {matrix, _Complex, 2}},
    Module[{tmp = matrix[[All, {1, 2, 3, 4, -1}]]},
        Select[tmp, Last[#] == inte &][[All, ;; -2]]
    ], RuntimeAttributes -> Listable, Parallelization -> True
];

An example of the improved timings:
range = {0, 10};
data = RandomInteger[range, {1*^5, 100}];

acl's version:
Timing[
    cf4[RandomInteger[range], data];
]

producing: {2.297, Null}
My version:
Timing[
    clusterFind[RandomInteger[range], data];
]

which gives {0.047, Null}.
Note that the above timings are not for C-compiled versions of the two functions; compilation to C does not help very much as there is not much computational work to be done in this process anyway and most of the timing consists of copying or extracting parts of tensors. Also, I should mention that RuntimeAttributes -> Listable and Parallelization -> True do not really buy you anything here unless you are operating on a list of matrices.
"
"version 8 - RunScheduledTask didn't execute itself the first time, why?","
Can't you do something like
RunScheduledTask[Pippo[]; RunScheduledTask[Pippo[], 60*60*24], {0}, ABSTIME]

"
graphics - How to draw multiple coordinates on mathematica?,"
You build this in Mathematica like you would do in any other descriptive language (you might want to use TikZ for this): step by step. Choosing nicer colors,adjusting the distances  etc. is left as an exercise to the reader.
cosy[labels_, labelstyle_] := Flatten@{
    Arrow[{{0, 0, 0}, {1, 0, 0}}],
    Arrow[{{0, 0, 0}, {0, 1, 0}}],
    Arrow[{{0, 0, 0}, {0, 0, 1}}],
    labelstyle,
    Text[labels[[1]], {1.1, 0, 0}],
    Text[labels[[2]], {0, 1.1, 0}],
    Text[labels[[3]], {0, 0, 1.1}]
};
Graphics3D[{
    { (* Coordinate system 1 *)

   cosy[{""X"", ""Y"", ""Z""}, Darker@Orange],
        Darker@Orange,
        Text[""World"", {-.3, -.3, .5}]
    },
    { (* Coordinate system 2 *)

   Rotate[cosy[{""x"", ""y"", ""z""}, Blue], -30 \[Degree], {-1, 0, 1}]~
    Translate~{0, 0, -2}
    },

    { (* Connecting arrow *)
        Darker@Green,
        Arrow[{{0, 0, 0}, {0, 0, -2}}],
        Text[""C(t)"", {0, -.2, -1}]
    },

    { (* Red stuff *)
        Red,
        Arrow[{{0, 0, 0}, {0, 3, -1}}],
        Arrow[{{0, 0, -2}, {0, 3, -1}}],
        Text[""\!\(\*SubscriptBox[\(p\), \(world\)]\)"", 
    1/2 {0, 3, -1} + {0, 0, .5}],
        Text[""\!\(\*SubscriptBox[\(p\), \(0\)]\)"", 
    1/2 {0, 3, -1} + {0, 0, -1.5}],
        Text[""p(t)"", {0, 3, -1} + {0, .5, 0}]
    }
  }, Boxed -> False]




"
programming - Downloading files without using Import,"
How about a version of:
Needs[""Utilities`URLTools`""];
path = FetchURL[
   ""http://www-roc.inria.fr/gamma/download/counter.php?dir=MECHANICAL//&\
get_obj=ifp2_cut.mesh.gz&acces=ifp2_cut"", ""ifp2_cut.mesh.gz""];

"
Knowing when a notebook has changed programmatically,"
I think that
""ModifiedInMemory"" /. NotebookInformation@SelectedNotebook[]

does what you want (ie, returns False if the notebook is saved, True if it is not saved). Although maybe not quite, try NotebookInformation[CreateDocument[""hi""]]
But it seems to work once you modify a notebook that's been saved once. I could be wrong though...
"
numerics - Why is MainEvaluate being used when LinearSolve can be compiled?,"
acl already posted the crucial information needed to solve this conundrum (i.e., the definition of Internal`CompileValues[LinearSolve]), but wishes to delete his post since he had not interpreted it to give the complete answer. Therefore I re-post the following observation along with a summary of what it means.
The input,
Internal`CompileValues[];
ClearAttributes[Internal`CompileValues, ReadProtected];
Internal`CompileValues[LinearSolve]

yields:
HoldPattern[Internal`CompileValues[LinearSolve]] :> {
  HoldPattern[
    LinearSolve[
      System`CompileDump`x_?(Internal`TensorTypeQ[Real, {_, _}]), 
      System`CompileDump`b_?(Internal`TensorTypeQ[Real, {_}])]
    ] :> _?(Internal`TensorTypeQ[Real, {_}]), 
  HoldPattern[
    LinearSolve[
     System`CompileDump`x_?(Internal`TensorTypeQ[Complex, {_, _}]), 
     System`CompileDump`b_?(Internal`TensorTypeQ[Complex, {_}])]
    ] :> _?(Internal`TensorTypeQ[Complex, {_}])
}

Briefly put, this tells us that when the compiler sees a function call like LinearSolve[x, b], it knows that:

when x is a real matrix and b is a real vector, the result is a real vector
when x is a complex matrix and b is a complex vector, the result is a complex vector

As a result of this knowledge, the compiler is able to determine what type of register is needed to store the return value from LinearSolve in these two cases. This is important if further operations are then carried out on the result: in the absence of type information, all subsequent operations on LinearSolve's return value would need to be performed via the interpreter using MainEvaluate for full generality, but because the type of the result is predetermined, such operations can be compiled instead. However, since LinearSolve is a highly optimized top-level function, compilation does not offer any benefit outside of this scenario, and so knowing the return type has no value if LinearSolve[x, b] is the entire contents of the compiled function, since the operation may as well have been performed via the interpreter anyway.
As regards why LinearSolve[x, b, Method -> m] produces a message: it is because the definition for Internal`CompileValues[LinearSolve] does not provide for pattern matching against LinearSolve calls when any Method is specified. It handles only the form LinearSolve[x, b].
Conclusion
Just because Internal`CompileValues[func] is defined for some function func, one cannot assume that func can be called directly from compiled code without using a MainEvaluate call. It simply means that the compiler has information about func which it can incorporate into the compilation process as a whole.
"
random - Creating randomly oriented planes,"
Why don't you pick a random vector on the sphere to be your first vector, instead of $\mathbf{n}$, and then pick a random uniform number between $0$ and $2 \pi$ to orient the second vector aronud the first?
Something like this, assuming you have your function randomVectorOnUnitSphere[] already
(haven't tested it)
generateRandomPositioning[v1_, v2_] := 
 With[{angle = VectorAngle[v1, v2], mag1 = Norm[v1], mag2 = Norm[v2], 
   rvec = randomVectorOnUnitSphere[]},
  Module[{v1out, v2out},
   v1out = rvec mag1;
   v2out = 
    Cross[rvec, v2] //
      (* this just gives a particular vector perpendicular to v2out, 
      assuming they are not colinear *) 
      RotationTransform[angle, #][rvec] & //
      (* now I have a particular vector at the corresponding angle of v1out *) 
      RotationTransform[RandomReal[2 Pi], rvec]//(* now it's distributed uniformly *) 
      Normalize[#] mag2 &;
    {v1out, v2out}
  ]
]

Ok, here's my test
randomVectorOnUnitSphere[]:=With[{θ = RandomReal[2 π], φ = ArcCos[RandomReal[{-1,1}]]},
    {Cos[θ] Sin[φ],Sin[φ] Sin[φ],Cos[φ]}
]

ListPointPlot3D[Table[randomVectorOnUnitSphere[], {10000}], AspectRatio -> 1]


In[28]:= v1 = {0, 1, 1}; v2 = {0, 3, 0.4};
test = Table[generateRandomPositioning[v1, v2], {500}];

In[13]:= arrowCouple[{pt1_, pt2_}] := {Arrow[{{0, 0, 0}, pt1}], 
   Arrow[{{0, 0, 0}, pt2}]};

In[30]:= Equal @@ VectorAngle @@@ test

Out[30]= True

In[31]:= VectorAngle @@ First@test == VectorAngle[v1, v2]

Out[31]= True

Graphics3D[{Opacity[
   0.2], {RGBColor[RandomReal[], RandomReal[], RandomReal[]], 
     arrowCouple[#]} & /@ test}, Boxed -> False]


Graphics3D[{Black, arrowCouple[{v1, v2}], 
    {RGBColor[RandomReal[], RandomReal[], RandomReal[]], 
     arrowCouple[#]} & /@ test[[;; 3]]}, Boxed -> False]


I know, these aren't proper tests, nor am I sure this is what you want to accomplish.
If I think about it more formally, and I remember well, you need to have a clear idea of how you measure sets of ""pairs of vectors of given magnitude and angle between them"", so that you can talk about uniform distribution. It would mean that the probabilty of the final pair of vectors being in a certain subset is proportional to the subset's measure... But if we assume that your measure is invariant to rotations, which makes sense, then probably it's all the same
"
Manipulate with a variable number of sliders,"
The Advanced Dynamic Functionality in Mathematica documentation has the following example that looks like what you need.
DynamicModule[{n = 5, data = Table[RandomReal[], {20}]},
Column[{
Slider[Dynamic[n], {1, 20, 1}],
Dynamic[Grid[Table[With[{i = i},
   {Slider[Dynamic[data[[i]]]], Dynamic[data[[i]]]}], {i, n}]
 ]]}]]


It builds a list of controllers (Slider-s in this particular case) by using the fact that you can assign values to not just symbols but also to members of a list by doing data[[1]] = value. Which is exactly the thing that happens inside Dynamic[data[[i]]], as it is equivalent to:
Dynamic[data[[i]], (data[[i]] = #)&]

telling Mathematica to whenever the actual value of data[[i]] is changed, use the new value (#) to update the expression data[[i]].
Also from the Documentation Center, the last example in Manipulate: Neat Examples may be useful:
Manipulate[
ArrayPlot[
Take[data, h, w]], {{data, RandomInteger[{0, 1}, {10, 20}]}, 
ControlType -> None}, {{h, 5}, 1, 10, 1}, {{w, 5}, 1, 20, 1}, 
Dynamic[Panel[
 Grid[Outer[Checkbox[Dynamic[data[[#1, #2]]], {0, 1}] &, Range[h], 
 Range[w]]]]]]

which gives

"
syntax - Multiple colors in Graphics[] environment,"
Maybe something like this?  I've controlled the colors based on the radius r and am passing in a location loc so that different disks are produced in the following example.
f[loc_, r_] := Graphics[{If[r > 0, Blue, Red], 
                  EdgeForm[Black], Disk[loc, Abs[r]]}]

Here it is for 100 random locations each with a radius ranging from 0 to 2.
Show[Table[f[i, RandomReal[{-2, 2}]], {i, RandomReal[{-10, 10}, {100, 2}]}]]


Edit: I'm not sure I understand exactly what you are asking for in the edits to the question. Going with the second it seems to me that you want to create a matrix of colored disks that corresponds to your original matrix m?  If that is the case, you could do something like the following.
diskMatrix[m_]:=
    Block[{r,max = Max[m^2],n=Length[m],p=Length[m[[1]]]},
       Graphics[
         Table[
            r=m[[i,j]]^2;
            {EdgeForm[Black],
            If[m[[i,j]]>0,Blue,Red],
            Tooltip[Disk[{j,-i},
                    Rescale[r,{0,max},{0,2/n}]],
                    Row[{""Radius : "",r}]
            ]}
         ,{i,n},{j,p}
         ]
       ]
    ]

This code is going to take a matrix m and effectively produce a grid of disks where the ijth disk has radius m[[i,j]]^2 and is red if m[[i,j]] is negative, blue otherwise. In order to prevent overlap in the resulting graphic I've rescaled the radii. A Tooltip is used to show the value of the radii on mouse-over.
Here is an example using the matrix provided in the simple example.
m1 = {{-1/2, 1/2, 0, -1/Sqrt[2]}, {1/2, 1/2, -1/Sqrt[2], 0}, {-1/2, 
    1/2, 0, 1/Sqrt[2]}, {1/2, 1/2, 1/Sqrt[2], 0}};

diskMatrix[m1]

Produces the following image...

Edit 2:
One last try in light of the most recent edit and posted comments. The following function will take a matrix of possibly complex values.  It assumes there will be 4 columns in this matrix.  
For each row m[[i]] a square is drawn. Proceeding from bottom left and counter-clockwise around the square a disk is rendered at each vertex.  The radius of the disk is proportional to Abs[m[[i,j]]]^2. The color is chosen based on the sign of the real part of m[[i,j]].
diskTangle[evect_] := 
 Block[{r, max = Max[Abs[Flatten[evect]]^2], 
   pos = {{0, 0}, {1, 0}, {1, 1}, {0, 1}}}, 
  Table[Show[Graphics[{EdgeForm[Thick], White, Rectangle[]}], 
    Graphics[
     Table[r = Abs[e[[i]]]^2; {EdgeForm[Black], 
       If[Sign[Re[e[[i]]]] > 0, Blue, Red], 
       Tooltip[Disk[pos[[i]], Rescale[r, {0, max}, {0, 1/2}]], 
        Row[{""Radius : "", r}]]}, {i, Length[e]}]]], {e, evect}]]

Using m1 from above...
evects = Eigensystem[m1][[2]]//N;

diskTangle[evects]


"
syntax - Using variables in function names,"
You can also use ToExpression to join the index n to your base function name, C, as in the following example:
C1 = Sin[x];
C2 = Cos[x];
C3 = Tan[x];
Table[Plot[Evaluate[ToExpression[""C"" <> ToString@i]], {x, -π, π}], {i, 3}]


"
replacement - Replace rule also matching complex numbers,"
Assuming you want to do all this with replacement rules rather than some built-in functions as noted in the comments, if you modify the rule and correct the typos you get the desired output from the example. For example:
 rule2 = g_  x_^4 + h_   x_^2  y_^2 + g_  y_^4 /; h == 2 g -> 
  g (x^2 + y^2)^2 ;

and
(2 Re[Hy Conjugate[Hx]] kx^4 vx vy)/(k^2 (kx^2 + ky^2)) + (4 Re[
  Hy Conjugate[Hx]] (kx^2  ky^2) vx vy)/(k^2 (kx^2 + 
   ky^2)) + (2 Re[
  Hy Conjugate[Hx]] ky^4 vx vy)/(k^2 (kx^2 + ky^2)) //. rule2

gives 
 (2 (kx^2 + ky^2) vx vy Re[Hy Conjugate[Hx]])/k^2

"
Good ways to organize and document collections of mathematica notebooks?,"
There are two answers to this question, and only one has anything to do with directory structure, and that only mildly. 
The first answer is to structure the notebook itself using the style groupings provided. This will greatly enhance your ability to find something within any given notebook. For instance, as a materials physicist I use a model known as tight binding, and as part of my learning about how to apply it to a particular crystal structure, I have a notebook that I treat as a lab notebook. It has three main sections: Setup, Preliminary Testing, and Full Testing all at the highest level of the hierarchy. The least organized section is the Preliminary Testing, but even there I make ample use of Text cells to record my thoughts and observations. The other two sections make full use of the hierarchy to organize and group my examinations of the tight-binding method.
The second answer is packages. If you have some code that you find yourself referring to often, put in a package. Here I tend to use a rule of three, if I have to refer to or rewrite something 3 or more times, it needs to be in a package. It is here that a directory structure is helpful.  In my case, my packages are currently organized into three directories: Quantum, Utilities, and Wien2k (a software package I've written interface scripts for) for a total of 16 packages. 
I try to make each package somewhat complete in that they provide a full range of services. For example, the Wien2k package for loading their crystal structure files provides a full range of functions for accessing the structured information in those files, but sadly not saving them, as I haven't had the need to write it. But, some packages are just buckets of loosely related functions, and they're perfect that way. 
"
cudalink - CUDA: setting grid dimensions,"
You cannot specify the grid dimensions, you can specify how many threads to launch. This is done by passing an extra argument when calling the CUDAFunciton, so 
colorNegate = CUDAFunctionLoad[{srcf}, ""imageColorNegate"",
 {{_Integer, _, ""InputOutput""},_Integer, _Integer, _Integer}, {16, 16}]

this will figure out the number of threads automatically:
colorNegate[img, 512, 512, 3]

this will force CUDALink to launch {256, 256} threads
colorNegate[img, 512, 512, 3, {256, 256}]

"
random - creating vectors with normal distribution of lengths,"
Technically, the normal distribution is defined on the real line, $\mathbb{R}$, but vector lengths are nonnegative numbers, elements of $\mathbb{R}_{0+}$. So you can't really have the lengths of your vectors satisfy a normal distribution. You have to choose a distribution for the lengths that has the correct domain, $\mathbb{R}_{0+}$.
One thing you can do, and my best guess at what you really want, is to use the restriction of the normal (or half-normal) distribution to the nonnegative numbers. That would be accomplished exactly like you said, by choosing the length from HalfNormalDistribution.
If the angular distribution of the vectors (the distribution of their directions) has reflection symmetry, in the sense that a vector is just as likely to point in any particular direction $\hat{n}$ as it is to point in the opposite direction $-\hat{n}$, then you actually can multiply the unit vectors you have by random numbers chosen from the full normal distribution. If the random number is negative, it will switch the direction of your vector, but since $P(\hat{n}) = P(-\hat{n})$, the probability of switching any one direction to the opposite direction is the same as the probability of switching the opposite direction to the original direction. Those two effects cancel out. If the angular distribution is not symmetric, however, then using the full normal distribution will have the effect of symmetrizing it, i.e. you'll wind up with a new distribution of directions $P'$ such that $P'(\hat{n}) = \frac{1}{2}\bigl(P(\hat{n}) + P(-\hat{n})\bigr)$.
"
Export Graphics[] without white edges,"
There's another, undocumented, approach, although I can't take credit for discovering this one. The solution you're probably looking for (in the sense that Brett Champion's solution seems to clip off a little too much at the edges) is the Method option for Graphics:
Method -> {""ShrinkWrap"" -> True}

e.g. (graphics example from the documentation for Circle):
Graphics[
  Table[{Hue[t/20], Circle[{Cos[2 Pi t/20], Sin[2 Pi t/20]}, 1]}, {t, 20}], 
  Method -> {""ShrinkWrap"" -> True}
]

Note that this has to be written as Method -> {""ShrinkWrap"" -> True}. The form Method -> ""ShrinkWrap"" -> True might be expected to work, but it doesn't.
"
front end - WYSIWYG table creating and editing,"
Mathematica already has some of these features: e.g


Regarding your comment about the appearance when you do this in a text cell. Here is what it looks like for me on a Mac:

So the font is Courier which, unless you have reconfigured your system, is not the default font for text cells. You can fix this by changing the grid box options: To do this -- in a menu driven way -- click on the cell bracket and go to Format > Option Inspector and type gridbox in the search field then when presented with the options edit the BaseStyle

Here I've changed the font to Times and you can see the change in the input cell. Note that you have also commented about alignments. You can set the grid alignments the same way. I'd suggest that you read up on various alignment points in the Grid documentation.
You are probably already thinking that this is inconvenient to do regularly so instead you can set up your own Grid style in a style sheet. The downside to that is that this will style Grid the same in all cells. So in fact what you need to do is create a stylesheet with a modified Text style:

Stylesheeting is beyond the scope if this Q&A but if you search you will find information about how to go about this. I'd suggest this is your best option for regular routine use.
Finally, to style tables and output a set of rules for later use a demo can be seen here from which a slightly reduced set of features can be downloaded.
"
graphics - Generate Random Text within a Rectangle,"
Maybe something like this (using Inset and Pane to place text inside the rectangle):
txdt = ExampleData[{""Text"", ""LoremIpsum""}]; 
Manipulate[Graphics[{EdgeForm[Thick], Opacity[0], Rectangle[{0, 0}, {160, 90}], 
Opacity[1], 
Inset[Pane[
 Style[txdt, TextAlignment -> Left], {Scaled[1], Scaled[.75]}, 
 Alignment -> Center,
 Scrollbars -> Automatic, AppearanceElements -> {""ResizeArea""}, 
 ImageSizeAction -> ""Scrollable""], {left, bottom}, {Left, 
 Bottom}, {right - left, top - bottom}], 
 Flatten@({Flatten@(Table[
        RandomChoice[{GrayLevel[.15], c0[[#]]}], {3}] & /@ 
      Range[2, 4, 1]), 
   MapThread[Function[{Xs, Ys}, 
     Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten@
      Table[Range[0, 32, 16], {3}], 
     Flatten@(Table[#, {3}] & /@ 
        Range[63, 81, 9])}]}\[Transpose]), Black, Thick, 
 Line[{{0, 63}, {160, 63}}]}, PlotRange -> {{0, 160}, {0, 90}}, 
 ImageSize -> 400], {{left, 0}, 0, 140, 1}, {{bottom, 0}, 0, 55, 1}, 
 {{right, 160}, 10, 160, 1}, {{top, 75}, 0, 75, 1}]

With output:
:
Source: Inset trick based on TextRect courtesy of Wolfram's John Fultz: pls see    MathGroup
EDIT: Without assuming that the current question is related to 
OP`s previous question, using just plain rectangles and text: 
 Graphics[{EdgeForm[Thick], Opacity[0], Rectangle[{0, 0}, {160, 90}], 
   Opacity[1], 
   Inset[Pane[Style[#, 12, TextAlignment -> Left], {Scaled[1], 
      Scaled[.75]}, Alignment -> Center, Scrollbars -> Automatic, 
     AppearanceElements -> {""ResizeArea""}, 
     ImageSizeAction -> ""Scrollable""], {5, 5}, {Left, 
     Bottom}, {150, 100}]}, PlotRange -> {{0, 160}, {0, 90}}, 
  ImageSize -> 400] &@
  RandomChoice@Take[ExampleData[{""Text"", ""LoremIpsum""}, ""Lines""], 
  {1,-1,2}] & /@    Range@4 // Grid[Partition[#, 2]] & 

which gives
 
If the rectangles are known to be large enough so that scrolling will not be needed, then Pane is not needed; you can use the following version of the Inset:
 Inset[Style[Text[#], 12, TextAlignment -> Left], {5, 90}, {Left, 
   Top}, {150, 100}]

EDIT 2: Putting the text in the proper rectangle (in response the OPs edit), using txt1 from Lorem Ipsum
 txt1 = Take[ExampleData[{""Text"", ""LoremIpsum""}, ""Lines""], {1, -1, 2}][[1]] //
 StringTake[#, 330] & ;

in 
 Graphics[{EdgeForm[{Thickness[0.005`], Black}], White, 
 Rectangle[{0, 0}, {160, 90}], Black, Opacity[0.7`], 
 EdgeForm[{Thickness[0.005`], Black}], Rectangle[{0, 0}, {80, 63}], 
 Inset[Pane[
 Style[txt1, 12, TextAlignment -> Left], {Scaled[1], 
 Scaled[0.75`]}, Alignment -> Center, 
 ImageSizeAction -> ""Scrollable""], {0, 8}, {Left, Bottom}, {78, 
 67}], Flatten[
 Transpose[{Flatten[(Table[
      RandomChoice[{GrayLevel[0.15`], c0[[#1]]}], {3}] &) /@ 
   Range[2, 4, 1]], 
 MapThread[
  Function[{Xs, Ys}, 
   Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten[
    Table[Range[0, 32, 16], {3}]], 
   Flatten[(Table[#1, {3}] &) /@ Range[63, 81, 9]]}]}]], Null, 
Black, Thickness[0.005`], Line[{{0, 63}, {159, 63}}]}, 
PlotRange -> {{0, 160}, {0, 90}}, Method -> {""ShrinkWrap"" -> True}, 
ImagePadding -> 2, ImageMargins -> 0, ImageSize -> 500]

you get

"
Selectively Mapping over elements in a List,"
Here's an option which only passes moons with images to the Labeled function:
Labeled[# // Text, AstronomicalData[#, ""Image""]] & /@ 
  Select[AstronomicalData[""PlanetaryMoon""], 
   ImageQ[AstronomicalData[#, ""Image""]] &] // Row


"
How to develop an Import/Export converter for Compress[]ed data?,"
In this case, developing the converters is dead-easy (which is not a good thing IMO, since it means that we really don't utilize the power of Import/Export framework, but rather are adding syntactic sugar):
CompressedFormat`CompressedFormatImport[filename_String, options___] :=
    {""Data"" -> Uncompress@Import[filename, ""String""]};

CompressedFormat`CompressedFormatExport[filename_String, data_, opts___] :=
    Export[filename, Compress@data, ""String""];

ImportExport`RegisterImport[
   ""CompressedFormat"",
   CompressedFormat`CompressedFormatImport
]

ImportExport`RegisterExport[
   ""CompressedFormat"", 
   CompressedFormat`CompressedFormatExport 
]

Example:
file = $TemporaryPrefix <> ""test"";
Export[file, Range[1000000], ""CompressedFormat""];
Import[file, {""CompressedFormat"", ""Data""}] // Length

(* 
  ==>  1000000
*)

That said, I think using Import - Export framework makes much more sense for specific formats where you can specify distinct elements and the framework makes it convenient to create importers for those elements (possibly avoiding full imports when unnecessary). So, for a meaningful exposition of the importer-writing procedure using Import/Export framework, some e.g. particular graphics of numerical format would be a better choice IMO, because your stated goal is too general for that. 
For that matter, I think that my large data framework (perhaps when extended and generalized) will make for a much better case for Import/Export framework use, as well as cover your use case and many more, because it:

Does use Compress under the cover
Uses lazy loading, which opens many possibilities to define certain elements for Import/Export, which are loaded individually / efficiently
Does not have a limitation that the file must fit in memory
Can be very fast for large files
In practice, we use large files much more frequently than carry them around from platform to platform. My framework can switch from extremely fast .mx files to Compress-ed non-.mx files very easily, and the details can be completely hidden from the user, who will just use Import in all cases, and have great performance. 

In other words, I feel that the direction I outlined there, does contain your suggestion as a special case, and is much more fruitful both for further development of the large-data framework / file format, and for the utilization of the power of the Import/Export framework (and, sure enough, this is the direction I will be extending the large-data framework in the future).
"
front end - Toolbars in Mathematica,"
To begin with, if you use menu: Palettes > Install Palette... the palette should open in the place it last appeared every time you start Mathematica.  I always have two custom palettes visible when I start Mathematica:

A palette to open one of dozen Notebooks I use frequently
Szabolcs's Paste Tabular Data

These admittedly do not ""dock"" if I move them around, but I have never actually looked for that option so it may be possible.  I know that you can make a palette float always-on-top with the option WindowFloating (in fact this may be the default; it it switchable with WindowFloating).
In answer to why I suppose:

Because people do such a range of different things with Mathematica there is less value in a standard toolbar.
Palettes actually do provide for a reasonably similar functionality
Actual toolbars are seen as taking up screen space
Someone in the FrontEnd GUI department is lazy.  This would also explain the lack of a multi-step Undo. ;-)

"
graphics - How to get rid of Panel margins?,"
In these situations I like to use Pane instead of Panel.  It has no frame or extra margins.
Pane[Graphics[{Circle[]}, ImageSize -> 300, Frame -> True, 
  FrameTicks -> None]]


Does this help?

In case if you just want a Panel with no margins, not even the small margins that are left after FrameMargins -> 0:
The problem is that the Panel margin is styled by the operating system and will look different on different platforms. For example, on Windows XP it has an ""engraved"" look. This would be not possible without some extra margin. If we take away the system-styled margins, then all we're left with is a Pane.
"
Fit an image within a Rectangle [] in Graphics,"
What about this to create the textured rectangle. Here, pic is the picture you want to use for the Texture and ll and ur are the lower left and upper right corners of the box.
rec[ll_, ur_, pic_] := Module[{crop, boxrat},
  boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}];
  crop = ImageCrop[pic, Transpose[{ ImageDimensions[pic]}], 
    AspectRatio -> boxrat];

  {Texture[ImageData[crop]],
   Polygon[Tuples[Sort /@ Transpose[{ll, ur}]][[{1, 2, 4, 3}]],
    VertexTextureCoordinates -> Tuples[{0, 1}, 2][[{1, 2, 4, 3}]]]}]

For your example you would get
pic = Import[
      ""http://dailytechgadgets.files.wordpress.com/2011/02/old-ferrari.jpg""];

Graphics[{EdgeForm[Thickness[.005]], White, 
  Rectangle[{0, 0}, {160, 90}], Black, Opacity[.7], 
  Rectangle[{0, 0}, {80, 63}], White, Opacity[1],

  rec[{80, 0}, {160, 63}, pic], Opacity[1], 

  Flatten@({Flatten@(Table[
        RandomChoice[{GrayLevel[.15], c0[[#]]}], {3}] & /@ Range[2, 4, 1]), 
    MapThread[
     Function[{Xs, Ys}, 
       Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten@
         Table[Range[0, 32, 16], {3}], 
       Flatten@(Table[#, {3}] & /@ 
           Range[63, 81, 9])}]}\[Transpose])}, 
 Method -> {""ShrinkWrap"" -> True}, ImageSize -> 500]

which produces

Edit 
Instead of cropping the image first and using that as the texture you can also play around with the settings for VertexTextureCoordinates. For example you could also do
rec2[ll_, ur_, pic_, f_:.5] := 
 Module[{boxrat, picrat},
  picrat = #2/#1 & @@ ImageDimensions[pic];
  boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}];
  {Texture[ImageData[pic]],
   Polygon[Tuples[Sort /@ Transpose[{ll, ur}]][[{1, 2, 4, 3}]], 
    VertexTextureCoordinates -> 
     Tuples[{ 
       {f Max[0, 1 - picrat/boxrat], 1 - (1-f) Max[0, 1- picrat/boxrat]}, 
       {f Max[0, 1 - boxrat/picrat], 1 - (1-f) Max[0, 1- boxrat/picrat]}}]
         [[{1, 2, 4, 3}]]]}]

I've added an extra argument f which indicates which indicates how much of the left or right of the image should be cropped. For example a setting of 0 would indicate that all cropping should be from the right side of the image (or the top depending on the aspect ration of the image). When f==0.5 equal parts are cropped from the left and right sides and when f==1 the image is only cropped on the left side (or bottom). 
Edit 2
It looks like Texture isn't playing nicely with Inset used in kguler's answer to your previous. To get the text and the image in the same picture you could do something like this instead
rec[ll_, ur_, pic_] := Module[{crop, boxrat},
  boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}];
  crop = ImageCrop[pic, Transpose[{ ImageDimensions[pic]}],
    AspectRatio -> boxrat];
  Inset[crop, Min /@ Transpose[{ll, ur}], {Left, Bottom}, 
   Abs[ur - ll]]]

Combined with kguler's answer you get something like
Graphics[{EdgeForm[{Thickness[0.005`], Black}],
   FaceForm[White], Rectangle[{0, 0}, {160, 90}],
   FaceForm[Darker[Gray]], Rectangle[{0, 0}, {80, 63}],

   (* code for picture *)
   {rec[{80, 0}, {160, 63}, pic],
    FaceForm[Opacity[0]],
    Rectangle[{80, 0}, {160, 63}]},

   (* code for text *)
   Inset[Pane[
     Style[txt1, 12, TextAlignment -> Left], {Scaled[1], 
      Scaled[0.75`]}, Alignment -> Center, 
     ImageSizeAction -> ""Scrollable""], {0, 8}, {Left, Bottom}, {78, 
     67}],

   Flatten[
    Transpose[{Flatten[(Table[
           RandomChoice[{GrayLevel[0.15`], c0[[#1]]}], {3}] &) /@ 
        Range[2, 4, 1]], 
      MapThread[
       Function[{Xs, Ys}, 
        Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}]], {Flatten[
         Table[Range[0, 32, 16], {3}]], 
        Flatten[(Table[#1, {3}] &) /@ Range[63, 81, 9]]}]}]],
   {Black, Thickness[0.005`], Line[{{0, 63}, {159, 63}}]}}, 
  PlotRange -> {{0, 160}, {0, 90}}, Method -> {""ShrinkWrap"" -> True}, 
  ImagePadding -> 2, ImageMargins -> 0, ImageSize -> 500]

which produces something like

"
performance tuning - Parallelize evaluation of function with memoization,"
The problem with SetSharedFunction is that it forces f to be evaluated on the main kernel: this means that if you simply do
SetSharedFunction[f]

then you will lose parallelization (a timing of ParallelTable[f[x], {x, 3}] will give about 9 seconds).
This property of SetSharedFunction is not clear from the documentation in my opinion.  I learned about it from this answer.  It is also not clear if the behaviour is the same in version 7 (can someone test? I tested my answer on version 8 only).
We can however store the memoized vales on the main kernel, while evaluating the expensive computations on the paralell kernels.  Here's one way to do it:
f[x_] :=
 With[{result = g[x]},
  If[result === Null,
   g[x] = (Pause[3]; N[Sin[x]]),
   result
  ]
 ]
    
SetSharedFunction[g]

Here I used the special property of shared functions that they return Null on the paralell kernels when they have no value for a given argument.
The first time we run this, we get a 6 s timing, as expected:
AbsoluteTiming@ParallelTable[f[x], {x, 3}]

(* ==> {6.0533462, {0.841471, 0.909297, 0.14112}} *)

The second time it will be very fast:
AbsoluteTiming@ParallelTable[f[x], {x, 3}]

(* ==> {0.0260015, {0.841471, 0.909297, 0.14112}} *)

However, as you noticed, evaluating f on the parallel kernels is a bit slow.  On the main kernel it's much faster.  This is due to the communication overhead: every time f is evaluated or changed on a subkernel, it needs to communicate with the main kernel.  The slowdown does not really matter if f is really expensive (like the 3 seconds in your toy example), but it can be significant if f is very fast to execute (comparable in time to the apparently ~10 ms communication overhead)
ParallelTable[AbsoluteTiming@f[x], {x, 3}]

(* ==> {{0.0100006, 0.841471}, {0.0110006, 0.909297}, {0.0110007,  0.14112}} *)

Table[AbsoluteTiming@f[x], {x, 3}]

(* ==> {{0., 0.841471}, {0., 0.909297}, {0., 0.14112}} *)


Finally a note about benchmarking:  in general, measuring very short times like the 10 ms here should be done with care.  On older versions of Windows, the timer resolution is only 15 ms.  On Windows 7, the resolution is much better.  These timings are from Windows 7.

Update:
Based on @Volker's @Leonid's suggestion in the comments, and @Volker's original solution, we can combine subkerel and main kernel caching like this:
f[x_] := With[{result = g[x]}, (f[x] = result) /; result =!= Null];
f[x_] := g[x] = f[x] = (Pause[3]; N[Sin[x]])


Packaged up solution
We can bundle all these ideas into a single memoization function (see the code at the end of the post).
Here is an example use:
Clear[f]
f[x_] := (Pause[3]; Sin[x])

AbsoluteTiming@ParallelTable[AbsoluteTiming@pm[f][Mod[x, 3]], {x, 15}]

(* ==>
{6.0683471, {{3.0181726, Sin[1]}, {0.0110007, Sin[2]}, 
             {3.0181726, 0}, {0., Sin[1]}, {3.0191727, Sin[2]}, 
             {3.0181726, 0}, {0.0110007, Sin[1]}, {0., Sin[2]}, 
             {0., 0}, {0., Sin[1]}, {0., Sin[2]}, 
             {0., 0}, {0., Sin[1]}, {0., Sin[2]}, {0., 0}}}
*)

The function simply needs to be called using pm[f][x] instead of f[x].  Memoized values are associated with f as UpValues, so I thought automatic distribution of definitions should take care of both synchronizing memoized values and clearing them when necessary.  Unfortunately this mechanism doesn't seem to be reliable (sometimes it works, sometimes it doesn't), so I provided a function clearParallelCache[f] that will clear all memoized values on all kernels.
Caching happens at two levels: on the main kernel level and on subkernels.  Computed or main-kernel-cached values are copied to the subkernels as soon as possible.  This is visible in the timings of the example above.  Sometimes retrieving cached values takes 10 ms, but eventually it becomes very fast.  Note that it might happen that the two kernels will each compute the same value (if they start computing it at the same time).  This can sometimes be avoided by using a different setting for the Method option of Parallelize (depending on the structure of the input data).
For simplicity, I restricted pm to only work with functions that take a single numerical argument (and return anything).  This is to avoid having to deal with more complex conditional definitions (especially cases when the function won't evaluate for certain argument types).  It could safely be changed to accept e.g. a vector or matrix of values instead.

The code
pm[f_Symbol][x_?NumericQ] :=
 With[{result = memo[f, x]},
  If[result === Null,
   With[{value = valueOnMain[f, x]},
    If[value === Null,
     f /: memo[f, x] = setValueOnMain[f, x, f[x]],
     f /: memo[f, x] = value]
    ],
   result]
  ]

memo[___] := Null
DistributeDefinitions[memo];

valueOnMain[f_, x_] := memo[f, x]

setValueOnMain[f_, x_, fx_] := f /: memo[f, x] = fx

SetSharedFunction[valueOnMain, setValueOnMain]

clearParallelCache[f_Symbol] := 
  (UpValues[f] = {}; ParallelEvaluate[UpValues[f] = {}];)

"
plotting - Why does ListPlot ignore some global options?,"
In version 7 it appears that ListPlot only uses global Options[] that are acceptable to Graphics (probably via FilterRules).  You can work around this manually with explicit declaration:
SetOptions[ListPlot, {PlotMarkers -> {""A""}, Filling -> Axis}];

ListPlot[Range[10], Options[ListPlot]]


If you want to make this fix automatic you can do this:
Unprotect[ListPlot];

ListPlot[args___] :=
  Block[{$lpOptsFix = True},
    ListPlot[args, Options[ListPlot]]
  ] /; ! TrueQ[$lpOptsFix]

"
numerics - How to fix errors in Gram-Schmidt process when using random vectors?,"
I'm not sure why you'd expect the resulting vectors to remain in the original swath because you're forcing the angle between the two resulting vectors to be 90 deg. Pairs of vectors with cross products far from the poles of the sphere will necessarily result in one of the vectors ""popping out"" of the swath.
I'd also like to point out that you don't need Gram-Schmidt to create an orthonormal basis for the two vectors.  Instead, you can just do the following: Given two vectors v1 and v2, define u1=v1 then construct u2=Normalize[v1 x v2]. Finally, u3 = u2 x u1.  Now u1 will be aligned with v1 and u3 will be in the plane defined by v1 and v2 but it will be orthogonal to u1 and in the general direction of v2. 
"
Pattern to match a non-empty list of non-empty lists,"
If I am understanding you:
x : {{__} ..}

See Repeated for more information and additional options.  Also see RepeatedNull while you're there.
Make sure you understand BlankSequence and Pattern as well.

Here is a breakdown of the expression above.  First let us view the FullForm which is as close to the way Mathematica sees it as possible:
FullForm[ x:{{__}..} ]


Pattern[x,
  List[
    Repeated[
      List[
        BlankSequence[]
      ]
    ]
  ]
]


This expanded form is useful to remove any ambiguity in Mathematica's parsing.
Therefore from the inside out we have (short form : long form : description):
__ : BlankSequence[] : one or more arguments with any head
{ } : List[ ] : inside the head List
.. : Repeated[ ] : one or more arguments matching the given pattern
{ } : List[ ] : inside the head List
x: : Pattern[x, ] : a unique expression that matches the given pattern, named x
Pay attention to this last point: naming the pattern changes the way it behaves, such that it represents a unique expression.  Consider this superficially similar pattern:
x : {{a__} ..}

This will only match e.g. {{1, 2}, {1, 2}, {1, 2}} but not {{1, 2}, {3}, {4, 5, 6}} because by naming the first sequence 1, 2 all other sequences must be identical.  Simply matching the pattern a__ independently is not enough.
"
interface - How can I use the Klingon alphabet symbols?,"
I found the solution.  Mathematica is set up to use the font KLIpIqaDmey.  The tip-off is in the UnicodeFontMapping.tr file referenced in the question.  The header reads:
@@resource UnicodeFontMapping
Mathematica: Times Automatic
Mathematica: (Times Courier) Automatic
Mathematica: (Mathematica1 Mathematica1Mono) Automatic
Mathematica: (Mathematica2 Mathematica2Mono) Automatic
Mathematica: (Mathematica3 Mathematica3Mono) Automatic
Mathematica: (Mathematica4 Mathematica4Mono) Automatic
Mathematica: (Mathematica5 Mathematica5Mono) Automatic
Mathematica: (Mathematica6 Mathematica6Mono) Automatic
Mathematica: (Mathematica7 Mathematica7Mono) Automatic
Mathematica: MathematicaInternal Automatic
Mathematica: Zapf_Dingbats Automatic
Mathematica: (DefaultKanjiFont DefaultMonoKanjiFont) Japanese
Mathematica: (DefaultKoreanFont DefaultMonoKoreanFont) Korean
Mathematica: (DefaultChineseSimplifiedFont DefaultMonoChineseSimplifiedFont) ChineseSimplified
Mathematica: (DefaultChineseTraditionalFont DefaultMonoChineseTraditionalFont) ChineseTraditional
Mathematica: KLIpIqaDmey Klingon



#  0  =  special: dynamically assigned
#  1  =  base font
#  2  =  Mathematica1: Greek letters and common operators
#  3  =  Mathematica2: Radicals, brackets, integrals, arrows
#  4  =  Mathematica3: Operators and shapes
#  5  =  Mathematica4: Arrows, vectors, over/under brackets, keys, icons
#  6  =  Mathematica5: the archaic alphabets, Script
#  7  =  Mathematica6: Gothic
#  8  =  Mathematica7: DoubleStruck
#  9  =  FE Internal
#  10  =  Zapf Dingbats
#  11  =  Kanji (if present)
#  12  =  Korean (if present)
#  13  =  Chinese Simplified (if present)
#  14  =  Chinese Traditional (if present)
#  15  =  Klingon (if present)

At first glance I overlooked the significance of the Mathematica: lines, but then I realized their relation to 0 - 15 below.
Image captured from Mathematica with the font installed:

"
java - Unit testing J/Link projects in Workbench,"
MUnit testing is surely supported on JLink projects (I used it in JLink projects which also contained Java classes,  without problems). In fact, MUnit is all about Mathematica, so you just follow the usual procedure. I actually never bothered to create configurations etc. 
I just took your code, created a J/Link project, and run the unit test file as Run As -> Mathematica test (position mouse on any place within a unit test file in the WorkBench editor, then right-click and choose Run-As). Everything was fine.

"
combinatorics - Permutations[Range[12]] produces an error instead of a list,"
Combinatorica` has the function NextPermutation which allows you to iterate over the permutations. There may be ways of generating a smaller subset if you have more information about what you are looking for.
"
Feed a Manipulate[] Output into a Graphics[],"
Just Set dist[[1]] to your output inside Manipulate. Putting additionally a Dynamic to your plots let's you see the change live.
(Edit) You can put your graphics of course inside the same Manipulate and change the graphics too. So after evaluating all your definitions from the first code-block, you could do something like
Manipulate[
 Column[{
   distToMean[[1]] = (Flatten@
       allTeamAverageStats[[Flatten@
          Position[
           Total[{v1, v2, v3, v4, v5, v6, v7, v8, v9, v10}/
                Total@{v1, v2, v3, v4, v5, v6, v7, v8, v9, 
                  v10} (allTeamAverageStats[[#]] - rosterRAMean)/
                rosterRASD] & /@ Range[792], 
           Max[Total[{v1, v2, v3, v4, v5, v6, v7, v8, v9, v10}/
                 Total@{v1, v2, v3, v4, v5, v6, v7, v8, v9, 
                   v10} (allTeamAverageStats[[#]] - rosterRAMean)/
                 rosterRASD] & /@ Range[792]]]]]) - rosterRAMean,
   Show[Function[attributes, 
      Graphics[{Blend[{{-Max[Abs[distToMean[[1]]]], Red}, {0, 
           LightRed}, {0, LightGreen}, {+Max[Abs[distToMean[[1]]]], 
           Green}}, distToMean[[1]][[attributes]]], 
        Rectangle[{If[distToMean[[1]][[attributes]] < 0, 
           distToMean[[1]][[attributes]]*10, 0], 
          attributes - 1}, {If[distToMean[[1]][[attributes]] < 0, 0, 
           distToMean[[1]][[attributes]]*10], attributes}], 
        PlotRange -> {{-6, 6}, {0, 10}}}, AspectRatio -> 16/9, 
       Epilog -> {Black, Thickness[thickness], 
         Line[{{0, 0}, {0, 11}}]}]] /@ Range[10], Frame -> False, 
    FrameTicks -> False]
   }, Center
  ],

 {v1, Range[.1, 1, .1]}, {v2, Range[.1, 1, .1]}, {v3, 
  Range[.1, 1, .1]}, {v4, Range[.1, 1, .1]}, {v5, 
  Range[.1, 1, .1]}, {v6, Range[.1, 1, .1]}, {v7, 
  Range[.1, 1, .1]}, {v8, Range[.1, 1, .1]}, {v9, 
  Range[.1, 1, .1]}, {v10, Range[.1, 1, .1]}, {thickness, 0.01, 0.1}, 
 ControlType -> Manipulator]

Note: This is far from being good programming style but for a test it should be fine.
"
list manipulation - How to Delete Elements from List1 appearing in List2?,"
Use
DeleteCases[list1, Alternatives @@ list2]

In new versions (M8.0+), DeleteCases is optimized on patterns not involving blanks, so this will be fast also for large lists. For earlier versions, this will work:
Replace[list1, Dispatch[Thread[list2 -> Sequence[]]],{1}]

being 2-3 times slower, but still very fast.
"
list manipulation - Check in a series if there exists adjacent values with less than a certain number of missing values,"
Suppose $p_k$ with $1\leq k\leq N_0$ is the position of the $k$-th zero in the data list $\{a_1,\ldots,a_N\}$, then each sublist which contains $\leq M$ zeros will be a sublist of one of the sublists
$$
\{ a_{p_k+1},\ldots, a_{p_{k+M+2}-1}\}, \qquad 1\leq k \leq N_{0}-M-2
$$ 
or $\{ 1,\ldots, a_{p_{M+1}-1}\}$ or $\{a_{p_{N_0-M-1}+1},\ldots, a_N\}$, so in Mathematica speak it is sufficient to construct the lists 
Take[lst {zlst[[k]]+1 ;; zlst[[k+maxZeros+2]]-1}]

for which zlst[[k+maxZeros+2]]-zlst[[k]]-1 >= minLen where zlst is the list of positions of the zeros in lst padded with 0 on the left and Length[lst]+1 on the right. This could be implemented as
findLsts2[lst_, minLen_Integer?Positive, maxZeros_, 
  n : (_Integer | All) : All] :=
 Module[{zeroLst, rangeLst},
  zeroLst = Flatten[Position[lst, (0 | 0. | Null)]];
  If[Length[zeroLst] <= maxZeros,
   lst,
   rangeLst = Transpose[{Prepend[Drop[zeroLst + 1, -maxZeros], 1],
      Append[Drop[zeroLst - 1, maxZeros], Length[lst]]}];
   {Take[lst, #], #} & /@ 
    Select[rangeLst, (#[[2]] - #[[1]] + 1) >= minLen &, 
     n /. All -> Sequence[]]
   ]
  ]

This would return the sublists of maximum length which contain at most maxZeros zeros together with the indices of these sublists in the data list lst. Example
findLsts2[{1, 0, 2, 0, 3, 0, 0, 0, 2, 4, 5, 6, 7, 0}, 4, 2] // MatrixForm


Edit
This updated version of findLsts2 randomly selects n sublists from all possible sublists of length len with at most maxZeros zeros from lst.
findLsts3[lst_, len_Integer?Positive, maxZeros_, 
  n : (_Integer | All) : All] :=
 Module[{zeroLst, rangeLst, startLst},
  zeroLst = Flatten[Position[lst, (0 | 0. | Null)]];
  If[Length[zeroLst] <= maxZeros,
   startLst = Range[Length[lst] - len + 1],
   rangeLst = Transpose[{Prepend[Drop[zeroLst + 1, -maxZeros], 1],
      Append[Drop[zeroLst - len, maxZeros], Length[lst] - len + 1]}];
   startLst = Flatten[Range @@@ (List @@ (Interval @@ 
          Select[rangeLst, (#[[2]] - #[[1]]) >= 0 &])), 1]];
  {lst[[# ;; # + len - 1]], #} & /@ Sort@RandomSample[startLst, n]
  ]

For the previous example we get
findLsts2[{1, 0, 2, 0, 3, 0, 0, 0, 2, 4, 5, 6, 7, 0}, 4, 2] // MatrixForm


Edit 2
The $k$-th pair in rangelst in findLsts3 corresponds to the values $\{j_1, j_2\}$ such that 
$$p_{k-1}+1 = j_1
\qquad\text{and}\qquad
j_2+l-1 = p_{k+M+1}-1$$
where $l$ is the length of the sublist you want to extract and $p_k$ is as above. Provided that $j_{1}\leq j_{2}$ we then have that for all $j_{1}\leq j\leq j_{2}$ the sublist $\{a_j,\ldots,a_{j+l-1}\}$ is a subset of $\{ a_{p_{k-1}+1},\ldots, a_{p_{k+M+1}-1}\}$. What the Select statement in startLst does is to filter out the pairs in rangelst for which $j_1\leq j_2$ doesn't hold. startLst is then the Union of the ranges Range[j1, j2] for all remaining pairs.
"
plotting - ListPlot with each point a different color and a legend bar,"
In this case I would use Point for plotting the points. For example
n = 5000;
pos = RandomVariate[NormalDistribution[0, 2], {n, 2}];
altitude = Norm /@ pos;
colorf = Blend[{{Min[altitude], Yellow}, {Max[altitude], Red}}, #] &

pl = Graphics[MapThread[{colorf[#1], Point[#2]} &, {altitude, pos}], 
  Axes -> True, AspectRatio -> 1]

As for plotting legends, that's a reoccurring issue in Mathematica. There is a package called  PlotLegends` which you could try but it is not very user friendly and the legends it produces are quite ugly IMHO. I find that it's often faster to just create a legend by hand. For example, this is a function I use for creating legends with contour plots:
plotLegend[{min_, max_}, n_, col_] := 
 Graphics[MapIndexed[{{col[#1], 
      Rectangle[{0, #2[[1]] - 1}, {1, #2[[1]]}]}, {Black, 
      Text[NumberForm[N@#1, {4, 2}], {4, #2[[1]] - .5}, {1, 0}]}} &, 
   Rescale[Range[n], {1, n}, {min, max}]],
  Frame -> True, FrameTicks -> None, PlotRangePadding -> .5]

Here, n is the number of subdivisions and col is the colour function. You could combine the legend with the original plot using Grid, e.g.
leg = plotLegend[Through[{Min, Max}[altitude]], 20, colorf];
Grid[{{Show[pl, ImageSize -> {Automatic, 300}], 
  Show[leg, ImageSize -> {Automatic, 250}]}}]


"
evaluation - General::ivar is not a valid variable when plotting,"
The problem lies in g[x_] := D[f[x], x]; remember that what SetDelayed (that is, :=) does is to replace stuff on the right corresponding to patterns on the left before evaluating. Thus, when one does something like g[2] (and something like this happens within Plot[]), you are in fact evaluating D[f[2], 2], and since one cannot differentiate with respect to a constant ;), you get the General::ivar error message.
If you use Set instead (that is, g[x_] = D[f[x], x]), f[x] is differentiated first before the result of D[] is assigned to g[x_]. Since what's on the right of g[x_] is now an actual function, Plot[] no longer has a reason to complain.
"
graphs and networks - How can I remove B -> A from a list if A -> B is in the list?,"
This seems to do what you want:
rules = {""A"" -> ""B"", ""B"" -> ""A"", ""C"" -> ""D""};

Rule @@@ Union[Composition[Sort, List] @@@ rules]
(* {""A"" -> ""B"", ""C"" -> ""D""} *)

"
notebooks - How to set default magnification for all windows,"
If the reason you ask is because the fonts are much too small, then there is another approach that is arguably more correct than changing Magnification, and that is to specify a better screen resolution.  By default it is 72ppi, but screens haven't been like that for years (mine is about 100ppi).
SetOptions[$FrontEndSession, 
 FontProperties -> {""ScreenResolution"" -> 96}
]

If you like the setting and what to make it persist between sessions, replace $FrontEndSession with $FrontEnd.
"
programming - Can Mathematica be regarded as a software prototyping environment?,"
I think that Mathematica is a great prototyping environment, and has a bright future as a system for both prototyping and implementation of complete components of other systems, from back-ends to front-ends. In my opinion, we are now witnessing the process of it being transferred from pure scientific tool to a general software engineering tool / language.
So, I think that moving to another language can be often done pretty late in the development cycle (disclaimer: I have not personally built large systems involving Mathematica as a part - although I worked on large systems written in Java  before -  so what I write here is mostly an educated guess based on my separate experiences in Mathematica and other languages). The great benefit of Mathematica is that it is a very high-level development environment which can serve as a gluing medium for development of hybrid systems, where different parts are written in different languages. For example, I found it a great testing / development medium for Java applications. This is generally not yet quite apparent since we still lack some tools to boost productivity and overcome cross-lnaguage barriers. But I am more than positive that such tools are going to emerge pretty soon. When you develop the system, what matters is how flexible is your architecture, how testable are your modules, and how fast are the development iterations. A high-level environment like Mathematica is a great win for all these.
That said, I would not currently use Mathematica as a central run-time of the application, simply because the kernel crashes every now and then. I would make that another runtime (e.g. Java), which calls Mathematica and handles possible errors, exceptions, crashes and the like (actually, WebMathematica is just that - Mathematica managed by the Java runtime and bundled as a web application for some Java container like Apache Tomcat). Mathematica can however serve as both an excellent back-end and an excellent prototyping environment, so once again, my feeling is that one can benefit a lot from developing even large industrial systems in or with Mathematica. There are actually companies which do just that, and are quite successful.
As to when to use C etc - my advice is: as late as you can. Many problems for which Mathematica is perceived as slow can be solved quite efficiently with the knowledge of how to write efficient Mathematica code. May be even more importantly, it is rare that you know the exact method you will use for a given problem, all in advance. Once you switch to C, you will have to deal with lots of low - level details, which will  increase development time and chances for errors, plus they will distract you from the essence of the problem you are solving. Even if you switch to C at the end, Mathematica can save you a lot of time in prototyping your solution, and minimize the amount of low-level work you have to do.
Scaling to large code bases:
This is a problem in pretty much every language. There are probably many factors which determine how well a given language scales. Part of this is also probably not just about language itself, but about existing development tools. For example, Java scales reasonably well, but no one in their right mind would use it for large projects without smart IDE-s. So, I'd set out a few important factors (a list is incomplete, of course):

Type system. Strongly typed languages can use the compiler to help find errors, and this will be particularly powerful for those with type inference (ML family languages for example).
Means for composition. These include classes / interfaces / inheritance for OO, and higher-order functions / closures / possibly macros for FP. I am biased towards FP here.
Means for information hiding, and separation between interface and implementation. This is extremely important, and this is where OO shines, IMO. You can get it in FP, but have to be more disciplined.
Package / module system, and namespaces - this is a very important tool for large-scale encapsulation / information-hiding
Development tools (IDE-s, debuggers, profilers) - can make a huge difference.
Standards of coding and code exchange. When they exist, it makes for much easier code reuse, assuming that you don't write everything yourself.

There are probably other important factors I missed. The question is how does Mathematica fare regarding these factors. I'd say that potentially, Mathematica can fare quite well. I think right now it suffers the most from a lack of certain development tools (a really good / useful debugger, for one) and coding / code exchange standards. Also, the programming practices which allow to scale to larger systems, while certainly possible in Mathematica, are not developed / not in widespread use yet. For example, closures and higher-order functions are very useful for that,  but it's not something every second Mathematica programmer is using. Also, while Mathematica allows to write macros (functions which manipulate code), its rather complex evaluation control mechanisms make them hard to write. And macros are the extremley powerful scaling tool - in LISP they allow for easy creation of DSL-s because essentially they extend the compiler in the direction you want. Another problematic thing is that Mathematica is often too general, and this generality gets in the way in forms of evaluation and performance surprises. Some intermediate language layer would be a big help here.
To summarize, my opinion is this; Mathematica can be used for large projects, even at present (it actually is used for at least two huge ones: it is written largely in itself, and WolframAlpha is another example. From my personal experience, a few of my projects were several thousand lines long), but your code won't scale automatically for you, and you need to be a pretty good Mathematica programmer to be able to manage the complexity of large projects. In this regard, many modern languages provide more automatic tools for scaling the code base, and more tecniques are well-known and in widespread use. I also think, that the situation with Mathematica will improve in the future, we will have better development tools, more programming practices will be shared, etc. So, yes, you definitely can use it for large projects, but right now it won't be as easy as say in Java, Python, or some other well-known languages. Much of it is not at all inherent in Mathematica per se, but reflects its young age as a general-purpose programming language used for larger projects outside academia. My two cents.
"
front end - Customizing syntax highlighting for private cell styles,"
As a part of a larger sets of development tools which I am working on currently, I have developed a general syntax highlighter generator which does just that (not yet with styles though, this is coming). I wanted to put in on GitHub and do a bit more polishing / development, but since you asked the question, here goes.
Features

From a simple lexical specification, a whole package is generated, which provides code highlighting capabilities for a given language. Once you generate the package, you (supposedly) start happily using it, and don't depend on the master package (the generator), unless you want to generate another highlighter package. For those who are familiar with js Google prettify, this is similar in spirit, but less developed as of now.
The lexical analyzer is generated automatically from your specifications, but you can also override it with a custom one.
You can customize it in many ways, including colors for keywords etc.
There are several optimizations which can be switched on and off, to control the responsiveness of the highlighter
keywords etc are highlighted as you type
Bracket and paren-matching  / highlighting is supported.
Cells can be evaluatable.

For the impatient, the package and a notebook with an example for C language can be downloaded here and here. I also made a gist where one can look at them as well. The notebook can be regarded as a brief manual to the package.
Installation steps

Place a CodeHighlighterGenerator.m package into any directory where Mathematica can find it (e.g. FileNameJoin[{$UserBaseDirectory,""Applications""}])

Open the CodeHighlighterGenerator.nb notebook and follow the discussion there.


Future plans
I plan to place the project to GitHub properly in a few days. There are several directions in which I plan to extend the package, it is a work in progress. All comments & suggestions are more than welcome!

Here are a few screen-shots:


"
Default position and size of front-end windows (in Windows 7),"
( Think out of the box? ) - Start Mathematica with a Windows macro ( any recorder will do ). First record the start of MMa and the resizing / moving of the menu bar and so on, then use the recording to start MMa.
"
front end - How do I extract the contents of a selected cell as plain text?,"
Assuming nb is your notebook object, then this will do what you want without touching the clipboard:
First[FrontEndExecute[
  FrontEnd`ExportPacket[NotebookSelection[nb], ""InputText""]]]

Some notes about this solution:

It preserves evaluation semantics precisely, regardless of typesetting.
It does not dirty the clipboard
If you prefer to get the appearance as opposed to the evaluation semantics, you can use ""PlainText"" (for example, grids copy as tabular looking things as opposed to as lists)
I tested this in 8.0.1, but it might not work in earlier versions

This FE packet only supports a limited number of formats. The public formats include ""GIF"", ""PPM"", ""EnhancedMetafile"" (Windows), ""PICT"" (Mac) , ""PostScript"", ""RTF"", ""PDF"", and ""SVG"".
I should say that the first argument of ExportPacket can also be any Notebook, Cell, or Box expression. Also, a NotebookObject, in which case it'd convert the entire notebook rather than just the selection. 
When the selection does not contain a full cell it is enough to work around by using the results of NotebookRead. E.g.:
First[FrontEndExecute[ FrontEnd`ExportPacket[BoxData @ NotebookRead[nb], ""PPM""]]]

"
How to neatly get the sum of symmetric elements in a list?,"
Playing with patterns:
{a, b, c, d, e} //. {h_, b___, t : Except[_List]} :> {h + t, {b}} // Flatten

This can be written more efficiently, without the full rescanning inherent in //., using recursion:
f1 = # /. {h_, b___, t_} :> Prepend[f1 @ {b}, h + t] &;

Also as a DownValues definition which is a bit more efficient still:
f2[{h_, b___, t_}] := Prepend[f2 @ {b}, h + t]
f2[x_] := x

f2 @ {a, b, c, d, e}
f2 @ {a, b, c, d, e, f}


{a + e, b + d, c}
{a + f, b + e, c + d}



Disregarding elegance, this is the fastest method I could come up with for packed arrays:
Module[{ln = Length@#, x},
  x  = #[[ ;; ⌈ln/2`⌉ ]];
  x += #[[ -1 ;; ⌊ln/2`⌋ + 1 ;; -1 ]];
  If[OddQ @ ln, x[[-1]] /= 2 ];
  x
] &

I imagine it can be bested by compile-to-C in v8, but I don't have that.
"
graphics - Background image in a polygon / CountryData,"
This example is from the documentation for Texture in Mathematica version 8:
With[{vc = 
 Transpose[
  Rescale /@ Transpose[First[CountryData[#, ""Coordinates""]]]]}, 
Show[CountryData[#, ""Shape""], 
 ImageSize -> {{100}, {100}}] /. {RGBColor[__] :> 
  Texture[ImageReflect[Image[CountryData[#, ""Flag""]], 
    Top -> Right]], 
 Polygon[a_] :> 
  Polygon[First[a], VertexTextureCoordinates -> vc]}] & /@ 
CountryData[""SouthAmerica""]

but I don't know whether it does what you need. Still, it looks pretty.

"
front end - Custom Mathematica Shortcut: Copy as $\LaTeX$,"
MenuEvaluator->Automatic uses the default kernel to evaluate the expression in the menu. MenuEvaluator->None is the default, which means that the front end ""evaluates"" the expression (which generally means the expression is composed only of FE tokens and packets). One could also use MenuEvaluator->""kernelname"" to point to an explicit kernel.
For doing the kind of menu editing you wish to do, you have to rewrite the menus wholesale. You can begin by reading the menu from the layout, tweaking it how you want, and then sending it to the FE in ResetMenusPacket. Here's an example:
Begin[""System`""];
menu = Get[
   FileNameJoin[{$InstallationDirectory, ""SystemFiles"", ""FrontEnd"", 
     ""TextResources"", ""Windows"", ""MenuSetup.tr""}]];
End[];
menu = menu /. {MenuItem[""Plain &Text"", ___] -> 
     MenuItem[""Plain &Text"", FrontEnd`CopySpecial[""PlainText""]], 
    MenuItem[""&LaTeX"", ___] -> 
     MenuItem[""&LaTeX"", 
      KernelExecute[ToExpression[""FrontEnd`CopyAsTeX[]""]], 
      MenuKey[""C"", Modifiers -> {""Control"", ""Shift""}], 
      MenuEvaluator -> Automatic]};
FrontEndExecute[FrontEnd`ResetMenusPacket[menu]]

Some notes about this code:

A number of symbols in the menu expression aren't in the System` context, but need to be for this to work. That's the reason for the Begin/Endcalls.
To make this code work on Linux, replace ""Windows"" with ""X""
To make this code work on Mac, replace ""Windows"" with ""Macintosh"", ""Control"" with ""Command"", and remove the ampersands.
This code only work on v7 and later (when MenuItem was introduced)

Finally, and this is really important, you need to be playing with this stuff in a fresh session of Mathematica, and frequently either saving your work or copying to the clipboard. If you make any mistakes, you can lose all of your menus, including the ability to evaluate, save, or copy.  You might be able to recover by using the contextual menu, but probably safer to just quit and restart.
Assuming you haven't really hosed your menus, you can reset to the default by evaluating:
FrontEndExecute[FrontEnd`ResetMenusPacket[{Automatic}]]

Another option is to simply make your own MenuSetup.tr which is in $UserBaseDirectory or $BaseDirectory, in the same location it is now in $InstallationDirectory. But I don't generally advise this because, if you do, all copies of Mathematica will find it, including past and future versions, which could cause you hopeless confusion.
"
list manipulation - Selecting a sublist based on Length,"
If you only want one item from the resulting list, you can use the two-argument form of Ordering instead of Sort to be a bit more efficient:
test[[Ordering[test, -1]]]


biglist = 
  Table[RandomInteger[10, RandomInteger[100]], {10^5}];

Timing[biglist[[Ordering[biglist, -1]]]]

(*
==> {0.006476, {{10, 10, 10, 3, 4, 7, 4, 3, 9, 8, 8, 1, 2, 1, 5, 
   10, 10, 10, 9, 4, 6, 6, 9, 1, 2, 10, 8, 3, 0, 9, 1, 2, 5, 1, 1, 2, 
   7, 8, 9, 10, 8, 4, 8, 4, 7, 9, 3, 4, 5, 1, 6, 6, 4, 5, 8, 6, 3, 2, 
   6, 4, 9, 9, 9, 7, 1, 10, 4, 2, 10, 8, 0, 8, 1, 0, 9, 10, 7, 4, 5, 
   3, 6, 6, 6, 4, 2, 3, 1, 4, 9, 6, 5, 1, 8, 10, 0, 1, 3, 5, 10, 4}}}
*)

Timing[Last@Sort@biglist]

(*
==> {0.170369, {10, 10, 10, 3, 4, 7, 4, 3, 9, 8, 8, 1, 2, 1, 5, 
  10, 10, 10, 9, 4, 6, 6, 9, 1, 2, 10, 8, 3, 0, 9, 1, 2, 5, 1, 1, 2, 
  7, 8, 9, 10, 8, 4, 8, 4, 7, 9, 3, 4, 5, 1, 6, 6, 4, 5, 8, 6, 3, 2, 
  6, 4, 9, 9, 9, 7, 1, 10, 4, 2, 10, 8, 0, 8, 1, 0, 9, 10, 7, 4, 5, 3,
   6, 6, 6, 4, 2, 3, 1, 4, 9, 6, 5, 1, 8, 10, 0, 1, 3, 5, 10, 4}}
*)

"
dynamic - How can I set the speed of manipulate play button?,"
AnimationRate is at least one way to do this, and it can be applied on a per-control basis:
Manipulate[x, {x, 0, 10, AnimationRate -> 1/10, Appearance -> ""Open""}]

Manipulate[x, {x, 0, 10, AnimationRate -> 10, Appearance -> ""Open""}]

"
Most Efficient Way to Calculate the Product of All Items in a List?,"
The function you're looking for is Times. Use it as Times@@list, or keeping in line with your functions,
listProduct[x_List] := Times @@ x

"
front end - How do I view initialization (or other invisible) cells in a notebook?,"
The initialization cells are not necessarily invisible.
You can convert any cell to an initialization cell using the relevant menu item:

To find such cells in your colleague's notebook, look for brackets that look like this (this is a magnified version):

The difference from a normal input cell is the little vertical spur coming off the diagonal. I think of this as being an ""i"" for initialization.
If the cell really is invisible, it means that it does not have the property ""Open"" as shown in the menu above. But there should be a small bracket visible nonetheless.
If the cell brackets are invisible for all cells, you might need to change something in the Options Inspector (under Cell Options -> Display Options -> CellBracket Options).
"
plotting - How do I change the Font in BarChart Legend?,"
Actually you can do it without using Map[] as Placed[] takes a third optional argument for cases like this:
BarChart[{1, 2, 3}, ChartStyle -> ""Pastel"", 
 ChartLegends -> 
  Placed[{""John"", ""Mary"", ""Bob""}, Bottom, Style[#, FontFamily -> ""Courier""] &]]

"
front end - How to make a parallel auto-generated .m package from Initialization cells?,"
This may be set from the Option Inspector (Format->Option Inspector) from this option:

Automatic automatically creates a package.
(to be clear, you need to select Global Preferences for this to apply to all your notebooks).
"
dynamic - How to create interrelated sliders?,"
This?
{Slider[Dynamic[x], {0, 10}], 
 Slider[Dynamic[2 x, Set[x, #/2] &], {0, 20}]}


The documentation explains, under More Information, that ""Dynamic[expr,f] makes interactive operations not change expr except by virtue of the evaluation of f[val,expr]. "". Otherwise, Mathematica attempts to assign a value to 2x.
"
plotting - Why is ContourPlot not displaying this curve?,"
This has to do with the HoldAll attribute of ContourPlot. Try it with Evaluate inserted, like this:
ContourPlot[
   SecondDegreeCurve[RandomReal[{5}, 6], x, y] // Evaluate,
   {x, -2, 2}, {y, -2, 2}
]

you get ouput like this:

or

"
undocumented - Items known by CurrentValue,"
Other answers have already suggested ways of querying options. There's no way of systematically generating a list of all string values, but it's not too difficult to put together a list of all of the values which are used by Wolfram Research in Mathematica itself. If you look in the various files in these locations:

$InstallationDirectory/SystemFiles/FrontEnd/StyleSheets
$InstallationDirectory/SystemFiles/FrontEnd/TextResources
$InstallationDirectory/SystemFiles/FrontEnd/SystemResources

for instances of CurrentValue, you'll get a pretty good list of what is in active use by Wolfram Research developers at any given time. Most of the undocumented string values are created specifically to fulfill a purpose required by one of these files, so that's a pretty good list.
There may be a few others used directly by the kernel but not anywhere in these files, but if so, not many. Any undocumented string values which are not in use by the product somewhere are likely to be untested as well, so if you're tempted to complain that this list isn't absolutely complete, be careful what you wish for.
"
front end - Mouse gestures or keyboard shortcuts for navigating forward/backward in the documentation center,"
According to the help page ref/menuitem/DocumentationCenter, the keyboard shortcuts to navigate one page backward or forward in Mathematica for OS X are ⌘ [ and ⌘ ]
(or alternatively ⌥ ⌘ ← and ⌥ ⌘ → ), so you could use a third-party app like for example MagicPrefs to bind those keys to a trackpad gesture.
For the sake of completeness, the corresponding shortcuts on Windows & Linux systems are Alt ← and Alt → respectively.
"
front end - How do I prevent auto loading of blank notebook at startup?,"
In Windows, you set InitialUntitledNotebook to False in the Global Options > PrivateFrontEndOptions section of the Option Inspector to prevent a Untitled-1 notebook opening at start-up. You can also supress/show the welcome splash screen.The combination ""ShowAtStartup""->""New Document"" and ""InitialUntitledNotebook""->False"" gives just the MMA toolbar at startup.

"
Function that takes another function inside,"
The reason you're getting that error is because you're using O, which is a built-in function to represent a term of a particular order. This has the attribute Protected, which prevents you from assigning any definition to it.
Attributes@O
Out[1]= {Protected, ReadProtected}

However, to answer the question in your title, here are a few simple ways in which you can use a function inside another function:
1: Simply call the function!
f[x_] := x^2
g[x_] := Sin[f[x]]


2: Use a Module
g[x_] := Module[{f},
  f[y_] := y^2; Sin[f[x]]
  ]


3: Pass the symbol for the function
f[x_] := x^2
g[func_Symbol, x_] := Sin[func[x]]


"
front end - How to change default notebook background color?,"
You can SetOptions for the current notebook as:
SetOptions[EvaluationNotebook[], Background -> LightGreen]

to change the background to whatever colour you like. You can also supply an RGB colour as:
SetOptions[EvaluationNotebook[], Background -> RGBColor[0.9, 0.7, 0.7]]


Other possibilities for the first argument of SetOptions are 

$FrontEnd which will change the background for all notebooks and last across restarting Mathematica.
$FrontEndSession which will change the background for all notebooks but won't be saved if you restart Mathematica.

"
syntax - Single dot textual form,"
Use OverDot
ref/OverDot in the documentation (but one of those cases where you need to know what you want in order to be able to enter it)
OverDot[Q]


"
string manipulation - How to overload System`StringJoin to automatically use ToString on arguments?,"
Short answer: because StringJoin has this little-known  behavior normally:
StringJoin[""abc"", {""def""}, ""ghi""]

(* 
  ==> ""abcdefghi""
*)

while after you overloaded it, the result is 
""abc{def}ghi""

Long answer
You start by using 
Trace[Append[test, 1], TraceInternal -> True]

from the Trace output, you can locate the following code:
StringJoin[(If[ListQ[#1], StringJoin[""\[NoBreak]"", #1, ""\[NoBreak]""],  #1] & ) /@ 
   StringSplit[
       ""Nonatomic expression expected at position `1` in `2`."", 
        System`Dump`del : ""`"" ~~ DigitCharacter ... ~~ ""`"" :> 
           {System`Dump`del}]
]

returning
""Nonatomic expression expected at position \[NoBreak]{`}\[NoBreak] in \[NoBreak]{`}\[NoBreak].""

Analyzing this code leads to the short answer above.
Conclusions
Don't overload built-ins globally. Who knows what else you will break? There are other options to do what you want. For example, you can use Internal`InheritedBlock to create local environments, as explained e.g. here.
"
plotting - Removing unwanted appearance of underlying mesh,"
You are combining the images in the form 
Show[Graphics[simplePrimitives], complicatedRegionPlot]

The options in the resulting figure are inherited from the first term, namely Graphics[simplePrimitives].  This does not include the ""TransparentPolygonMesh"" -> True generated by RegionPlot.  You see the mesh as a result.  If you combine things as follows:
Show[complicatedRegionPlot, Graphics[simplePrimitives]]

Then the resulting image will have the standard RegionPlot options and you'll no longer see the mesh.
I think the preferred way to do this, however, is to use Epilog, as in J.M.'s response.
"
export - Reading from a text file and store the results back into it,"
I'm new to Mathematica too, and finding some of it quite difficult, etc. However, the Import and Export commands seem to be pretty useful and simple for simple tasks.
To import a text file of numbers, one to a line, you basically do this:
aList = Import[""test,dat"", ""Table""]

where the Table option reads the file into a list of lists, where each line is a list. So you might end up with something like this:
{{42}, {142857}, {6}, {12}}

This is then easy to operate on. Mathematica has functions for nearly everything, and lists are about the best thing to put your data in, so you can just write your own wrapper function:
numberToBinary[n_] :=  IntegerString[n, 2, 24];

Finally, you can export the numbers and convert them all in one go, by mapping this function over the list you created earlier:
Export[""test1.dat"", numberToBinary[#] &  /@ aList, ""Table""]

and the file might well contain this:
000000000000000000101010
000000100010111000001001
000000000000000000000110
000000000000000000001100

It's true that things are rarely as simple as this, but it's a start... (And performance for 100,000 numbers might be important, I didn't check.)
"
graphics - Plotting several functions,"
Mesh will do the trick:
Plot3D[Sin[x^2 - y], {x, -2, 2}, {y, -3, 3}, MeshFunctions -> {#2 &}, 
 PlotStyle -> None, Mesh -> 30]


Placing the “wires” on integer values is also easy – see example below. For the range {y, -7, 5} there are 13 integers so you need to ask for 11 wires Mesh -> 11 (in red) because 2 are taken by boundary (blue). With such settings ""wires"" fall exactly on integer values.
Plot3D[Sin[x^2 - y/2], {x, -2, 2}, {y, -7, 5}, MeshFunctions -> {#2 &}, 
PlotStyle -> None, Mesh -> 11, MeshStyle -> {Thick, Red}, 
BoundaryStyle -> {Thick, Blue}]


"
export - Is Compress[] compatible between different Mathematica versions?,"
Compress[expr] will take an expression, convert it to a string, using some form, which would allows to recover the expression later on (most likely InputForm is used) and compress the string. 
If the resulting compressed expression is uncompressed in an earlier version of Mathematica, the result is going to be an expression, which has no code associated with it, so it will, most likely, just remain unevaluated, if executed. 
To reiterate, yes, Compress/Uncompress is cross version compatible, yet the result obtained on uncompressing, may not evaluate in earlier versions of Mathematica
"
performance tuning - How are MemberQ and FreeQ so fast?,"
What you observed seems to be an instance of the general behavior of the pattern-matcher when used with what I call ""syntactic patterns"" - patterns which only reflect the rigid structure of an expression, like e.g. _f. The speed-up with respect to the scanning is because the main evaluation loop is avoided - for FreeQ and MemberQ, the scannng is done all inside the pattern-matcher, which is lower-level compared to the main evaluator. 
In this answer, and also here, there are some examples of this behavior, and further discussion. I think that a good rule of thumb is that you gain an order and a half of magnitude speed-up by clever use of syntactic patterns in place of top-level scanning code (pushing all work into the pattern-matcher), and you gain 2-3 orders of magnitude speed-up if you manage to recast the problem as a vectorized numerical problem on packed arrays.
"
output formatting - Show path with arrows in a matrix,"
Mathematica's Graph related functionality is pretty great. You can easily style vertexes, edges and their labels, apply interesting functions. For small increase in code sophistication you gain quite a bit of advantage. Your data:
poli = {{1, 1}, {2, 1}, {3, 1}, {4, 1}, {5, 1}, {5, 2}, {4, 2}, {3, 
    2}, {2, 2}, {1, 2}, {1, 3}, {2, 3}, {3, 3}, {4, 3}, {5, 3}, {5, 
    4}, {4, 4}, {4, 5}, {5, 5}};

A simple solution with still quite wide styling options I think would be this
arrow[coord_, e_] := Style[Arrow[coord], Red, Thickness[.01], Arrowheads[0.06]]

pg = PathGraph[Range[19], VertexCoordinates -> poli, 
EdgeShapeFunction -> arrow, ImageSize -> 300, PlotRangePadding -> .2];

gg = GridGraph[{5, 5}, EdgeStyle -> Dashed, VertexLabels -> ""Name"", 
ImageSize -> 300, PlotRangePadding -> .2];

Overlay[{gg, pg}]


The rest is some more elaborate exploratory fun with graphs.
We'll use GridGraph again but instead of PathGraph we'll use GraphHighlight option. GridGraph has its own 1D node index system (see indexes above), not 2D indexes as in matrix. So we have to remap the indexes.
vertex = (5 (#[[1]] - 1) + #[[2]]) & /@ poli;

edge = ( #[[1]] \[UndirectedEdge] #[[2]]) & /@ Partition[vertex, 2, 1];

To add correct labels:
lab = MapThread[Rule[#1, ToString@#2] &, {vertex, poli}];

GridGraph[{5, 5}, EdgeStyle -> Dashed, GraphHighlight -> edge, 
 VertexLabels -> lab, PlotRangePadding -> .3]


If you want arrows there are many ways around, especially depending on how you choose the path. Quick cooking gives something like this:
arr[coord_, e_] := 
 Style[Arrow[
   If[Positive[(e)[[2]] - (e)[[1]]], Identity[coord], 
    Reverse[coord]]], Red, Thickness[.01], Arrowheads[0.06]]

GridGraph[{5, 5}, EdgeStyle -> Dashed, GraphHighlight -> edge, 
 VertexLabels -> lab, PlotRangePadding -> .5, 
 EdgeShapeFunction -> (# -> arr & /@ edge)]


"
front end - What is this character: [esc][comma][esc]?,"
It's what's called an \[InvisibleComma]. It's useful for those times where you don't want a comma to appear, but you still need it, e.g. ""a[[p\[InvisibleComma]q]]"" for a matrix entry.

The third entry uses an \[InvisibleComma] in between the matrix indices.
"
Is it possible to prerender animation in Wolfram Mathematica?,"
Here is an example of how to create an animation from DensitPlot results. I have chosen a simple Gaussian function to plot, but its center depends on a parameter t. Now I create a table of plots for many different values of t, and then I take several different steps to create various kinds of movies from it. The parameter t and its step size is going to be the main variable that you have to decide on depending on your application, in order to make a smooth animation. 
Note on speed
To save time, you should execute the following commands in separate cells, and only choose the export or display method that you need. Otherwise the evaluation will probably stretch your patience.
exampleFrames =
  Table[
   DensityPlot[
    Evaluate[
     Exp[-((x - Cos[t])^2 + (y - Sin[t])^2)/.025]
     ],
    {x, -1.5, 1.5}, {y, -1.5, 1.5},
    ColorFunction -> GrayLevel,
    PlotRange -> All,
    PlotPoints -> 30,
    Frame -> None,
    PlotRangePadding -> None
    ],
   {t, Pi/50, 2 Pi, Pi/50}
   ];

rasterizedFrames = Map[Image, exampleFrames];

Export[""movie.mov"", exampleFrames];

Export[""movie.avi"", exampleFrames];

ListAnimate[rasterizedFrames]

What I did above is to first rasterize the individual frames before making the ListAnimate. 
Update: thanks to Alexey Popkov for reminding me that Image can be used instead of Rasterize to perform the rasterization more efficiently.
Working with rasterizedFrames speeds up the ListAnimate process. This is especially noticeable if your movie has 3D graphics as frames. Rasterization allows you in principle to customize the quality of the video frames. For the export as .mov and .avi, though, it seems to be faster to not use the pre-rasterized frames and instead start from the original exampleFrames. 
If you want the movie in Flash format, do this:
Export[""movie.swf"", rasterizedFrames];

In the Flash file, rasterization leads to a smaller file size but the export takes longer for this format.
Edit
Thanks to @halirutan for pointing out that Rasterize gets much faster when replacing the above instruction by:
rasterizedFrames = Map[Rasterize[#,""Image""]&, exampleFrames];

Update In Mathematica version 9, though, I see no speed difference with our without the ""Image"" argument.
ListAnimate is the easiest way to create animations in Mathematica, but it can sometimes by so horribly slow that the notebook becomes unresponsive. This may happen if you have many frames with complicated plots. 
That's why I also included some Export commands that generate movies in standard formats that can be read by other applications (media players). The file movie.mov should be a Quicktime movie, and movie.swf is a Flash animation. 
Finally, depending on your operating system, it may in fact be best to create the movie in an external application. In that case, you can do the following:
Export[""movie001.png"", exampleFrames, ""VideoFrames""];

This will create all the frames as individual files numbered movie001.png, movie002.png, etc. These can subsequently assembled in a movie editor. 
If you want to go that route, that's a different topic that I have discussed some more on the following page:
Mathematica image sequence export
"
programming - Threading a compiled function over multiple arguments of different lengths,"
I think your problem is equivalent to trying to get something like this
l := Power[2, 2]

f /@ l

return f[2]^f[2] instead of 4
You can control argument evaluation in MMA, for it to be either evaluated or not evaluated, but not half evaluated. If you wanted that you would have to either redesign your variables, or use things like replacement rules of OwnValues/DownValuess
In your case, you are expecting ppost1 to evaluate to fc, but fc not try to evaluate its arguments (until Thread had a chance to act)
If someone understood better than I did what your goal is, perhaps he can help you do it in some way
EDIT
Perhaps what you're looking for then can be achieved by masking the compiled function with a function that knows how to stay symbolically unevaluated
With[{cmp = 
   Compile[{{arg, _Real, 1}, {c1, _Real, 
      1}, {c2, _Real}, {c3, _Real}}, c3*arg + c2*c1]},
 fc[arg : {___Real}, c1 : {___Real}, c2_Real, c3_Real] :=
  cmp[arg, c1, c2, c3]
 ]

"
combinatorics - Probability problem -- Rube Goldberg solution?,"
Don't even know how I came across this old question, but, interesting and seeing as Mr. W asked it, it piqued my interest.
The answer by David is a good use of simulation, and his ""back-o-the-envelope"" approximation using the probability functions of Mathematica over a discrete uniform is also kind of neat.
The other two answers, however are flat-out wrong: Both admit hand sets that are impossible, e.g., looking at the first entry of allPossibilities from Rojo's answer shows an entry of {{1, 1}, {1, 1}, {1, 1}}. I don't know about you, but ""a standard 52 card deck"" with six aces would get you shot in the old west...
In addition, counting winning hands via tuples/etc. and getting a ratio of winning to total hands is not correct (although by happenstance, it gets pretty close): take, e.g., the hand sets {{4, 4}, {3, 3}, {3, 3}} vs  {{6, 5}, {4, 3}, {2, 1}}. In both, the ""first"" hand wins. But the second set is over 14X more likely to occur. So any tuple-counting/filtering approach must calculate the probabilities of each winning set and total them...
So, why not solve it directly and exactly?
(* bulid lists of possible ways to take from ranks of deck in two draws, pairs and singlets *)

two = Permutations[Prepend[ConstantArray[0, 12], 2]];
one = Permutations[Join[{1, 1}, ConstantArray[0, 11]]];
tt = Tr /@ (two*Range@13);
oo = Tr /@ (Range@13*# & /@ one);
ways = Sort@Join[Transpose[{oo, one}], Transpose[{tt, two}]];

(* helper functions - get p of a draw sum given current deck configuration,
   and p of draw sums less than given sum *)
pe[n_, db_] := With[{c = Select[ways, #[[1]] == n &]},
  Module[{z = #, r}, 
     If[FreeQ[r = db - z, _?Negative], {PDF[
        MultivariateHypergeometricDistribution[2, db], z], r}, {0, r}]] & /@ c[[All, 2]]]

ple[n_, db_] := With[{c = Select[ways, #[[1]] < n &]},
  Module[{z = #, r}, 
     If[FreeQ[r = db - z, _?Negative], {PDF[
        MultivariateHypergeometricDistribution[2, db], z], r}, {0, r}]] & /@ c[[All, 2]]]


(* get probabilities of paths for given sum and remaining 2 players both having less *)
Monitor[res = Table[{n,
     peres = pe[n, ConstantArray[4, 13]];
     secondres = Map[ple[n, #] &, peres[[All, 2]]];
     step3 = Transpose[{secondres[[All, All, 1]]*peres[[All, 1]], secondres[[All, All, 2]]}];
     step4 = Map[With[{c = #}, Map[ple[n, #] &, c]] &, step3[[All, 2]]];
     Total[Total /@ Map[Total, step3[[All, 1]]*step4[[All, All, All, 1]], {2}]]
     }, {n, 2, 26}], n];

(* final probability of a player winning *)

res[[All, 2]] // Total
% // N

(*
4710593/15268890
0.308509
*)

And some graphical results (a priori probability of holding some sum, probability of sum given you won, and probability of winning given you are holding some sum):

"
java - Why does JLink lock unopened jar-files in Windows,"
I also encountered this problem. Not an authoritative answer, but here is one blind guess to what is happening. JLink has its own classloader, JLinkClassLoader.java, which calls another one, JLinkClassLoaderHelper.java. The latter is a sub-class of URLClassLoader.java. Both are used in the class JLinkSystemClassLoader.java. The second part of this story is that there is an unresolved bug in the JVM related to URLClassLoader.java class, which locks jars, on Windows only. It has been discussed on SO here. The problem seems to be Windows-specific. What I don't know is at what time this happens, and why this affects jars that weren't even used. If this is at all a right guess, this can probably be traced by using a debugger.
"
front end - Syntax highlighting for your own functions,"
What you want is SyntaxInformation. With this, you can use every highlighting which already exists for things like Table, Solve, etc. for your own functions. You can specify the pattern of the arguments. With this you get the typical red commas if you use too many parameters. Or you can highlight locally used variables inside the function-arguments:
SetAttributes[SequenceVars, HoldAll]
SyntaxInformation[SequenceVars] = {""ArgumentsPattern"" -> {_, _}, 
   ""LocalVariables"" -> {""Solve"", {1, 1}}};
SequenceVars[vars_List, expr_] := 
 Block[vars, vars = Range@Length@vars; expr]

It looks like this in the front-end:

The usage of the ""LocalVariables"" highlighting is as follows. First, you choose the general type of highlighting. For instance ""Solve"" provides simple x or lists like {a,b} while ""Plot"" provides highlighting for the first element in e.g. {a,1,2}.
You can use the following settings as templates
{""Table"", ""Solve"", ""Integrate"", ""Limit"", ""Plot"", ""Manipulate""}

Additionally, you need to specify at which places of your function call the local variable specifications can appear. Say you want a function where in the first argument is some expression and then can follow arbitrary many lists of local variables. The definition for that would look like
SyntaxInformation[f] = {""ArgumentPattern"" -> {_, __},
  ""LocalVariables"" -> {""Solve"", {2, Infinity}}}

This looks then like



and should make clear how ""LocalVariables"" has to be used.
Update
Since this function seems to be of unexpected interest, I should add one more important thing: SyntaxInformation can highlight wrong options. If you use OptionsPattern in your ""ArgumentsPattern"" option, all non-existent options will be highlighted in red
Options[f] = {a -> 1, b -> True};
f[x_] = Identity;
SyntaxInformation[f] = {""ArgumentsPattern"" -> {_, OptionsPattern[]}};

Now using f with right/wrong options gives

"
mathlink or wstp - Suppress Mathematica Kernel taskbar tab when using .NETLink,"
The command line option to call the kernel with to suppress the taskbar button is -noicon.  You need to pass this flag to MathKernel.exe when launching it.
Here's a demonstration from within Mathematica:
kernel = LinkLaunch[First[$CommandLine] <> "" -mathlink -noicon""]

This will launch a new kernel and connect to it.  On Windows, the new kernel will not show on the taskbar.
I do not remember where I learned about this command line flag.  It took me quite a few minutes to be able to recall it at all.
"
databaselink - Stealth daylight saving shift in SQL data,"
DatabaseLink uses Java Database Connectivity (JDBC) internally.  The behaviour you describe is a known, long-standing, and annoying bug in JDBC.  The problem is that Java inappropriately attempts to apply daylight savings time adjustments to dates in the database -- even though such adjustments are likely to have taken place already.  This bug occurs even if the server and client machines are configured to be in the same time zone.  There is no easy workaround to this problem as long as the class java.sql.Date (et al) is in the loop.  Non-trivial workarounds involve things such as trying to configure the entire database stack to use UTC.  Also, some JDBC drivers provide alternate data-type mapping for date/time types.
However, the simplest workaround is to change your SQL statements to return dates as strings.  This side-steps all of the JDBC date arithmetic nightmare.  In most dialects of SQL, this means changing:
SELECT ... myDate ...

to something like
SELECT ... CAST(myDate AS VARCHAR) ...

Unfortunately, the exact syntax is not standardized so you will have to look it up for your dialect of SQL.
In SQL Server, for example, we have a couple of options:
SELECT CAST(GETDATE() AS VARCHAR)

returns a localized string like ""Feb  7 2012  8:56PM"".  Mathematica has no trouble interpreting this:
""Feb  7 2012  8:56PM"" // AbsoluteTime // DateString
(* Tue 7 Feb 2012 20:56:00 *)

However, we might want to take out the vagaries of localization by converting dates to a fixed format instead.  Again, using SQL Server as an example:
SELECT CONVERT(VARCHAR, GETDATE(), 121)

returns an ISO-like date string: ""2012-02-07 20:56:32.733"".  Again, you will have to adjust the syntax to suit your specific dialect of SQL.
"
front end - How to set focus of a dialog window?,"
After István Zachar's points, I was investigating Input definitions to learn more. It seams that 2 years later WRI changed approach from SelectionMove based to more automatic BoxReferenceFind.
usage
So what we only have to do is to set BoxID option for fields of interest and find those references when we want, with:
MathLink`CallFrontEnd[
 FrontEnd`BoxReferenceFind[ 
   FE`BoxReference[
     _NotebookObject, {{ID_String}}, 
     FE`BoxOffset -> {FE`BoxChild[1]},   
     FE`SearchStart -> ""StartFromBeginning""
   ]
 ]
]

This is a way more flexible approach, e.g. you can easily put InputField somewhere else and you don't have to change SelectionMove steps to get there.
example
DynamicModule[{name = """", surname = """", setFocus}
  , Column[{
        InputField[Dynamic@name, String, BoxID -> ""name""]
      , InputField[Dynamic@surname, String, BoxID -> ""surname""]
      , Button[""setFocusToFirst"", setFocus[EvaluationNotebook[], ""name""]]
    }]
  , SynchronousInitialization -> False
  , Initialization :> (
        setFocus[nb_, ID_] :=  MathLink`CallFrontEnd[
            FrontEnd`BoxReferenceFind[ FE`BoxReference[
                nb
              , {{ID}}
              , FE`BoxOffset -> {FE`BoxChild[1]}
              , FE`SearchStart -> ""StartFromBeginning""
            ]]
        ]
      ; setFocus[EvaluationNotebook[], ""surname""]
    )
]

"
graphics - How do you draw the plane on which two vectors lie?,"
SeedRandom[3];
{v1, v2} = RandomReal[{-2, 2}, {2, 3}];
n = Cross[v1, v2];
Show[{
  ContourPlot3D[n.{x, y, z} == 0, {x, -2, 2}, {y, -2, 2}, {z, -2, 2},
    ContourStyle -> Opacity[0.5], Mesh -> False],
  Graphics3D[{Arrow[{{0, 0, 0}, v1}], Arrow[{{0, 0, 0}, v2}]}]
}]


"
databaselink - What is the quickest way to convert a lot of SQLDateTime[] objects to DateLists,"
The fastest way should be to use Part I think, particularly as your list gets larger.
data={{SQLDateTime[{2005, 10, 3}], 188.88}, {SQLDateTime[{2005, 10, 4}], 
184.53}, {SQLDateTime[{2005, 10, 5}], 
176.5}, {SQLDateTime[{2005, 10, 6}], 
172.}, {SQLDateTime[{2005, 10, 7}] . . . etc}

For example
data[[All, 1]] = data[[All, 1, 1]]

leaves you with
data

{{{2005, 10, 3}, 188.88}, {{2005, 10, 4},184.53}, {{2005, 10, 5}, 
    176.5}, {{2005, 10, 6},172.}, {{2005, 10, 7} . . . etc}

This is another way but probably slower:
data /. SQLDateTime -> Identity

Timings
Using kgulers data generator with a list of 10000 elements:
ClearSystemCache[];
Timing[tmp1 = data /. SQLDateTime[x_] :> DateList[x];]
{0.469574, Null}

ClearSystemCache[];
Timing[tmp2 = data /. SQLDateTime[x_] :> x;]
{0.024052, Null}

ClearSystemCache[];
Timing[tmp3 = Map[{#[[1]][[1]], #[[2]]} &, data];]
{0.043545, Null}

ClearSystemCache[];
Timing[tmp4 = data /. SQLDateTime -> Identity;]
{0.060517, Null}

ClearSystemCache[];
Timing[data[[All, 1]] = data[[All, 1, 1]];]
{0.006412, Null}

tmp1 == tmp2 == tmp3 == tmp4 == data
True

Part is the fastest.
Edit
I'm not sure why you would actually do SQLDateTime[x_] :> DateList[x], the ""x"" is already a date list. SQLDateTime[x_]->x is sufficient. ...but since Part is faster I guess the discussion is redundant.
"
graphics - How do I draw a triangle given the lengths of the sides?,"

I'm not sure how to draw a triangle if all I care about is the length of the sides. (I'm happy to place one of the vertices at the origin and place one of the sides on the nonnegative side of the $x$-axis, but that doesn't really matter.) Is there a straightforward way?

Given a triangle with side lengths $p \leq q \leq r$ (assuming the lengths satisfy the triangle inequality, of course), with hypotenuse on the positive $x$-axis, and the origin as one endpoint, you can solve a system of equations to get the third point, apart from $(0,0)$ and $(r,0)$:
FullSimplify[{x, y} /. 
             Last[Solve[{x^2 + y^2 == p^2, (x - r)^2 + y^2 == q^2}, {x, y}]]]
{(p^2 - q^2 + r^2)/(2 r),
 Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + r)]/(2 r)}

and thus, either of 
Graphics[Line[{{0, 0}, {r, 0}, {(p^2 - q^2 + r^2)/(2 r),
         Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + r)]/(2 r)}, {0, 0}}]]

or
Graphics[Polygon[{{0, 0}, {r, 0}, {(p^2 - q^2 + r^2)/(2 r),
         Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + r)]/(2 r)}}]]

does the job.
Verify the triangle:
FullSimplify[
 Norm /@ Differences[{{0, 0}, {r, 0}, {(p^2 - q^2 + r^2)/(2 r), 
     Sqrt[-(p - q - r) (p + q - r) (p - q + r) (p + q + 
          r)]/(2 r)}, {0, 0}}], 0 <= p <= q <= r && p + q >= r]
{r, q, p}



This raises the additional question, ""how do I draw a triangle in Mathematica, given three angles?"". (Say I want to it to reside somewhere in the unit circle.)

The law of sines saves your bacon here (the ratio of a side length and the sine of the opposite angle gives the diameter of the triangle's circumcircle). Skipping details, here's how to inscribe a triangle with specified angles into the unit circle:
parts = IntegerPartitions[180, {3}];

(* generate corresponding sides from randomly chosen angles *)
angles = parts[[RandomInteger[{1, Length[parts]}]]];
{r, q, p} = 2 Sin[angles Degree];

Graphics[{Line[{{1, 0}, {1 - p^2/2, p Sqrt[1 - p^2/4]},
                {1 - q^2/2, -q Sqrt[1 - q^2/4]}, {1, 0}}], 
          Circle[{0, 0}, 1]}]

You can use the next two snippets to verify that the triangle generated fits the specifications:
(* check side lengths *)
Norm /@ RotateLeft[Differences[
     N[{{1, 0}, {1 - p^2/2, p Sqrt[1 - p^2/4]},
        {1 - q^2/2, -q Sqrt[1 - q^2/4]}, {1, 0}}]]] - {r, q, p} // Chop

(* check angles *)
(Apply[VectorAngle, Map[Function[pt, pt - First[#]], Rest[#]]]/Degree) & /@ 
   NestList[RotateLeft, N[{{1, 0}, {1 - p^2/2, p Sqrt[1 - p^2/4]},
       {1 - q^2/2, -q Sqrt[1 - q^2/4]}}], 2] - angles // Chop

Both snippets should return {0, 0, 0} if all goes well.
"
evaluation - Implementing a safe ValueQ that does not evaluate its argument,"
Preamble
This has been discussed before, and this problem was also identified and partially addressed in the same question. I will use a slightly simpler implementation which also covers UpValues. It is probably not complete either, but it covers many common cases of interest. 
Implementation
Here is the code:
ClearAll[symbolicHead];
SetAttributes[symbolicHead, HoldAllComplete];
symbolicHead[f_Symbol[___]] := f;
symbolicHead[f_[___]] := symbolicHead[f];
symbolicHead[f_] := Head[Unevaluated[f]];

ClearAll[valueQ];
SetAttributes[valueQ, HoldAllComplete];
valueQ[a_Symbol] /; OwnValues[a] =!= {} :=
    With[{result = (# =!= (# /. OwnValues[a])) &[HoldComplete[a]]},
       result /; result];

valueQ[a : f_Symbol[___]] /; DownValues[f] =!= {} :=
    With[{result = (# =!= (# /. DownValues[f])) &@HoldComplete[a]},
       result /; result];

valueQ[a_] :=
    With[{sub = SubValues[Evaluate[symbolicHead[a]]]},
      With[{result  = (# =!= (# /. sub)) &[HoldComplete[a]]},
          result /; result] /; sub =!= {}
    ];

valueQ[a_] :=
   With[{upsyms  =
       Flatten@Cases[Unevaluated[a], s_Symbol :> UpValues[s], 1, Heads -> True]},
          With[{result  = (# =!= (# /. upsyms)) &[HoldComplete[a]]},
             result /; result] /; upsyms =!= {}
   ];

valueQ[_] := False;

Symbolic heads are further discussed in this answer. The order of definitions is important, and roughly corresponds to the order of steps applying those global rules,  in the main evaluation sequence.
Examples
a := Print[""*""];
b[1] := Print[""*""];
c[1][4] := Print[""*""];
d /: f[x_Integer, d, y_Integer] := Print[""*""];

valueQ /@ Unevaluated[{a, b[1], c[1][4], f[1, d, 2]}]

(*
  ==> {True, True, True, True}
*)

Limitations
I did not include the NValues (this can be done, but the question is whether we really want to do that). This seems to pretty much exhaust the set of things we can do without really evaluating an expression in question. In certain cases, the results will be different from ValueQ, for example:
{valueQ[N[Pi]],ValueQ[N[Pi]]}

(*
  ==> {False,True}
*)

Summary
The code above was not meant to be absolutely complete, and probably can not be, since not everything is exposed to the top-level / end user. But it is hoped that it covers many cases of interest, and can be further extended to cover some that it misses currently. Note that, since internal global rules are not available at the top-level, valueQ is mostly limited to user-defined or top-level functions and variables. If one wants to include system symbols with internal rules, I don't see other ways than allowing the expression to evaluate. 
This may also explain (to some extent), why built-in ValueQ was written the way it was - to also cover the system symbols and be general. On a deeper level, this seems to reflect that the separation between internal and top-level rules is rather artificial and sometimes flies in the face of the core language semantics, particularly when one wants to write some general functions related to introspection, such as ValueQ.
"
graphics - How to fix the orientation and scaling of Graphics3D?,"
Have you tried setting PlotRange->10 ?
"
symbols - How to unload automatically loaded packages?,"
If you want to revert the entire system to some state, then CleanSlate` may be the best option. If you want to unload a few specific packages though, you can use my package PackageManipulations`, available here. It has a function PackageRemove, which does exactly that. It has an accompanying notebook with explanations. Some additional notes on it are in this and this answers. If you want to just clear all the package and sub/package symbols but not Remove them, you can use functions PackageClear and PackageClearComplete from the same package (a disclaimer : the package may contain bugs, although I used it successfully many times)
Note that removing all symbols in the package (and subsequently removing its context) - which is what PackageRemove does and what you seem to ask for - may be unsafe if other packages use some of those symbols, since those symbols in the definitions of symbols in dependent packages would turn to Removed[symbs] and won't be usable any more, in a sutble way. To check that there are no such dependencies, you can use another package I wrote, PackageSymbolsDependencies`, available from the same place (it also has a notebook with explanations and examples).
"
evaluation - How to determine how much of a table is generated?,"
Given your current situation, there is another option that might help if you have set ""Enable notebook history tracking"" in Preferences > Advanced:

Then, you go to Cell > Notebook history and navigate to your currently evaluating cell and look at the time stamp when you last edited it. Chances are that you edited it just prior to evaluating (note that if you open an old notebook and execute the cell right away, this might not work, because the last edit timestamp will not be what you want it to be).

Now find the current time from your system clock. Assuming you know how long it takes for one evaluation of SuperSlowExpression, you can now simply do:
$$\mathrm{approx\ progress=\frac{current\ time - last\ edited\ time}{time\ for\ one\ evaluation}}$$
This will give you a rough estimate of the progress — enough to make a decision whether to wait a bit longer or to give up. 
Remember, this should be a last ditch option! There are many ifs and buts here, but seeing as all the other options require an iterator and you don't have one (and your Table is running), it's worth trying...
"
performance tuning - How can I speed up image importing?,"
The cause of the slow speed is the presence of a modified System` function: StringJoin. As this modified StringJoin operates at suboptimal speed (see Leonid's answer and comments here), there is a performance drop of 1-2 magnitudes. So I did learn the hard way why is it a bad idea to modify built-in symbols.
"
Is there a syntax for single-line comments for notebooks?,"
There is no way to comment out a single line.
Mathematica doesn't really respect lines, it pushes working at the expression level when possible (not at the source text level).  Converting cells between different forms (StandardForm, InputForm) will even shuffle around newlines.  Copying and pasting code does the same.
As @acl has mentioned, you can select a piece of code and comment it out with Alt-/.  The shortcut Ctrl-. makes it easy to select subparts of expressions.  These commands are found in the Edit menu (mentioning in case the keyboard shortcut is different on other platforms).
I am not advocating this behaviour, just explaining the current situation.
"
linear algebra - Obtaining the square-root of a general positive definite matrix,"
Are all of the Fs real? If so, try this:
Assuming[{F11, F12, F13, F21, F22, F24, F33, F35, F44, F45, F53, F54, 
   F55} \[Element] Reals, MatrixPower[Ftemp, 1/2]]

You'll get an answer, but it'll be ugly...
You can use Position to test for zero elements like this (in this case I'm applying it to your original matrix to show that it works):
Position[Ftemp,x_/;PossibleZeroQ[x]]
{{1, 4}, {1, 5}, {2, 3}, {2, 4}, {2, 5}, {3, 2}, {3, 4}, {4, 1}, {4, 
  2}, {4, 3}, {5, 1}, {5, 2}}

So for the matrix you're interested in:
FtempInv = Assuming[{F11, F12, F13, F21, F22, F24, F33, F35, F44, F45, F53, 
     F54, F55} \[Element] Reals, MatrixPower[Ftemp, 1/2]];
Position[FtempInv,x_/;PossibleZeroQ[x]]

Unfortunately, when I do that MMA spends a great deal of time thinking and I have yet to see an answer. There may be better test to use here than PossibleZeroQ; if so, I'm sure someone else will suggest one.
It turns out that PossibleZeroQ is Listable, so you can you just do
PossibleZeroQ[FtempInv]

But that doesn't solve the speed problem...
I let PossibleZeroQ[FtempInv] run for a while. Here's what I got:
{{False, False, False, False, False}, {False, False, False, False, 
  False}, {False, False, False, False, False}, {False, False, False, 
  False, False}, {False, False, False, False, False}}
"
graphics - Export a Row or Column as an image,"
I'd do this, probably
Export[
 ""~/Desktop/out.png"",
 GraphicsGrid[
  {
   {Graphics@Disk[], Graphics@Rectangle[]}, {Graphics@Rectangle[], 
    Graphics@Disk[]}
   },
  ImageSize -> 800
  ]
 ]

"
graphics - Take off {} using Position [],"
You can add a parameter to Position so it returns only one result and apply First or Partas needed
subIDs = {""AK6"", ""CF11"", ""CL4"", ""FC21"", ""MK5""};

subColors = {LightOrange, LightBlue, LightYellow, LightGreen, LightRed}

Graphics[{subColors[[Position[subIDs, #, 3, 1][[1, 1]]]], 
    Rectangle[]}] & /@ subIDs

Furthermore, you could also use Extract that's more suited to Position's output
subIDs = {""AK6"", ""CF11"", ""CL4"", ""FC21"", ""MK5""};

subColors = {LightOrange, LightBlue, LightYellow, LightGreen, LightRed}

Graphics[{First@Extract[subColors, Position[subIDs, #, 3, 1]], 
    Rectangle[]}] & /@ subIDs

"
"numerics - How to apply restrictions to the ""integrated"" variable, when using NDSolve?","
You could do something like this which is inspired by the bouncing ball example in the tutorial on the ""EventLocator"" Method: 
g[x_] := Floor[x]

h[x0_, x1_] := Function[{t}, Evaluate@Module[{f},
    Reap[NestWhile[
       Module[{sol, xend},
         sol = First@NDSolve[{f'[x] == 1/2 + g[x] - f[x], 
           f[#] == g[# + .0001]}, f, {x, #, x1},
         Method -> {""EventLocator"", ""Event"" -> (f[x] <= g[x])}];
           xend = sol[[1, 2, 1, 1, -1]];
           Sow[{f[t] /. sol, # < t < xend}];
         xend] &, 
       x0, (# < x1) &],
    _, Piecewise[#2] &][[2, 1]]
]]

The basic idea is to run NDSolve until f[x] drops below some critical function g[x], calculate a new initial value for f, continue the calculation starting from the position where NDSolve stopped until f[x] drops below g[x] again, etc. until a final time x1 is reached. The solution for this example looks like
sol = h[0, 10];
Plot[{sol[x], g[x]}, {x, 0, 10}]


"
interruption - How to abort on any message generated?,"
I found a robust solution described in this MathGroup message by Maxim Rytin:
messageHandler = If[Last[#], Abort[]] &

Internal`AddHandler[""Message"", messageHandler]

This will abort the computation whenever a message would be printed.  
It can be turned off using
Internal`RemoveHandler[""Message"", messageHandler]

Alternatively this can be temporarily applied to a piece of code like this:
Internal`HandlerBlock[
 {""Message"", messageHandler},
 (* ... code here ... *)
]

The currently set message handlers can be retrieved using
Internal`Handlers[""Message""]

(Internal`Handlers[] will return all existing handlers)
Whenever a message is generated, Hold[message, printed] is passed to all ""Message"" handler functions where message is the message text and printed is True is the message would be printed, False otherwise.
The debugging palette appears to use the same mechanism to break on messages.

To make it work with parallel evaluations, one can simply register the same handler on all kernels using ParallelEvaluate.
"
graphics - Apply 2 Styles within Text[],"
You could use Row to build up the text to be shown:
aboveBox[info_, colors_] := 
 Graphics[{colors, EdgeForm[Thick], Rectangle[{0, 0}, {26, 3}], 
   Text[Row[{Style[""subject"", 12, Bold, Black, 
       TextAlignment -> Center], 
      Style[info, 18, Bold, Red, TextAlignment -> Center]}], {26, 3}/
     2]}, ImageSize -> 300]

aboveBox[""AK6"", LightBlue]


"
graphics - Recovering data points from an image,"
I started with the image you provide and called it img. This solution isn't perfect but it might serve as a starting point.
Get some known points:
I right clicked the image and selected ""Get Coordinates"".  I then clicked as closely as possible to the origin, and the points {0,1.3} and {10.,.82}.  On Windows hold Ctrl+C to copy those points.  And then Ctrl+V to paste them into the notebook...
{o, y, x} = {{36.5173`, 206.72`}, {17.5824`, 17.3711`}, {391.209`, 54.9028`}};

Find a transformation that will return the proper points:
Here I use FindGeometricTransform and feed it the known values for the selected points along with their image coordinates. This produces a TransformationFunction to use later.
trans = FindGeometricTransform[
            {{0, .82}, {0, 1.3}, {10, .82}}, 
             {o,      y,        x}
         ][[2]];

Obtain and process the image data:
Here I round the RGB color values in the ImageData so that the blue curve is coded as {0,0,1}. This will allow me to extract the curve.
data = Round[ImageData[img], 1];

col = DeleteDuplicates[Flatten[Round[ImageData[img], 1], 1]];

Graphics[{RGBColor[#], Disk[]}, ImageSize -> Tiny] & /@ col


The nice blue color I'm wanting to extract is the third color in the list. Now I binarize the image. I convert non-blue pixels to black and the blue to white.
binImage = Image@Replace[data, {col[[3]] -> 1, _ :> 0}, {2}]


But this has some spurious points I'd like to remove so I only have the curve remaining. I'll use a GaussianFilter to create a binary mask that will allow me to filter those points out. This should give me the curve I want.
curve = ImageApply[{0, 0, 0} &, binImage, 
  Masking -> ColorNegate[Binarize[GaussianFilter[binImage, 5]]]]


That's much cleaner! Now to extract the locations of the white pixels while maintaining the proper orientation.
curvLoc = (Reverse /@ 
    Position[ImageData[curve, DataReversed -> True], {1., 1., 1.}]);

Apply the transformation before to the curve points and show it with the original plot before distortion. I called this plot...
Show[ListPlot[trans@curvLoc, PlotRange -> All], plot]


Its not perfect, but it should be a start.
EDIT: I realized that the coordinates of the origin were actually {0,.82} rather than {0,.8}. With this realization we get an even better approximation. Note that I've also employed an interpolating function. Using various smoothing techniques on the function values prior to interpolating should further improve things.
pts = Sort[trans@curvLoc];

g = Interpolation[pts, InterpolationOrder -> 1]

Show[Plot[g[x], {x, .05, 10}, PlotStyle->Red], plot]


"
cudalink - Can't use CUDA shared memory,"
This Mathematica 8 documentation should answer your question.
"
front nd - Txt in columns - Mathmatica Stack Exchang,"
Check MakeBilateralCells.m in the directory 
$InstallationDirectory\Mathematica\8 .0\AddOns\Applications\AuthorTools
Examples:
This package has been around since Version 4. 
Haven't checked/test all features, but the basic functions seems to work with Version 8.0.4. 
Some examples:
 Needs[""AuthorTools`""];
 PasteBilateralTemplate[EvaluationNotebook[]]

pastes a template that you can edit:

Open another notebook (Untitled-5 on the left in the screenshot) and evaluate an expression (say Plot something). 
In your input notebook (Untitled-4 in my example), evaluate
 Notebooks[]

to get the list of open notebooks:

Your screen now looks like:

Select the first cell group in the target notebook. Go back to the input notebook and evaluate the folowing:
 MakeBilateral[NotebookSelection[Notebooks[][[2]]]]

The fist cell group in the target notebook now becomes:


"
functions - Can someone explain this snippet: (#[#] &)[#[#][#] &],"
Going out on a limb here, but the exhibited expression looks like a brave but flawed attempt to implement the Y-combinator extremely concisely.
The Y-combinator is a technical trick used to implement recursion in the lambda calculus.  Here is an implementation that stoops to using some symbols:
Y[f_] := #[#]&[Function[n, f[#[#]][n]]&]

... and here is an example of its use to calculate factorials recursively:
fac[r_] := If[# < 2, 1, # * r[# - 1]]&

Y[fac][10]


3628800

Of course, in Mathematica there is no need to engage in such gymnastics since explicit recursion is supported directly.  But it is a nice brain-teaser: can Y be expressed using no symbols?  (Ideally using nothing other than special input form #, the postfix operator &, the matchfix operator [...] and parentheses -- just like the original expression.)
The Obscurity Continues
Since we are exploring obscure corners of Mathematica function syntax, here is another version of the Y-combinator that uses the rarely seen \[Function], an infix operator for function definition (keyboard shortcut: ESCfnESC):
Y = f ↦ (g ↦ g[g])[h ↦ n ↦ f[h[h]][n]]

(* but copy this instead to get the correct Mathematica character:
ClearAll[Y]
Y = f \[Function] (g \[Function] g[g])[h \[Function] n \[Function] f[h[h]][n]]
*)

"
differential equations - Solution Curves and Order of Evaluation Question,"
When you do solns = Table[y = Sin[x] + i, {i, -5, 5}], you are setting y=Sin[x]+i at each iteration; the last one is y=Sin[x]+5, so that is what y is. 
If you instead do solns = Table[Sin[x] + i, {i, -5, 5}] and then ContourPlot[y == solns, {x, -5, 5}, {y, -5, 5},  FrameLabel -> Automatic]  then you get y as a label, because now no value has been assigned to y.
Regarding it being an unintended consequence, y=expr explicitly sets y to expr; so if you do not intend this, then simply do not put y there. And as for this not being indicated, it is not indicated for the same reasons something like x=12 would not be; it just returns the value being assigned to x.
That is, what is effectively happening with something like Table[f[i],{i,1,10}] is that a loop is set up (with i localized, effectively with Block); at each iteration, f[i] is evaluated, and whatever it returns is appended to a list. In the end, the list is returned. Thus, if evaluating f[i] has side effects (such as assigning a value to y), you do not see that.
So in this case, you can think of Table[f[i], {i, 1, 10}] as equivalent to 
Module[{
  lst = {}},
 Do[
  AppendTo[lst, f[i]], {i, 1, 10}
  ];
 lst
 ]

"
dynamic - Checking from a preemptive evaluation whether a main evaluation is ongoing,"
If you control the launch of the main evaluation process, then a very simple way is to wrap your code in a dynamic environment (Block), which would set some flag:
mainEvaluationOngoingQ[] := TrueQ@mainEvaluationQ

Block[{mainEvaluationQ = True}, Do[i^2, {i, 1, 10^8}]]

You can automate this by creating an environment:
SetAttributes[withMainEvaluation, HoldAll];
withMainEvaluation[code_] :=
    Block[{mainEvaluationQ = True}, code]

You can further automate this with $Pre, if needed: $Pre = withMainEvaluation.
"
export - Exporting graphics to PDF,"
My preferred method to export graphics to pdf is to do something like
Export[""figure.pdf"", plot, ""AllowRasterization"" -> True, 
    ImageSize -> 360, ImageResolution -> 600]

This uses vectors for simple graphics, but produces a high resolution rasterized image if the plot becomes too complicated.
"
parallelization - Monitor doesn't work with ParallelTable,"
One way is to set a shared variable that would be assigned to an iterator variable, and monitor that:
SetSharedVariable[j]
Monitor[
   ParallelTable[j = n;Length[FactorInteger[2^n - 1]], {n, 50, 300}], 
   j
]

This may make sense if the computation for each i is rather intensive, so that the overhead of communication with the main kernel is negligible. Note also that the results you see are not generally in sequential order, since they depend on how ParallelTable schedules the computations to available kernels. As to the original example, here is a modified version,
SetSharedVariable[j]
Monitor[ParallelTable[Pause[RandomReal[{0.5, 4.}]];j = i, {i, 1, 10}], j]

where the intervals to pause are random, so that not all kernels finish computing at the same time. 
EDIT
As mentioned by @Szabolcs in the comments, 

You could use j++ in place of j=i, if you are mostly interested in the overall progress
One should be aware of what type of communication overhead this induces. 

Here is one way to find out:
j = 0;
First@AbsoluteTiming[ParallelTable[j++, {i, 1, 1000}];]/1000

which returns 0.0028 on my machine.
"
parallelization - PrintTemporary in ParallelTable,"
This will display a list that's updated as long as the calculation runs, and vanishes afterwards:
(* Pattern that translates the kernel's ID to
   a number from 1 to $KernelCount *)
kernels = ParallelTable[$KernelID -> i, {i, $KernelCount}];
SetSharedVariable[kernels]; (* for Mathematica 7 *)

(* This is the list that will display each kernel's current operation *)
SetSharedVariable[currentNumber]
currentNumber = ConstantArray[0, Length@kernels];

PrintTemporary[""Current calculations:""];
PrintTemporary@Dynamic[currentNumber];

(* Start the computation *)
ParallelTable[
    Pause@RandomReal[{0, .25}]; (* Long calculation *)
    currentNumber[[$KernelID /. kernels]] = i,
    {i, 100},
    Method -> ""FinestGrained""
]

The immediate output looks like this:

Current calculations:
{15, 24, 16, 23, 25, 29, 27, 20}


Now wait for ParallelTable to finish, and the above will disappear, leaving only the result:

{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...}


You can modify the Dynamic statement according to your needs of course, such as adding a // Column to the argument to print it nicer etc.
"
list manipulation - How to change step size of ListPlot,"
Lists don't save the value they have been generated with. Consider the example of plotting a sine using a discrete point set:
data = Table[Sin[2 Pi x], {x, 0, 1, 0.05}];
ListPlot[data]




Notice the nonsense values on the $x$ axis.
There are three possible solutions for this, all of which give the following plot as a result:

Using DataRange to manually specify the domain of the data in ListPlot
data = Table[Sin[2 Pi x], {x, 0, 1, 0.05}];
ListPlot[data, DataRange -> {0, 2 Pi}]

The disadvantage of this approach is that the data range is not known to the plot, and it has to be entered by the user manually. If the data itself changes, the plot will still assume these manual numbers, even if the domain is now much larger (consider expanding the above table to run from 0 to 20).
Embedding the data range into the list
data = {
        Table[Sin[2 Pi x], {x, 0, 1, 0.05}],
        DataRange -> {0, 2 Pi}
       };
ListPlot @@ data

Disadvantage: the DataRange option is only useful for a couple of functions. When you're planning to further modify the data, you will always have to pay attention that data doesn't save the data on the first level, but on the second one of this nested list.
Incorporating the x values when generating the data
data = Table[{2 Pi x, Sin[2 Pi x]}, {x, 0, 1, 0.05}];
ListPlot[data]

The disadvantage of this approach is of course a more complicated list structure, as well as about twice the amount of data.
"
Is there a more elegant and efficient way to write brainf*** style loops in Mathematica?,"
My solution isn't precisely what was asked for: it is the complete parser. At the moment, it is strictly a parser, but the functionality is all ready to be added.
Clear[bfinterpreter, bfeval, movf, movb, add1,  sub1, write, read, loop, 
      stored, loopdepth, rls]
rls = {"">"" -> movf, ""<"" -> movb, ""+"" -> add1, 
       ""-"" -> sub1, ""."" -> write, "","" -> read,
       ""]"" :> With[{mode = loopdepth--}, loop[stored[mode]]]
  };

bfeval[a : ("">"" | ""<"" | ""+"" | ""-"" | ""."" | "","" | ""]"")] := 
  With[{val = a /. rls}, 
   If[loopdepth == 0, 
    val[ptr], 
    AppendTo[stored[loopdepth], val]; ## &[]] 
  ]

bfeval[""[""] := (stored[++loopdepth] = {}; ## &[])
bfeval[_] := (## &[])

bfinterpreter[code_String] := 
  Block[{loopdepth = 0, stored, ptr, 
         movf, movb, add1,  sub1, write, read}, 
   bfeval /@ StringSplit[code, """"]
  ];

A user would access this by passing bfinterpreter as String of BF commands.  The string is split into individual characters via StringSplit[code, """"], and then bfeval is mapped over the resulting list. Scan would be better for the full implementation, but I used Map here to show that the parser works. In particular, using this on the OPs supplied BF code we get
(* spaces added for demo purposes *)
bfinterpreter[""[[-]>> > . <<<]>>>  >>>.""]
(*
=> {loop[{          (* [ *)
      loop[{sub1}], (* [-] *)
      movf, (* > *)
      movf, (* > *)
      movf, (* > *) 
      write, (* . *) 
      movb, (* < *) 
      movb, (* < *) 
      movb  (* < *)
     }               
    ][ptr],    (* ] *)
    movf[ptr], (* > *) 
    movf[ptr], (* > *) 
    movf[ptr], (* > *) 
    movf[ptr], (* > *) 
    movf[ptr], (* > *) 
    movf[ptr], (* > *) 
    write[ptr] (* . *)
   }
*)

As you've probably figured out, all the magic happens in bfeval. The first form accepts all BF characters {"">"", ""<"", ""+"", ""-"", ""."", "","", ""]""}, but the open loop, ""["". It works by applying a list of replacement rules to the supplied character and either storing it, if we're within a loop, or evaluating it immediately. The close loop rule, though, has added functionality in that it needs to both reduce loop counter, loopdepth, and return the stored commands for the loop, hence the use of RuleDelayed (:>).
The second form of bfeval simply increments the loop counter, and returns ##&[] to ensure the final list doesn't contain Nulls. And, the final form is the catch all for every other type of character.
"
performance tuning - Setting a lower limit on calculation time,"
A similar but slightly shorter solution...
SetAttributes[pauseAtLeast2, HoldFirst]; 

pauseAtLeast2[calculation_, pause_] := 
   With[{res = AbsoluteTiming[calculation]},
        If[res[[1]] < pause, 
               Pause[pause - res[[1]]]
        ]; 

        res[[2]]
   ]

"
graphics - How can Magnify be forced to ignore the notebook's window width?,"
Try setting ImageSize:
p = Plot[x^2, {x, -1, 1}, ImageSize -> 300];
Magnify[p, 4]

As Szabolcs kindly notes one may use ImageSize -> Medium to preserve the default sizing while still embedding an explicit ImageSize that prevents the resize-to-window behavior you wish to avoid.
You could also rasterize at 4X normal ppi (default 72) and display 1:1 :
ppi = CurrentValue[""FontPropertiesScreenResolution""];

Image[p, ImageResolution -> 4 * ppi, Magnification -> 1]

"
function construction - How to avoid collision between optional arguments and options,"
Mathematica has to be able to tell that the default arguments can't be rules. So, for some special cases, you could do 
Options[f] = {""g"" -> Identity};

f[x_, y_Integer: 2, z_Integer: 3, OptionsPattern[]]:= OptionValue[""g""][x + y + z]

Testing:
f[1, 2, 3, ""g"" -> (#^2 &)]


36


f[1]


6


f[1, ""g"" -> (#^2 &)]


36


"
packages - How to distribute proprietary Mathematica code,"
My suggestion is to use a combination of encryption, DumpSave (as noted in some answers / comments), and Locked / ReadProtected, which should give your code a reasonable level of security. You can't make things totally safe, in Mathematica or any other language.  Using DumpSave however means that you should create a version of a package for each platform you want to support. But, if you really want to protect your code, this extra work does not seem that unreasonable.
"
front end - How to convert between various ItemSize/ImageSize units?,"
It's not really the done thing to answer a question you've set a bounty on, but here is an explanation of why Mike's answer isn't quite right. The first point to note is that item sizes include the width of frames, so one needs to allow for the thickness of the frames in the ImageSize option for the second grid (thus the +2 in the option since FrameStyle has a setting including AbsoluteThickness[1] and you need to count both sides.)
It's also necessary to ensure ContentPadding is False. This affects placement of the text in the grid cell.
Finally, Row doesn't take the  Spacings option while Grid does. In these circumstances it helps to used Grid for both cases. Notice I've used the Offset specification of spacing, which only counts the spacing excluding frames and borders.
Overlay[{Grid[{{""Sample"", ""Text""}}, Frame -> All, 
   FrameStyle -> Directive[AbsoluteThickness[1], Red], 
   Spacings -> {Offset[0], 0}, ItemSize -> itemSize, 
   Alignment -> {Left, Center}], 
  Grid[{{Framed[""Sample"", 
      ImageSize ->  2 + Dynamic[
         itemSize*{CurrentValue[""FontMWidth""], 
           CurrentValue[""FontLineHeight""]}], FrameMargins -> 0, 
      BaseStyle -> Red, 
      FrameStyle -> Directive[AbsoluteThickness[1], Blue], 
      ContentPadding -> False], 
     Framed[""Text"", 
      ImageSize -> 
       Dynamic[{2, 2} + 
         itemSize*{CurrentValue[""FontMWidth""], 
           CurrentValue[""FontLineHeight""]}], FrameMargins -> 0, 
      BaseStyle -> Red, 
      FrameStyle -> Directive[AbsoluteThickness[1], Blue], 
      ContentPadding -> False]}}, Spacings -> {Offset[0], 0}]}]


"
replacement - Replace rule does not match,"
Pattern matching with complex numbers is notoriously difficult because Complex numbers are atomic yet have non-trivial FullForm.
{AtomQ[-3 I], FullForm[-3 I]}


{True,Complex[0,-3]}


Examining the FullForm of your expression, perhaps you want the following.
rule = a_Complex*x_*Re[y_] + b_Complex*y_*Re[x_] :>
  Abs[a]*Re[I x Conjugate[y]] /; a == -b;
-3 I Ez Re[Ex] + 3 I Ex Re[Ez] /. rule


-3 Im[Ex Conjugate[Ez]]


"
export - Question about $\LaTeX$ generated by Mathematica,"
The immediate problem with the LaTeX is that \( and \) appear twice.  Thus, the following works fine, assuming the setspace package has been loaded.
\begin{doublespace}
\noindent\(\{0,10,1\}\)
\end{doublespace}

Another question, of course, is why this export went wrong and how to change that.  That's hard to say without seeing the Mathematica expression.
"
graphs and networks - How to determine edgeweights from width of skeleton using MorphologicalGraph (or workaround)?,"
This is more of a remark than a solution, but it was too long for a comment.
First of all, although it's not visible in the plot, MorphologicalGraph with EdgeWeight -> Automatic does set edge weights for the edges. However, these are not based on the thickness of the edges but on their length. For example, for the example in the original post the edge weights of g are equal to 
g = MorphologicalGraph[img, EdgeWeight -> Automatic];
weights = OptionValue[Options[g, EdgeWeight], EdgeWeight]


{22, 20, 5, 11, 5, 34, 49, 13, 41, 12, 7, 6, 9, 34, 44, 24, 29, 54, 
  65, 17, 34, 26, 38, 21, 43, 41, 13, 52, 3, 14, 6, 47, 19, 24, 9, 14, 
  82, 8, 13, 13, 52, 23, 63, 99, 73, 84, 40}


Using a custom EdgeRenderingFunction for GraphPlot to colour the edges and change their thickness according to weights you get something like
vertices = VertexList[g];
crds = OptionValue[Options[g, VertexCoordinates], VertexCoordinates];
edges = List @@@ EdgeList[g];

GraphPlot[Rule @@@ edges,
  VertexCoordinateRules -> Thread[vertices -> crds],
  EdgeRenderingFunction -> (With[{w = 
        Pick[Rescale[weights], edges, (#2 | Reverse[#2])][[1]]},
      {Thickness[.02 (.1 + w)],
       ColorData[""SunsetColors""][.9 w], Line[#1]}] &), 
  AspectRatio -> 1]


"
graphics - Animating a rotating disk,"
Lets start with some parameters (note that I've chosen larger values for a and x0 here to actually see the movement of the centre)
radius = 20;
x0 = 10;
a = 5;
om1 = 10 Degree; 
om2 = 10 Degree; 

The centre of the rotating object at time t is given by
centre[t_] := {x0 + a Cos[om1 t], a Sin[om1 t]};

I'm using RegionPlot to create an image of the disk centred at the origin
circ = RegionPlot[x^2 + y^2 <= radius^2, {x, -radius, radius}, 
  {y, -radius, radius}, 
  Mesh -> 20, MeshStyle -> {{Red}, {Blue}}, BoundaryStyle -> Black, 
  PlotStyle -> None]


Next, we're defining a function for creating the plot at time t. I'm using Rotate and Translate to get the orientation and position of the disk. The path of the centre is plotted using ParametricPlot
plot[t_] := Show[Graphics[
  Translate[Rotate[{circ[[1]], Point[{0, 0}]}, om2 t], centre[t]]],
  If[Abs[t] <= $MachineEpsilon, {},
    ParametricPlot[centre[s], {s, 0, t}, PlotStyle -> {Black}]],
  PlotRange -> {{-2 radius, 2 radius}, {-2 radius, 2 radius}}, 
  Axes -> True]

Plugging this function into Animate will create an animation of this function:
Animate[plot[t], {t, 0, 36}]


"
programming - Embed CDF into an Apple iBook?,"
The first question would be: do the devices on which your iBook will be viewed also allow you to install the CDF player? If not, then that's the end of it. The FAQ says CDF doesn't run on the iPad (yet?). 
Just as an aside: when I saw that FAQ, I was reminded of Wolfram Publicon (there was a similar FAQ for it ten years ago, and it had a very similar statement along the lines of: the release is just around the corner, just contact us...).
"
guidelines - Resource management in Mathematica,"
There is an undocumented function, CheckAll, that can be used for this purpose.  It dates back to at least version 7.  All the usual caveats about undocumented functions apply -- it might not be supported in future releases, there may be gaps in its functionality, etc.  Buyer beware.
The usage information looks like this:

The usage text is slightly in error as the control arguments are wrapped in Hold rather than HoldComplete.
CheckAll can be used to detect all manner of non-local exits, such as:
CheckAll[Abort[], List]
(* {$Aborted, Hold[Abort[]]} *)

CheckAll[Throw[1], List]
(* {$Aborted, Hold[Throw[1]]} *)

CheckAll[Goto[a], List]
(* {$Aborted, Hold[Goto[a]]} *)

CheckAll[MemoryConstrained[Range@1000, 100], List]
(* {$Aborted, Hold[]} *)

CheckAll[TimeConstrained[Pause[1000], 1], List]
(* {$Aborted, Hold[]} *)

We can use this function to build unwindProtect, a control structure that assures that a clean-up expression is evaluated after any non-local exit of its body:
ClearAll @ unwindProtect
SetAttributes[unwindProtect, HoldAll]
unwindProtect[body_, cleanup_] :=
  CheckAll[body, HoldComplete] /.
    ( cleanup
    ; { _[_, _[r__]] :> r
      , _[r_, _[]] :> r
      }
    )

It starts by evaluating the body, guarded by CheckAll.  Then it evaluates the clean-up expression.  Finally, it returns either the pending non-local control actions or, if there are none, the return value of the body (which might be a held Sequence).
Here are some examples of its use:
hi[] := Print@""hi""
bye[] := Print@""bye""
fail[] := Print@""FAIL!""

unwindProtect[hi[]; Abort[], bye[]]
(* During evaluation of In[75]:= hi
   During evaluation of In[75]:= bye
   Out[75]= $Aborted *)

Catch @ unwindProtect[hi[]; Throw[1]; fail[], bye[]]
(* During evaluation of In[76]:= hi
   During evaluation of In[76]:= bye
   Out[76]= 1 *)

Module[{n = 0}
, Label[a]
; If[n < 2, unwindProtect[Print[""hi "", ++n]; Goto[a], Print[""bye "", n]]]
]
(* hi 1
   bye 1
   hi 2
   bye 2 *)

It even handles some tricky cases:
Catch@unwindProtect[hi[];Throw[Unevaluated[Abort[]]], bye[]]
(* During evaluation of In[82]:= hi
   During evaluation of In[82]:= bye
   Out[82]= $Aborted *)

Catch@unwindProtect[hi[];Throw[Unevaluated[Throw[$Failed]]], bye[]]
(* During evaluation of In[83]:= hi
   During evaluation of In[83]:= bye
   Out[83]= $Failed *)

unwindProtect can be used to build a still higher-level control structure (withSetup) that supports the declaration of Module-like variables, with sequential assignment and resource-cleanup expressions:
ClearAll[withSetup]
SetAttributes[withSetup, HoldAll]

withSetup[{}, body_] := body

withSetup[{var_ = val_; cleanup___, rest___}, body_] :=
  Module[{var = val}
  , unwindProtect[withSetup[{rest}, body], CompoundExpression[cleanup]]
  ]

withSetup[{var_ = val_, rest___}, body_] :=
  Module[{var = val}, withSetup[{rest}, body]]

w:withSetup[___] := (Message[withSetup::malformed, Short@HoldForm[w]]; Abort[])

withSetup::malformed = ""``"";

withSetup starts out resembling Module:
withSetup[{x = 1}, x + 1]
(* 2 *)

It differs from Module in that the variable assignments are performed sequentially:
withSetup[{x = 1, y = x + 1}, {x, y}]
(* {1, 2} *)

But the real value of withSetup is that it can be used to declare clean-up actions for each variable:
open[f_] := (Print[""opened "", f]; file[f])
close[f_] := Print[""closed "", f]

withSetup[{f = open[""f1""]; close[f]}, f]
(* During evaluation of In[152]:= opened f1
   During evaluation of In[152]:= closed file[f1]
   Out[154]= file[f1] *)

... and those clean-up actions are performed even in the face of a non-local return:
Catch @ withSetup[{f = open[""f1""]; close[f]}, Throw[""early exit""]]
(* During evaluation of In[160]:= opened f1
   During evaluation of In[160]:= closed file[f1]
   Out[160]= early exit *)

Clean-up actions are performed in reverse order from their corresponding initializations:
withSetup[
  { file1 = open[""f1""]; close[file1]
  , file2 = open[""f2""]; close[file2]
  , files = {file1, file2}
  }
, doStuffWith[file1, file2, files]
]
(* During evaluation of In[155]:= opened f1
   During evaluation of In[155]:= opened f2
   During evaluation of In[155]:= closed file[f2]
   During evaluation of In[155]:= closed file[f1]
   doStuffWith[file[f1],file[f2],{file[f1],file[f2]}] *)

withSetup assumes that any variable initialization that is a compound expression is initialized using the first part of the expression, and is cleaned up using the remaining parts.  One is free to write {var = (init1; init2); cleanup1; cleanup2} if desired.
Beware that any errors or other non-local exits from the clean-up actions can cause all kinds of strange behaviour.  Clean-up actions should be foolproof, with no reasonable chance of failure.  Wrap them in CheckAbort, AbortProtect or even unwindProtect if there is any doubt and circumstances demand it.  unwindProtect does not do this automatically, although it could be changed to do so according to one's personal preference (I prefer to see the errors rather than muffle them).
Update
I subsequently discovered that CheckAll muffles all messages generated by the exit function.  Furthermore, any messages from the main expression are also muffled in such circumstances.  Here is a revised version of unwindProtect that performs some gymnastics to preserve the main messages and to inform the user when a clean-up expression fails:
ClearAll@unwindProtect
SetAttributes[unwindProtect, HoldAll]
unwindProtect[body_, cleanup_] :=
  CheckAll[body, HoldComplete] /.
    ( CheckAll[cleanup, HoldComplete] /. _[v_, _[c__]] :>
        Check[
          Message[unwindProtect::cleanupFailed
          , HoldForm @ cleanup
          , HoldForm @ {v}
          , HoldForm @ {c}
          ]
        , Null
        ]
    ; { _[_, _[r__]] :> r
      , _[r_, _[]] :> r
      }
    )

unwindProtect::cleanupFailed =
  ""Cleanup expression failed: ``, results: ``, controls:  ``"";

"
front end - How make AddMenuCommands work in an init.m,"
I can only speak for Windows but I would expect the solution should be similar for Mac.
I created a file $BaseDirectory\FrontEnd\init.m
In that file I added the following lines. Note they are slightly different than what you provide but should do what you want.
FrontEndExecute[AddMenuCommands[""AboutBoxDialog"",{Delimiter,
  Item[""Installed Add Ons"",FrontEndExecute[FrontEnd`FrontEndToken[""OpenHelpLink"",
    {""guide/InstalledAddOns"",Automatic}]]],Item[""Standard Extra Packages"",
       FrontEndExecute[FrontEnd`FrontEndToken[""OpenHelpLink"",
          {""guide/StandardExtraPackages"",Automatic}]]]}]]

I attempted to do this using $UserBaseDirectory\FrontEnd but Mathematica insists on wiping out any changes I make to the init.m file that already exists there.
EDIT:
Following the comment by @Matariki one can place the init.m file in $UserBaseDirectory\Autoload\PacletManager\Configuration\FrontEnd\ instead. I'm not sure which is preferable. The $BaseDirectory installation should add the customization for any user on the machine whereas the $UserBaseDirectory option will only work for the selected user.
Extension:
Also worth noting is that ""AboutBoxDialog"" is a front end token that can be found in MenuSetup.tr located in $InstallationDirectory/SystemFiles/FrontEnd/TextResources/.  
These tokens, to my knowledge, are the only way to control the placement of new commands in menus. I could for example have added a background color to the Format>Background Colors menu by noting that ""BackgroundDialog"" is the token closest to the relevant menu in MenuSetup.tr. Adding the following code to the previously mentioned init.m will add a Linen color to the Background Colors sub-menu.
FrontEndExecute[ 
  AddMenuCommands[""BackgroundDialog"", {Delimiter, 
   Item[""L&inen"",Background->RGBColor[0.980,0.941,0.902]]}]];

"
pattern matching - Replacement rule only matches part of expression,"
In reply to the remaining issue addressed in the comments, here is the reason the 3 is not taken out of the brackets.
You have
rule = {f_ x_ + f_ y_ -> f (x + y), f_ x_ - f_ y_ -> f (x - y)};

3 Hx Re[Ez] vz - 3 Ez Re[Hx] vz //. rule


vz (3 Hx Re[Ez] - 3 Ez Re[Hx])

leaving the multiple 3 inside.  Taking a simplified case, this works:
3 a + 3 b /. f_ x_ + f_ y_ :> f (x + y)


3 (a + b)

But this does not work, for the reason stated by Mr. Wizard:
3 a - 3 b /. f_ x_ - f_ y_ -> f (x - y)


3 a - 3 b

And neither does this:
3 a - 3 b /. f_ x_ + f_ y_ -> f (x + y)


3 a - 3 b

for reason that FullForm[3 a - 3 b] is

Plus[Times[3, a], Times[-3, b]

so f cannot ever match 3 and -3.
An awkward solution to this simple case is:
3 a - 3 b /. 
 f_ x_ + g_ y_ :> 
  Which[f == g, f (x + y), f == -g, f (x - y), True, f x + g y]


3 (a - b)

But this does not work for more complicated inputs.
Simplify on the other hand works ok:
Simplify[3 a - 3 b]


3 (a - b)

3 Hx Re[Ez] vz - 3 Ez Re[Hx] vz // Simplify


3 vz (Hx Re[Ez] - Ez Re[Hx])

And perhaps rule = f_ x_ + g_ y_ :> Simplify[f x + g y] would work for your original case, depending on what you are specifically seeking.
"
parallelization - Parallelizing Numerical Integration in Mathematica,"
The best you can do it is to speed up your function. Your calc is using a replace, but it's better if you use With:
calc[a_, b_, c_, d_, e_, f_] := 
 With[{Q = (8000000 \[Pi] Sin[
       1/2 ArcCos[
         1/2 Sqrt[Cos[2 c] + Cos[2 d]] Sqrt[Cos[2 e] + Cos[2 f]] + 
          Sin[c] Sin[e] + 
          Sin[d] Sin[f]]])}, (1.97531*10^15 (3. Q Cos[(3 Q)/20000] - 
         20000. Sin[(3 Q)/20000])^2)/(1.58025*10^24 + 
      6.32099*10^16 Q^2 + 
      Q^6 + (-1.58025*10^24 + 7.90123*10^15 Q^2 - 
         3.55556*10^8 Q^4) Cos[(3 Q)/10000] + (-4.74074*10^20 Q - 
         2.96296*10^12 Q^3) Sin[(3 Q)/10000])*
   UnitStep[5/2 - a]^2 UnitStep[5/2 + a]^2 UnitStep[5 - b]^2 UnitStep[
     5 + b]^2 UnitStep[5 - a - 1944 c] UnitStep[
    5 + a + 1944 c] UnitStep[5 - b - 1944 d] UnitStep[
    5 + b + 1944 d] UnitStep[40 + a - 1600 e] UnitStep[
    40 - a + 1600 e] UnitStep[45/2 + b - 1600 f] UnitStep[
    45/2 - b + 1600 f]]

For working with parallel, it's better if you distribute your definitions before calling parallel:
DistributeDefinitions[calc]

Then try:
Total[ParallelTable[
   NIntegrate[
    calc[a, b, c, d, e, f], {a, -1, 1}, {b, -1, 1}, {c, -1, 
     1}, {d, -1, 1}, {e, -1, 1}, {f, -1 + i/4, -1 + (i + 1)/4}], {i, 
    0, 7}]] // AbsoluteTiming

"
differential equations - Evaluation of a Variable Coefficient PDE,"
As far as I know Mathematica can only solve very special cases of partial differential equations exactly. However, since you want to render the solution, a numerical solution will be enough. Here's an example using the heat equation as a placeholder:
(* Differential equation *)
eqn = D[u[x, t], t] - D[u[x, t], x, x];
(* Boundary/Initial conditions:
   Absorbing boundaries, Gaussian bump *)
ic = {
    u[x, 0] == Exp[-x^2/2],
    u[-10, t] == u[10, t] == Exp[-10^2/2]
};
(* Unleash the fury *)
s = NDSolve[{eqn == 0}~Join~ic, u, {x, -10, 10}, {t, 0, 20}];
(* Visualize result *)
Plot3D[Evaluate[u[x, t] /. s], {x, -10, 10}, {t, 0, 20}]




NDSolve does not care about the type of differential equation, so your variable coefficients aren't a problem (modulo numerical instabilities of course). Replace eqn by your equation and add according initial conditions and you'll be fine. Here's an example of the same equation, only that now the diffusion constant is not $1$ but $e^{-t/3}$, making diffusion disappear over a time scale of $3$:
eqn = D[u[x, t], t] - E^(-t/3) D[u[x, t], x, x];
ic = {
    u[x, 0] == Exp[-x^2/2],
        u[-10, t] == u[10, t] == Exp[-10^2/2]
    };
s = NDSolve[{eqn == 0}~Join~ic, u, {x, -10, 10}, {t, 0, 20}];
Plot3D[Evaluate[u[x, t] /. s], {x, -10, 10}, {t, 0, 20}, AxesLabel -> Automatic, MaxRecursion -> 8, PlotPoints -> 32]




"
How can I extract the data from an image and process it pixel by pixel?,"
Certainly. For instance, here's how to reduce the number of colours to 10 (randomly chosen in RGB space):
i = Import[""ExampleData/lena.tif""]


You can try ImageData[i] to see the actual RGB values for each pixel. Now produce ten random triplets of reals between 0. and 1., and construct a function to quickly pick the one closest to some given number:
colours = RandomReal[{0, 1}, {10, 3}];
nf = Nearest[colours];

Then map the thing over the RGB values of the image and look at it:
Map[First[nf[#]] &, ImageData[i], {-2}] // Image


Try increasing the number of randomly selected colours to see what happens:
Manipulate[
 Module[{colours = RandomReal[{0, 1}, {num, 3}], nf},
  nf = Nearest[colours];
  Map[First[nf[#]] &, ImageData[i], {-2}] // Image
  ],
 {{num, 10}, 1, 1000, 1}
 ]


"
graphics - Mathematica: Label specific vertices in GraphPlot,"
You could do something like this. It's an adaptation of the first example in the documentation for VertexLabelingFunction where I used an If statement to determine whether a vertex should be labeled or not. The function offset is just a helper function to determine by what amount the arrows should be shortened based on whether they end or start at a labeled vertex or not and lblLst is the list of vertices you want to label:
lblLst = {1, 5, 10};

offset[lblLst_, edge : {e1_, e2_}] := If[MemberQ[lblLst, #], .13, .07] & /@ edge

GraphPlot[data, 
 EdgeRenderingFunction ->
  ({Red, Arrowheads[Small], Arrow[#1, offset[lblLst, #2]]} &),

 VertexRenderingFunction -> (If[MemberQ[lblLst, #2],
     {White, EdgeForm[Black], Disk[#, .1], Black, Text[#2, #1]},
     {Blue, Point[#1]}] &)]


"
Changing the MouseAppearance on the entire notebook front end,"
One can change the default cursor for all Output by setting up $Post with something like the following.
mouseApp[expr_] := 
      MouseAppearance[expr, Graphics[{Red, Disk[]}, ImageSize -> 10]]

$Post = mouseApp;

I'm not sure this answers your question though since it doesn't change the appearance of the mouse cursor for Input.
"
programming - Generating a matrix using sublists A and B n times,"
Perhaps this:
x = 2;
a = Range[0, x, 0.5];
b = Range[0.25, x + 0.25, 0.5];

PadRight[#, Length@#[[1]], #] & @ {a, b}

Could also be written:
PadRight[{a,b}, Length@a, {a,b}]


Performance
There is a reason to use the form I proposed over that which Heike gave.  If the first argument of PadRight is a packed array, and the padding list is packable (but not necessarily packed) the result will also be packed, and it is produced more quickly than if it were not packed.
foo = Range[5]; (* packed array *)

(r1 = PadRight[{},  5*^6, foo];) // RepeatedTiming
(r2 = PadRight[foo, 5*^6, foo];) // RepeatedTiming

Developer`PackedArrayQ /@ {r1, r2}
Divide @@ ByteCount /@ {r1, r2} // N


{0.047, Null}

{0.0096, Null}

{False, True}

2.99999


So using the list to pad as the seed instead of {} can result in five times better speed and three times better memory consumption.
However as Karsten 7. notes this doesn't actually help with the question example.  In either case the vector elements are kept packed but the outer list is not:
Needs[""Developer`""]

PackedArrayQ /@ PadRight[#,  Length@#[[1]], #] &@{a, b}
PackedArrayQ /@ PadRight[{}, Length@#[[1]], #] &@{a, b}


{True, True, True, True, True}
{True, True, True, True, True}


So while in principle it is better to pad the input list rather than {} as some cases greatly benefit from it, this case does not.
"
front end - Changing default window appearance,"
The help window position can be set to be remembered from the Options Inspector: open it, select Global preferences, go to Global Options -> Dialog Settings -> Help Viewer Settings and set Enabled to True. 
"
notebooks - Quickly editing the stylesheet and saving it,"
Normal behavior is that simply closing the edited style sheet will transparently save it.
If you create a new private style sheet for a new Notebook and you still do not have this behavior then you must have changed a global configuration setting.
If this problem is peculiar to a particular private style sheet then I suggest going over the raw file looking for how it differs from the freshly created Notebook described above.
Also, you describe having to save this private style sheet with Save As into $UserBaseDirectory; as far as I know this is not how private style sheets work.  How did you create this ""private"" style sheet in the first place?
"
"packages - What is a ""Paclet""?","
Update for version 12.1
Starting with version 12.1, paclets are now exposed as user-accessible packaging functionality.  They are documented here.
Todd Gayley of WRI has published some preliminary documentation about Paclets and Paclet Development.  There is also an associated introductory video.

Original Response
A paclet is a distribution mechanism for resources that contribute to the contents of a package.  Most of the paclet machinery is in the PacletManager context, which is not public API.
It appears that the only part of paclet functionality presently intended for public use involves PacletInfo.m, a descriptor file for Mathematica applications.  This is described in the Wolfram Workbench documentation.
"
probability or statistics - How to define a new copula distribution family,"
The function ProbabilityDistribution allows you to define your own distribution functions that can be used with all distribution-related functions. The following example is from the documentation. 
Define a custom probability distribution giving its pdf:
  dD = ProbabilityDistribution[ Piecewise[{{x^2/9, 0 < x <= 3}}], {x, -\[Infinity], \[Infinity]}];

Then you can use the built-in functions CDF, Mean etc with it just like any other built-in distribution function. For example:
  CDF[dD,x]

gives:

Documentation also contains examples of how construct your own multivariate distributions. There are no specific examples of custom copulas in the documentation but the same principle should apply: you need to use ProbabilityDistribution to define such things in order to be able to use built-in function like CDF, PDF, RandomVariate... with them.
"
performance tuning - Efficient conditional Mean[] on a large data set,"
You could do something like this
mean = Reap[Sow @@@ Flatten[cogAK6, 1];, _, {Mean[#2], #} &][[2]];

This will be a lot faster than your approach because by using Sow and Reap this code only iterates through the list of data once. In your code, you reiterate through all elements of the data list for every value of gazeNo (so 3000 times instead of only once).
"
"warning messages - Table function with Part[] call misbehaving, but only after initial startup of Mathematica","
One way to deal with problems like this is to use DynamicModule inside the Manipulate:
Manipulate[
  DynamicModule[{e1, e2, standardBasis, y, p}
  , e1 := {1, 0}
  ; e2 := {0, 1}
  ; standardBasis := {e1, e2}
  ; y := 3
  ; Dynamic[
      p := {x, y}
    ; arrowsReference =
        Table[Arrow[{p, p + Part[standardBasis, j]}], {j, 2}]
    ]
  ]
  , {{x, 1}, -10, 10}
]

The example localizes all of the symbols except arrowsReference.  In the original example, it seemed like arrowsReference was meant to ""escape"" the Manipulate.  Adjust these decisions to meet your needs.
The expressions that initialize e1, e2, standardBasis and y will each be evaluated exactly once (each session) as the Manipulate is initialized.  Only the contents of the Dynamic expression will be re-evaluated each time the controls are manipulated.
This approach saves the state of the localized variables across Mathematica front-end sessions.  Also, the output cell can be copied and pasted to create a new independent cell with its own state -- a desirable attribute when creating CDFs and demonstrations.
All this works because of the unusual evaluation sequence documented under the More Information section of DynamicModule.  Essentially, there is a kind of ""double evaluation"" at work.  The initial definitions (e1 := ... through Dynamic[...]) are evaluated in the first pass as if they were defined within a Module.  Then, the final result (in this case Dynamic[...]) is wrapped into a new DynamicModule and that becomes the content of the the Manipulate.
"
Adding a point to an already existing graphic,"
radius = 20;

circ = RegionPlot[
  x^2 + y^2 <= radius^2, {x, -radius, radius}, {y, -radius, radius}, 
  Mesh -> 20, MeshStyle -> {{Red}, {Blue}}, BoundaryStyle -> Black, 
  PlotStyle -> None]

circ2 = Show[circ, Graphics[{PointSize[0.025], Point[{10, 10}]}]]


You could have used ListPlot too, but the point here is that Show combined Graphics into a new Graphics, so you need to feed it with Graphics (ListPlot returns a Graphics object)
circ3 = Show[circ, 
  ListPlot[{{10, 10}}, PlotStyle -> PointSize[0.025]]]

Another option perhaps more similar to what you were trying could be
Show[circ, Epilog -> {PointSize -> Large, Point[{{10, 10}}]}]

Graphics are composed of primitives, directives and options. 
Primitives are the shapes (Line, Point, Circle, etc). 
Directives are stuff that affect the shapes, such as color settings, point size, line type, arrow heads, etc. In the same Graphic object you can combine several directives, affecting different primitives (a red circle with a black dot)
Options are general to the graphic. AspectRatio, stuff about the axes, etc..
So, a Graphics object is Graphics[{list of primitives and directives}, options]
What Show does is take several Graphics, combine its primitives and directives, and optionally change the general options.
PlotStyle is an option for functions that automatically create Graphics, like Plot and his family. It is NOT a Graphics option. In those functions, it allows among other things to set directives to the stuff you're plotting. So if you're used to writing Plot[f[t], {t, 0, 10}, PlotStyle->something, otheroptions->othervalues] then that something is probably a directive. And probably, otheroptions are general graphic options (or other particular options of the plotting function such as Filling, etc).
So, let's see what you were trying to do with your code
Show[circ, 
Epilog -> Inset[ListPlot[{10, 10}], PlotStyle -> PointSize[0.025]] ]

You were trying to create a new Graphics with the same primitives and directives than circ, but with an extra option Epilog. Furthermore, you were trying to add as options to the Graphics something that is not an option :P. 
Epilog just adds more primitives to the Graphics object after it is rendered. It is more or less the same as adding more primitives to the list, except that it allows to do it as an option so it's convenient to add annotations in functions such as Plot. The fact that they are added after the Graphics was rendered also means you can mix 2D and 3D primitives. No different in your case than writing the following
Show[circ, Graphics[{Inset[ListPlot[{10, 10}]]}]]

Moving on. Inset takes a Graphics, Image, cell expression, string, etc, and turns it into a primitive. So, the Graphics object generated by ListPlot now is taken as a whole, with it's own set of axes and everything, and combined with the primitives of circ. Not what you wanted
Final comment. ListPlot if it's given a one dimensional list, interprets all the numbers as y-coordinates. If you want it to plot (x,y) pairs, you need to give it a list of (x, y) pairs. In your case, a list of only one pair,  {{10, 10}}
Hope that now you not only understand why your code didn't work but also why what works works
"
Dimensions of the results of Text[] within Graphics[],"
Here you go:
t = Text[Style[""how quickly daft jumping zebras vex"", 
    FontFamily -> ""Verdana"", FontSize -> 20]];
{l, h} = d = Rasterize[t, ""RasterSize""];
Graphics[{Green, Rectangle[{0, 0}, d], Black,
  Inset[t]}, PlotRange -> {{0, l}, {0, h}}, ImageSize -> l]


"
programming - How can I make CurrentValue for font characteristics pick up the font of the output not the input cell?,"
You could do something like
{Framed@Graphics[
   Text[Style[DynamicWrapper[""how quickly daft jumping zebras vex"",
       p = CurrentValue[""FontNWidth""]], FontFamily -> ""Verdana"", 
     FontSize -> 20]], ImageSize -> Dynamic[p]*35], Dynamic[p]}


This code demonstrates that the font chosen for the styled output is definitely being picked up by CurrentValue.
Manipulate[{Framed@
   Graphics[
    Text[Style[
      DynamicWrapper[""how quickly daft jumping zebras vex"", 
       p = CurrentValue[""FontNWidth""]], FontFamily -> fontfam, 
      FontSize -> i]], ImageSize -> Dynamic[p]*42], Dynamic[p]}, {i, 
  10, 40}, {fontfam, {""Verdana"", ""Arial"", ""TimesNewRoman"", ""Tahoma""}}]


"
programming - Alternative ways to implement a triangular recursion,"
The following is a naive but general implementation of the recursion formula
$$T_k^{(n)}=f(T_{k-1}^{(n)},T_{k-1}^{(n+1)})$$
triangular[f_, initial_] := 
  First@Nest[
   f @@@ MapIndexed[Join, Partition[#, 2, 1]] &,
   initial,
   Length[initial] - 1
  ]

triangular takes a function f[tn0, tn1, n] where tn0 corresponds to $T_{k-1}^{(n)}$, tn1 corresponds to $T_{k-1}^{(n+1)}$ and n corresponds to $n$.
Then the Bernoulli number function can be implemented as
myBernoulliB[n_] := triangular[#3 (#1 - #2) &, 1/Range[n+1]]

We can write it a bit more readably as
triangular[Function[{Tn0, Tn1, n}, n (Tn0 - Tn1)], 1/Range[5]]

The other two algorithms can also be written in terms of triangular[], but I don't think this is really better than your Do loop.  (triangular[] would need to be extended to pass $k$ to the function as well.)

This can be generalized, based on the same principle, to return multiple results ($\{T_0^{(3)}, T_1^{(2)}, T_2^{(1)}, T_3^{(0)} \}$ above) like this:
triangular2[f_, initial_] := Module[{tag, a, b},
  {{a}, {b}} = Reap[
    Nest[
     Function[arg,
      Sow[Last[arg], tag];
      f[##, Last[arg]] & @@@ MapIndexed[Join, Partition[arg, 2, 1]]
      ],
     initial,
     Length[initial] - 1
     ],
    tag
    ];
  Append[b, a]
  ]

Then bezierChop can be implemented using:
fb[u_] := Function[{tn0, tn1}, u tn1 + (1 - u) tn0];

bezierChop[BezierCurve[pts_?MatrixQ, opts___], u_?NumericQ] :=
 BezierCurve@Transpose@MapThread[triangular2[fb[u], {##}] &, pts]

To make this easier to understand using the original triangular function, MapThread[triangular[fb[u], {##}]&, pts] would return only the first point out of all points included in the resulting BezierCurve.
"
Symmetrical image transformation for a kaleidoscope-type image,"
I think the main problem is that ArcTan runs from $-\pi$ to $\pi$, but the DataRange in the x direction runs from 0 to 1, so you're actually using 6 and a bit copies of the original image to cover the whole circle. This is easily fixed by specifying explicit values for DataRange, i.e.
Manipulate[
 With[{sectors = 8},
  ImageTransformation[
   ImagePad[im, {{-x, x}, {-x, x}}, Padding -> ""Reversed""], 
   Function[{pt}, {ArcTan[-#2, #1] & @@ (pt), Norm[pt]}], 250,
   DataRange -> {Pi/sectors {-1, 1}, {0, 1}}, 
   PlotRange -> {{-2, 2}, {-2, 2}}, Padding -> ""Reversed""]], {x, 0, 
  100, 5}]


Here, sectors is the number of sectors in the transformed image.
Edit
Note that while ImageTransformation works it isn't very fast. If you are using Mathematica 8 you could use for example ParametricPlot in combination with TextureCoordinateFunction to  get a similar but faster result.  
First, we need a source image for the Texture. To get the right tiling where two neighbouring images are each other's reflection, I'm using the following:
imReflected = ImageAssemble[{
   {ImageReflect[im, Bottom], ImageRotate[im, Pi]},
   {im, ImageReflect[im, Left]}}]


Next, we need a TextureCoordinateFunction. To get the reflections of the shifted image in the circles r=a and the radial lines t=b where a and b are integers I'm using a triangle wave with period 2 and amplitude 1/2 which is vertically shifted by some offset corresponding to x in the solution above.
func[p_, x_] := x + TriangleWave[{0., 1/2.}, p/2 - 1/4]

The transformed image can then be plotted according to
Manipulate[
 ParametricPlot[{r Cos[2 Pi/sectors t], r Sin[2 Pi/sectors t]}, 
    {r, 0, 3}, {t, 0, sectors},
  Mesh -> None, BoundaryStyle -> None,
  Axes -> False,
  PlotStyle -> {Opacity[1], Texture[imReflected]},
  TextureCoordinateFunction -> ({func[#4, x], func[#3, x]} &),
  TextureCoordinateScaling -> False,
  PerformanceGoal -> ""Quality"", 
  PlotPoints -> {4, 1 + Round[40, sectors]},
  PlotRange -> {{-2, 2}, {-2, 2}}],
 {x, 0, 1},
 {{sectors, 6}, 4, 10, 2}]


Note that for the best result the number of plot points in the r and t direction should be one plus a multiple of the number of rings and sectors, respectively. 
Edit
Inspired by faleichik's answer below, I've decided to implement his solution using textured triangles. There are basically two different triangles in the tessellation, one being the mirror image of the other. The other triangles are rotated and/or translated copies of either of these triangles which can be constructed from the base triangles using Rotate and Translate. Therefore, one way to get the tessellation is as follows:
Manipulate[
 DynamicModule[{texcrds, base, hex, im},
  im = ImageResize[ExampleData[{""TestImage"", ""Mandrill""}], 100];

  texcrds = offset + {{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}};
  base = {Polygon[{{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}}, 
     VertexTextureCoordinates -> texcrds],
    Polygon[{{0, 0}, {1, 0}, {1/2, -Sqrt[3]/2}}, 
     VertexTextureCoordinates -> texcrds]};
  hex = Rotate[base, #, {0, 0}] & /@ {0, 2 Pi/3, -2 Pi/3};

  Graphics[{Texture[im],
    Translate[Translate[hex, {{0, 0}, {3/2, -Sqrt[3]/2}}], 
     Tuples[{3 Range[0, n/2], Range[0, n] Sqrt[3]}]]},
   PlotRange -> {{-1/2, 3 n/2 + 1/2}, {-Sqrt[3]/2, n Sqrt[3]}}]],
 {{n, 3, ""resolution""}, 1, 5, 1},
 {{offset, 0}, 0, 2}]


"
matlab - Pass many variables in SQL query,"
Use AND keyword in your SQL query for multiple criteria. You can use SPRINTF MATLAB function to insert variable parameters. I've also separated your query into multiple substrings for better readability.
sql = sprintf( [ ...
    'SELECT lic.licence_plate_num, lic.owner_name, lic.owner_address, '...
    'lic.owner_tel_no, lic.owner_email, vio.violation_date, '...
    'vio.violation_time, vio.vehicle_type, vio.violation_type '...
    'FROM licence_plate_details lic RIGHT JOIN violated_vehicles vio '...
    'ON lic.licence_plate_num = vio.licence_plate_num '...
    'WHERE vio.vehicle_type = ""%s"" AND vio.violation_type = ""%s""' ], ...
    vehicle, violation_type );

"
syntax - Why doesn't PatternTest work with Composition?,"
Because PatternTest binds very tightly. You need extra parentheses:
MatchQ[3, _?(Composition[Not, OptionQ])]

"
plotting - Series of piecewise  functions,"
You can pretty much enter your question in that form in Mathematica:

The first definition, f[x_, n_] /; n == 0, reads ""define $f_n(x)$ in the case of $n=0$ to be the following"". The fancy bracket is pretty frontend notation for the Piecewise function (shortcut: EscpwEsc). The next line is the same thing again, after that there's the definition of your function $f(x)$, which is the partial sum up to $\mathcal N$. I don't think you can use $\mathcal N=\infty$ in this case, as it will exceed the maximum recursion depth by, well, infinity. If you want to have an exact result, try using RSolve to get an explcit equation for $f_n(x)$.
If you want to evaluate the code above on your own, here's a copyable version:
f[x_, n_] /; n == 0 := Piecewise[{
    {3 x, 0 <= x <= 1/3},
    {-3 x + 2, 1/3 < x <= 2/3},
    {3 x + 2, 2/3 < x <= 1},
    {Indeterminate, True}
}]
f[x_, n_] /; n >= 0 := Piecewise[{
    {1/3 f[3 x, n - 1], 0 <= x <= 1/3},
    {1/3 + 1/3 f[3 x - 1, n - 1], 1/3 < x <= 2/3},
    {2/3 + 1/3 f[3 x - 2, n - 1], 2/3 < x <= 1},
    {Indeterminate, True}
}]
f[x_, _, \[ScriptCapitalN]_] := Sum[(-1)^k f[x, k], {k, 0, \[ScriptCapitalN]}]
Plot[f[x, _, 10], {x, 0, 1}, PlotPoints -> 100, MaxRecursion -> 5]

For the third part of your question, simply define $p$ as an additional parameter for your function, so it's something like f[x_, n_, p_] := ..., and edit the definitions accordingly.
"
Automatically counting the number of lines of code in a set of notebooks,"
Assuming that the notebook object is contained in the variable nb (for the current notebook do nb = EvaluationNotebook[]), one could use the following:
StringCount[
 First@FrontEndExecute@FrontEnd`ExportPacket[
    Notebook@Cases[First@NotebookGet[nb], Cell[_, ""Input""|""Code"", ___]],
    ""PlainText""],
 ""\n""
 ]

Using ""InputText"" will wrap lines much more frequently and will give a substantially larger count.
This is equivalent to Alt-clicking an input cell to select all input cells, then copying the contents as ""plain text"" or ""input text"" and counting the lines.
As you can see, Mathematica does not really respect line breaks.  If you are trying to measure the volume of code, I suggest using the LeafCount of expressions instead of counting code lines.
"
syntax - Differentiation w/o assiging concrete values,"
The error comes from the first line. I am not sure what the second does; finally, you differentiate with respect to s, but have a variable S, which is different.
Perhaps you wanted to do this:
v = v0*Sin[Pi*s/s0]
D[v, s]

which works.
To see the problem with recursion, run this:
ClearAll[v]
v = Subscript[v, 0]


What is happening is the same that happens if you evaluate k = k + 1.
"
dynamic - I want to update a financial chart when I select a new stock from a popup menu,"
I believe the easiest way to accomplish this is with Manipulate.
Manipulate[
 InteractiveTradingChart[
  FinancialData[ticker, 
   ""OHLCV"", {{2008, 7, 3}, {2008, 9, 30}}]], {ticker, instruments}]


"
signal processing - Numerical Fourier transform of a complicated function,"
There is the function NFourierTransform[] (as well as NInverseFourierTransform[]) implemented in the package FourierSeries`. The function, as with the related kernel functions, takes a FourierParameters option so you can adjust computations to your preferred normalization as needed. For your specific normalization, you apparently want the setting FourierParameters -> {1, 1}.
Now, since NFourierTransform[] internally uses NIntegrate[], the function also takes options that can be passed to NIntegrate[]; you can thus change Methods as seen fit. I will in particular recommend that you look into the Method choices ""ExtrapolatingOscillatory"" (Longman's method), ""DoubleExponentialOscillatory"" (Ooura-Mori double exponential quadrature) and ""LevinRule"" (Levin's method), as well as the general controller method ""OscillatorySelection"". See this scicomp.SE answer for a short description of oscillatory quadrature methods and links to references, and NIntegrate Integration Strategies in the Mathematica help file for more details on how to employ them within Mathematica.
"
plotting - Seeing the whole financial chart,"
Edit
My initial answer seems to have missed the point, which was about how to call up InteractiveTradingChart[] with its controls initialized to some values other than defaults.
Someone more able than moi may want to examine the output from 
InteractiveTradingChart[{""GOOG"", {{2009, 1, 1}, {2009, 12, 31}}}]
FullGraphics[%] // InputForm

and determine whether variables such as plotrangemin can be set by the programmer.

The date range you specify in the command sets the full time period you work with. The actual display is handled by the buttons and slider at the button of the chart.  If you click on the Max setter button, the whole period will be displayed.  If you click on the month button, one month will be displayed.  You may move to other months (than the one currently being displayed) by using the Slider.  Same respective behavior for Week.
By default, the chart does not display the full time period but rather only a part of it.
 
"
plotting - What is the most efficient way to save a big graphic?,"
For a nice plot you don't need all the million points in your graphic. 10^10 points is a bit heavy for this curve, so why not using Plot? It has the advantage of adaptive sampling and it seems to do it absolutely correct in this case. The runtime is only about 1 second:
Plot[100 PrimePi[x]/x, {x, 1, 10^10}, 
  PlotRange -> {Automatic, {0, 10}}]


And even if you reduce your range, it catches all features
Plot[100 PrimePi[x]/x, {x, 1, 50}, PlotRange -> Automatic]


Update on Accuracy
In the comment you asked how accurate this is. I assume you mean ""are there enough points in the plot to represent important features?"" Consider the following Manipulate where you can visually inspect the sampling points in your plot with different settings for PlotPoints and MaxRecursion
Manipulate[
 Plot[100 PrimePi[x]/x, {x, 1, xEnd}, PlotRange -> Automatic, 
  Mesh -> All, MeshStyle -> Directive[PointSize[.005], Red], 
  MaxRecursion -> maxRecursion, PlotPoints -> plotPoints, 
  AxesOrigin -> {0, 0}],
 {xEnd, 10, 1000}, {maxRecursion, 0, 5, 1}, {plotPoints, 5, 30, 1}]


Basically those options work like that: PlotPoints defines how many sampling points are in your region initially. With the MaxRecursion setting Plot has the opportunity to subdivide the region at places where the function is not represented properly. This can be deduced by some curvature measure, but what exactly Mathematica is using for this decision is afaik not documented. 
Therefore, MaxRecursion is more important to catch features than many PlotPoints alone. On the other hand when you want a plot from 1 to 10^10 than you are clearly more interested in the overall tendency of the function than in the structure of the sharp edges between 4 and 10, which couln't be displayed anyway.
So when you are asking about accuracy, I'm not really sure what to answer. Every (red) point you see above is as accurate as it would be in DiscretePlot and usually the default settings for Plot work nicely and catch most features you want to see. But to have a feeling for that you can now use the Manipulate and watch what happens. 
In return I could ask, in your DiscretePlot do you see the difference between point 10^5 and point 10^5+1? Or is this maybe the wrong scale and you are more interested in the global bend from 0 to 2*10^9, because then you could leave out many points and exactly this is, what Plot tries to do. 
"
programming - Does AbsoluteTiming slow the evaluation time?,"
If you look in the Option Inspector, there's a setting called EvaluationCompletionAction that I keep set to ""ShowTiming""

The result of this is that whenever an evaluation finishes, the amount of time it took is displayed in the status area at the bottom of the notebook

This saves me from needing to remember to wrap inputs in Timing or AbsoluteTiming.  
One thing to note is that the time shown includes the conversion of the kernel output to boxes as well as the MathLink transmission time.  I don't think it includes any time used by the frontend to draw the result to screen.
The downside is that there's no history.
"
"How do I export to Excel in multiple, named worksheets?","
Using Export and specifying rules to create the sheet names:
Export[""sampledata.xlsx"", {""list1"" -> list1, ""list2"" -> list2}]

"
plotting - Plot draws list of curves in same color when not using Evaluate,"
The list structure is not manifest to Plot as it has the attribute HoldAll (to get a function's attributes, either use Attributes[func] or ??func). Hence Plot evaluates the Table functions as one unit and it appears as if there is only one function, not four. 
Evaluate will make the list structure manifest and each function will be plotted with a separate style.
"
import - How do you convert a string containing a number in C scientific notation to a Mathematica number?,"
I think probably the cleanest way to do this (at least, if you have only a single string, or are faced with a separate string for each number you wish to convert as a result of some other process) is to use the undocumented function Internal`StringToDouble, i.e.:
s = ""1.23e-5"";
Internal`StringToDouble[s]

which gives:
0.0000123

However, if you are trying to convert many such numbers at once, the standard, documented methods (Import, Read, etc.), are likely to represent better approaches.
UPDATE:  As of at least version 12.3 the proper way to invoke this is:
Internal`StringToMReal[""1.23e-5""]

"
formatting - What is the most convenient way to read definitions of in-memory symbols when we don't have the source files? (Spelunking tools),"
Link to the code on GitHub

I have been using this. It's mostly Leonid's code from the stackoverflow question you linked to, but it uses Definition instead of DownValues. Symbol names are printed without any context, but the full symbol name is put into a Tooltip so you can always find out what context a symbol is in.
Update
FullDefinition[symbol] claims to ""print the definitions given for symbol, and all symbols on which these depend"", but sometimes one wants to explore deeper than the first level of dependency. Here is a version of Spelunk which uses plain Definition instead of FullDefinition, but allows you to click on symbols in the definition to get their definition. So you can dig right down into the dependency chain.
Update 2
The code now copes with definitions containing strings with backticks in, and cases where Definition throws an error.
Also, it now works for symbols which have OwnValues, e.g. Internal`$VideoEncodings.
BeginPackage[""Spelunk`""];

Spelunk::usage = ""Spelunk[symbol]"";

Begin[""`Private`""];

defboxes[symbol_Symbol] := Hold[symbol] /. _[sym_] :>
        If[MemberQ[Attributes[sym], Locked], ""Locked"",
          Internal`InheritedBlock[{sym},
            Unprotect[sym]; ClearAttributes[sym, ReadProtected];
            Quiet@Check[ToBoxes[Definition@sym], ""DefError""] /. 
            InterpretationBox[a_, b___] :> a ]];

defboxes[s_String] := defboxes[#] &@ToExpression[s, InputForm, Unevaluated]

prettyboxes[boxes_] := 
  boxes /. {"" ""} -> {""\n-----------\n""} //. {RowBox[{left___, "";"", 
       next : Except[""\n""], right___}] :> 
     RowBox[{left, "";"", ""\n"", ""\t"", next, right}], 
    RowBox[{sc : (""Block"" | ""Module"" | ""With""), ""["", 
       RowBox[{vars_, "","", body_}], ""]""}] :> 
     RowBox[{sc, ""["", RowBox[{vars, "","", ""\n\t"", body}], ""]""}]};

fancydefinition[symbol_Symbol] :=
  Cell[BoxData[
    prettyboxes[
     defboxes[symbol] /. 
      s_String?(StringMatchQ[#, __ ~~ ""`"" ~~ __] &) :> 
       First@StringCases[s, 
         a : (__ ~~ ""`"" ~~ b__) :> processsymbol[a, b]]]], ""Output"", 
   Background -> RGBColor[1, 0.95, 0.9],
   CellGroupingRules->""OutputGrouping"",
   GeneratedCell->True,
   CellAutoOverwrite->True,
   ShowAutoStyles->True,
   LanguageCategory->""Mathematica"",
   FontWeight->""Bold""
];

processsymbol[a_, b_] := Module[{db},
  Which[
   ! StringFreeQ[a, ""\""""], a,
   ! StringFreeQ[a, ""_""] || (db = defboxes[a]) === ""Null"", 
   TooltipBox[b, a],
   db === ""Locked"", TooltipBox[b, a <> ""\nLocked Symbol""],
   db === ""DefError"", TooltipBox[b, a <> ""\nError getting Definition""],
   True, ButtonBox[TooltipBox[b, a], ButtonFunction :> Spelunk@a, 
    BaseStyle -> {}, Evaluator -> Automatic]]]

Spelunk[symbol_Symbol] := CellPrint[fancydefinition[symbol]];

Spelunk[s_String] := CellPrint[fancydefinition[#] &@ToExpression[s, InputForm, Unevaluated]];

SetAttributes[{defboxes, fancydefinition, Spelunk}, HoldFirst] 

End[];

EndPackage[];

"
output formatting - List of different values which have to be formatted differently,"
(edit: you should use lower-case letters to start user function names so as not to conflict with built-ins.)
Please tell me if this does what you want:
formats[{}, _] = {};
formats[list_, 1] := NumberForm[N[list], {3, 2}]
formats[list_, 5] := DateString[list, {""Quarter"", "" "", ""Year""}]


Testing.  With dat1 set to your Out[2259]=, and dat2 set to your Out[2265]= :
Map[{First[First[#]], formats[Last[#], 1]} &, dat1]


{{Australia,{}},{Austria,-1.21},{Belgium,-1.46},{Canada,-1.30},{Czech
  Republic,-1.67},{Denmark,-1.87},{Estonia,-3.97},{Finland,-2.53},{France,-1.00},{Germany,-1.74},{Greece,-1.16},{Hungary,-1.45},{Iceland,-1.83},{Ireland,-1.67},{Israel,{}},{Italy,-1.42},{Japan,-0.69},{Korea,{}},{Luxembourg,-1.67},{Netherlands,-0.98},{New
  Zealand,-0.50},{Norway,-0.64},{Poland,{}},{Portugal,-0.40},{Republic
  Slovak,{}},{Slovenia,-3.31},{Spain,-0.71},{Sweden,{}},{Switzerland,-0.82},{Turkey,-3.39},{Kingdom
  United,-1.45},{States United,-1.28}}

Map[{First[First[#]], formats[Last[#], 5]} &, dat2]


{{Australia, {}}, {Austria, ""1 2008""}, {Belgium, ""2 2008""}, {Canada,
  ""3 2008""}, {Czech Republic, ""3 2008""}, {Denmark,    ""2 2008""},
  {Estonia, ""2 2008""}, {Finland, ""2 2008""}, {France,    ""1 2008""},
  {Germany, ""1 2008""}, {Greece, ""3 2008""}, {Hungary,    ""1 2008""},
  {Iceland, ""3 2008""}, {Ireland,    ""4 2007""}, {Israel, {}}, {Italy, ""1
  2008""}, {Japan,    ""3 2010""}, {Korea, {}}, {Luxembourg, ""1 2008""},
  {Netherlands,    ""1 2008""}, {New Zealand, ""4 2007""}, {Norway,    ""2
  2008""}, {Poland, {}}, {Portugal,    ""3 2010""}, {Republic Slovak, {}},
  {Slovenia, ""3 2008""}, {Spain,    ""1 2008""}, {Sweden, {}},
  {Switzerland, ""2 2008""}, {Turkey,    ""1 2008""}, {Kingdom United, ""1
  2008""}, {States United, ""2 2008""}}

"
front end - How to anchor a Pane's scroll position to the bottom?,"
I was busy exploring this problem on my own for some time now, and was not satisfied with any of the answers. They both work for some extent, but, concerning Szabolcs's answer, I would like to avoid image-processing and in case of Mr.Wizard's answer there are slight problems with it during startup (see comments) and it breaks down when the scroll position is defined as a dynamic variable itself. Thus I set out to find a better solution.
The problem
First, I want to clearly state the problem (at least what my problem was originally): given a Pane that listens to a dynamic variable text, I have to update it such that whenever text changes by a controller (e.g. a button), the Pane is automatically scrolled down to the actual end of content. But I also want to keep both the manipulable scrollbar of the Pane and the possibility to manipulate the vertical scroll position pos via another external controler (e.g. a slider). Thus the resulting Pane must be updated differently, depending on whether text or pos triggers an update.
I present two solutions, the second one being the better one in my opinion. For both cases, I exploit the fact that if the initial vertical scroll position value (pos) is set large enough, Mathematica automatically finds and sets the scroll position to the end of content.
1. Injecting code in the external controller
The simpler method is to separate the different updates by assigning them to the external controllers. Here, a button is provided that updates text externally (external to the dynamic Pane object), but it also directly redraws the Pane to find the end-of-content position.
pos = 1000; (* vertical scroll position *) 
c = 5; (* text update counter *)
text = ""1\n2\n3333333333333333\n44"";

(* note that this button explicitly contains the update[] code *)
Button[""Update text"", cc = c++; text = text <> ""\n"" <> 
   StringJoin@Table[ToString@cc, {RandomInteger@{1, 15}}] <> ""<""; pane = update[]]
update[] := (
   pos = pos + 1000; 
   Framed@Pane[Dynamic@text, ImageSize -> {120, 60}, 
     Scrollbars -> {False, True}, 
     ScrollPosition -> Dynamic[{0, pos}, (pos = Last@#) &]]
  );

pane = update[]; (* initialize Pane *)
{Dynamic@pane, Dynamic@pos}

Note that updating text via the button or via the scrollbar correctly updates pane and pos. The only problem here is that one has to manually put the pane = update[] code into the controller, which is unwanted (at least in my case), as one only wants to change text via the button.
2. Separating updates via selective triggers
The beautiful answer by @Leonid provides a method to selectively separate different update methods of a dynamic expression depending on which ""parent"" variable triggers an update.
SetAttributes[makeTrigger, HoldAll];
makeTrigger[res_, var_, updateCode_] := Module[{varOld = var, trigger}, 
   trigger /; varOld =!= var := (varOld = var; res = updateCode); 
   trigger];

pos = 1000;
c = 5;
text = ""1\n2\n3333333333333333\n44"";
size = {120, 60};

Button[""Update text"", cc = c++; text = text <> ""\n"" <> 
   StringJoin@Table[ToString@cc, {RandomInteger@{1, 15}}] <> ""<"";]
Row@{""Update pos: "", Slider[Dynamic@pos, {0, 200}]}
update[] := Framed@Pane[text, ImageSize -> Dynamic@size, 
    Scrollbars -> {False, True}, 
    ScrollPosition -> Dynamic[{0, pos}, (pos = Last@#) &]];

(* triggers ONLY if text is changed! *)
trigger = makeTrigger[pane, text, (pos = pos + 1000; update[])];
pane = update[]; (* initialize pane *)
{With[{tr = trigger}, Dynamic[tr; pane, TrackedSymbols :> {text, pos}]], Dynamic@pos}


(The ""<"" character indicates the end of newly added content.)
First, a trigger is set up in the final line, that listens to whether text or pos is changed. If only pos is changed, then the resulting expression becomes Dynamic[pane], updating the vertical scroll position as required. However, if text is changed, then trigger triggers and update[] kicks in, redrawing the whole Pane object from scratch, finding and setting the correct end-of-content position.
Now it became possibly to have various controllers only updating independent variables (like text, pos, etc.) and a dependent expression that listens to the independent variables and updates according to which of them was triggered.
"
calculus and analysis - Kramers-Kronig relations,"
I think you intended to use {li, 200, 800} instead of {li, 800, 200}.
If you do so, then you could visualize the result :
ListLinePlot@dnFpoints


Moreover I would rather define  daF in the following form :
daF[l_]:= 500 * 0.28 Exp[-((l - 500)/90)^2]
c = 3 10^8;

Edit
Instead of using Table of dnFpoints I add an alternative method for calculation of dnF function.
dnF[ln_] := 
  1/( 4c Pi^3 10^18 ) NIntegrate[ daF[li] / ( 1/li^2 - 1/ln^2 ), 
                                  { li, -\[Infinity],  ln, \[Infinity] }, 
                                  Method ->  ""PrincipalValue"", 
                                  Exclusions ->  Automatic  
                                ] // Quiet

In general one should choose appropriate options for NIntegrate like PrecisionGoal and MaxRecursion  however in this case it is quite sufficient to use Quiet for evaluating of dnF function without outputting any messages generated.
Now we can plot dnF function  increasing appropriately a range of the dependent variable, e.g. :
Plot[dnF[ln], {ln, 30, 900}, AxesOrigin -> {0, 0}, PlotPoints -> 200]


"
list manipulation - Finding time-series direction reversal of certain magnitude,"
You seem to be on the right track.  If I understand your question I believe this will help:
f = If[#2 + 4 <= #, -∞, Max[##]] &;

FoldList[f, ts]

Position[%, -∞, {1}]

(See Shorter syntax for Fold and FoldList? regarding FoldList[f, ts].) 
The above assumes that you want to reset the new maximum to the value after the reversal (3).
If you want to reset it to the reversal point value itself, try this:
f = If[#2 + 4 <= Max@#, {#2}, Max[##]] &;

FoldList[f, ts]

Position[%, {_}, {1}]


I argue the superiority of the FoldList method over Module/MapIndexed.  The latter introduces a variable that it does not need to, it is longer, and it is slower.
SeedRandom[1]
ts = RandomInteger[20, 50000];

Timing[
  r1 =
   Module[{max = -∞}, 
       MapIndexed[(max = Max[max, #1]; 
           If[max - #1 >= 4, Sow[#2]; max = -∞;]) &, ts];] //
       Reap // Last // Flatten;
]


{0.1966, Null}

f = If[#2 + 4 <= #, -∞, Max[##]] &;

Timing[
  r2 = Join @@ Position[FoldList[f, #, {##2}] & @@ ts, -∞, 1];
]


{0.0874, Null}

r1 === r2


True

"
performance tuning - Function does not compile with Greater in it,"
The following seems to work based on what I assumed would be valid input.
compiledFunc = 
  Compile[{{w, _Real, 2}, {v, _Integer, 1}, {hb, _Real, 
     1}, {vb, _Real, 1}}, 
   Module[{h, hs, vr, hr, rr}, h = 1./(1. + Exp[-(w.v + hb)]);
    rr = RandomReal[{0, 1}, Length@hb];
    rr = h - rr;
    hs = UnitStep[rr] Unitize[rr];
    vr = 1./(1. + Exp[-((Transpose@w).hs + vb)]);
    hr = 1./(1. + Exp[-(w.vr + hb)]);
    w + (0.01*(Outer[Times, h, v] - Outer[Times, hr, vr]))], 
   Parallelization -> True];

Edit:
Since you are comparing to random reals we can safely assume none of the elements of hb will ever equal the pseudo-random values and remove the Unitize[rr] from the code. The above is for a more general comparison where equality can occur. Here is the cleaned up but less general version.
compiledFunc = 
  Compile[{{w, _Real, 2}, {v, _Integer, 1}, {hb, _Real, 
     1}, {vb, _Real, 1}}, 
   Module[{h, hs, vr, hr}, h = 1./(1. + Exp[-(w.v + hb)]);
    hs = UnitStep[h-RandomReal[{0, 1}, Length@hb]];
    vr = 1./(1. + Exp[-((Transpose@w).hs + vb)]);
    hr = 1./(1. + Exp[-(w.vr + hb)]);
    w + (0.01*(Outer[Times, h, v] - Outer[Times, hr, vr]))], 
   Parallelization -> True];

As for the second part of the question, apparently Compile doesn't like Boole being applied outside of MapThread. OleksandrR explained why in the comments. Compile cannot work with the boolean tensor that is created by MapThread. You can replace the line with 
MapThread[Boole[#1 > #2] &, {h, RandomReal[{0, 1}, Length@hb]}]

and it should work.
"
evaluation - With/Function(/etc) replacement behaviour,"
You were asking why
f[_?NumericQ] := 8

With[{a = f[a]}, Block[{NumericQ = True &}, a]]

outputs f[a].
This is because of caching of the result of Conditions and PatternTests.  Compare with this:
With[{a = f[a]}, Block[{NumericQ = True &}, Update[]; a]]

(* ==> 8 *)

Generally, making global changes that might affect the outcome of a Condition will have unpredictable results due to caching---unless you use Update[] after each change.
Please see also the last paragraph of Controlling Infinite Evaluation.
"
programming - ParallelTable and Table do not give same result,"
Why the unexpected result?
You quoted the documentation:

Parallelize[Table[expr,iter, …]] (which is equivalent to
ParallelTable[expr,iter,…]) will give the same results as Table,
except for side effects during the computation.

The explanation why the parallelized version returns an incorrect result is that your code does have side effects: you are using Set (i.e. =) to change the elements of an array.
What is a side effect?
Let me illustrate using ParallelMap:
If we have a list of values list = {1, 2, 3, 4, 5, 6, 7, 8}, and we wish to evaluate a function for all these values, we can use Map:
f /@ list

This is easily parallelized to two processors by splitting the list into two parts (list1 = {1, 2, 3, 4} and list2 = {5, 6, 7, 8}), sending them to two different Mathematica kernels running on these two processors, and performing the map operation on the two sublists separately:
f /@ list1 (* evaluated on processor 1 *)
f /@ list2 (* evaluated on processor 2 in parallel *)

The reason this works at all is that these two operation are completely independent: the result of one does not depend on the evaluation of the other.
Actually this is only true if f is a function in the mathematical sense: it simply takes an input and produces an output, but computing its value does not change the ""outside world"" (the Mathematica kernel's user-visible state) in any way.  Examples: Sin is a function without side effects in this sense.  Print is not without side effect because while its value is being computed (it always returns Null), the outside world changes: something appears on your screen.  Set also has side effects because it induces permanent outside changes again: the value of a variable will be different after evaluating Set.
If our function f has side effects then there is no guarantee that {f[1], f[2]} will give the same result as {f[2], f[1]} because evaluating f[1] might change the environment in a way that will affect the outcome of f[2].  The order of evaluation might matter, so parallelization cannot work reliably (the order of evaluation is unpredictable in any kind of parallel evaluation).
You are using Set (i.e. =) in your code, which has side effects.  What actually happens is that a copy of arrayToBeFilled is sent to both subkernel 1 and subkernel 2, and different parts of the array are changed on the two subkernels.  But the changed arrayToBeFilled is not being sent back to the main kernel (which one should be sent back at all?  the one on subkernel 1 or the one on subkernel 2?  they are different because different indices have been changed on the two subkernels)
How to make the code auto-parallelizable?
We just need to write the expression to be computed in a way that avoids side effects:
arrayToBeFilled = 
   Parallelize[Map[If[# <= 0, # + 5, # - 5] &, arrayA]]; // AbsoluteTiming

This is both much faster and parallelizable.  In fact it's so fast that when the array is only 1000 elements long the parallelization overhead will just slow the computation down.  (For much larger arrays though it will speed it up.)
"
syntax - Working with PhysicalConstants,"
As J.M. comments, but opts not to post as an answer, you can use Convert in the Units package to convert between types.  Be sure to read the documentation on that package.
Needs[""Units`""]

Convert[(32.5 Newton)/(7 Meter/Second^2), Kilogram]


4.64286 Kilogram

You will also find use in the Automatic Units package described on the Wolfram Blog.
"
interoperability - Web Browsing Automation with Mathematica,"
Here is a package which does what you want:
https://github.com/arnoudbuzing/webunit
Clone the repository from github, and place the WebUnit folder under $UserBaseDirectory/Applications
To use it:

Needs[""WebUnit`""]
InstallWebUnit[] (* launches chromedriver.exe *)
StartWebSession[] (* launches Chrome web browser, assuming you have that installed *)
OpenWebPage[""http://mathematica.stackexchange.com""] (* opens the web page *)
ClickElement[Id[""nav-users""]] (* clicks the web element 'nav-users' the users tab *)

And then TypeElement works similarly (assuming you have an input field with an id).
Edit: You can also use JavascriptExecute[""alert('hi');""] to execute arbitrary javascript (in this example case it brings up the alert dialog).
"
plotting - How can I set the ratio of the axis to 1:1 when plotrange->1 or how can I scale a rectangle according to the axis,"
Depending on your needs is may be both simpler and more flexible to bypass ListPlot completely and do this directly in Graphics.  Here is a simple example:
dat = RandomReal[11, {15, 2}];

Graphics[{
   {Hue @ RandomReal[], Rectangle[# - 0.5]} & /@ #,
   {GrayLevel[.3], PointSize[.02], Point@#, Thick, Line@#}
  },
  AspectRatio -> 0.5,
  Frame -> True
] & @ dat


"
plotting - How to plot planar graphs as such?,"
You can plot it using the GraphLayout option, which has, since v9, ""PlanarEmbedding"" as a possible value:
Graph[Rule @@@ {{1, 2}, {2, 3}, {3, 1}, {1, 4}, {3, 4}, {2, 4}}, GraphLayout -> ""PlanarEmbedding""]

.
(BTW: This is the standard Mathematica Graph, not the Combinatorica Graph function)
Another one:
truncatedCube =
  {{0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1}, {1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1}, 
   {1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1}, {1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0}, 
   {0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0}, {1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0}, 
   {0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0}, 
   {0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, 
   {0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0}, 
   {0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}};

AdjacencyGraph[truncatedCube, 
  GraphLayout -> ""PlanarEmbedding"", 
  VertexLabels -> Array[# -> # &, Length @ truncatedCube], 
  PlotRangePadding -> 0.5]


Without GraphLayout -> ""PlanarEmbedding"":

"
How to force Compile to return multiple results?,"
What about making the result uniform inside Compile and constructing things back afterwards? Like
   cFunc = Compile[
       {{a, _Integer, 1}}, 
       Join @@ {a, {a . a}}]; 
cFunc[{1, 3}]
Function[z, {Most[z], 
       Last[z]}][%]

which has the nice feature of not calling MainEvaluate:
    Needs[""CompiledFunctionTools`""]; cFunc // CompilePrint

(* 
==>
    1 argument
        2 Integer registers
        3 Tensor registers
        Underflow checking off
        Overflow checking off
        Integer overflow checking on
        RuntimeAttributes -> {}

        T(I1)0 = A1
        I0 = 4
        Result = T(I1)2

1   I1 = DotVV[ T(I1)0, T(I1)0, I0]]
2   T(I1)1 ={ I1 }
3   T(I1)2 = Join[ T(I1)0, T(I1)1]]
4   Return

*)

"
Workbnch Profil[] qustion - Mathmatica Stack Exchang,"
If you can settle for anything other than Workbench's Profile, here is a simplistic profiler function with a fairly low latency:
ClearAll[profile];
SetAttributes[profile, HoldAll];
profile[code_] :=
  Block[{$totalTime = 0, t, res, time,exclude},
     SetAttributes[{time, exclude}, HoldAll];
     exclude[cd_] := 
       (t = AbsoluteTime[];res = cd; $totalTime -= AbsoluteTime[] - t; res);
     time[cd_] := 
       (t = AbsoluteTime[];res = cd; $totalTime += AbsoluteTime[] - t; res);
     {code, $totalTime}];

To illustrate how you can use it:
b[] := Do[Range[10], {100}];
aa[] :=
  Module[{},
     Pause[2];
     Do[time@b[], {1000}];
     Pause[3];
  ];

Note that I inserted time wrapper in the place in the code which I want to profile. All invocations of time will add up:
profile[aa[]]

(*
   ==> {Null, 0.0791}
*)

Note that profile has some overhead, but it seems to at least give the right order of magnitude for the result:
a[] :=
  Module[{},
     Pause[2];
     time@Do[b[], {1000}];
     Pause[3];
  ]; 

profile[a[]]

(*
   ==> {Null,0.0781250}
*)

The granularity may be not as good as in Profile, but in case it is not enough (meaning you are timing something very fast), you should try to wrap time around pieces of code where your very fast operation is repeated (like loops). You can wrap pieces inside those which you want to exclude, in the exclude wrapper. Obviously, the code or functions it uses should not use the symbols time and exclude for other purposes, but this is easy to fix by placing profile into a separate context / package.
"
programming - Deploying Mathematica Content Online,"
You cannot use CDF for this because you have textual import fields and these are not supported when you embed online. You will just get a big grey box. InputField cannot accept strings (non-numeric) for online CDFs unless you are Wolfram Research and can override it. (I'm guessing you don't want to pay many thousands for CDF Pro.)
You also cannot import and export into an online embedded CDF, not even a Pro CDF (got that first hand from Wolfram). This is for security reasons.
So to create something like you have described using Mathematica and have online, the only possible way to do it, it would seem, is to use webMathematica. 
"
matrix - Take[] and other Mathematica functions with live streams,"
The question doesn't provide enough specifics to give a very detailed answer but here are a couple of things that might help get you started.
First, here I use my webcam's CurrentImage with ColorConvert to create a live grayscale video.  Note the semicolon.  If you are going to be doing a lot of dynamic video stuff the additional outputs will slow things down.
img = Dynamic@ColorConvert[CurrentImage[], ""Grayscale""];

There are a whole host of image processing capabilities that I would try first before digging into the matrix data themselves.  Chances are good, you will find what you want there without having to reinvent the wheel.  Here I use ImagePartition to break the image live video into blocks 64x64 pixels. Note the use of Dynamic.  This ensures that this updates rather than grabbing the value of img at evaluation.
Dynamic[ImagePartition[img[[1]], 64]]

Now if you don't find what you need in image processing you can still get the image data. Here I obtain the first 18x12 matrix of color values using ImageData and Part.  
Dynamic[ImageData[img[[1]]][[1 ;; 18, 1 ;; 12]]]

Some notes: 
One reason you might have been having difficulty is that the head of img is Dynamic not Image.  This is why I take img[[1]] every time I use it.
In[119]:= Head[img]

Out[119]= Dynamic

In[120]:= Head[img[[1]]]

Out[120]= Image

Also, you want to make sure you save very often and that you are familiar with the menu command Evaluation>Dynamic Updating Enabled.  Working with live video will cause you a number of headaches and you don't want to lose hard work.'
Edit: 
In response to the answer to your own question. First off, you've placed ""Byte"" in the wrong place. It should be an argument to ImageData.  Once you've fixed that it should just work.  Here is my interpretation of the 1/2 byte data for the first 18x12 submatrix.
Dynamic[Floor[ImageData[img[[1]], ""Byte""][[1 ;; 18, 1 ;; 12]]/2]]

Edit 2:
Now if you want the Mean of this dynamic byte data we could use
rawimg = Dynamic[Floor[ImageData[img[[1]], ""Byte""][[1 ;; 18, 1 ;; 12]]/2]];

Dynamic[Mean[rawimg[[1]]]]

"
import - Importing .txt or .csv financial data,"
Overall, your data is just badly formatted. For instance, later in the list your dates look similar to ""3-Mar"" which is interpreted as the third of March not March 2003, as you intended. For the most part, this is not your fault, but Excel arbitrarily formats data, and you have to be vigilant that it doesn't misinterpret it. Towards that end, I've rewritten my answer to work around the misformatting.
First things first, your numeric data is formatted with commas, so we need to get rid of them.
killCommas[a_String] := StringReplace[a, "","" -> """"]
killCommas[a_] := a

Second, your dates, as I said above, are misformatted. The code, below, splits the date at ""-"", checks if the numeric part has length 1 and prepends it with a ""0"" if it does, sorts the two strings by length, reverses the sort, and puts them back together with ""-"" between. 
fixDate[a_String] := StringJoin@
  Riffle[Reverse[
    If[StringLength[#] == 1, ""0"" <> #, #] & /@ 
     SortBy[StringSplit[a, ""-""], StringLength]],
   ""-""]

Now, I strip off the header from the list
dat = Import[<txt url>, ""TABLE""][[2 ;;]] 

and using the helper functions, I fix all of the data:
{DateList[{fixDate[#1], {""MonthNameShort"", ""YearShort""}}],
   Sequence @@ ToExpression[ killCommas /@ {##2}]} & @@@ dat

"
guidelines - How to compile effectively?,"
I'll just throw in a few random thoughts in no particular order, but this will be a rather high-level view on things. This is necessarily a subjective exposition, so treat it as such.
Typical use cases
In my opinion, Compile as an efficiency-boosting device is effective in two kinds of situations (and their mixes):

The problem is solved most efficiently with a procedural style, because for example an efficient algorithm for it is formulated procedurally and does not  have a simple / efficient functional counterpart (note also that functional programming in Mathematica is peculiar in many respects, reflecting the fact that functional layer is a thin one on top of the rule-based engine. So, some algorithms which are efficient in other functional languages may be inefficient in Mathematica). A very clear sign of it is when you have to do array indexing in a loop.
The problem can be solved by joining several Compile-able built-in functions together, but there are (perhaps several) ""joints"" where you face the performance-hit if using the top-level code, because it stays general and can not use specialized versions of these functions, and for a few other reasons. In such cases, Compile merely makes the code more efficient by effectively type-specializing to numerical arguments and not using the main evaluator. One example that comes to mind is when we compile Select with a custom (compilable) predicate and can get a substantial performance boost (here is one example).

I use this rule of thumb when determining whether or not I will benefit from Compile: the more my code inside Compile looks like C code I'd write otherwise, the more I benefit from it (strictly speaking, this is only true for the compilation to C, not MVM).
It may happen that some portions of top-level code will be the major bottleneck and can not be recast into a more efficient form, for a given approach to the problem. In such a case, Compile may not really help, and it is best to rethink the whole approach and try to find another formulation for the problem.  In other words, it often saves time and effort to do some profiling and get a good idea about the real places where the bottlenecks are, before turning to Compile.
Limitations of Compile
Here is an (incomplete) list of limitations, most of which you mentioned yourself

Can only accept regular arrays (tensors) of numerical or boolean types. This excludes ragged arrays and more general Mathematica expressions.
In most cases, can only return a single tensor of some type
Only machine-precision arithmetic
From the user-defined functions, only pure functions are compilable, plus one can inline other compiled functions. Rules and ""functions"" defined with rules are inherently not compilable.
No way to create functions with memory (a-la static variables in C)
Only a small subset of built-in functions can be compiled to byte-code (or C)
Possibilities for writing recursive compiled functions seem to be very limited, and most interesting cases seem to be ruled out
No decent pass-by-reference semantics, which is a big deal (to me anyways)
You can not really use indexed variables in Compile, although it may appear that you can.
...

Whether or not to compile to C?
I think this depends on the circumstances. Compilation to C is expensive, so this makes sense only for performance-critical code to be used many times. There are also many cases when compilation to MVM will  give similar performance, while being much faster. One such example can be found in this answer, where the just-in-time compilation to MVM target led to a major speed-up, while compilation to C would have likely destroyed the purpose of it - in that particular case. 
Another class of situations when compiling to C is may not be the best option is when you want to ""serialize"" the CompiledFunction object, and distribute it to others, for example in a package, and you don't want to count on a C compiler being installed on the user's machine. As far as I know, there is no automatic mechanism yet to grab the generated shared library and package it together with the CompiledFunction, and also one would have to cross-compile for all platforms and automatically dispatch to the right library to load. All this is possible but complicated, so, unless the speed gain can justify such complications for a given problem, it may be not worth it, while compilation to MVM target creates the top-level CompiledFunction object, which is automatically cross-platform, and does not require anything (except Mathematica) to be installed.
So, it really depends, although more often than not compilation to C will lead to faster execution and, if you at all decide to use Compile, will be justified.
What to include in Compile
I share an opinion that, unless you have some specific requirements, it is best to only use Compile on minimal code fragments which would benefit from it the most, rather than have one big Compile. This is good because:

It allows you to better understand where the real bottlenecks are
It makes your compiled code more testable and composable
If you really need it, you can then combine these pieces and use ""InlineCompiledFunctions"" -> True option setting, to get all the benefits that one large Compile would give you
Since Compile is limited in what it can take, you will have less headaches on how to include some uncompilable pieces, plus less chances to overlook a callback to the main evaluator

That said, you may benefit from one large Compile in some situations, including:

Cases when you want to grab the resulting C code and use it stand-alone (linked against Wolfram RTL)
Cases when you want to run your compiled code in parallel on several kernels and don't want to think about possible definitions distribution issues etc (this was noted by @halirutan)

Listable functions
When you can, it may be a good idea to use the RuntimeAttributes -> Listable option, so that your code can be executed on (all or some) available cores in parallel. I will give one example which I think is rather interesting, because it represents a problem which may not initially look like one directly amenable to this (although it is surely not at all hard to realize that parallelization may work here) - computation of Pi as a partial sum, of a well-known infinite sum representation. Here is a single-core function:
Clear[numpi1];
numpi1 = 
   Compile[{{nterms, _Integer}}, 
      4*Sum[(-1)^k/(2 k + 1), {k, 0, nterms}], 
        CompilationTarget -> ""C"", RuntimeOptions -> ""Speed""];

Here is a parallel version:
numpiParallelC = 
  Compile[{{start, _Integer}, {end, _Integer}}, 
    4*Sum[(-1)^k/(2 k + 1), {k, start, end}], CompilationTarget -> ""C"",
       RuntimeAttributes -> Listable, RuntimeOptions -> ""Speed""];

Clear[numpiParallel];
numpiParallel[nterms_, nkernels_] := 
  Total@Apply[numpiParallelC, 
     MapAt[# + 1 &, {Most[#], Rest[#] - 1}, {2, -1}] &@
        IntegerPart[Range[0, nterms, nterms/nkernels]]];

Now, some benchmarks (on a 6-core machine):
(res0=numpiParallel[10000000,1])//AbsoluteTiming
(res1=numpiParallel[10000000,6])//AbsoluteTiming
(res2=numpi1[10000000])//AbsoluteTiming
Chop[{res0-res2,res0-res1,res2-res1}]

(*
 ==>
 {0.0722656,3.14159}
 {0.0175781,3.14159}
 {0.0566406,3.14159}
 {0,0,0}
*)

A few points to note here:

It may happen that the time it takes to prepare the data to be fed into a Listable compiled function, will be much more than the time the function runs (e.g. when we use Transpose or Partition etc on huge lists), which then sort of destroys the purpose. So, it is good to make an estimate whether or not that will be the case.
A more ""coarse-grained"" alternative to this is to run a single-threaded compiled function in parallel on several Mathematica kernels, using the built-in parallel functionality (ParallelEvaluate, ParallelMap, etc). These two possibilities are useful in different situations.

Auto-compilation
While this is not directly related to the explicit use of Compile, this topic logically belongs here. There are a number of built-in (higher-order) functions, such as Map, which can auto-compile. What this means is that when we execute
Map[f, list]

the function f is analyzed by Map, which attempts to automatically call Compile on it (this is not done at the top-level, so using Trace won't show an explicit call to Compile). To benefit from this, the function f must be compilable. As a rule of thumb, it has to be a pure function for that (which is not by itself a sufficient condition) - and generally the question of whether or not a function is compilable is answered here in the same way as for explicit Compile. In particular, functions defined by patterns will not benefit from auto-compilation, which is something to keep in mind. 
Here is a little contrived but simple example to illustrate the point:
sumThousandNumbers[n_] := 
   Module[{sum = 0}, Do[sum += i, {i, n, n + 1000}]; sum]

sumThousandNumbersPF = 
   Module[{sum = 0}, Do[sum += i, {i, #, # + 1000}]; sum] &

Now, we try:
Map[sumThousandNumbers, Range[3000]]//Short//Timing
Map[sumThousandNumbersPF, Range[3000]]//Short//Timing

(*
  ==> {3.797,{501501,502502,503503,504504,505505,<<2990>>,3499496,
               3500497,3501498,3502499,3503500}}

      {0.094,{501501,502502,503503,504504,505505,<<2990>>,3499496,
               3500497,3501498,3502499,3503500}}
*)

which shows a 40-times speedup in this particular case, due to auto-compilation.
There are in fact many cases when this is important, and not all of them are as obvious as the above example. One such case was considered in a recent answer to the question of extracting numbers from a sorted list belonging to some window. The solution is short and I will reproduce it here:
window[list_, {xmin_, xmax_}] := 
    Pick[list, Boole[xmin <= # <= xmax] & /@ list, 1]

What may look like a not particularly efficient solution, is actually quite fast due to the auto-compilation of the predicate Boole[...] inside Map, plus Pick being optimized on packed arrays. See the aforementioned question for more context and discussion.
This shows us another benefit of auto-compilation: not only does it often make the code run much faster, but it also does not unpack, allowing surrounding functions to also benefit from packed arrays when they can.
Which functions can auto-compile? One way to find out is to inspect SystemOptions[""CompileOptions""]:
Cases[""CompileOptions""/.SystemOptions[""CompileOptions""],
      opt:(s_String->_)/;StringMatchQ[s,__~~""Length""]]

{""ApplyCompileLength"" -> \[Infinity], ""ArrayCompileLength"" -> 250, 
 ""FoldCompileLength"" -> 100, ""ListableFunctionCompileLength"" -> 250, 
 ""MapCompileLength"" -> 100, ""NestCompileLength"" -> 100, 
 ""ProductCompileLength"" -> 250, ""SumCompileLength"" -> 250, 
 ""TableCompileLength"" -> 250}

This also tells you the threshold lengths of the list beyond which the auto-compilation is turned on. You can also change these values. Setting the value of ...CompileLength to Infinity is effectively disabling the auto-compilation. You can see that ""ApplyCompileLength"" has this value. This is because it can only compile 3 heads: Times, Plus, and List. If you have one of those in your code, however, you can reset this value, to benefit from auto-compilation. Generally, the default values are pretty meaningful, so it is rarely necessary to change these defaults. 
A few more techniques
There are a number of techniques involving Compile, which are perhaps somewhat more advanced, but which sometimes allow one to solve problems for which plain Compile is not flexible enough. Some which I am aware of:

Sometimes you can trade memory for speed, and, having a nested ragged list, pad it with zeros to form a tensor, and pass that to Compile.
Sometimes your list is general and you can not directly process it in Compile to do what you want, however, you can reformulate a problem such that you can instead process a list of element positions, which are integers. I call it ""element-position duality"". One example of this technique in action is here, for a larger application of this idea see my last post in this thread (I hesitated to include this reference because my first several posts there are incorrect solutions. Note that for that particular problem, a far more elegant and short, but somewhat less efficient solution was given in the end of that thread). 
Sometimes you may need some structural operations to prepare the input data for Compile, and the data contains lists (or, generally, tensors), of different types (say, integer positions and real values). To keep the list packed, it may make sense to convert integers to reals (in this example), converting them back to integers with IntegerPart inside Compile. One such example is here 
Run-time generation of compiled functions, where certain run-time parameters get embedded. This may be combined with memoization. One example is here, another very good example is here
One can emulate pass-by-reference and have a way of composing larger compiled functions out of smaller ones with parameters (well, sort of), without a loss of efficiency. This technique is showcased for example here
A common wisdom is that since neither linked-lists, nor Sow-Reap are compilable, one has to pre-allocate large arrays most of the time, to store the intermediate results. There are at least two other options:

Use Internal`Bag, which is compilable (the problem however is that it can not be returned as a result of Compile as of now, AFAIK).
It is quite easy to implement an analog of a dynamic array inside your compiled code, by setting up a variable which gives the current size limit, and copy your array to a new larger array once more space is needed. In this way, you only allocate (at the end) as much space as is really needed, for a price of some overhead, which is often negligible.

One may often be able to use vectorized operations like UnitStep, Clip, Unitize etc, to replace the if-else control flow in inner loops, also inside Compile. This may give a huge speed-up, particularly when compiling to MVM target. Some examples are in my comments in this and  this blog posts, and one other pretty illustrative example of a vectorized binary search in my answer in this thread
Using additional list of integers as ""pointers"" to some lists you may have. Here, I will make an exception for this post, and give an explicit example, illustrating the point. The following is a fairly efficient function to find a longest increasing subsequence of a list of numbers. It was developed jointly by DrMajorBob, Fred Simons and myself, in an on and off-line MathGroup discussion (so this final form is not available publicly AFAIK, thus including it here)

Here is the code
Clear[btComp];
btComp = 
Compile[{{lst, _Integer, 1}}, 
   Module[{refs, result, endrefs = {1}, ends = {First@lst}, 
      len = Length@lst, n0 = 1, n1 = 1, i = 1, n, e}, 
     refs = result = 0 lst;
     For[i = 2, i <= len, i++, 
        Which[
          lst[[i]] < First@ends, 
             (ends[[1]] = lst[[i]]; endrefs[[1]] = i; refs[[i]] = 0),
          lst[[i]] > Last@ends, 
             (refs[[i]] = Last@endrefs;AppendTo[ends, lst[[i]]]; AppendTo[endrefs, i]), 
          First@ends < lst[[i]] < Last@ends, 
             (n0 = 1; n1 = Length@ends;  
              While[n1 - n0 > 1, 
                n = Floor[(n0 + n1)/2];
                If[ends[[n]] < lst[[i]], n0 = n, n1 = n]];
                ends[[n1]] = lst[[i]];
                endrefs[[n1]] = i;
                refs[[i]] = endrefs[[n1 - 1]])
        ]];
        For[i = 1; e = Last@endrefs, e != 0, (i++; e = refs[[e]]), 
            result[[i]] = lst[[e]]];
        Reverse@Take[result, i - 1]], CompilationTarget -> ""C""];

Here is an example of use (list should not contain duplicates):
test = RandomSample[#, Length[#]] &@ Union@RandomInteger[{1, 1000000}, 1000000];

btComp[test] // Length // Timing

The fastest solution based on built-ins, which is indeed very fast, is still about  6 times slower for this size of the list:
LongestCommonSequence[test, Sort@test] // Short // Timing

Anyways, the point here is that this was possible because of extra variables refs and endrefs, the use of which allowed to only manipulate single integers (representing positions of sub-lists in a larger list) instead of large integer lists.
A few assorted remarks

Things to watch out for: see this discussion for some tips on that. Basically, you should avoid

Callbacks to the main evaluator
Excessive copying of tensors (CopyTensor instruction)
Accidental unpacking happening in top-level functions preparing input for Compile or processing its output. This is not related to Compile proper, but it happens that Compile does not help at all, because the bottleneck is in the top-level code. 

Type conversion I would not worry about performance hit, but sometimes wrong types may lead to run-time errors, or unanticipated callbacks to MainEvaluate in the compiled code.
Certain functions (e.g. Sort with the default comparison function, but not only), don't benefit from compilation much or at all. 
It is not clear how Compile handles Hold- attributes in compiled code, but there are indications that it does not fully preserve the standard semantics we are used to in the top-level.
How to see whether or not you can effectively use Compile for a given problem. My experience is that with Compile in Mathematica you have to be ""proactive"" (with all my dislike for the word, I know of nothing better here). What I mean is that to use it effectively, you have to search the structure of your problem / program for places where you could transform the (parts of) data into a form which can be used in Compile. In most cases (at least in my experience), except obvious ones where you already have a procedural algorithm in pseudo-code, you have to reformulate the problem, so you have to actively ask: what should I do to use Compile here. 

"
How to sum up subelements of a list of unknown length,"
Use either 
Plus@@c

or
Total[c]

"
plotting - Day of the week vs time on BoxWhiskerChart,"
Assuming that the days and times in the gathered data list are strings you could do something like
days = {""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", 
   ""Saturday"", ""Sunday""};

data2 = Reap[
    Sow[(AbsoluteTime[#2] - AbsoluteTime[""00:00:00""])/3600., #1] & @@@
      Flatten[data, 1],
    days, #2 &][[2, All, 1]];

Show[BoxWhiskerChart[data2],
  FrameTicks -> {Thread[{Range[7], days}],
   {#, IntegerString[#, 10, 2] <> "":00""} & /@ Range[0, 24, 4],
   Thread[{Range[7], """"}], Thread[{Range[0, 24, 4], """"}]}]


"
equation solving - Using results of Reduce,"
You may want to look at the documentation for ToRules.  When applied to the output of Reduce you provided, the result is
Sequence[{x -> 1, y -> 1}, {x -> 1, y -> 2}, {x -> 1, y -> 3}, 
         {x -> 2, y -> 1}, {x -> 2, y -> 2}, {x -> 3, y -> 1}]

If you want to substitute this back to f[x,y], put curly braces to turn the sequence into a list and use ReplaceAll:
f[x,y] /. {%}

This will give the desired output {115000, 150000, 185000, 145000, 180000, 175000}.
"
number theory - Which DirichletCharacter is KroneckerSymbol?,"
I wrote this answer as I was figuring things out. If you just want the answer, copy the definitions of fundQ, Ast, ksFactors, foo, makeOneIndex and magicJ out of the code blocks below. You should have
DirichletCharacter[d, magicJ[d], n] == KroneckerSymbol[d, n]

Disclaimer 1: This answer is based on plausible interpretations of things not quite said in the DirichletCharacter documentation and tested for $-120 \leq d \leq 120$. To be sure it's right, you would have to actually look inside DirichletCharacter or find better documentation.
Disclaimer 2: $\newcommand{\KS}[2]{\left( \frac{#1}{#2} \right)}$ The set up of this question assumes that $d$ is a fundamental discriminant. I really need that. For $s$ odd, we have $\KS{-1}{2^b s} = (-1)^{(s-1)/2}$, so $\KS{-1}{n}$ is not periodic in $n$, and DirichletCharacter[k,j,n] is always periodic modulo $k$. So not all Kronecker symbols can be expressed as Dirichlet characters. Fortunately, the fundamental discriminants can. If you run magicJ[] on something which is not a fundamental discriminant, it objects. If you run the internal helper functions on something which is not a fundamental discriminant, I make no promises as to what will happen.

Here is a function to test whether $d$ is a fundamental discriminant:
fundQ[d_] := Switch[Mod[d, 4], 1, SquareFreeQ[d], 
                      0, SquareFreeQ[d/4] && (Mod[d/4, 4] == 2 || Mod[d/4, 4] == 3), 
                      _,  False]

discs = Select[Range[-120, 120], fundQ]
(* Out={-120, -119, -116, -115, -111, -107, -104, -103, -95, -91, -88, -87,  
        -84, -83, -79, -71, -68, -67, -59, -56, -55, -52, -51, -47, -43, -40, 
        -39, -35, -31, -24, -23, -20, -19, -15, -11, -8, -7, -4, -3, 1, 5, 8, 
         12, 13, 17, 21, 24, 28, 29, 33, 37, 40, 41, 44, 53, 56, 57, 60, 61, 
         65, 69, 73, 76, 77, 85, 88, 89, 92, 93, 97, 101, 104, 105, 109, 113, 120}

For any odd prime $p$, define $p^{\ast} = (-1)^{(p-1)/2} p$. Let $d = u 2^b (p_1^{\ast})^{a_1} (p_2^{\ast})^{a_2} \cdots (p_r^{\ast})^{a_r}$ with $u = \pm 1$ and $p_i$ distinct odd primes listed in increasing order. If $d$ is a fundamental discriminant then all the $a_i$ are $1$ and $u 2^b$ is one of $1$, $-4$, $8$ or $8$ so we will assume this from now on.
Here is some code to perform the above computations
 Ast[p_] := (-1)^((p-1)/2) p;

 ksFactors[d_] := 
   If[fundQ[d], Module[{facts = FactorInteger[d], primes},
         primes =Map[Ast, Select[Map[First, facts], (# != -1 && # != 2)&]];
         Prepend[primes, d/Product[p, {p, primes}]]], 
      ""Error: Not a fundamental discriminant""]

   ksFactors[120]
   (* Out={-8,-3,5} *)

Then we have 
$$\KS{d}{n} = \KS{u 2^b}{n} \prod \KS{p_i^{\ast}}{n}^{a_i}$$
For any odd prime $p$, the character $\KS{p^{\ast}}{n}$ is the unique nontrivial real Dirichlet character modulo $|p|$. According to the documentation, the real characters modulo $p$ will be in positions $1$ and $\phi(p)/2+1$, and the one in position $1$ will be trivial. 
Actually, the documentation (version 8) says ""Real Dirichlet characters modulo k have index $1$ or $\phi(k)/2+1$"", which would seem to say that those are the only two real Dirichlet characters. That can't be true since, in many cases, there are more than two real Dirichlet characters. However, it does appear to be true that the characters in those positions are always real. 
In any case, when $p$ is prime, there is only one nontrivial real Dirichlet character, namely $\KS{p^{\ast}}{n}$, and it appears in index $\phi(p)/2+1$. Also, for $p$ prime, $\phi(p)/2+1$ simplifies to $(p+1)/2$. Let's check that we're right so far:
Table[KroneckerSymbol[Ast[p], Range[4p]] == DirichletCharacter[p,(p+1)/2,Range[4p]], 
         {p,Prime[Range[2,20]]}]]

(* Out = {True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True} *)

Now, let's deal with the $\KS{u 2^b}{n}$ term. By trial and error, I found
KroneckerSymbol[1,n]==DirichletCharacter[1,1,n]
KroneckerSymbol[-4,n]==DirichletCharacter[4,2,n]
KroneckerSymbol[-8, n] == DirichletCharacter[8, 4, n]
KroneckerSymbol[8, n] == DirichletCharacter[8, 2, n]

Let's define a function to handle what we know so far
foo[x_] :=
    If[PrimeQ[Abs[x]] && Mod[x, 4] == 1, {Abs[x], (Abs[x] + 1)/2}];
foo[1] = {1, 1};
foo[-4] = {4, 2};
foo[-8] = {8, 4};
foo[8] = {8, 2};

map[foo, ksFactors[120]]
(* Out = {{8, 4}, {3, 2}, {5, 3}} *)

thing1 = Table[DirichletCharacter[8, 4, n]*DirichletCharacter[3, 2, n]*DirichletCharacter[5, 3, n], {n, 1, 120}];

thing2 = KroneckerSymbol[120, Range[120]];

thing1 == thing2
(* Out = True *)

We now need to combine all of those DirichletCharacters into a single term.
Look at the documentation of DirichletCharacter and scroll down to the portion of Properties and Relations beginning ""A character modulo $k$ can be written as a product of characters modulo prime powers..."". I've cut off the last bit of the quote because it is misleading; they say ""prime powers of $k$"" but they mean ""prime power factors of $k$"".
The documentation doesn't quite say the following, but it appears to be true: If $d=\prod_{i=1}^r p_i^{a_i}$, where the $p_i$ are primes listed in increasing order, and
$$j = 1+\sum_{i=1}^r (j_i-1) \cdot  \phi\left( \prod_{k=i+1}^r p_i^{a_i} \right)$$
then DirichletCharacter[d,j,n] is the product of the terms DirichletCharacter[p[i]^a[i], j[i],n].
Let's write some code to do this:
makeOneIndex[jList_] :=
  1 + Sum[
    (Last[jList[[i]]] - 1)*
    EulerPhi[Product[
       First[jList[[k]]], 
    {k, i + 1, Length[jList]}]], 
 {i, 1, Length[jList]}]

 magicJ[d_]:=
    If[fundQ[d], makeOneIndex[Map[foo, ksFactors[d]]], ""Not a fundamental discriminant""]

And let's test it:
Table[DirichletCharacter[d, magicJ[d], Range[d]] == KroneckerSymbol[d, Range[d]], {d, discs}]

 (* Out = {True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True} *)

"
equation solving - Arithmetic operation on the value returned by Solve,"
Try using
x + n /. First[SolC1]

(* ==> L/2 + n *)

If you need a new rule as the result, then you can do
x -> (x + n /. First[SolC1])

"
graphs and networks - Centrality measures for single nodes,"
Important note: The order in which BetweennessCentrality (or any other graph-related function, including AdjacencyMatrix) will return results is not the same as the order in which you passed vertices to Graph, nor is it the lexicographic order of vertices.  It is the order in which VertexList returns vertices.
Misunderstandings about this are a common source of error, so I thought it important to spell this out. Do not count on vertex n corresponding to the nth element in the result list.  Always use VertexList!
Now, an easy way to pick out the betweenness centrality of vertex is
Pick[BetweennessCentrality[graph], VertexList[graph], vertex]

Unfortunately it does not seem to be possible to compute the result for one vertex only.
To get the centrality of more than one node, contained in the list vertices, use 
Pick[BetweennessCentrality[graph], VertexList[graph], Alternatives @@ vertices]

To see all vertex names paired up with their centralities in a table, you can use
Grid[Transpose[{VertexList[graph], bc}]]

"
dfin a function from a list - Mathmatica Stack Exchang,"
Scan[] is your friend:
Scan[(f[First[#]] = Last[#]) &, 
  WaveletFilterCoefficients[DaubechiesWavelet[2], ""PrimalHighpass""]];
f[_] = 0;

??f
  Global`f
f[-2]=-0.0915064

f[-1]=-0.158494

f[0]=0.591506

f[1]=-0.341506

f[_]=0

"
plotting - How to plot layered graphs?,"
I was about to give this a second go and implement a layout algorithm manually based on Szabolcs's answer, when I realized that since v9, we have built-in options to lay out trees and directed acyclic graphs in the above specified layered way:
SetOptions[Graph, VertexLabels -> ""Name"", ImagePadding -> 10];
edges = {1 -> 2, 1 -> 3, 1 -> 5, 1 -> 8, 2 -> 4, 4 -> 6, 4 -> 7, 5 -> 10, 6 -> 9};
Prepend[
  Graph[edges, GraphLayout -> #, PlotLabel -> If[ListQ@#, Column@#, #]] & /@ {
  ""LayeredEmbedding"", {""LayeredEmbedding"", ""RootVertex"" -> 1}, 
  ""LayeredDigraphEmbedding"", {""LayeredDigraphEmbedding"", ""Orientation"" -> Left},
  {""LayeredDigraphEmbedding"", ""Tolerance"" -> .5}},
 LayeredGraphPlot[edges, Top, VertexLabeling -> True, PlotLabel -> ""LayeredGraphPlot""]]


Note that simple ""LayeredEmbedding"" still produces the wrong layout (1 is below 2), but now a ""RootVertex"" option can specify the root node. I've included LayeredGraphPlot for comparison. ""LayeredDigraphEmbedding"" was specifically added in v9 for directed acyclic graphs. Its submethod options can be used to tweak the position of the root, orientation and the tolerance used in terminating the energy minimization process.
One could get the vertex coordinates as follows:
coord = {};
Graph[edges, GraphLayout -> ""LayeredDigraphEmbedding"", 
  VertexShapeFunction -> (Disk[AppendTo[coord, #2 -> #1]; #1, .1] &)]
coord


{1 -> {0., 4.}, 2 -> {1., 3.}, 3 -> {-2., 3.}, 5 -> {-1., 3.}, 8 -> {0., 3.},
 4 -> {1., 2.}, 6 -> {0., 1.}, 7 -> {1., 1.}, 10 -> {-1., 2.}, 9 -> {0., 0.}}


Check out the GraphLayout option because it contains some more layout methods in v9!
"
linear algebra - Can Eigenvalues[] and Eigenvectors[] be assumed to return the same ordering?,"
If you need to be sure that the order is correct, there is a function Eigensystem that returns a list of both the eigenvalues and -vectors, which is in the right order.
{eValues, eVectors} = Eigensystem[{{2, 0}, {0, 1}}];
eValues
eVectors


{2, 1}
{{1, 0}, {0, 1}}


It's probably worth using just for the slight off-chance that Eigenvalues and Eigenvectors do not yield the same order (not sure about whether this may or may not happen), which will be really painful to debug.
"
functions - Using a PatternTest versus a Condition for pattern matching,"
I usually consider PatternTest as local to a specific pattern such as x_Integer?Positive and Condition as more general, often involving multiple patterns, e.g.:
f[x_, y_] /; x+y < 10 := x*y

An aspect of PatternTest that is different from Condition is that it is automatically applied to each element of a sequence, whereas Condition applies to the whole.  A pattern such as __?EvenQ means a sequences of arguments all of which pass EvenQ.  Consider:
f2[x__?EvenQ] := . . .

This is awkward with Condition:
f1[x__] /; (And @@ EvenQ /@ {x}) := . . .

Furthermore the naive method above does not short-circuit on a failure therefore it will be inefficient.  This could be fixed but it will be even more clumsy.
Then consider the converse:
f3[x__] /; Plus[x] == 7 := . . .

To do this using PatternTest we would need to apply it to the entire expression f3[x__], complicating its form and risking unwanted evaluation or recursion.  (Counterexample: see my proposed solution to Quick way to use conditioned patterns when defining multi-argument function? for where I feel that PatternTest is the best way to proceed.)
There is one rather obscure (at least to me) yet very important use of Condition that extends this generality.

lhs := Module[{vars}, rhs /; test] allows local variables to be shared
  between test and rhs. You can use the same construction with Block and
  With.

This is quite unusual in Mathematica's patterns and assignments.  It allows execution of code as part of the definition, then testing by a condition based on the result.  If the condition fails, the pattern matcher then moves on to search for other matches.  The evaluation that occurred can produce side effects but otherwise Mathematica behaves as though the entire pattern (lhs := rhs assignment) did not match.
One elegant use of this functionality is the Trott-Strzebonski method for In-Place Evaluation.

Leonid wrote, and encouraged me to include here:

One other thing I want to mention is that with PatternTest, it is
  easier to inadvertently leak evaluation, while in Condition avoiding
  that is usually just a matter of inserting Unevaluated in a proper
  place. I discussed this topic to some extent here
Finally, there are some syntactic differences which are good to keep
  in mind, for example precedence-related issues like this one.


Rojo stated:

Another consequence of this shows when you want to store a pattern in
  a variable, or inject it with a With. ... Can't do that with Condition
  unless you want all the instances of the pattern in each definition to
  be the same.

As a rather contrived counter-example one can use Unique symbols in a pattern constructor:
pat[] := Pattern[#, _] /; # > 4 & @ Unique[]

f[a : pat[], b : pat[]] := {a, b}

f[5, 6]


{5, 6}

Of course it is better to use PatternTest for this, but I think it is useful to show that it can be done.
"
calculus and analysis - Equation of a line that is tangent to a curve at point,"
Certainly, there is a better way:
y[x_] := 2 x Sin[x]; a = Pi/2;
Collect[Normal[Series[y[x], {x, a, 1}]], x, Simplify]

Recall that the formula for a Taylor polynomial looks a bit like this:
$$f(x)=\color{red}{f(a)+f^\prime (a)(x-a)}+\frac{f^{\prime\prime}(a)}{2}(x-a)^2+\cdots$$
and reconciling this with the geometric interpretation of the Taylor polynomial as the best one-point osculatory (agrees at function and derivative values) approximation of a function shows why the approach works. I believe this should be a standard way to look at Taylor polynomials in the textbooks, if it already isn't.

Here is an equivalent approach:
Collect[InterpolatingPolynomial[{{{a}, y[a], y'[a]}}, x], x, Simplify]

This is based on the fact that the tangent line is the unique Hermite interpolating polynomial of degree $1$.

Certainly, one could do the plodding, ""traditional"" (whatever that means) approach:
y[x_] := 2 x Sin[x]; a = Pi/2;
Collect[y[a] + y'[a] (x - a), x, Simplify]

In any event, Solve[] is definitely unnecessary here.
"
output formatting - ScientificForm is not being applied,"
The result of that sum is an (exact) integer, so Mathematica will display every digit because they're all significant. To get the output you're looking for, you just have to convert the result to a floating point number using N.
ScientificForm[N@Sum[2^Binomial[n, 2], {n, 58, 3249}]]

"
Txt[] using Graphics - Mathmatica Stack Exchang,"
If you take out Method -> {""ShrinkWrap"" -> True} it works as I think you expect.
"
graphs and networks - Convert GraphPlot[]s with many nodes into something that's human-understandable,"
Your graph has many vertexes, while the exemplary graph you link to does not and this is why it looks so nice. Styling with pie charts is not a problem at all:
g = RandomGraph[{15, 43}];

vfc[{xc_, yc_}, name_, {w_, h_}] := 
 Inset[PieChart[{VertexDegree[g, name], VertexList[g] // Length}, 
   SectorOrigin -> {Automatic, .7}, 
   ChartStyle -> ""AvocadoColors""], {xc, yc}, Automatic, 
  VertexDegree[g, name]/30]

SetProperty[g, VertexShapeFunction -> vfc]


I by the way understand that you want more - to replace ""heavy"" sub-graphs by nodes reflecting their statistics. That could be done, but it is a bit messy and ambiguous, more of a research question. If I find time I may post a solution. 
Here is another angle at a quicker analysis. Automatic spatial layouts Mathematica uses for graph carry a lot of information too. We can use FindClusters to analyse it. I will remove directed and multiple edges for clear picture. To see clustering of regions, after you execute your code do this:
n = 10;(*number of clusters*)
grr = Graph[Union[Sort /@ gc], DirectedEdges -> False, GraphStyle -> 
      ""LargeNetwork"", VertexSize -> 0];
cls = ListPlot[FindClusters[AbsoluteOptions[grr, VertexCoordinates][[2]], n],
      PlotStyle -> ColorData[3, ""ColorList""]];
Show[grr, cls, BaseStyle -> PointSize[.01]]


"
plotting - adding labels to points in ListPlot,"
All plotting functions are just wrappers for Graphics objects. Show can be used to combine these objects, and that's one way of doing what you want here.
Take the following code as a starting point; you will of course have to tweak the positions of the labels (right now it's just a radial factor that offsets them). Note that I modified the data variable so that it includes $t$; it is now of the form {t, Re, Im}. The ListPlot will plot only the real and imaginary parts (data[[All, {2, 3}]]), while the Text passage also takes into account the value of $t$.
data = Table[{t, Re[5 Exp[I 5/2 t]], Im[5 Exp[I 5/2 t]]}, {t, 0, 6}];
dataPlot = ListPlot[data[[All, {2, 3}]], PlotStyle -> PointSize -> Large];
labels = Text[#[[1]], 1.1 #[[{2, 3}]]] & /@ data;
Show[
    dataPlot,
    Graphics[{Red, labels}],
    PlotRange -> 6 {{-1, 1}, {-1, 1}},
    AspectRatio -> 1
]




You can of course generalize this arbitrarily, e.g. color the labels differently, change font size etc. I kept the above to a minimum to avoid cluttering, the rest is up to you.
"
equation solving - Result of Reduce contains duplicate terms,"
I'll try to sum up here the answers given so far in comments:

if you work in a single period, you get the expected results:
In:=  Reduce[f'[x] == 0 && 0 <= x <= 2 Pi, x]
Out=  x == \[Pi]/2 || x == (3 \[Pi])/2

if you work on the whole real domain, you can get the expression to be reduced by using Simplify:
In:=  Simplify[Reduce[f'[x] == 0, x]]
Out=  C[1] \[Element] Integers && (\[Pi] + 2 x == 4 \[Pi] C[1] || \[Pi] + 4 \[Pi] C[1] == 2 x || 2 x == \[Pi] (3 + 4 C[1]))

the reason why you get one of the elements twice in the first place is that it's a double root.

"
How to add fill color to a 2D Graphics object?,"
I presume you are looking for FilledCurve.


"
Module vs DynamicModule for a dynamic variables in a grid. || Spelling Bee,"
This is because the object created by DynamicModule does not actually evaluate until it is displayed, therefore Grid has nothing to format other than the outer list.
words = {""lightning"", ""lightning"", ""cloudy""};

dynlist = 
  DynamicModule[{x = 0, t = 0},
    {
     #,
     Button[""Start"", t = Hold@AbsoluteTime[] - AbsoluteTime[]], 
     Button[Style[""\[Checkmark]"", Darker@Green], t = ReleaseHold[t]; x++],
     Button[Style[    ""\[Times]"",        Red  ], t = ReleaseHold[t]; x--],
     Dynamic[x],
     Dynamic[Clock[]; ReleaseHold[t]]
     }
    ] & /@ words;


ToString[ dynlist[[1]] ]


""DynamicModule[{x = 0, t = 0}, {lightning, Button[Start, t = \
  Hold[AbsoluteTime[]] - AbsoluteTime[]], Button[[Checkmark], t = \
  ReleaseHold[t]; x++], Button[[Times], t = ReleaseHold[t]; x--], \
  Dynamic[x], Dynamic[Clock[]; ReleaseHold[t]]}, DynamicModuleValues :>
  \ {}]""

You could build the rows inside the module:
Column[
 DynamicModule[{x = 0, t = 0},
    Grid@{{
     #,
     Button[""Start"", t = Hold@AbsoluteTime[] - AbsoluteTime[]], 
     Button[Style[""\[Checkmark]"", Darker@Green], t = ReleaseHold[t]; x++],
     Button[Style[    ""\[Times]"",        Red  ], t = ReleaseHold[t]; x--],
     Dynamic[x],
     Dynamic[Clock[]; ReleaseHold[t]]
     }}
    ] & /@ words]



Addressing your comment you could move the map operation inside Grid like this:
DynamicModule[{x, t},
 x[_] = 0;
 t[_] = 0;
 Grid[
  MapIndexed[
    {#, Button[""Start"", t[#2] = Hold@AbsoluteTime[] - AbsoluteTime[]], 
     Button[Style[""\[Checkmark]"", Darker@Green], 
      t[#2] = ReleaseHold[t[#2]]; x[#2]++], 
     Button[Style[""\[Times]"", Red], t[#2] = ReleaseHold[t[#2]]; 
      x[#2]--], Dynamic[x[#2]], 
     Dynamic[Clock[]; ReleaseHold[t[#2]]]} &,
   words
]]]


"
programming - RecurrenceTable not evaluated: mathematica just echoes input,"
As far as I can see with a quick look, you system is overdetermined.
You have to leave out s1[0, k] == 1
RecurrenceTable[
  {
   s1[n, k] == s1[-1 + n, -1 + k] + s1[n, -1 + k],
   s1[n, 0] == Boole[n == 0],
   s1[n, 1] == Boole[n <= 2]
   }, s1, {n, 0, 6}, {k, 0, 4}] // Grid

(*
1   1   1   1   1
0   1   2   3   4
0   0   1   3   6
0   0   0   1   4
0   0   0   0   1
0   0   0   0   0
0   0   0   0   0
*)

"
numerics - Is there any automatic differentiation package?,"
For anyone still interested in this: I'm working on an implementation of dual numbers for Mathematica which should allow you to calculate automatic derivatives of (hopefully) many programs.
Check it out on GitHub.
Here's a quick example of how to obtain the derivative of a programmatic function with a While loop (adapted from the documentation). It's a fixed point algorithm to solve an equation:
f[a_?NumericQ, x0 : _?NumericQ : 1.0] := 
 Module[{ x = x0, y, i = 0},
  While[(y = Cos[a x]) != x,
   x = y;
   i++
   ];
  x
 ];

It doesn't have a symbolic derivative:
Derivative[1] @ f
(* Derivative[1][f] *)

You can find the derivative of its first argument simply by passing a Dual with non-standard part equal to 1:
<<DualNumbers`
f[1.]
f[Dual[1., 1.]]
(* 0.739085 *)
(* Dual[0.739085, -0.297474] *)

The first argument of Dual is the function value and the second argument is the derivative at that point. Let's convince ourselves that this derivative is correct:
With[{h = 0.001, a = 1.0},
 (f[a + h] - f[a - h])/(2 h)
 ]
(* -0.297474 *)

Let's also check the derivative of the second argument:
f[1., Dual[1., 1.]]
(* Dual[0.739085, 1.86543*10^-14] *)

The derivative of the second argument is pretty much zero. This makes sense, of course, since small variations in the initial value in the fixed point search shouldn't influence the result.
"
system variables - Where can I permanently modify $Path?,"
You can add the following line:
AppendTo[$Path, FileNameJoin[{$UserBaseDirectory, ""ExtraPackges""}]]

to the file:
FileNameJoin[{$UserBaseDirectory, ""Kernel"", ""init.m""}]

init.m is described here, under ""more information"".

To do this automatically you can run:
With[
 {newPath = FileNameJoin[{$UserBaseDirectory, ""ExtraPackges""}]},
 PutAppend[
  Unevaluated @ AppendTo[$Path, newPath],
  FileNameJoin[{$UserBaseDirectory, ""Kernel"", ""init.m""}]
 ]
]

"
numerics - RootSearch for complex or multiple equations,"
You can use Solve to specify a range of interest.
In[10]:= Solve[{Tan[z] + I == (I) (z)^(-1/2), Abs[z]<=10}, z]

(*
Solve::incs: Warning: Solve was unable to prove that the solution set found is
 complete.
*)


Out[10]= {
 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   -7.132251035054214302104690186362585697068142403087646814465 - 

    0.842662781181162221826225669202853177237728217131893274490 I}]}, 

 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   -4.0072460838160107316714173702742991366776869325551029661934 - 

    0.7019645733961268997044074293090492296764597316326821770525 I}]}, 

 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   -0.9400640610224741334606974053019750421040015028175053694335 - 

    0.3643340656419651371252025602838905385545008341650161006297 I}]}, 

 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   0.42502056063258650274891169514957099586187780514338474096327 + 

    0.28887193948823718272333177173656870529846993666625322445517 I}]}, 

 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   3.0894479592377390694689578127850505603723837467810656253546 - 

    0.4659016059311814902662713357028283109716496004755022472595 I}]}, 

 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   6.2485902300197850812539412523087220367984004253401247062207 - 

    0.6952369865703343084749992220176303906987008887723814228223 I}]}, 

 {z -> Root[{-I + I Sqrt[#1] + Sqrt[#1] Tan[#1] & , 

   9.3988273465945532374205413428073199349703889446719754737117 - 

    0.8189381870367646618319736159465519157976282115012488727359 I}]}}


I doubt any roots were missed, warning message notwithstanding. But it can be iffy when dealing with functions that are not everywhere analytic in the region of interest.
"
parallelization - Efficiency of ParallelDo when a global variable./matrix is being updated,"
Is there any reason you can't directly construct the Table, as in:
DistributeDefinitions[a,b]
c1 = ParallelTable[b[[i, j]] + a[[i, j]], {j, 1, n}, {i, 1, n}]

On my machine, with n=500, Table[b[[i, j]] + a[[i, j]], {j, 1, n}, {i, 1, n}];// AbsoluteTiming takes 0.59 s, while ParallelTable takes only 0.16 s. With n=1000, Table takes 2.1s while ParallelTable takes only 0.47s.
For future reference, unlike in MATLAB or other languages, in Mathematica you do not need to first ""initialize"" the table, and then fill it.
"
graphics - Rectangle with rounded edges,"
Using pieces from the linked answers, and Heike's code:
Text piece:
 txt1 = Take[
 ExampleData[{""Text"", ""LoremIpsum""}, ""Lines""], {1, -1, 2}][[1]] //
 StringTake[#, 330] &;

Image piece:
 pic = Import[""http://dailytechgadgets.files.wordpress.com/2011/02/old-ferrari.jpg""];

And Heike's code for rectangles:
 rec[ll_, ur_, pic_] := 
 Module[{crop, boxrat}, 
 boxrat = #2/#1 & @@ MapThread[Abs[#2 - #1] &, {ll, ur}]; 
 crop = ImageCrop[pic, Transpose[{ImageDimensions[pic]}], 
 AspectRatio -> boxrat]; 
 Inset[crop, Min /@ Transpose[{ll, ur}], {Left, Bottom}, 
 Abs[ur - ll]]]

and Heike's code again for putting all together -- just adding RoundingRadius to rectangle objects and commenting out lines that produce lines--:
 Graphics[{EdgeForm[{Thickness[0.005`], Black}], FaceForm[White], 
 Rectangle[{0, 0}, {160, 90}, RoundingRadius -> 4], 
 FaceForm[Darker[Gray]], 
 Rectangle[{0, 0}, {80, 63}, 
 RoundingRadius -> 4],(*code for picture*){rec[{80, 0}, {160, 63}, 
 pic], FaceForm[Opacity[0]], 
 Rectangle[{80, 0}, {160, 63}, 
 RoundingRadius -> 4]},(*code for text*)
 Inset[Pane[
 Style[txt1, 12, TextAlignment -> Left], {Scaled[1], 
 Scaled[0.75`]}, Alignment -> Center, 
 ImageSizeAction -> ""Scrollable""], {0, 8}, {Left, Bottom}, {78,67}], 
 Flatten[Transpose[{Flatten[(Table[
      RandomChoice[{GrayLevel[0.15`], c0[[#1]]}], {3}] &) /@ 
   Range[2, 4, 1]], 
 MapThread[
  Function[{Xs, Ys}, 
   Rectangle[{Xs, Ys}, {Xs + 16, Ys + 9}, 
    RoundingRadius -> 4]], {Flatten[Table[Range[0, 32, 16], {3}]],
    Flatten[(Table[#1, {3}] &) /@ Range[63, 81, 9]]}]}]](*,{Black,
 Thickness[0.005`],Line[{{0,63},{159,63}}]}*)}, 
 PlotRange -> {{0, 160}, {0, 90}}, Method -> {""ShrinkWrap"" -> True}, 
 ImagePadding -> 2, ImageMargins -> 0, ImageSize -> 500]

produces:

You need further refinements to clean up. 
In particular, the image needs to be masked with a rectangle with rounded corners.
EDIT: For masking an image with a round-cornered reactangle, play with the parameters of Rectangle in
 pic2 = ImageAdd[ pic, 
 Graphics[{Black, Rectangle[{2, 1}, {4, 2}, RoundingRadius -> .2]}]]

Update: For better masking using SetAlphaChannel and better handling of image size (Thanks: @ssch and @Jens)
roundImage[img_, r_] := Module[{dim = ImageDimensions[img], sr}, 
sr = Max[dim]*r; 
SetAlphaChannel[img, 
   Graphics[{White, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}], RoundingRadius -> sr]},
 Background -> Black, PlotRangePadding -> 0, 
 PlotRange -> {{0, 0}, dim}\[Transpose], AspectRatio -> Automatic] ]]

"
parallelization - List of Parallelize[]-able functions,"
While I cannot answer the general question, I would like to point out that Parallelize does more than replace certain functions with their parallel versions.
Consider this:
Parallelize[{f[$KernelID], f[$KernelID], f[$KernelID], f[$KernelID]}]

(* ==> {f[2], f[2], f[1], f[1]} *)

Parallelize[f[$KernelID] + f[$KernelID] + f[$KernelID] + f[$KernelID]]

(* ==> 2 f[1] + 2 f[2] *)

Notice that Parallelize has evaluated instances of f in parallel even when they appeared in a more complex expression (in a list or in a sum)
The documentation mentions somewhere (I can't find where right now, if you do please edit it in) that a general way to parallelize the evaluation of a function f is to replace every instance of f by Composition[ParallelSubmit, f], then applying WaitAll to the whole expression.  (One must be careful to keep things in an unevaluated state before submitting the evaluations though.)
As an example, I copied the following possible (not actual) implementation of ParallelMap directly from a comment in the Parallel package:
ParallelMap[f_, h_[exprs___]] := 
    h @@ WaitAll[ Composition[ParallelSubmit,f] /@ {exprs} ]

This type of parallelization is not ideal though because it corresponds to using the finest granularity: each evaluation of f is submitted separately, one by one (not in batches), thus the overhead is large.
The sources of the parallel computing tools are available and are commented, so if you have time, you can try digging in the package to find the answer to the question.
Update From the Evaluate.m source file in the parallel computing tools package it appears that the following functions are treated specially by Parallelize:
Map, MapIndexed, MapThread, Scan, Apply, Outer, Inner, Dot, Through
Pick
Table, Sum, Product, Do, Array
Cases, Select
Count, MemberQ, FreeQ

Some other functions are treated specially as well.  I did not take the time to go through the source and understand it in detail.
The point I want to emphasize is that Parallelize seems to be able to parallelize very general expressions, but not all of them with the same quality (granularity)
"
list manipulation - Transform vector with lag,"
Assuming that the vector is called z and $n$ in your formula is the integer index of vector elements, use
x = Drop[z, 2] + 0.7 Drop[z, -2]

This adds the vector (sans the last two elements) to the vector times 0.7 with the first two elements removed (i.e. shifted by two elements to the left).  Of course the result will be 2 elements shorter than the original.  If this is not desired, you need to decide what $Z_0$ and $Z_{-1}$ should be and pad (PadLeft) z with these values.
This is likely the fastest possible solution in Mathematica.
EDIT
Another, also very fast possibility is
x = ListCorrelate[{0.7, 0, 1}, z]

ListCorrelate has settings for padding the arrays as well, if needed.
"
mathlink or wstp - Calling IronPython code from Mathematica,"
Being the fan of Mathematica<->CLR interop that I am, your question has inspired me to try to get IronPython fully working with Mathematica for the last couple of days.
I haven't yet had total luck. Part of my problem is that I don't have a Windows Mathematica license, so I can't fully double-check my work. While I'm trying to hunt down Mathematica for Windows, here's my work so far. There's a good chance it'll work fine for you.
Note: If it fails on one of the LoadNETType[] lines, let me know. I had to recompile all of the .NET/Link binaries from source to link them against .Net 4.0. The binaries with Mathematica 8, at least on Mac, are linked against .NET 2.0 with an exuberant message that it works just fine with .NET 3.0 since they only added a few namespaces. Unfortunately, that's not much consolation for those of us IronPython users who need .NET 3.5 or newer.
(If it turns out that a version update is necessary on Windows as it was for me and you need instructions for the ""rebuild from source"", let me know in comments, and I can write up my build steps.)
(* .NET/Link ceremony *)
Needs[""NETLink`""]
InstallNET[]

(* This is one of the steps that doesn't really work for me,
   but I think it'll work on Windows. *)

ShowNETConsole[]

(* IronPython-specific imports *)

LoadNETAssembly[""/PATH/TO/IronPython.dll""]
LoadNETAssembly[""/PATH/TO/Microsoft.Scripting.dll""]
LoadNETType[""IronPython.Hosting.Python"", StaticsVisible -> True]
LoadNETType[""Microsoft.Scripting.SourceCodeKind""]

(* Transliteration of the first IronPython hosting example from
   http://www.voidspace.org.uk/ironpython/hosting_api.shtml *)

engine = IronPython`Hosting`Python`CreateEngine[]
st = SourceCodeKind`Statements
source = ""print 'Hello World'"";
script = engine@CreateScriptSourceFromString[source, st]
scope = engine@CreateScope[]
script@Execute[scope]

Note: You'll have to change /PATH/TO/ above (2 occurrences) to be the correct path to the IronPython binaries on your system. An alternative would be to install them in the GAC.
As I hinted in the code comments above, there's a pretty good crash-course on the IronPython hosting API on Michael Foord's blog.
"
"fitting - Using FindFit to fit $a\,b^t$: how to avoid introducing complex numbers?","
The solution
It's usually a very very very very good idea to plot your data to see what shape it roughly has in the beginning. In your case, it looks like this:

... wait, that's not an exponentially rising function! Of course $a\,b^t$ won't fit that, but $a\,b^{-t}$ might work, let's try:
FindFit[data, a*b^(-t), {a, b}, t]


{a -> 100.004, b -> 22099.8}


Tadaa :-)
Some further remarks
I have of course used the fact that $b^t=\left(\frac1b\right)^{-t}$ here. You could have fitted with your function as well, only that Mathematica chose inappropriate starting parameters. I do not know how Mathematica determines these, but I think assuming it uses something around 1 is reasonable. My impression is always that it favors large to small numbers, but I wouldn't count on that.
You can specify starting parameters like this:
FindFit[data, a*b^t, {{a, aStart}, {b, bStart}}, t]

This will tell Mathematica to use aStart and bStart initially; it will then continue to slighly alter these values to see whether the fit gets better.
""Wait, but if I don't know these parameters at all, how can I find good starting values out"" - here's one of the great powers of Mathematica: easy interactivity. Simply code a Manipulate environment where you can set the parameters yourself, like this:
Manipulate[
    Show[
        ListLinePlot[data],
        Plot[a b^(-t), {t, 0, .10}, PlotStyle -> Red]
    ],
    {a, 0, 200},
    {b, 0, 50000}
]




Here you can play around with the parameters, until your function (in red) roughly matches the data. Read the values of the parameters, use them as starting values, get delicious fit.
Let's say you found out your starting parameters using Manipulate or from some solution manual (cough). Say your approximate values are $a\approx 100$, $b\approx10^{-5}$:
FindFit[data, a*b^t, {{a, 100}, {b, 10^(-5)}}, t]


{a -> 100.004, b -> 0.0000452493}


That's your textbook solution right there.
Another thing worth mentioning is NonlinearModelFit, the big brother of FindFit. It features not only fitting, it also generates a huge amount of extra data for statistical analysis, for example error estimates of the parameters and plotting confidence bands. Here's an example where I fitted a Gaussian point set with the theoretical curve:

"
graphics - How can this confetti code be improved to include shadows and gravity?,"

How can this code be improved, for example, by including shadows, raytracing or the effects of gravity to make it more realistic?

I felt that this question deserved an answer.  The one I describe here is to create a set of confetti ""agents"" that respond in quasi-physical ways to external forces and ""know"" how they should be displayed.
It is handy, and a whole lot of fun, to do this in an extensible and easily modified way, because you're going to think of loads of improvements to make once the framework is in place.  It helps to have well-documented code--there is less cognitive burden on you, the programmer, when modifying it--so I hope you won't mind that it's somewhat more verbose than usual.
By taking a top-down approach, this code practically writes itself.  Start with the agents themselves, the confetti:
update[confetto[symbols_, location_, frame_, momentum_, angularMomentum_], 
      force_, {t_, dt_}] := 
  With[{δMomentum = force[location, frame, momentum, t]},
   confetto[symbols, location + dt momentum, 
   rotate[frame, dt angularMomentum], 
   momentum + dt δMomentum, angularMomentum]
  ];

I have endowed a single ""confetto"" with information about how to draw it (symbols), its present location and momentum (location and momentum)--that is, its physical state--, and some internal state information (frame for the orientation and angular momentum for its rate of change: you will see the little pieces of paper rotate as they move).  That should be enough for rich simulations.  A simulation will proceed by applying update over time periods of short duration to update the state of each object.  This will rely on two other methods: force to compute forces and display to draw an object in its current state.
Update calls rotate to change the orientation, so let's take care of that detail now:
crossProduct[{x_, y_, z_}, {x0_, y0_, z0_}] := 
   {y z0 - y0 z, z x0 - z0 x, x y0 - x0 y};
rotate[frame_, α_] := # / (Norm[#] + 0.000001) & /@ 
      (Map[# + crossProduct[#, α] &, frame, {1}]);

(You can probably do this faster with quaternions, but this is good enough for a start.)
There are many ways to display a confetto, depending on what kind of object you would like it to be.  For instance--this will be relatively fast and is useful for testing--just draw a point as a visual placeholder:
display[confetto[symbols_, location_,  ___]] := {symbols, Point[location]}

You can get more information by drawing a ""tail"" showing how the objects have been moving:
display[confetto[symbols_, location_, frame_, momentum_, ___]] := 
    {symbols, Thick, Line[{location, location - 0.2 momentum}]}

To emulate the other examples offered in this thread, and to show how the angular momentum works, let's view each object as a square.  The frame attribute of a confetto determines its size and orientation.  At the same time we draw these objects, we also draw their ""shadows,"" provided they are in front of the coordinate planes. Here, then, is a fancier version of display:
shadow[x_, k_] /; 1 <= k <= Length[x] := ReplacePart[x, k -> 0];
display[confetto[symbols_, location_, frame_, ___]] := 
  Block[{x = frame[[1]], y = frame[[2]], vertices, objects, 
    shadowPlanes},
   vertices = {location + x, location + y, location - x, location - y};
   objects = {symbols, Polygon [vertices]};
   shadowPlanes = Pick[Range[Length[location]], Positive[location]];
   If [Length[shadowPlanes] > 0,
    f = Function[{k}, Polygon[shadow[#, k] & /@ vertices]];
    objects = Join[objects,
      {Opacity[0.5], GrayLevel[0.3], EdgeForm[{GrayLevel[0.3], Opacity[0.1]}]},
      f /@ shadowPlanes];
    ];
   objects
   ]

Write your own display function to simulate other objects.
Notice that none of this graphical work needs to get done except when we want to look at an object.  Thus, we could create a long simulation (using update) but call display only at key times, or when interesting things happen.  Separating the physics from the graphics is a good strategy.
Later on, to help the eye make sense of these shadows, we will want to have some fixed ""walls"" on which the shadows appear.
walls[indexes_List, size_, ϵ_] := 
  With[{square = {{1, 1}, {-1, 1}, {-1, -1}, {1, -1}}},
   {RGBColor[.97, .97, .97], Opacity[.1],
    Polygon /@ 
     Outer[Insert[ #2, ϵ, #1] &, indexes, size square, 1] 
    }
   ]

Update invokes a ""force"" function to change an object's momentum.  Newtonian gravitation on a flat earth is especially simple:
gravity[location_, frame_, momentum_, time_] := {0, 0, -1}

In general, the forces applied to an object depend on its location, the time (for time-varying forces), the object's location, and the situations of all other objects.  Handling the latter is complicated so I have not built it into this framework: only external forces are applied.  Here is a more complex example of what we can still do despite this limitation:
smokeRing[location_, frame_, momentum_, time_] := 
  Module[{normal = crossProduct @@ frame, origin = {15, 15, 15}, x,
    wind0 , ρ, z, wind1, wind, windSpeed = 5},
   x = location - origin;
   wind0 = {x[[2]], -x[[1]], 0};
   ρ = Sqrt[x[[1]]^2 + x[[2]]^2] ; 
   If[ρ == 0, ρ = 1];
   z = x[[3]] ;
   wind1 = {-z x[[1]] / ρ, -z x[[2]]/ ρ, ρ - 3};
   wind = (wind0  + wind1) windSpeed / Norm[x] - momentum;
    Abs[normal . wind] wind / Norm[wind] 
   ]

You can see it in action in the example below, where it has been added to the gravitational force.  If you would like to see this force field, (partial) visualizations can be drawn; e.g.,
VectorPlot3D[
    smokeRing[{x, y, z}, {{1, 0, 0}, {0, 0, 1}}, {0, 1, 0}, 0], 
        {x, 0, 30}, {y, 0, 30}, {z, 0, 30}]

Note, though, that the force on a confetto depends on its orientation and its momentum: this attempts a realistic simulation of what wind does to a small slip of paper.
You might like to write code for other kinds of forces.  Can you blow one smoke ring through another and then turn it green? :-)
We're all set to go!  Let's make some confetti.  I will place them all at the same location with the same orientation at the outset, but endow them with randomly varying momenta and angular momenta so that they all do different things:
r[n_] := RandomReal[NormalDistribution[0, 1], n];
confetti = 
  Table[confetto[
    Hue[RandomReal[]], {20, 20, 25}, {{1,0,0}, {0,1,0}}, r[3], r[3]/2], {320}]

To make them fly, we just need to keep updating their state as a clock ticks:
 Module[{c = confetti, speed = 0.06, nFrames = 240, 
    w = walls[Range[3], 30, e = -0.02], time = 0, slices, 
    force = Through[(gravity + smokeRing)[##]] &},
   slices = Table[time = time + speed; 
   c = ParallelMap[update[#, force, {time, speed}] &, c, {1}], {i, 1, nFrames}];
   frames = ParallelMap[Graphics3D[{w, Map[display, #, {1}]}, 
         PlotRange -> {{e, 29}, {e, 29}, {e, 29}},
         ViewVector -> {{70, 50, 40}, {-1, -1, -1}},
         Boxed -> False, ImageSize -> 400] &, Prepend[slices, confetti], {1}]
  ];

(You could anti-alias the graphics here if you like.  I find that the computation takes too long, so I have left it out.)  Through is a handy way to create combinations of forces: this gives you a manageable way to handle extremely complex combinations of additive forces.
That was a 30 second calculation, by the way: not fast, but not too shabby.
To keep the file size down, I have exported only some of these frames:
Export[""F:/temp/confetti4a.gif"", frames[[141 ;; 210]]]

Enjoy!

"
options - Passing down arguments,"
Are you looking for implementing option handling by any chance?
Here's a small demonstration of implementing the WorkingPrecision option for function fun, giving it a default value, and always passing it down to subfun.
Options[fun] = {WorkingPrecision -> MachinePrecision}

(* ==> {WorkingPrecision -> MachinePrecision} *)

fun[arg1_, OptionsPattern[]] := 
 subfun[arg1, WorkingPrecision -> OptionValue[WorkingPrecision]]

fun[1]

(* ==> subfun[1, WorkingPrecision -> MachinePrecision] *)

fun[1, WorkingPrecision -> 10]

(* ==> subfun[1, WorkingPrecision -> 10] *)

If you need to pass down every option, then @Mr.Wizard's solution is the right one.  To restrict it to options only (expressions of the form name -> value), use
ClearAll[fun]
fun[arg_, opt: OptionsPattern[]] := subfun[arg, opt]

fun[1, WorkingPrecision -> 10, someOptions -> ""value""]

(* ==> subfun[1, WorkingPrecision -> 10, someOptions -> ""value""] *)

"
What is the fastest way to locate an image inside a larger image?,"
Using ImageCorrelate, you can do something like
bbox[img_, crop_] := {#, # + Reverse@ImageDimensions[crop] - 1} &@
  Position[ImageData@
     Binarize[
      ImageCorrelate[img, crop, SquaredEuclideanDistance, 
       Padding -> None], .001], 0][[1]]

Example
img = ExampleData[{""TestImage"", ""Mandrill""}]
crop = ImageTake[img, {40, 80}, {141, 200}]

bbox[img, crop]


{{40, 141}, {80, 200}}


Edit
In response to the OP's question,here is an explanation of how bbox works.
ImageCorrelate in bbox creates a new image by calculating the Euclidean distance between crop and each of the sub images of img with the same dimensions as crop. The option Padding -> None is to make sure that the pixel at {i,j} in the result of ImageCorrelate corresponds to the sub image whose upper left corner is at position {i,j} in the original image. 
The Euclidean distance between two images is zero only if they are the same, so to find the position of crop in img we just need to extract the position of the pixels with value {0.,0.,0.} from the image data of ImageCorrelate which is what Position[ImageData@Binarize[....]], 0] does. 
This will give us the position of the upper left corner of crop. The lower right corner is then the upper-left corner plus the dimensions of crop (note that since ImageDimensions returns {number of cols, number of rows}, and the bounding box is given as {{rowMin, colMin}, {roxMaw, colMax}} we need to reverse ImageDimensions)
Edit 2
As Szabolcs pointed out, the cut off in Binarize is somewhat arbitrary, and might cause false positives. As an alternative you could do something like this instead, which would find the best fit in the image:
bbox[img_, crop_] := {#, # + Reverse@ImageDimensions[crop] - 1} &@
 (Position[#, Min[#]][[1]] &@
   ImageData[ColorConvert[
     ImageCorrelate[img, crop, SquaredEuclideanDistance, 
      Padding -> None], ""Graylevel""]])

"
programming - Visualizing several long lists of numerical information to see relative frequency,"
It seems to me that the zeros take up a lot of space and, if I understand the problem correctly, they aren't very useful in determining which works best match a particular search. 
Here is an alternative visualization that allows you to set thresholds on some basic statistics which ultimately allows you to ""zoom in"" on the works that are a best match under certain criteria. Note that it will drop any works where all word counts are zero (you can of course adjust this).
viewerCount2 = RandomChoice[viewerCount1, Length[viewerCount1]];
viewerCount3 = RandomChoice[viewerCount1, Length[viewerCount1]];

Manipulate[
 BarChart[Map[
   Tooltip[Most[#], Row[{""Work: "", Last[#], "" Counts: "", Most[#]}]] &,
    DeleteCases[
    Transpose@{viewerCount1, viewerCount2, viewerCount3, 
      Range[Length[viewerCount1]]}, {x__, w_} /; 
     Max[x] <= max || Mean[{x}] <= mean]], ChartLayout -> ""Stacked"", 
  ChartLegends -> {""word1"", ""word2"", ""word3""}], {max, 0, 20, 
  1}, {mean, 0, 10}]


"
list manipulation - How to Derive Tuples Without Replacement,"
Here is an alternative version of Mr. Wizard's uniqueTuples function, which is faster on the data I have tested.
The idea is to create a function f which has the following properties:

It returns an empty Sequence[] if two of its arguments are the same
For any other input it outputs a List of the arguments, but also
sets a downvalue so that next time it is called with the same
arguments, it returns an empty Sequence[]
It is Orderless so that ""the same arguments"" can be in any order

The two input lists are then processed by Outer, feeding each tuple (as a flattened sequence of arguments) to f.
For example, 

The list elements provided by Outer are {1,2,3} and 2. We evaluate f[1,2,3,2] which returns Sequence[] because 2 is duplicated.
The next list elements provided by Outer are {4,5,6} and 7.  We evaluate f[4,5,6,7] which returns {4,5,6,7} and sets f[4,5,6,7]=Sequence[].
The next list elements provided by Outer are {5,7,4} and 6.  We evaluate f[5,7,4,6] which is the same as f[4,5,6,7] and therefore returns Sequence[].

So the output from these 3 calls to f is just {4,5,6,7} as the others are not considered unique.
The alternative uniqueTuples looks like this:
(* this is the re-written bit *)
uniqueTuples[a_List, b_List] := Module[{f},
  f[___, x_, x_, ___] = Sequence[];
  f[x_, y__] := (f[x, y] = Sequence[]; {x, y});
  SetAttributes[f, Orderless];
  Flatten[Outer[f @@ Flatten[{##}] &, a, b, 1], 1]]

(* this is the same as Mr. Wizard *)
uniqueTuples[{a_List, x__List}] := Fold[uniqueTuples, a, {x}] 

Testing on data = RandomInteger[40, {6, 11}] gave me a Timing of 47.7 seconds for Mr. Wizards original code, and 6.6 seconds using this. I have no idea how the timings and memory usage scale as you go to larger data sets.
"
image processing - Measure a DensityHistogram[] pair similarity,"
We'll use SmoothKernelDistribution. Correlated pair with left data set reflected around y-axis:
lefTimagE = SmoothKernelDistribution[{-1, 1} # & /@ allSymFix[[3, 1]]];
righTimagE = SmoothKernelDistribution[allSymFix[[3, 2]]];

Visualize in 3D:
  Row@Plot3D[Evaluate[#], {x, -13, 13}, {y, -13, 13}, PlotRange -> All,
  MeshFunctions -> {#3 &}, Mesh -> 15, PlotPoints -> 50] & /@ 
  {PDF[lefTimagE, {x, y}], PDF[lefTimagE, {x, y}] PDF[righTimagE, {x, y}], 
  PDF[righTimagE, {x, y}]}


The middle is overlap - notice small values. Integrate to find total characteristic
NIntegrate[Evaluate[PDF[lefTimagE, {x, y}] PDF[righTimagE, {x, y}]], 
{x, -13, 13}, {y, -13, 13}, Method -> ""AdaptiveMonteCarlo""] 

Answer: 0.00549086
Random pair:
lefTimagE = SmoothKernelDistribution[{-1, 1} # & /@ allSymFix[[3, 1]]];
righTimagE = SmoothKernelDistribution[allSymFix[[15, 2]]];

Visualize in 2D this time for verity:
Row@ContourPlot[Evaluate[#], {x, -13, 13}, {y, -13, 13},PlotRange -> All, 
Mesh -> 15, PlotPoints -> 50] & /@ {PDF[lefTimagE, {x, y}], PDF[lefTimagE, 
{x, y}] PDF[righTimagE, {x, y}], PDF[righTimagE, {x, y}]}


The middle is overlap. Integrate to find total characteristic
NIntegrate[Evaluate[PDF[lefTimagE, {x, y}] PDF[righTimagE, {x, y}]], 
{x, -13, 13}, {y, -13, 13}, Method -> ""AdaptiveMonteCarlo""]

Answer: 0.0038788
I liked Andy's analysis of the whole set for his metric. I ran it for my integral metric too:
Correlated pairs:
coRdaT = Table[NIntegrate[Evaluate[PDF[SmoothKernelDistribution[{-1, 1} 
# & /@ allSymFix[[k, 1]]], {x, y}] PDF[SmoothKernelDistribution[
allSymFix[[k, 2]]], {x, y}]], {x, -13,13}, {y, -13, 13}, 
Method -> ""AdaptiveMonteCarlo""] , {k, 1, 93}];

Random pairs:
uNcoRdaT = Table[NIntegrate[Evaluate[PDF[SmoothKernelDistribution[{-1, 1} 
# & /@ allSymFix[[k, 1]]], {x, y}] PDF[SmoothKernelDistribution[
allSymFix[[RandomInteger[{1, 93}], 2]]], {x, y}]], {x, -13, 13}, 
{y, -13, 13}, Method -> ""AdaptiveMonteCarlo""] , {k, 1, 93}];

Analysis:
SmoothHistogram[{coRdaT, uNcoRdaT}, Filling -> Axis, 
PlotStyle -> {{Thick, Blue}, {Thick, Red}}]


Conclusion: on average integral of overlap for correlated pairs almost order of magnitude greater than for random pairs.
======= ARCHIVE: less reliable, needs-polishing approach =======
Here is a very simple take on this. If my understanding is correct, @500 wishes to see spatial correlation between left and right 2D patterns. I'll use SmoothDensityHistogram because it IMO gives better data representation in this case, but you can use your original approach too. The idea is to use ImageMultiply to ""amplify"" overlapping regions. Midle image is the overlap for a specific set of your data. Note it was ImageAdjust-ed for better visual perception. As numeric measure you have red number (computed before ImageAdjust for uniform scale) The red number is total ""intensity"" of overlap which could be some sort of correlation measure. BTW we also need to reflect one of the images around vertical axis, otherwise overlap will be meaningless. Here is correlated pair - data set 3, left and right images. As you can see the red number is high and the overlap does look like originals.
ili = SmoothDensityHistogram[#, Background -> Black, 
     ColorFunction -> GrayLevel, ImageSize -> 300, 
     PlotRange -> {{-13, 13}, {-13, 13}}, ImagePadding -> 0, 
     ImageMargins -> 0, PlotRangePadding -> 0, Mesh -> 0] & /@ 
   allSymFix[[3]];
il = {ImageReflect[ili[[1]], Left -> Right], ili[[2]]};
Framed@Labeled[GraphicsRow[Riffle[il, (cori = 
       ColorConvert[ImageMultiply @@ il, ""Grayscale""]) // 
     ImageAdjust], Spacings -> 1], ImageData[cori] // Total // Total, 
  Top, LabelStyle -> Directive[Red, Bold, 20]]


And here is random pairing of set 3 left image and set 15 right image. As you can see the red number is much less and the overlap does not look like originals.
ili = SmoothDensityHistogram[#, Background -> Black, 
     ColorFunction -> GrayLevel, ImageSize -> 300, 
     PlotRange -> {{-13, 13}, {-13, 13}}, ImagePadding -> 0, 
     ImageMargins -> 0, PlotRangePadding -> 0, 
     Mesh -> 0] & /@ {allSymFix[[3, 1]], allSymFix[[15, 2]]};
il = {ImageReflect[ili[[1]], Left -> Right], ili[[2]]};
Framed@Labeled[GraphicsRow[Riffle[il, (cori = 
       ColorConvert[ImageMultiply @@ il, ""Grayscale""]) // 
     ImageAdjust], Spacings -> 1], ImageData[cori] // Total // Total, 
  Top, LabelStyle -> Directive[Red, Bold, 20]]


A word of caution: Andy's good comment made me realize there are a few things to worry about here. Most impotently, in most cases our graphics resales the data before it passes them to ColorFunction. This means that for these different data sets their maximums will look same bright on the plots:
Max /@ {allSymFix[[3, 1]], allSymFix[[15, 2]]}
*Answer:* {10.466, 11.172}

This affects correct overlap estimates. 
"
evaluation - Injecting a sequence of expressions into a held expression,"
{3, 4} /. {x__} :> Hold[{1, 2, x}]


Hold[{1, 2, 3, 4}]


Leonid Shifrin used this here long before I wrote this answer.

In light of Leonid's comment to halirutan it is worth pointing out that you can inject expressions from an arbitrary head including Hold.  You can also use -> rather than :> like this:
expr = Hold[{1, 2, x}];

Hold[6/2, 2 + 2] /. _[x__] -> expr 


Hold[{1, 2, 6/2, 2 + 2}]


"
performance tuning - Efficiently collecting results inside a compiled function,"
Assuming you know the dimensions of the pieces that you want to come out you can always add a second argument to Internal`StuffBag that indicates the rank of the elements going in. The result is still flat so you have to partition after the fact.
cf = Compile[{}, Module[{bag = Internal`Bag[]},
    Do[Internal`StuffBag[bag, {i, i, i}, 1], {i, {0, 1, 2, 3}}];
    Partition[Internal`BagPart[bag, All], 3]]];

Here I'm indicating that vectors will be going in to the bag.  I would specify 2 for a matrix. Notice that it no longer calls MainEvaluate.
In[25]:= StringFreeQ[CompilePrint[cf], ""MainEvaluate""]

Out[25]= True

In[20]:= cf[]

Out[20]= {{0., 0., 0.}, {1., 1., 1.}, {2., 2., 2.}, {3., 3., 3.}}

"
How to write a function to add edges or vertex to a graph,"
Update: Can I add a mixture list of vertices and edges to an existing graph?
ClearAll[addToGraph]
addToGraph[g_Graph, stuffToAdd_] := Fold[
 If[Head[#2] === UndirectedEdge || Head[#2] === DirectedEdge, EdgeAdd, VertexAdd]@ ## &,
 g, stuffToAdd]

Example:
g = Graph[{a, b, c}, {a <-> b, b <-> c, c <-> a}, 
 VertexLabels -> Placed[""Name"", Center], VertexSize -> Scaled[.1], 
 VertexLabelStyle -> 18, AspectRatio -> 1];

addToGraph[g, {d, d <-> a, e, h <-> a}]


Original answer:
The functions you need are VertexAdd, EdgeAdd, and their relatives VertexDelete and EdgeDelete.
For the graph
g = Graph[{a, b, c}, {a <-> b, b <-> c, c <-> a}, 
 VertexLabels -> Placed[""Name"", Center], VertexSize -> Scaled[.1], 
 VertexLabelStyle -> 18, AspectRatio -> 1]


Adding a vertex 
VertexAdd[g, d]


Adding an edge
EdgeAdd[g, d <-> a]


Deleting an edge
EdgeDelete[g, c <-> a]


"
Get the neighboring vertices and incident edges from a vertex in a graph,"
A random graph
 g = RandomGraph[{15, 35}, VertexLabels -> ""Name"", PlotRangePadding -> .2]


Edges for the vertex 4:
 EdgeList[g, 4 \[UndirectedEdge] _]

Result:

Now vertexes around vertex4:
 VertexList[NeighborhoodGraph[g, 4]]

Result:
 {4, 14, 11, 6, 7, 9, 13, 15}

Illustration:
  HighlightGraph[g, NeighborhoodGraph[g, 4]]


There are many other ways. You could also use AdjacencyMatrix to get all that info.
"
front end - How can I change the keyboard shortcut for switching the active window?,"
You need to add the following to KeyEventTranslations.tr:
Item[KeyEvent[""Tab"", Modifiers -> {Control}],
   FrontEndExecute[FrontEndToken[""CycleNotebooksForward""]]],

Item[KeyEvent[""Tab"", Modifiers -> {Shift, Control}],
   FrontEndExecute[FrontEndToken[""CycleNotebooksBackward""]]],

This will map Control-Tab and Control-Shift-Tab to cycling between notebooks.
For some reason, using the Tab key sometimes fails, but any alternative shortcut could be used (for example Ctrl-`).
On Windows KeyEventTranslation.tr is located in
$InstallationDirectory\SystemFiles\FrontEnd\TextResources\Windows

"
hold - How can you stop ordering of InputField entries?,"
You could do something like
InputField[Dynamic[d, (d = HoldForm @@ #) &], Hold[Expression]]

This will wrap the expression typed into the input field in HoldForm.



"
calculus and analysis - Using implicit differentiation to find a line that is tangent to a curve at a point,"
I'm not sure the implicit case allows for a solution as elegant as the explicit case; here is what I'd do, however:
eq = x^2 + x y + y^2 == 3; pt = {1, 1};
With[{m = (Dt[y, x] /. First[Solve[Dt[eq, x], Dt[y, x]]]) /.
            Thread[{x, y} -> pt]}, 
           Collect[m (x - First[pt]) + Last[pt], x, Simplify]]
2 - x

As you can see, this assumes a point pt on the implicitly-defined curve eq is already known; if not, a preliminary application of Solve[] is necessary.

Prompted by Michael's answer, I managed to figure out a second solution, based on the properties of the gradient of a function of two variables (here computed as D[f, {{x, y}}]):
eq = x^2 + x y + y^2 == 3; pt = {1, 1};
Expand[(D[Subtract @@ eq, {{x, y}}] /. Thread[{x, y} -> pt]).({x, y} - pt)] == 0
-6 + 3 x + 3 y == 0

This also requires that both coordinates of pt are already known, as in the first method.

Warning:
It must be noted, however, that both approaches given so far will fail spectacularly if the point being considered is in fact a singular point of the given curve (e.g. the (cru)node at the point $(0,0)$ of the folium of Descartes $x^3+y^3=3xy$). There are special techniques to attack cases like this (based on the clever evaluation of an appropriate limit), but I shall not say anything further about them in this answer.
"
plotting - How to work around incorrect tooltips in plots exported to HTML,"
Some time ago I wanted to have good tooltips for images composed by polygons. Mathematica generated square areas only, and the polygons had many shapes. Then I did my own export function for polygons with tooltips. I basicaly rescaled all the polygon points to the image size and wrote the image maps. I never found how to get the right area from Mathematica. I also investigated the SVG, but didn't find anything useful (didn't get the tooltips to work). I will have to check the SVG capabilities of M8, but I guess they have not change much.
"
front end - Implementing efficient multiple undo,"
I implemented a multiple undo mechanism in v10.
It's not as perfect as I would like it to be, yet, but it does a pretty decent job in my experience.   And a few of the documented options for it got ahead of the implementation...think of some of that stuff as a ""coming soon"".
Feel free to ping me on any problems you find with it.
Edit: In 10.0.2, all of the documented options are implemented except for ""SpoolDirectory"".
"
numerics - Is it possible to use the LevenbergMarquardt algorithm for fitting a black-box residual function?,"
Here is the solution based on Faysal's code:
steps=0; 
FindMinimum[Null,
 {optimVariables, initialGuess}\[Transpose],
 Method -> {""LevenbergMarquardt"", 
   ""Residual"" -> Sqrt[2] residualVector[optimVariables], 
   ""Jacobian"" -> {Sqrt[2] jacobianMatrix[optimVariables], EvaluationMonitor :> ++steps}, 
   ""StepControl"" -> {""TrustRegion"", ""StartingScaledStepSize"" -> 1/1000, ""MaxScaledStepSize"" -> 1/10, ""AcceptableStepRatio"" -> 1/3}}]

Note that it is recommended to use exact numbers for the parameters of the ""TrustRegion"" method because these parameters are used inside of the algorithm without any check for consistency with WorkingPrecision. I should also note that the actual residual vector and jacobian must be multiplied by Sqrt[2] for having FindMinimum returning the minimum equal to
residualVector[optimVariables].residualVector[optimVariables]

and not to
residualVector[optimVariables].residualVector[optimVariables]/2

as it is by default.
The jacobian may be calculated automatically by the following code:
jacobianMatrix[_] = D[residualVector[optimVariables], {optimVariables}]

One can restrict the jacobian to be evaluated for numerical values only by defining it as:
jacobianMatrix[_List?(VectorQ[#, NumberQ] &)] = 
    D[residualVector[optimVariables], {optimVariables}]

"
export - How do I save a variable or function definition to a file?,"
You can use DumpSave:
exampleData = {{1, 1}, {2, 3}, {3, 4}, {4, 7}, {5, 5}, {6, 4}, {7, 2}};
interPolFunc[x_] = Interpolation[exampleData, x]

(note the use of Set (=) rather than SetDelayed so as to have the interpolating function evaluated only once; the way you had it, you interpolated each and every time).
DumpSave[""~/Desktop/interpol.mx"", interPolFunc]

then
Quit[]
DumpGet[""~/Desktop/interpol.mx""]
interPolFunc[4]
(*7*)

"
front end - Delete the current notebook cell using the keyboard,"
Referencing Szabolcs's answer, here is the code that must be added to KeyEventTranslations.tr:
Item[KeyEvent[""m"", Modifiers -> {Control}],
    FrontEndExecute[{
        FrontEnd`SelectionMove[FrontEnd`SelectedNotebook[], All, Cell], 
        FrontEnd`FrontEndToken[""Clear""]
    }]],

I chose Ctrl+M at random; change it to whatever you want.
See this before you edit the file.
"
.netlink - Using .NET 4.0 from NETLink,"
UPDATE The following steps are no longer necessary if one is using Mathematica version 9 -- it comes preconfigured to use .NET 4.x.
NETLink uses an interlude .NET application to broker communication with the framework. The application is called InstallableNET.exe (InstallableNET32.exe on 32-bit systems) and can be found in this directory:
SystemOpen @
  FileNameJoin[{$InstallationDirectory, ""SystemFiles"", ""Links"", ""NETLink""}]

The application will use the version of the .NET framework that is configured in its .config file.  To make it use version 4.0, add a new line within the startup element:
<supportedRuntime version = ""v4.0""/>

Versions are tried in the order that they appear in the file, so place the preferred version first.  The updated  InstallableNET.exe.config will look something like this:
<?xml version=""1.0"" encoding=""utf-8"" ?>
<configuration>
  <startup>
    <!-- The supportedRuntime lines control which version of the .NET Framework will
         be used when .NET/Link is launched with InstallNET[].
         .NET/Link requires at least .NET 2.0. If you have .NET 3.0 installed,
         it will be used (note that the 3.0 version is really just the 2.0
         version with some extra assemblies).
      -->
      <supportedRuntime version=""v4.0"" />
      <supportedRuntime version=""v2.0.50727"" />
  </startup>
</configuration>

Note: If you're using Mono instead of Microsoft's CLR, you'll have to delete the first few (invisible) bytes from the XML file due to a Mono bug. One way to do this would be to tell your text editor to save the XML file as ASCII instead of Unicode. Another way would be to copy and paste the body of the file into a new file and then copy the new file over the previous InstallableNET.exe.config file.

UPDATE: .NET Versions 4.5.x and Later
The steps reported above will automatically select the latest installed version of the .NET Framework in the 4.x line.  This includes the 4.5.x releases.
Beware, however, that the call to System`Environment`Version shown above can be misleading.  All of the 4.5.x versions report a version string that starts with ""4.0"".  For example, at time of writing my machine has version 4.5.2 installed.  Yet:
System`Environment`Version@ToString[]
(* 4.0.30319.34209 *)

The magic number 34209 on the end of this version string actually identifies it as a 4.5.2 build - see StackOverflow answer (12972517) for a list of version strings.
The .NET documentation for Environment.Version expressly discourages its use to identify the 4.x minor version.  Instead, it recommends querying the registry to identify the exact version:
Needs[""Developer`""]
ReadRegistryKeyValues @
  ""HKEY_LOCAL_MACHINE\\Software\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full""

(* { Version->4.5.51209,
     TargetVersion->4.0.0,
     Install->1,
     MSI->1,
     Servicing->0,
     InstallPath->C:\Windows\Microsoft.NET\Framework64\v4.0.30319\,
     Release->379893
   } *)

The Release magic number is described in a Microsoft library article.  But be aware that this registry key does not exist for earlier .NET versions.
If we want even more evidence to convince ourselves that Mathematica is accessing the latest .NET version, we can always attempt to access API that does not exist in earlier versions.  Here is an example using a type that does not exist prior to version 4.5.x:
LoadNETType[""System.Reflection.ReflectionContext""]
(* NETType[System.Reflection.ReflectionContext,6] *)

"
functional style - Using sets of arguments from a list,"
You could use Apply at the first level:
Times @@@ listA

"
mathematical optimization - Symbolic Optimisation,"
The error is in your differentiation line:
FOC = D[f[qu_, quu_, qud_, \[Psi]_], quu]

Change this to
FOC = D[f[qu, quu, qud, \[Psi]], quu]

and you'll get a meaningful answer.
The reason for this behavior is that x_ is a pattern that matches anything, and this anything can then be referred to by using x. You can read your function definition, f[qu_, ...] := ... as ""Whenever Mathematica encounters an expression of the form f[something, ...], it is to be replaced by whatever you specified on the right side of the :=. When you call the function, you do of course not want to differentiate the pattern f[qu_, ...], you want Mathematica to substitute it by some term, and then differentiate whatever is the result of the substitution (i.e. your actual formula). What the program does right now is use your definition of f, insert a pattern as function values, and then differentiate that. You do not want that of course, you want to insert the actual variables.
"
calculus and analysis - Hankel Transform integrals won't work in Mathematica,"
The answer is simply that integrating with the assumption that a variable comes from the class of integers is really difficult. What Integrate does with Assumptions -> Element[m, Integers] is try to generically integrate without the assumption and then apply the assumption to the result to try and simplify it. I've asked around about this before and there doesn't seem to be a good way to make a generic algorithm that actually handles assumptions like Element[m, Integers]. 
You can find many cases where Assumptions -> Element[something, Integers] doesn't produce the expected simplification. Most of the cases I've seen of integrals where a variable is assumed to be an integer are where the integrand is the product of two orthogonal functions. In these cases,the way these are solved on paper doesn't generalize easily.
"
formatting - Keeping Text Size the Same Throughout Entire Notebook File,"
There are a variety of ways to do this.  One can use Stylesheets as noted by acl.  Perhaps the most direct way is this:
For one Notebook:
SetOptions[EvaluationNotebook[], FontSize -> 16]

For all Notebooks:
SetOptions[$FrontEnd, FontSize -> 16]

You can also set FontSize for different Box types, such as GraphicsBox:
SetOptions[$FrontEnd, GraphicsBoxOptions -> {BaseStyle -> {FontSize -> 15}}]

If you are more comfortable with a GUI, all of these options are available through the Options Inspector in the Format menu.

If you decide to go the advanced route and use style sheets here is a guide to get you started:
David Park's StyleSheet creation notes (.zip file)

Depending on your goals, this question may also be of interest:
How to set default magnification for all windows
"
graphics - How do I plot a plane EM wave?,"
Here's a variation of the plane wave rendering done in rm -rf's answer. Here, I use arrows instead of lines to indicate the wave's displacement from the axis:
waveDiagram[xm_, col_, k_] := Flatten[First[
    Normal[Plot[Sin[x], {x, 0, xm}, Mesh -> Full, 
                PlotStyle -> Directive[col, Arrowheads[Small]]]] /. 
           Point[{x_, y_}] :> 
             If[Chop[Abs[y]] < 0.1, Point[{x, 0}], Arrow[{{x, 0}, {x, y}}]]]] /. 
          v_ /; VectorQ[v, NumericQ] && Length[v] == 2 :> Insert[v, 0, k]

Graphics3D[(* axes *)
           {{Gray, {Arrowheads[.02], 
            Arrow[{{0, 0, 0}, {9 π/2, 0, 0}}]}, {Arrowheads[.01 {-1, 1}], 
            Arrow[{{0, 1, 0}, {0, -1, 0}}], Arrow[{{0, 0, 1}, {0, 0, -1}}]}}, 
           waveDiagram[4 π, Darker[Blue], 2], 
           waveDiagram[4 π, Darker[Green], 3]},
           Boxed -> False, BoxRatios -> {2, 1, 1}]


As a variation, here's a depiction of the circular polarization of a plane wave:
Show[
     (* circularly polarized wave *)
     Normal[ParametricPlot3D[{t, -Sin[t], Cos[t]}, {t, 0, 4 π}, Mesh -> Full, 
            PlotStyle -> Directive[Darker[Blue], Arrowheads[Small]]]] /. 
     Point[{x_, y_, z_}] :> 
           If[Chop[Norm[{y, z}]] < 0.1, Point[{x, 0, 0}], 
              Arrow[{{x, 0, 0}, {x, y, z}}]],
     (* axes *)
     Graphics3D[{{Gray, {Arrowheads[.02], Arrow[{{0, 0, 0}, {9 π/2, 0, 0}}]},
                 {Arrowheads[.01 {-1, 1}], Arrow[{{0, 1, 0}, {0, -1, 0}}], 
                  Arrow[{{0, 0, 1}, {0, 0, -1}}]}}}],
                Axes -> None, Boxed -> False, BoxRatios -> {2, 1, 1}, PlotRange -> All]



The common theme in both diagrams is the use of the Mesh option of the plotting functions, which generates Point[]s on the curve(s) at preset locations. From here, we replace each Point[] object generated with an Arrow[] whose head has the coordinates of the original Point[]; how the position of the tail is determined depends on the plot being done.
"
"programming - How to make a function like Set, but with a Block construct for the pattern names","
Perhaps something like this:
SetAttributes[localSet, HoldAll]

localSet[lhs_, rhs_] := 
  Union @@ Cases[
    Unevaluated[lhs], 
    Verbatim[Pattern][p_, _] :> HoldComplete[p],
    Infinity,
    Heads -> True
  ] /. _[x___] :> Block[{x}, lhs = rhs;]

Test:
var=3;
localSet[f[var_],Normal[Series[Exp[var],{var,0,3}]]]
DownValues[f]


{HoldPattern[f[var_]] :> 1 + var + var^2/2 + var^3/6}


"
plotting - Creating Plots for a Family of Solutions,"
I guess you have some sort of time evolution of Bessel-like waves. I also see that your examples deal with 3rd zero of Bessel J0 - I'll use it too. Define a function: 
mYf[r_, t_, n_] := With[
    {k = BesselJZero[0, n]}, 
    (Cos[k t] + Sin[k t]) BesselJ[0, k r]
]

Build a time evolution list:
giflist = Table[
    RevolutionPlot3D[
        Evaluate[N@mYf[r, t, 3]],
        {r, 0, 1}, 
        SphericalRegion -> True,
        PlotRange -> {{-1, 1}, {-1, 1}, {-1.5, 1.5}},
        ImageSize -> 450,
        PlotStyle -> Opacity[.7],
        ColorFunction -> ""TemperatureMap"", 
        MeshStyle -> Opacity[.5],
        PlotLabel -> time == t
    ], 
    {t, 0, 2 Pi/N[BesselJZero[0, 3]], .05}
];

Display as animated .GIF -
Export[""bessel.gif"", giflist]


Display as a table:
GraphicsGrid[
    Partition[
        Show[#,Boxed ->False, Axes -> False] & /@ giflist,
        5
    ], 
    ImageSize -> 500,
    Spacings -> 0
]


Create an interface to investigate parameters. You BTW did not define dependence of a and b on n so I'll just define them generically: 
Manipulate[
    RevolutionPlot3D[
        Evaluate[N@mYf[r, t, n, a, b, α]],
        {r, 0, 1},
        SphericalRegion -> True, 
        PlotRange -> {{-1, 1}, {-1, 1}, {-1.5, 1.5}},
        ImageSize -> 350,
        PlotStyle -> Opacity[.7],
        ColorFunction -> ""TemperatureMap"",
        MeshStyle -> Opacity[.5],
        PlotLabel -> time == t,
        PlotPoints -> 25
    ], 
    {{t, 1.36, ""time""}, 0, 2, ImageSize -> Tiny},
    Delimiter,
    ""zero's order"", 
    {{n, 7, """"}, Range[7], SetterBar, ImageSize -> Tiny},
    Delimiter,
    {{a, 1.2, ""a_n""}, 0, 2, ImageSize -> Tiny},
    {{b, 1, ""b_n""}, 0, 2, ImageSize -> Tiny},
    {{α, .9, ""α""}, 0, 2, ImageSize -> Tiny},
    FrameMargins -> 0,
    ImageMargins -> 0, 
    ControlPlacement -> Left, 
    Initialization :> (
        mYf[r_, t_, n_, a_, b_, α_] := 
            With[
                {k =  BesselJZero[0, n]},
                (a Cos[α k t] + 
                  b Sin[α k t]) *
                  BesselJ[0, k r]
            ]
    )
]


"
front end - How to automate a FrontEnd return?,"
Try using this:
FrontEndExecute[
  {FrontEnd`NotebookFind[FrontEnd`SelectedNotebook[], 
                         ""Output"", All, CellStyle, AutoScroll->False], 
   FrontEnd`FrontEndToken[""Clear""]}]

(Untested in KeyEventTranslations.tr, but works as a button!)

Regarding automating confirming the dialog---I don't think it is possible from within Mathematica.  I'd like to note though that you can press Space to confirm the dialog (instead of using Enter), which is considerably easier for me due to the size and position of the key.

Update:  As Albert Retey pointed out in a comment, this will only remove output cells, but not ""Message"" or ""Print"" cells.  Those need to be added separately to the command, and this is still a workaround to finding all GeneratedCells.
"
What is the best way to clip a graphic to a region?,"
I'm pretty sure this can't be done. As evidence of this I put forward Import[] of .EPS and .PDF with such clipping in it: mathematica imports the shapes unclipped. If there would be some undocumented function to do this clipping, I would assume that Import[] would make use of it.
"
compile - Visual Studio Express 2010 on x86-64: libcmt.lib missing,"
Just thought I'd share.
I had the same problem after re-installing VS2010 Ultimate (I also have 2008).
To fix it, I copied the following

libcmt.lib
libcmt.pdb
libcmtd.lib
libcmtd.pdb
oldnames.lib

from C:\Program Files\Microsoft Visual Studio 11.0\VC\lib
to C:\Program Files\Microsoft Visual Studio 10.0\VC\lib
Hope this helps someone.
"
graphics - Subplots with connector lines,"
This solution uses FullGraphics to transform axes and ticks in a plot to lines which allows you to resize and translate the plot while keeping the ticks of the original plot. In raster, main is the main plot, list is the list of sub plots, pts is the list of points in the main plot corresponding to the begin points of the red lines, and {dx, dy} are the gaps between the sub plots and the main plot. The sub plots are placed in clockwise direction starting with the one in the upper right corner. The end plot is such that the plot range of the main plot is {{0, 0}, {1, 1}}.
raster[main_, list_, pts_, {dx_, dy_}] := 
 Module[{fgmain, fglist, prm, prl, scmain, sclist, scpts, lines},
  fgmain = FullGraphics[main];
  fglist = FullGraphics /@ list;
  prm = OptionValue[AbsoluteOptions[main, PlotRange][[1]], 
    PlotRange];
  prl = OptionValue[Options[#, PlotRange][[1]], PlotRange] & /@ list;
  scmain = 
   Translate[
    Scale[fgmain[[1]], 1/(prm[[All, 2]] - prm[[All, 1]]), 
     prm[[All, 1]]], -prm[[All, 1]]];
  scpts = Transpose[{Rescale[pts[[All, 1]], prm[[1]]],
     Rescale[pts[[All, 2]], prm[[2]]]}];
  sclist = MapThread[
    Translate[
      Scale[#, (.5 - {dx, dy}/
           2)/(#2[[All, 2]] - #2[[All, 1]]), #2[[All, 1]]],
      -#2[[All, 1]] + #3] &,
    {fglist[[All, 1]], prl, {{-.5 - dx/2, 1 + dy},
      {0, 1 + dy}, {.5 + dx/2, 1 + dy}, {1 + dx, 1 + dy},
      {1 + dx, .5 + dy/2}, {1 + dx, 0}, {1 + dx, -.5 - dy/2},
      {.5 + dx/2, -.5 - dy/2}, {0, -.5 - dy/2}, {-.5 - dx/2, -.5 - 
        dy/2},
      {-.5 - dx/2, 0}, {-.5 - dx/2, .5 + dy/2}}}];
  lines = Transpose[{scpts,
     {{-dx, 1 + dy}, {.25 - dx/4, 1 + dy}, {.75 + dx/4, 
       1 + dy}, {1 + dx, 1 + dy},
      {1 + dx, .75 + dy/4}, {1 + dx, .25 - dx/4}, {1 + dx, -dy},
      {.75 + dx/4, -dy}, {.25 - dx/4, -dy}, {-dx, -dy},
      {-dx, .25 - dy/4}, {-dx, .75 + dy/4}}}];
  Graphics[{scmain, sclist, {Red, Dashed, Line[lines]}}]]

Example:
list = MapIndexed[ParametricPlot[#, {x, 0, 2 Pi}, 
     Frame -> True, Axes -> False,
     PlotStyle -> (ColorData[1] @@ #2)] &,
   Table[{(n - 1) 2 Pi + x, n Sin[x]}, {n, 12}]];
main = Show[list, PlotRange -> All];
pts = N[Table[{(n - 1) 2 Pi + x, n Sin[x]}, {n, 12}] /. x -> Pi];

raster[main, list, pts, {.15, .15}]


"
linear algebra - Computing eigenvectors and eigenvalues,"
The function to obtain both the eigenvalues and the eigenvectors is Eigensystem. Use it as {eigVals,eigVecs} = Eigensystem[matrix]. 
If the matrix is symbolic, then the output (if you wait long enough for it to churn out an answer!) will only be as a list of general solutions for the roots of a 9th order polynomial with unknown coefficients, and there are no closed form solutions for polynomials with orders greater than 4. The results will not have any particular ordering.
On the other hand, a 9x9 numerical matrix is a piece of cake (even if you were to solve the characteristic polynomial), so you should have no problems.
To obtain the largest (first) eigenvalue and the corresponding eigenvector, use the optional second argument as Eigensystem[matrix, 1]. Here's an example (with a smaller matrix to keep the output small):
mat = RandomInteger[{0, 10}, {3, 3}];
{eigVals, eigVecs} = Eigensystem[mat] // N

(* Out[1]= {{21.4725, 6.39644, 0.131054}, {{1.3448, 0.904702, 1.}, 
            {0.547971, -1.99577, 1.}, {-0.935874, -0.127319, 1.}}} *)

{eigVal1, eigVec1} = Eigensystem[mat, 1] // N
(* Out[2]= {{21.4725}, {{1.3448, 0.904702, 1.}}} *)

"
bugs - Avoid crash in recursive Dynamic,"
Based on this MathGroup post describing a similar crash, the right click can be caught and discarded like this:
l = 1;
EventHandler[Dynamic[Sin[l = l + 1]], {""MouseUp"", 2} :> Null]

This won't let you copy the value, but it will prevent crashes due to accidental right clicks.
You can obtain the value by evaluating l as a different input.
"
programming - Simplifying already defined symbols,"
How about defining this function
SetAttributes[updateSymbols, HoldAll]
updateSymbols[syms__] := 
   Scan[Function[x, If[ValueQ[x], x = x], HoldAll], Hold[syms]]

then running
updateSymbols[x, y]

after the definitions have been made?
It will redefine each symbol, evaluating the RHS of their definitions.
Note: Only works for OwnValue-symbols, and I'm not entirely sure it can't break something.

Usage example:
x=y;
y=2;

?x
(* ==>
 Global`x
 x=y
*)

?y
(* ==>
Global`y
y=2
*)

updateSymbols[x,y]

?x
(* ==>
Global`x
x=2
*)

?y
(* ==>
Global`y
y=2
*)

"
java - How do you get Weisstein’s Hyphenate package to run?,"
The package comments contain the following information:

Requirements
      Download and install http://www.davidashen.net/texhyphj.html in 
      $HyphenPath = ""/Volumes/Users/eww/tex/texhyphj"";

The package relies on this external Java code, and will not run without it. It needs to be downloaded separately, and put in the same folder as the Hyphenate.m file. Then, you modify the following code line from the package:
$HyphenPath=""/Volumes/Users/eww/tex/texhyphj"";

to refer to the path of the files on your own system.
"
scoping - Local variabls - Mathmatica Stack Exchang,"
Ok, let me tell you straight away that what you are trying to do is likely to be a bad idea. Now, let me explain. The problem you face on the surface is that Evaluate is only effective at the first level inside heads which hold their arguments. Since you have SetDelayed[f[y_],Module[...]], the stuff inside Module is too deep. You need With to inject arbitrarily deep, so we try:
ClearAll[f, x];
With[{tmp = tmp2},
   f[y_] := Module[{x = 1}, y tmp]] 

However, now you face another problem: variable renaming mechanism in scoping constructs tries to protect the scoping and renames variables in part of your code:
?f
Global`f
f[y$_]:=Module[{x$=1},y$ (1+x^2)]

Here is what you can do to achieve your goal:
ClearAll[f, x];
Block[{tmp}, Unevaluated[f[y_] := Module[{x = 1}, y*tmp]] /. tmp -> tmp2]

This is explained in details here. Note however that the fact that we had to go against the system twice tells us already that this is a fragile and generally bad practice. Please see more discussion on that in the linked answer.
EDIT
In response to the edit in the question: in your case, I suggest to use Block and create a dynamic environment, where to execute the code for which you do want your transformations:
SetAttributes[withTransforms,HoldAll];
withTransforms[code_]:=
 Block[{kx=k*Sin[a]*Cos[b],ky=k*Sin[a]*Sin[b],kz=k*Cos[b]},
   code
 ]

This will allow you to selectively enable these definitions:
withTransforms[Integrate[kx^2+ky^2,{a,0,2 Pi}]]

"
export - Creating a realtime MIDI Out,"
Here is a letter I got regarding this question from premier service technical support:

Thank you for taking the time to send this in. Unfortunately, I do not
  believe this functionality currently exists in Mathematica and I have
  forwarded the suggestion that it be included in a future release of
  Mathematica to the developers in charge of this area.

I can imagine that this might be possible just JLink or MathLink.
Essentially it would require writing a Java or C program that served as an
interface with Mathematica.""
"
evaluation - A combination of Set::setraw and Set::shape errors,"
This problem occurs because you are trying to make assignments to the same object multiple times.  As far as I can tell this is simply broken code.  You get the Set::setraw because you give hyb[""chip1""] the value {7, 8}, then you try to set it to {6, 6}.  Because you are forcing an Evaluate here you get {7, 8} = {6, 6} which is not an acceptable assignment.  In effect:
x = 1;
Evaluate[x] = 2;

I am going out on a limb and suggesting this is what you want:
Evaluate[toylist] = 
  Table[Extract[toydata[[i]], toyindices[[j]]], {i, 1, 
    Length[toylist]}, {j, 1, Length[toyindices]}];

hyb[""chip2""]


{{16, 17}, {15, 15}, {12, 11}}


This however is not as clean as it could be.  I await an explanation of what you are actually trying to accomplish so that I can be more helpful.
As an example of cleaner coding, consider:
Outer[Extract, toydata, toyindices, 1]


{{{7, 8}, {6, 6}, {3, 2}},
 {{16, 17}, {15, 15}, {12, 11}},
 {{25, 26}, {24, 24}, {21, 20}}}



Addressing your edit, first an explanation of Set::shape.  Set automatically threads over lists, such that {a, b} = {1, 2} is equivalent to a = 1; b = 2.  This will work at deeper levels of the lists as well.  If the lists on either side are not the same shape this fails.
{a, b, c} = {1, 2} (* failure *)

{{a}, b} = {{3}, 4} (* success *)

{a, b} = {{3}, 4} (* success *)

{{a}, b} = {3, 4} (* failure *)

You state:

I have created a list called mmsignalnames which is composed of
  indexed symbols such as mmsignal[""GSM356796""], mmsignal[""GSM356797""]
  .... up to all 24 datasets.

You're doing it wrong. :-)  You should store the list of keys: {""GSM356796"", ""GSM356797"", ...""}.  This way you can handle the key names and the symbol mmsignal easily and without anything prematurely evaluating.  Example:
keys = {""red"", ""green"", ""blue""};

Do[signal[ keys[[i]] ] = i^2, {i, 3}]

signal[""green""]


4


signal /@ keys


{1, 4, 9}


"
graphics - Show[] combines my Graphics3D objects in an undesirable way,"
Checking the values of plot range  for the three graphics object:
 {AbsoluteOptions[slab, PlotRange], AbsoluteOptions[EMw1, PlotRange]}

you get

{{PlotRange -> {{0., 38.}, {0., 57.}, {0., 4.}}}, {PlotRange -> {{0., 
 6.27}, {-0.999974, 0.999999}, {-0.999999, 0.999974}}}}


Using this information, define the rescaling transform
 rscTr = RescalingTransform[{{0, 6.27}, {-1, 1}, {-1, 1}}, {{0, 
38}, {-8, 8}, {-8, 8}}]

and rescale the data for EMw1:
 rescaledPts1 = rscTr[pts1]; rescaledPts2 = rscTr[pts2];

and redraw your EMw1 with rescaled data:
 rescaledEMw1 = 
 Graphics3D[{Thickness[0.007], {RGBColor[0.439, 0.188, 0.627], 
 Line[rescaledPts1]}, {RGBColor[1, 0.721, 0.039], 
 Line[rescaledPts2]}, Thickness[0.002], 
 Line[{#, # {1, 0, 1}}] & /@ rescaledPts1[[;; ;; 3]], 
  RGBColor[1, 0.721, 0.039], 
 Line[{#, # {1, 1, 0}}] & /@ rescaledPts2[[;; ;; 3]]}, 
 AxesOrigin -> {0, 0, 0}, Axes -> {True, False, False}, 
 Ticks -> None, 
 AxesStyle -> 
 Directive[Thickness[0.0075], RGBColor[0.439, 0.188, 0.627]], 
 Boxed -> False, ImageSize -> {400, 520}]

Now, 
 Show[slab, grating, rescaledEMw1]

gives 

The same output from a different viewpoint:

EDIT: Alternative approach: Define corrdinates of the slab and grating directly. I use a modification of R.M.`s answer to OP's previous question, and specify the coordinates of the slab and grating objects.
First, slab and grating objects with modified coordinates:
 sw = 4 Pi; sh = .5; gw = .5; gh = .5; cw = 1.; sl = 9 gw + 8 cw; 
 grating =  Graphics3D[{RGBColor[0.917, 0.082, 0.478], Opacity[.3], 
 Cuboid[{{0, 0, 0}, {sw, gw, gh}}], 
 Cuboid[{{0, gw + cw, 0}, {sw, 2 gw + cw, gh}}], 
 Cuboid[{{0, 2 (gw + cw), 0}, {sw, 3 gw + 2 cw, gh}}], 
 Cuboid[{{0, 3 (gw + cw), 0}, {sw, 4 gw + 3 cw, gh}}], 
 Cuboid[{{0, 4 (gw + cw), 0}, {sw, 5 gw + 4 cw, gh}}], 
 Cuboid[{{0, 5 (gw + cw), 0}, {sw, 6 gw + 5 cw, gh}}], 
 Cuboid[{{0, 6 (gw + cw), 0}, {sw, 7 gw + 6 cw, gh}}], 
 Cuboid[{{0, 7 (gw + cw), 0}, {sw, 8 gw + 7 cw, gh}}], 
 Cuboid[{{0, 8 (gw + cw), 0}, {sw, 9 gw + 8 cw, gh}}]}, 
 Boxed -> False, ImageSize -> {400, 520}];
 slab = Graphics3D[{RGBColor[0.101, 0.701, 0.623], Opacity[.5], 
 Cuboid[{0, 0, -.5}, {4 Pi, 4 Pi, 0}]}, Boxed -> False, ImageSize -> {400, 520}];

Next, a modifed version of R.M.`s waves (replicating the pair of waves four times):
  Module[{w1, w2, w3, w4, w5, w6, w7, w8, colors, plot, lines}, 
  w1[x_] := {x, 0, Sin[x]}; w2[x_] := {x, Sin[x], 0}; 
  w3[x_] := {4 \[Pi], x, Sin[x]}; w4[x_] := {4 \[Pi] + Sin[x], x, 0}; 
  w5[x_] := {x, 4 \[Pi], -Sin[x - Pi]}; 
  w6[x_] := {x, 4 \[Pi] - Sin[x - Pi], 0}; w7[x_] := {0, x, Sin[x]}; 
  w8[x_] := {Sin[x], x, 0};
  colors =   Darker /@ {Blue, Orange, Blue, Orange, Blue, Orange, Blue, Orange};
  {plot, lines} = 
  ParametricPlot3D[{w1[x], w2[x], w3[x], w4[x], w5[x], w6[x], w7[x], 
   w8[x]}, {x, 0, 4 \[Pi]}, Boxed -> False, AxesOrigin -> {0, 0, 0},
  MaxRecursion -> 0, PlotRange -> {{-Pi, 5 Pi}, {-Pi, 5 Pi}, {-2, 2}}, 
  BoxRatios -> {1, 1, .5}, 
  PlotStyle -> {{Thick, Thick, Thick, Thick, Thick, Thick, Thick, 
    Thick}, colors}\[Transpose], 
  EvaluationMonitor :> 
  Sow[{Line[{w1[x], {x, 0, 0}}], Line[{w2[x], {x, 0, 0}}], 
   Line[{w3[x], {4 \[Pi], x, 0}}], Line[{w4[x], {4 \[Pi], x, 0}}],
    Line[{w5[x], {x, 4 \[Pi], 0}}], 
   Line[{w6[x], {x, 4 \[Pi], 0}}], Line[{w7[x], {0, x, 0}}], 
   Line[{w8[x], {0, x, 0}}]}]] // Reap; 
  GraphicsRow[{Show[plot, 
  Graphics3D[Insert[Flatten[lines, 1], colors, 1]\[Transpose]], 
  ViewPoint -> {3.009, -1.348, 0.759}, 
  ViewVertical -> {0.406, -0.398, 5.732}, Ticks -> None, 
  AspectRatio -> 0.75], 
  Show[plot, slab, grating, 
  Graphics3D[Insert[Flatten[lines, 1], colors, 1]\[Transpose]], 
  ViewPoint -> {3.009, -1.348, 0.759}, 
  ViewVertical -> {0.406, -0.398, 5.732}, Ticks -> None, 
  AspectRatio -> 0.75]}, ImageSize -> 900]]

Two views of the resulting 3D graphs:


"
How to execute kernel command from Front End?,"
You can add the menu command to your Insert menu using AddMenuCommands in the following manner.  (These modifications will only persist for the current front end session.)
First a demo function, just creating a dialog:
FrontEndExecute[FrontEnd`AddMenuCommands[""DuplicatePreviousOutput"",
  {Delimiter, MenuItem[""CreateDialog &Demo"",
    FrontEnd`KernelExecute[CreateDialog[{TextCell[""Click OK to close""],
       DefaultButton[]}]], 
    MenuKey[""D"", Modifiers -> {""Control"", ""Shift""}],
    System`MenuEvaluator -> Automatic]}]]

(Note the required context specification for MenuEvaluator.)
This version will run OptionsExplorer[]
FrontEndExecute[FrontEnd`AddMenuCommands[""DuplicatePreviousOutput"",
  {Delimiter, MenuItem[""Options &Explorer"",
    FrontEnd`KernelExecute[ToExpression[""OptionsExplorer[]""]],
    MenuKey[""O"", Modifiers -> {""Control"", ""Shift""}],
    System`MenuEvaluator -> Automatic]}]]

"
linear algebra - Simpler way of performing Gaussian Elimination?,"
Based upon your update, you are trying to solve the system
$$\mathbf{A}\vec{x} = \vec{b}$$
for $\vec{x}$, so LinearSolve is exactly what you want. Also, it has the exact form
LinearSolve[A, b]

that you're asking for. Internally it uses a form of Gaussian elimination to solve such systems; this is most likely a variant of LU decomposition, but other methods are available. If you have more than one $\vec{b}$, you can use the form
solv = LinearSolve[A]

which returns a LinearSolveFunction which you can apply to each $\vec{x}$ in turn via
solv[b]

Edit:  In the case of your example, RowReduce will return the identity matrix as your matrix is invertible (non-singular), so it would not be immediately useful. You could make it ""useful"" and create an augmented matrix, via
 augA = ArrayFlatten[{{#, IdentityMatrix[Length@#]}}]& @ A

which creates $$\left(\mathbf{A}\, |\, \mathbf{I} \right).$$ Then, 
 redAugA = RowReduce[augA]

gives a matrix of the form $$\left(\mathbf{I}\, |\, \mathbf{A}^{-1} \right),$$ and the inverse is extractable via 
redAugA[[All, Length@A + 1 ;; ]]

which uses the shorthand form of Part and Span to extract only the columns you want. But, if your going to go to the trouble of getting the inverse, you might as well use Inverse[A] directly.
However, if your matrix is singular, i.e. MatrixRank[A] < Length[A], then you need to use LeastSquares which returns the vector, $\vec{x}$, that minimizes $\lVert\mathbf{A}\vec{x} - \vec{b}\rVert_2$ where $\lVert\cdot\rVert_2$ refers to the standard Euclidean norm. Which has the same calling convention
LeastSquares[A, b]

but it lacks the pre-calculation capabilities of LinearSolve. If you need those, then you would first decompose the matrix using QRDecomposition and then LinearSolve is used, as follows 
{q,r} = QRDecomposition[A];
LinearSolve[r, q.b]

Or, if you want a single function that operates like the second form of LinearSolve but with the least squares minimization,
savedLeastSquares[m_?MatrixQ]:= 
 Module[{q,r}, 
  {q,r} = QRDecomposition[m];
  LinearSolve[r, q.#]&
 ]

"
How does string interpolation work in Mathematica,"
StringForm does not create a string.  As StringForm[""x=``"", 1] // FullForm will show you, it stays unevaluated.  But it is shown in a special way in the notebook (i.e. the `` replaced by 1).
You can create a plain string from it using
ToString[ StringForm[""x=``"", 1] ]

which will give
""x=1"" 

Unfortunately, when we need to build strings, this does not always work perfectly:
ToString[ StringForm[""x=``"", 1/2] ]

  1
x=-
  2

This gave the result as a three-line string, in OutputForm.  We can try ToString[ StringForm[""x=``"", 1/2], InputForm ], but it'll return ""StringForm[\""x=``\"", 1/2]"" (unformatted).  We can also try ToString[ StringForm[""x=``"", 1/2], StandardForm], but the result will be a string containing box expressions (as you noticed).  These special expressions can contain information about formatting (everything from font styles to two-dimensional math such as $\frac{1}{2}$), but they can only be shown in a Mathematica notebook.  They are not human readable and cannot be used by other programs.
To get the desired ""x=1/2"", the workaround is 
ToString@StringForm[""x=``"", InputForm[1/2]]

Recap:

StringForm does not change the expressions passed to it at all.  StringForm expressions are merely displayed specially in notebooks.
How StringForm is displayed depends on the output format set (OutputForm, StandardForm, TraditionalForm, etc.)
Use ToString to obtain an actual string.

"
packages - Automated testing for compatibility with older Mathematica versions,"
The only reliable way seems to have a good set of unit test suites, and run them in earlier versions of Mathematica (I mention this here since the answer and comments mentioning this were deleted). However, having  explicit rules for when functions were introduced and / or last changed, extracted from the docs, seems to me a good thing, which may help reduce some work, give hints, etc. So, in addition to the suggestions in other answers / comments (I particularly support the unit testing suggestion), the following code can be executed to extract the versioning information from the documentation:
ClearAll[getVersionSince];
getVersionSince::fail = ""Unable to extract version information for function `1`"";
getVersionSince[file_String?FileExistsQ] :=
  With[{nb = NotebookOpen[file, Visible -> False]},
    With[{res = 
       Cases[
         NotebookGet[nb],
         Cell[s_String, ""History"", ___]:>
          StringCases[StringTrim@s,
           {""New in"" ~~ (Whitespace | """") ~~ d : ((DigitCharacter | ""."") ..) ~~ __ ~~  
             ""Last modified in"" ~~ (Whitespace | """") ~~  m : (((DigitCharacter | ""."") ..)) :>
                 {d, m},           
            ""New in"" ~~ (Whitespace | """") ~~ d : ((DigitCharacter | ""."") ..) :> d}
         ],
         Infinity]},
      NotebookClose[nb];
     First@res /; res =!= {}] /; nb =!= $Failed];

getVersionSince[file_String?FileExistsQ] :=
   (Message[getVersionSince::fail, Style[FileBaseName[file], Red]]; $Failed);

Here is the setup I used:
$docdir = 
  FileNameJoin[{$InstallationDirectory, ""Documentation"", ""English"", 
      ""System"", ""ReferencePages"", ""Symbols""}];
$functions = FileNames[""*.nb"", {$docdir}];

To produce the rules for the functions, you can use something like 
rules = Table[FileBaseName[f] -> getVersionSince[f],{f, $functions}]

I actually used 
j = 0;
Monitor[
 functionRules = 
   abortableTableAlt[(j++; FileBaseName[f] -> getVersionSince[f]), {f, $functions}], 
 j]

where the abortable table function abortableTableAlt is described at the bottom of this answer. The process was time and memory-consuming, so I saved the result to a file, available from this gist. The result has this format:
{""AbelianGroup"" -> {""8""}, ""AbortKernels"" -> {""7""}, ""Abort"" -> {""2""}, 
  ""AbortProtect"" -> {""2""}, ""Abs"" -> {""1""}, ""AbsoluteCurrentValue"" -> {""6""}, 
 ""AbsoluteDashing"" -> {{""2"", ""6""}}, ""AbsoluteFileName"" -> {""7""}, << 3400 >>,
 ""$UserName"" -> {""3""},  ""$Version"" -> {""1""}, ""$VersionNumber"" -> {""2""}, ""$$Media"" -> {""1""}}

Where a single number (string) is the earliest version when the function (or at least the doc.page) was introduced, and the format like {{""2"",""6""}} means that it was introduced in v.2 and last modified in v.6. In total, 3412 notebooks were processed. The only function for which this code failed was KConnectedComponents.
You can import the file from the mentioned gist, and I'd recommend to use Dispatch to speed up the rule application. Alternatively, you can use Save to attach these rules to whatever function (symbol) you want. As was suggested in another answer, this can be combined with some tool to extract dependencies, which would give you a list of system symbols used in your code. One such tool was developed David Wagner way back in 1996 and desribed in his article in the Mathematica Journal. I developed a similar tool here, but it is a work in progress and contains some bugs as of now.
"
Krnl Managmnt - Mathmatica Stack Exchang,"
You can select which kernel is used by your notebook from the menu item Evaluation -> Notebook's Kernel. By default you will probably only have one kernel called Local available. If your Mathematica license allows for it (typically licenses allow for two simultaneous kernels on a machine), you can add new kernels by selecting the Evaluation -> Kernel Configuration Options... menu item. Select ""New"" to add a new Kernel, give the kernel any name you want and accept the default options. This new kernel will now be selectable from the Evaluation -> Notebooks Kernel menu.
"
differential equations - Using physical dimensions in Mathematica DSolve,"
It is generally better to work in dimensionless units to start with. In your case, your a and b have units of $L^{-2}$, while eta is dimensionless. Taking fx''[x] + a*fx[x] == -I*eta*fy''[x] - b*fy[x] as an example, you could use $\xi=x/L$, $\alpha=a L^2$, $\beta=b L^2$ (all of which are now dimensionless), whereupon your differential equation becomes $L^{-2}\left(\partial_{\xi,\xi}F_x(\xi)+\alpha F_x(\xi)+i\eta \partial_{\xi,\xi}F_y(\xi)+\beta F_y(\xi)\right)=0$, where I have set $F_x(\xi)=f_x(x)$ and similarly for $y$. Solving the equation in the brackets is what you really should do; no problems like you mention above can now arise.
To summarise, one should almost always switch to dimensionless units before numerically solving a problem.
"
plotting - How to repeatedly show variations on a plot,"
You probably want Animate, if your intent is to show the plot varying for different n. Here's an example:
Animate[Plot[Sqrt[(1/n) x], {x, 0, 1}, PlotRange -> {All, {0, 1}}], {n, 1, 5}]


"
graphics - Sizing cells in a GraphicsGrid/GraphicsRow,"
One way of doing it is to use Row instead of GraphicsRow and setting an explicit ImageSize. The solution also scales for different sizes. Setting the same ImagePadding on both plots will ensure that they are nicely aligned.  For example:
With[{size = 300}, 
 Row[Show[#, ImageSize -> {Automatic, size}, 
     ImagePadding -> 20] & /@ {DensityPlot[
     Sin[Norm[{x, y}]], {x, -10, 10}, {y, -10, 10}], colorbar[]}]]



The above plot still has excess spacing between the graphic and the color bar. The reason for this is because of the uniform padding of 20. So this translates to 20 for the right side of the first + 20 for the left side of the second which means a 40 total between the two. Using the {{left, right}, {bottom, top}} spacing specification for ImagePadding works very well in aligning color bars to a plot. For this case, modify the above code to: ImagePadding -> {{20, 0}, {20, 5}}, which results in 

You can now set a separate right padding if you need to leave some more space between the two.
"
calculus and analysis - recursive integration,"
I think this should work:
ClearAll[r];
r[0, t_] := Exp[-k*t]*Cos[t];
r[n_, t_] := Integrate[r[0, t - td]*r[n - 1, td], {td, 0, t}]

eg
r[2,t]

(*
(\[ExponentialE]^(-k t) (2 \[ExponentialE]^(k t) k^2 - 
   k (2 k + t + k^2 t) Cos[t] + (k - k^3 + t + k^2 t) Sin[t]))/(2 (1 +
    k^2)^2)
*)

"
"plotting - Remove tick labels, but retain tick marks in RegionPlot (and related functions)","
An even simpler way that does not require you to figure out the tick positions, is to set the tick font opacity to 0 and the tick font size to 0 to avoid the excess margin where the ticks would have been. Here's an example:
RegionPlot[Sin[x y] > 0, {x, -1, 1}, {y, -1, 1}, 
    FrameTicksStyle -> Directive[FontOpacity -> 0, FontSize -> 0]]


Alternately, you could also use FontColor -> White, but note that it won't work with all backgrounds.
"
plotting - How do I plot coordinates (latitude and longitude pairs) on a geographic map?,"
data:
latlong = {{32.6123, -117.041}, {40.6973, -111.9}, {34.0276, -118.046}, 
{40.8231, -111.986}, {34.0446, -117.94}, {33.7389, -118.024}, 
{34.122, -118.088}, {37.3881, -122.252}, {44.9325, -122.966},
{32.6029, -117.154}, {44.7165, -123.062}, {37.8475, -122.47}, 
{32.6833, -117.098}, {44.4881, -122.797}, {37.5687, -122.254},
{45.1645, -122.788}, {47.6077, -122.692}, {44.5727, -122.65}, 
{42.3155, -82.9408}, {42.6438, -73.6451}, {48.0426, -122.092},
{48.5371, -122.09}, {45.4599, -122.618}, {48.4816, -122.659}, {42.3398, -70.9843}}

To put the data on latitude-longitude pairs on a map, yo will need to transform your data based on the projection method used by the map.
For example, 
 coords = CountryData[""UnitedStates"", ""Coordinates""];

gives the latitude-longitude data for US boundaries.
To use this data to put together a map with a specific projection method (say Mercator),
you need to transform your data 
 Map[ GeoGridPosition[ GeoPosition[#], ""Mercator""][[1]] & , {latlong}, {2}]

which gives

  {{{1.09884, 0.602677}, {1.18857, 0.778879}, {1.0813, 
   0.632239}, {1.18707, 0.781777}, {1.08315, 0.632597}, {1.08169, 
   0.62617}, {1.08057, 0.634228}, {1.00789, 0.704491}, {0.995431, 
   0.879708}, {1.09687, 0.602482}, {0.993756, 0.874393}, {1.00409, 
   0.714614}, {1.09785, 0.604149}, {0.998381, 0.868794}, {1.00786, 
   0.708463}, {0.998538, 0.88544}, {1.00021, 0.947273}, {1.00095, 
   0.870866}, {1.694, 0.816595}, {1.85624, 0.824365}, {1.01069, 
   0.958578}, {1.01072, 0.97155}, {1.0015, 0.892771}, {1.00079, 
   0.970088}, {1.90268, 0.817169}}}


Doing this transformation for both your data and the latitude-longitude data for world countries inside Graphics:
 Graphics[{Red, Point /@ Map[ 
  GeoGridPosition[ GeoPosition[#], 
   ""Mercator""][[1]] & , {latlong}, {2}], Gray, 
 Polygon[Map[ GeoGridPosition[ GeoPosition[#], ""Mercator""][[1]] & , 
  CountryData[#, ""Coordinates""], {2}]] & /@ 
 CountryData[""Countries""]}]

you get:

Now I know I can focus on US:
 Graphics[{ Gray, 
 Polygon[Map[ GeoGridPosition[ GeoPosition[#], ""Mercator""][[1]] & , 
 CountryData[""UnitedStates"", ""Coordinates""], {2}]], Red, 
 PointSize[.02], Point /@ Map[ 
 GeoGridPosition[ GeoPosition[#], 
   ""Mercator""][[1]] & , {latlong}, {2}]}]

to get

A simpler method avoiding GeoPosition, GeoGridPosition ...  etc
Get the coordinates of US:
 coords = CountryData[""UnitedStates"", ""Coordinates""];

and use 
 Graphics[{EdgeForm[Black], Polygon[Reverse /@ First[coords]], Red, 
 Point /@ Reverse /@ latlong}]

to get

"
palindrome - How can I get the list of dates in the next $n$ years,"
Might I suggest a different approach?
Assuming that you are interested in dates in the format DD-MM-YYYY then:
Needs[""Calendar`""]

Tuples @ Range @ {31, 12};

Append[#, FromDigits@StringReverse["""" <> IntegerString[#, 10, 2]]] & /@ %;

palindromicDates = Select[%, DateQ[Reverse@#] &]

Gives all valid palindromic dates.  You could filter out years below 1000 if you don't want those:
Cases[palindromicDates, {_, _, x_ /; x > 999}]

"
graphics - Retrieving the ImagePadding in absolute units,"
Update
I created a paclet. Install the paclet with
PacletInstall[
    ""GraphicsInformation"",
    ""Site""->""http://raw.githubusercontent.com/carlwoll/GraphicsInformation/master""
]

and then load the paclet with
<<GraphicsInformation`

Use GraphicsInformation instead of graphicsInformation
Original post
Here is my attempt to create a function that returns reliable values for ImagePadding, ImageSize and PlotRange. It is inspired by the efforts of @LLlAMnYP in his answer to 83636 and @AlexeyPopkov in his answer to 18034
The basic idea is use ExportPacket to find out what the FrontEnd computes for these values. Not only is this what Rasterize uses under the hood, it allows one to support Scaled ImageSize settings as well by setting the WindowSize of the Notebook object fed to ExportPacket. For instance, @Heike's answer doesn't fair well when ImageSize->Full is used.

ImageSize /ImagePadding - Adding an Annotation wrapper to appropriate Rectangle objects added as an Epilog can be used to determine these values.
PlotRange - Rather than using pure function Ticks, I used pure function GridLines. GridLines apply whether Frame/Axes are True or False.

Here is the function:
graphicsInformation[gr_Graphics] := Module[{info},
    info = Flatten @ Reap[
        Rule @@@ ReplaceAll[
            ""Regions"",
            FrontEndExecute @ ExportPacket[
                toNotebook[gr],
                ""BoundingBox"",
                Verbose->True
            ]
        ],
        _,
        #1->#2[[1]]&
    ];
    extract[info]
]

toNotebook[gr_] := Notebook[
    {
    Cell[BoxData @ ToBoxes @ instrumentGraphics[gr],
        ""Output""
    ]
    },
    WindowSize -> CurrentValue[EvaluationNotebook[], WindowSize],
    Evaluator -> CurrentValue[EvaluationNotebook[], Evaluator]
]

instrumentGraphics[gr_Graphics] := Show[
    gr,
    GridLines -> {sowRange[""X""], sowRange[""Y""]},
    Epilog -> {
        Annotation[
            Rectangle[Scaled[{0,0}], Scaled[{1,1}]],
            ""PlotRange"", ""Region""
        ],
        Annotation[
            Rectangle[ImageScaled[{0,0}], ImageScaled[{1,1}]],
            ""ImageSize"", ""Region""
        ]
    }
]

sowRange[label_] := Function[Sow[{##}, label]; None]

extract[rules_] := Module[{pr, is, xr, yr},
    {pr, is, xr, yr} = {{""PlotRange"", ""Region""}, {""ImageSize"", ""Region""}, ""X"", ""Y""} /. rules;
    {
    ""ImagePadding""->Abs[is-pr],
    ""ImageSize""->Abs[Subtract@@@is],
    ""PlotRangeSize""->Abs[Subtract@@@pr],
    ""ImagePaddingSize""->Total[Abs[is-pr],{2}],
    ""PlotRange""->{xr,yr}
    }
]

Here are a couple examples:
graphicsInformation @ Plot[
    Sin[x],
    {x, 0, Pi},
    ImagePadding -> {{1.1,2.2}, {3.3,4.4}}
]


{""ImagePadding"" -> {{1.1, 2.2}, {3.3, 4.4}}, ""ImageSize"" -> {360., 228.153}, 
   ""PlotRangeSize"" -> {356.7, 220.453}, ""ImagePaddingSize"" -> {3.3, 7.7}, 
   ""PlotRange"" -> {{-0.0654498, 3.20704}, {-0.0555556, 1.05556}}}

plot = Plot[
    Sin[x],
    {x, 0, Pi},
    ImageSize -> Full,
    ImagePadding -> {{1.1,2.2}, {3.3,4.4}}
];
graphicsInformation[plot]


{""ImagePadding"" -> {{1.1, 2.2}, {3.3, 4.4}}, ""ImageSize"" -> {706., 441.992}, 
   ""PlotRangeSize"" -> {702.7, 434.292}, ""ImagePaddingSize"" -> {3.3, 7.7}, 
   ""PlotRange"" -> {{-0.0654498, 3.20704}, {-0.0555556, 1.05556}}}

Compare to Heike's solution:
heike[g_]:=BorderDimensions@Image[Show[g,LabelStyle->White,Background->White]]
heike[plot]


{{19, 4}, {5, 7}}

One final comment. It is possible to use a single call to ExportPacket to extract graphics information from multiple graphics objects. Since the call to ExportPacket is the most time consuming part of the code, using a single call to ExportPacket will be much quicker than using graphicsInformation on multiple Graphics objects. Here is a version that does this:
Clear[graphicsInformation, extract]
graphicsInformation[gr:{__Graphics}] := Module[{info, res},
    info = Flatten @ Reap[
        Rule @@@ ReplaceAll[
            ""Regions"",
            FrontEndExecute @ ExportPacket[
                toNotebook[gr],
                ""BoundingBox"",
                Verbose->True
            ]
        ],
        _,
        #1->#2[[1]]&
    ];
    res = extract[info] /@ Range @ Length @ gr;
    Thread @ Rule[
        {""ImagePadding"", ""ImageSize"", ""PlotRangeSize"", ""ImagePaddingSize"", ""PlotRange""},
        Thread @ ReplaceAll[
            {""ImagePadding"", ""ImageSize"", ""PlotRangeSize"", ""ImagePaddingSize"", ""PlotRange""},
            res
        ]
    ]
]
graphicsInformation[gr_Graphics] := Replace[
    graphicsInformation[{gr}],
    Rule[a_, {b_}] :> a -> b,
    {1}
]

toNotebook[gr_] := Notebook[
    {
    Cell[BoxData @ ToBoxes @ instrumentGraphics[gr],
        ""Output""
    ]
    },
    WindowSize -> CurrentValue[EvaluationNotebook[], WindowSize],
    Evaluator -> CurrentValue[EvaluationNotebook[], Evaluator]
]

instrumentGraphics[gr:{__Graphics}] := MapThread[
    Show[#1,
        GridLines -> {sowRange[""X"" -> #2], sowRange[""Y"" -> #2]},
        Epilog -> {
            Annotation[
                Rectangle[Scaled[{0,0}], Scaled[{1,1}]],
                ""PlotRange"", #2
            ],
            Annotation[
                Rectangle[ImageScaled[{0,0}], ImageScaled[{1,1}]],
                ""ImageSize"", #2
            ]
        }
    ]&,
    {gr, Range@Length@gr}
]

instrumentGraphics[gr_Graphics] := instrumentGraphics[{gr}]

sowRange[label_] := Function[Sow[{##}, label]; None]

extract[rules_][k_] := Module[{pr, is, xr, yr},
    {pr, is, xr, yr} = {{""PlotRange"",k}, {""ImageSize"",k}, ""X""->k, ""Y""->k} /. rules;
    {
    ""ImagePadding""->Abs[is-pr],
    ""ImageSize""->Abs[Subtract@@@is],
    ""PlotRangeSize""->Abs[Subtract@@@pr],
    ""ImagePaddingSize""->Total[Abs[is-pr],{2}],
    ""PlotRange""->{xr,yr}
    }
]

"
parallelization - How to distribute definitions when loading external *.m packages,"
Don't ever call functions like Get inside ParallelTable because it will be difficult to control side effects.  Get should be evaluated only once per kernel to load definitions:  to achieve this, use either ParallelEvaluate[Get[...]] or ParallelNeeds (for proper packages).
It is good practice to only place definitions inside .m files, and not code that computes results.  If .m files contain calculations instead of definitions, they are bound to use global variables.  Handling these from parallel evaluations will be difficult and error prone.
"
graphics - Plotting a set of trajectories (not a vector field) in 3D,"
Let me add a few ideas, but be aware that this is unpolished code which was only hacked to show my points. I assume you have some kind of function $f(t;x_0,y_0,z_0)$ which gives you a trajectory starting at the initial point $(x_0,y_0,z_0)$ for $t=0$. I used $t$ only for convenience. Your function should be parametrized by the arc-lenc if you want a defined length for your field-lines
Let's consider some arbitrary pde I stole from the examples of NDSolve and create a function which takes an initial point, a length l, the number of points n and returns a StreamLine object containing n points of the trajectory
makeStreamLine[{x0_, y0_, z0_}, l_, n_] :=
 Block[{x, y, z},
  Block[{len = 
     Sqrt[(-3 (x[t] - y[t]))^2 + (-x[t] z[t] + 26.5 x[t] - 
          y[t])^2 + (x[t] y[t] - z[t])^2]},
   With[
    {sol = {x, y, z} /. First@NDSolve[{
          x'[t] == -3 (x[t] - y[t])/len,
          y'[t] == (-x[t] z[t] + 26.5 x[t] - y[t])/len,
          z'[t] == (x[t] y[t] - z[t])/len,
          x[0] == x0, z[0] == z0, y[0] == y0}, {x, y, z}, {t, 0, l}]
     },
    StreamLine[Table[Through[sol[t]], {t, 0, l, l/(n - 1.0)}]]
    ]
   ]
  ]

What you would maybe do in a first attempt is to take some random points from your domain of interest, use them as initial points, call the above function and get your StreamLines which you can draw as you like. 
This is a bad idea for several reasons: First, the case where a random generator really creates nicely distributed seed points is really rare. Most of the times, the seed points are noticeably denser in some areas. But the real bad thing is, even if your seed points are nicely distributed, this does not mean that your stream-lines fill the space in a way it looks good.
The simple idea which solves this is to use a distance-transform. What you do is, you create exactly one StreamLine a a random place and then you calculate the next seed, by taking a point which is inside your domain, but as far as possible away from all already existing trajectory points.
The distance-transform is currently only available for images, so a very basic approach will help us out here. I sample the domain with Table, and use Nearest to calculate the seed with maximal distance. The function gets all previously calculated stream-lines, the domain and the number n of sampling points. 
findNextSeedPoint[
  streamlines : {_StreamLine ..}, {{x0_, x1_}, {y0_, y1_}, {z0_, 
    z1_}}, n_] := 
 Block[{pts = Join @@ (streamlines /. StreamLine :> Sequence),
   nearestfunc, seed, maxDist = -1},
  nearestfunc = Nearest[pts];
  Table[With[{dist = Norm[{x, y, z} - First@nearestfunc[{x, y, z}]]},
    If[dist > maxDist,
     maxDist = dist;
     seed = {x, y, z}
     ]
    ],
   {z, z0, z1, (z1 - z0)/(n - 1.0)},
   {y, y0, y1, (y1 - y0)/(n - 1.0)},
   {x, x0, x1, (x1 - x0)/(n - 1.0)}];
  seed
  ]

What's left is the iteration of those two functions. The next function gets the domain, the length len of each stream-line, then number of stream-lines to create, the number of sampling points along each stream-line and the number of domain sampling points for the calculation of the next seed. As first initial point I use the center of the domain. 
makeStreams[dim : {{x0_, x1_}, {y0_, y1_}, {z0_, z1_}}, len_, 
  nStreams_, nStreamPts_, regRes_] := Block[
  {seed = {x1 - x0, y1 - y0, z1 - z0}/2.0, streams},
  Nest[
   Append[#, 
     makeStreamLine[findNextSeedPoint[#, dim, regRes], len, 
      nStreamPts]] &, {makeStreamLine[seed, len, nStreamPts]}, 
   nStreams - 1]
  ]

Now you can plot the streams like you want. I use here the tubed 3d arrows
plotStreamLines[streams : {_StreamLine ..}] := 
 Graphics3D[{ColorData[24, RandomInteger[{1, 12}]], 
     Arrow[Tube[#]]} & @@@ streams];

plotStreamLines@
 makeStreams[{{-20, 20}, {-20, 20}, {-20, 20}}, 50, 20, 57, 20]


Heike showed in her post, how to create several arrows along one trajectory. This is of course possible too. A StreamLine object is only a series of points and you can surely partition this into several sublists where each one is displayed as its own arrow

There are several other extensions which could be implemented.

It is not ensured, that a stream-line does not leave the domain. What needs to be done is simply going through all stream-lines and using all points from the start until the domain is left. If all points are in, fine, if not, then you have some arrow, which are shorter.
While the seed points are nicely distributed, the stream-line itself can come really close to an already existing line. What could be useful is a function which cuts of stream-lines when they come too close to another one. With this you should get your domain filled without having the feeling, that there are too many arrows at some places
I just assumed, that you want field-lines with a defined length. You can of course integrate your lines as long as possible in both directions: You stop when they either leave the domain, reach a singularity or come too close together. If you look at the first example in the help of StreamPlot you notice exactly this behaviour.

"
cellular automata - Generate Chaotic Time Series using CellularAutomaton[],"
Here's a line right out of the help for CellularAutomaton.
ListLinePlot[Accumulate[(-1)^CellularAutomaton[30, 
  {{1}, 0}, {500, {{0}}}]]]


"
graphics - Arranging connector lines,"
This method tries to find a minimum of the total length of all connecting lines by repeatedly swapping the endpoints of pairs of connecting lines if that reduces the total length of those two connecting lines until the list of edges doesn't change anymore. From the triangle inequality this then also guarantees that no two connecting lines will intersect each other.
start = RandomReal[1, {12, 2}];
end = With[{dx = 0.1, dy = 0.1}, 
       {{-dx, 1 + dy}, {.25 - dx/4, 1 + dy}, {.75 + dx/4, 1 + dy}, 
        {1 + dx, 1 + dy}, {1 + dx, .75 + dy/4}, {1 + dx, .25 - dx/4}, 
        {1 + dx, -dy}, {.75 + dx/4, -dy}, {.25 - dx/4, -dy}, 
        {-dx, -dy}, {-dx, .25 - dy/4}, {-dx, .75 + dy/4}}];

combis = Subsets[Range[12], {2}];
length[{b_, e_}] := EuclideanDistance[start[[b]], end[[e]]]

newedges = Transpose[{Range[12], Range[12]}];
FixedPoint[
 Do[p = {#[[{1, 4}]], #[[{3, 2}]]} &@Flatten[newedges[[c]]];
   If[Total[length /@ p] < Total[length /@ newedges[[c]]],
    newedges[[c]] = p],
   {c, combis}] &, newedges, 10]

Then the before picture is this:

and the after picture is:
Graphics[{FaceForm[Lighter@Orange], 
  Polygon[{{0, 0}, {1, 0}, {1, 1}, {0, 1}}], 
  Line@Transpose[{start[[newedges[[All, 1]]]],
     end[[newedges[[All, 2]]]]}], AbsolutePointSize[18], 
  Lighter@Orange, Point[end[[newedges[[All, 2]]]]], Black, 
  MapThread[Text, {Range[12], end[[newedges[[All, 2]]]]}]}, 
 Frame -> True, FrameTicks -> None, 
 PlotRange -> {{-.2, 1.2}, {-.2, 1.2}}]


"
How to add vertex/edge labels to existing graph,"
A random graph without any labeling:
g = RandomGraph[{11, 21}]


You can use SetProperty to add labeling P.S. 
SetProperty[g, {EdgeLabels -> {3 \[UndirectedEdge] 4 -> ""COOL""}, 
  VertexLabels -> {1 -> ""STUFF""}}]


"
graphs and networks - VertexLabelStyle not found in Mathematica 8.0.0.0,"
VertexLabelStyle was introduced in Mathematica 8.0.1.
The online documentation does not differentiate between the 8.0.x releases, but the in-product documentation does and has no mention of VertexLabelStyle in 8.0.0.
"
Manipulate[] inside DialogInput[],"
Try using global variables. Return the value with DialogReturn.
res = DialogInput[{
         TextCell[""Set value of e. Then click Proceed.""],
         Manipulate[Plot[Sin[e x], {x, 0, 2 \[Pi]}], {e, 1, 10, 
              Appearance -> ""Open"" }, 
         LocalizeVariables -> False], 
         Button[""Proceed"", DialogReturn[e]]
                 }]


"
numerics - Why round to even integers?,"
It is called bankers' rounding. The rationale is that the rounding behaves ""nicely"" even if you have negative numbers, i.e. rounding commutes with negation, which is nice.
"
equation solving - Root finding in Mathematica,"
The canonical way to solve algebraic equations is to use Solve,  e.g. 
2 - 4 x - x^2 + 2 x^3 == 0 // Solve[#, x] &


{{x -> 1/2}, {x -> -Sqrt[2]}, {x -> Sqrt[2]}}


The above  eqn //Solve[#,x]& is a so called postfix notation. 
This is an infix notation:  eqn ~ Solve ~ x
and  prefix :    Solve[ #, x]& @(eqn) 
If you want to solve a transcendental equation e.g. x^2 == Cos[x] you can use Solve as well as Reduce, however one should specify the real domain because by default Mathematica working in the complex domain cannot find all solutions.
Reduce[x^2 == Cos[x], x, Reals]


x == Root[{-Cos[#1] + #1^2 &, -0.82413231230252242296}] ||
x == Root[{-Cos[#1] + #1^2 &, 0.82413231230252242296}]


Solve[x^2 == Cos[x], x, Reals]


{{x -> Root[{-Cos[#1] + #1^2 &, -0.82413231230252242296}]},
 {x -> Root[{-Cos[#1] + #1^2 &, 0.82413231230252242296}]}}


If you are interested in numerical values of solutions you could also choose FindRoot, it works like this :  
 FindRoot[ x^2 == Cos[x], {x, Pi/6}]


{x -> 0.824132}


In general x0, here  Pi/6 is the point where it starts to search a numerical solution.
NSolve also tackles equations numerically: 
NSolve[x^2 == Cos[x], x, Reals]

{{x -> -0.824132}, {x -> 0.824132}}


And here I briefly sketch a few samples of using  functions which you mentioned : 
Roots[ 2 - 4 x - x^2 + 2 x^3 == 0, x]


x == Sqrt[2] || x == -Sqrt[2] || x == 1/2


Root[ 2 - 4 x - x^2 + 2 x^3, #] & /@ Range[3]


{-Sqrt[2], 1/2, Sqrt[2]}


Reduce[ 2 - 4 x - x^2 + 2 x^3== 0, x]


 x == 1/2 || x == -Sqrt[2] || x == Sqrt[2]


"
Pasting $\LaTeX$ into a Mathematica notebook,"
I'm prompted by Mathematica when pasting (using 8.0.4) so I don't have this issue. The following seems to do the trick though..
ToExpression[""\\frac{1}{2}"", TeXForm]

I would expect others might have more illuminating responses to this.
EDIT:
The prompt I referred to  is controlled via GlobalOptions > MessageOptions > TeXPasteWarning in the Options Inspector which can be found under Edit > Preferences > Advanced. If this is set to False you won't get prompted as to how you would like to paste the input.
"
finance - List all financial Assets data conditionally,"
As far as I know, FinancialData does not provide a way to query the length of data available for a particular stock. The only way of knowing it is to query the data and select those that have data for 20 years. First, let's get a list of all NYSE stocks with:
stocks = FinancialData[""NYSE:*"", ""Lookup""];

Now, I have multiple interpretations for your 20 year constraint, so I'll address them below.
1. The stock existed 20 years ago
This does not take into account if the stock exists at present. So, first we get the exact date 20 years ago with
date20yAgo = DatePlus[DatePlus[0], {-20, ""Year""}];

and select those stocks that have data on that day. To account for that day being a Saturday/Sunday or any other public holiday, we retrieve data for the entire week:
existed20yAgo := ! FinancialData[#, {date20yAgo, DatePlus[date20yAgo, 7]}] === 
  Missing[""NotAvailable""] &;

Select[stocks[[ ;; 20]], existed20yAgo] // Quiet
(* 
Out[1]= {""NYSE:AA"", ""NYSE:AAI"", ""NYSE:AAN"", ""NYSE:AAR"", ""NYSE:AB"",
    ""NYSE:ABA"", ""NYSE:ABK"", ""NYSE:ABK-PZ"", ""NYSE:ABM"", ""NYSE:ABN-PE""}
*)

I've just retrieved for the first 20 so that it runs in a reasonable time when you're checking. For the full list, remove the call to Part.
2. The stock has existed for the past 20 years
You can simply modify the above example a little as:
existedForPast20y[stock_] := 
   FreeQ[! (FinancialData[stock, {#, DatePlus[#, 7]}] === 
       Missing[""NotAvailable""]) & /@ {date20yAgo, DatePlus[-7]}, False]

You can do a quick check of the above with:
existedForPast20y /@ {""AAPL"", ""GOOG""}
(* Out[2]= {True, False} *)

You can use Select[...] as before and use this function to test.
3: The stock has 20 years of historical data (any date range)
This will unfortunately require pulling all the data for each stock, and will definitely be slower.
has20yData := DateDifference[Sequence @@ (First /@ 
        Through[{First, Last}[FinancialData[#, All]]]), ""Year""][[1]] >= 20 &

Again, replace the test function in Select with has20yData. I'll leave the rest of the constraints for you to work on.
"
functions - DiracDelta attributes,"
You're right, applying FullDefinition I see that DiracDelta lacks the NumericFunction attribute. And indeed, NumericQ[DiracComb[1]] yields True whereas NumericQ[DiracDelta[0]] doesn't. 
Although I'm not sure why that difference exists, you may perhaps be able to get the desired result (you didn't say what your bug was) by setting SetAttributes[DiracDelta, NumericFunction]. At least it then allows you to work with the knowledge that NumericQ[DiracDelta[0]] is True.
Actually, maybe it would be more correct to remove the NumericFunction from both... depends on what you want, I guess.
"
graphs and networks - Truncate TreeForm to show only the top,"
Can use something like this:
ClearAll[showTopTree];
showTopTree[expr_, level_] :=
  Module[{myHold}, 
     SetAttributes[myHold, HoldAll];
     Function[code,
       TreeForm[Unevaluated@Unevaluated@code],
       HoldAll] @@
    (Hold[#] &@
      DeleteCases[MapAll[myHold, expr], _, {2*level, Infinity}] //.
           myHold[x__] :> x)];

Pretty ugly, but seems to work:
expr = Nest[1/(1 + #) (1 - #) &, w, 5]
Manipulate[showTopTree[expr, n], {n, 1, Depth[expr], 1}]

GraphicsGrid[Partition[showTopTree[expr, #] & /@ Range[6], 3]]


"
pattern matching - Extracting coefficients from a partial differential equation,"
So, this is a solvable problem, but my solution is hacky, not cookbook by any means. It involves using Apply to make algebraic expressions into lists of terms and factors, and it relies the optional levelspec arguments for Cases and DeleteCases being infinity. 
Also note the use of Block to temporarily suspend the evaluation rules for Derivative, so that I can make things more regular by replacing F[x, y] with Derivative[0, 0][F][x, y]. This is a frequently useful trick when doing algebraic manipulations. 
coeffRules = Block[{Derivative},
  With[{terms = 
     Apply[List, eqn /. F[x, y] :> Derivative[0, 0][F][x, y]]},
   Cases[
    Flatten@Map[CoefficientRules[#, {x, y}] &, terms],

    (pows_ -> rhs_) :> 
     With[{degs = 
        Flatten[Cases[rhs, Derivative[degs___][F][x, y] :> degs, 
          Infinity]]},
      With[{args = Join[pows, degs]},
        If[Length@args == 4, a @@ args, b @@ args]]
       -> DeleteCases[rhs, Derivative[___][F][x, y], Infinity]]]]];

Here, coeffRules is just a list of rules for the a and b coefficients you described:
{a[0, 0, 0, 0] -> l^4 m^4, a[0, 0, 0, 0] -> -57 l^4 Lambda M^2, 
 a[0, 1, 0, 1] -> l^4 m^4, a[0, 1, 0, 1] -> -4 l^2 M^2, 
 a[0, 1, 0, 1] -> 57 l^4 Lambda M^2, b[0, 6, 0, 0, 0, 4] -> 4 M^2, 
 b[0, 8, 0, 1, 0, 5] -> 2 M^2, a[0, 8, 2, 4] -> -4 M^2}

You can then verify that this answer is correct like so:
In[17]:= Total[coeffRules /. {
             (a[i_, j_, k_, l_] -> coeff_) :> 
              coeff*x^i*y^j*Derivative[k, l][F][x, y],
             (b[i_, j_, k_, l_, m_, n_] -> coeff_) :> 
              coeff*x^i*y^j*
               Derivative[k, l][F][x, y] Derivative[m, n][F][x, y]}] - eqn
Out[17]= 0 

Hopefully this is enough to get you started.
EDIT to add: In reply to @sjdh's comment, you can collect all the terms with the same left-hand side using Map, GatherBy and Total:
In[69]:= gatheredRules = Map[
          (#[[1, 1]] -> Total@#[[All, -1]]) &,
          GatherBy[coeffRules, First]]
Out[69]= {a[0, 0, 0, 0] -> l^4 m^4 - 57 l^4 Lambda M^2, 
          a[0, 1, 0, 1] -> l^4 m^4 - 4 l^2 M^2 + 57 l^4 Lambda M^2, 
          b[0, 6, 0, 0, 0, 4] -> 4 M^2, b[0, 8, 0, 1, 0, 5] -> 2 M^2, 
          a[0, 8, 2, 4] -> -4 M^2}

In order to verify that this matches the original equation, use Simplify:
In[70]:= Simplify[eqn - 
          Total[gatheredRules /. {
            (a[i_, j_, k_, l_] -> coeff_) :> 
             coeff*x^i*y^j* Derivative[k, l][F][x, y], 
            (b[i_, j_, k_, l_, m_, n_] -> coeff_) :> 
             coeff*x^i*y^j*Derivative[k, l][F][x, y] Derivative[m, n][F][x, y]}]]
Out[70]:= 0

The secret to doing these kind of algebraic manipulations in Mathematica is that algebraic expressions are just list structures with some fancy heads, and thus can be manipulated with exactly the same functions (like Map and Cases) as lists. Indeed, as you become more familiar with Mathematica, you'll discover that pretty much everything, from graphics to imported XML to notebooks themselves, can be manipulated this way.
"
Switching off Dynamic updating on a cell by cell basis,"
You can click in the front-end
Evaluation->Dynamic Updating Enabled
to switch off dynamic updating of the cell.
In case you want to switch off evaluation of the cell, click 
Cell->Cell Properties -> Evaluatable.
"
import - Release the web camera after using CurrentImage[],"
To turn the camera off you could use the undocumented function IMAQ`StopCamera[]. Similarly IMAQ`StartCamera[] will turn it back on again.
Alternatively you can use the On/Off button on the control interface returned by ImageCapture[]:

"
programming - Splitting up delimited data in lists,"
The first thing that comes to mind is:
list = {""section 1"", ""a"", ""b"", ""c"", ""section 2"", ""d"", ""e"", ""f""};

delimiterQ[s_String] := StringMatchQ[s, ""section "" ~~ __]
delimiterQ[_] := False

SplitBy[list, delimiterQ][[2 ;; ;; 2]]


{{""a"", ""b"", ""c""}, {""d"", ""e"", ""f""}}



Szabolcs raised the concern that if the first element of list is not a delimiter this breaks.  If you know in advance that the first element is not a delimiter you can use [[;; ;; 2]] -- if it is uncertain you might use this rather ugly blob of code:
#[[If[delimiterQ@#[[1, 1]], 2, 1] ;; All ;; 2]] & @ SplitBy[list, delimiterQ]


If you can create a list of all separators another option would be using Import.  With your data in splitdat.txt:
Rest@Import[""splitdat.txt"", ""Table"", 
  ""LineSeparators"" -> {""section 1"", ""section 2""}, 
  ""FieldSeparators"" -> ""\n""]


{{""a"", ""b"", ""c""}, {""d"", ""e"", ""f""}}


Likewise ReadList, which is probably faster:
ReadList[""splitdat.txt"",
  Word,
  WordSeparators -> ""\n"",
  RecordLists -> True,
  RecordSeparators -> {""section 1"", ""section 2""}
]

"
customization - Customize front end to add notifications when evaluation finishes?,"
Here's a quick solution. 
Note that it's only tested in Ubuntu - please test it in other operating systems and make any changes that are necessary.
First we define a sendNotification command and then show how to create a style of input cell that automatically calls it. Also included is a palette that will modify any cell to have the appropriate CellEpilog option.

sendNotification[txt_String, opts___] := 
 Module[{text = "" \"""" <> txt <> ""\"""", icon},
  icon = FileNameJoin[{$InstallationDirectory, ""SystemFiles"", ""FrontEnd"",
     ""SystemResources"", Switch[$OperatingSystem, 
     ""Unix"", ""X"", ""MacOSX"", ""OSX"", ""Windows"", ""Windows""], ""Mathematica.png""}];
  Switch[$OperatingSystem,
   ""Unix"", 
   Run[""("" <> ""notify-send"" <> "" -i "" <> icon <> "" Mathematica"" <> text <> "")&""],
   ""MacOSX"", 
   Run[""("" <> ""growlnotify"" <> "" -n \""Mathematica.app\"""" <> 
     "" -a \""Mathematica\"""" <> text <> "")&""],
   ""Windows"", 
   Run[""start /b "" <> ""growlnotify"" <> "" /s:true"" <> "" /p:2"" <> 
      "" /i:"" <> icon <> "" /t:Mathematica"" <> text]]]

The code assumes that: 

In linux you have notify-send installed.
in OSX you have Growl installed and growlnotify in your path (which it is by default)
in Windows you have Growl for Windows installed and growlnotify in your path.    

Notify-send (which in Ubuntu plugs into NotifyOSD) does not play with the GNTP so it can not easily be used to interact with other systems and mobile devices. An alternative is to use Growl on Linux with gntp-send.  In KDE there is also KNotify. For notify-send, another possible networking solution is this SO answer.
In Windows, you could also (maybe) use Snarl.
You can test the notifier using
sendNotification[""test""]


You can create a modified Input style that automatically calls sendNotification after it has finished evaluating. Simply add the following style to your stylesheet
Cell[StyleData[""InputNotify"", StyleDefinitions -> StyleData[""Input""]], 
  CellEpilog :> sendNotification[""Evaluation of line "" <> ToString[$Line-1]
     <> "" is complete""],
  MenuCommandKey -> ""-"",
  CellDingbat->""\[LightBulb]""]

Then you can insert a InputNotify cell by pressing Alt--


Alternatively, here's a palette that will modify a cell to have the appropriate CellEpilog. Run the code and then, if you want to keep the palette, you can install it via the palette menu.
CreatePalette[{
  Button[""Make Cell Growl!"", SelectionMove[InputNotebook[], All, Cell];
   With[{cell = NotebookSelection[InputNotebook[]]},
    SetOptions[cell, TaggingRules -> Options[cell, {CellDingbat, CellEpilog}],
     CellDingbat -> ""\[LightBulb]"",
     CellEpilog :> sendNotification[""Evaluation of line "" 
                    <> ToString[$Line - 1] <> "" is complete""]]]],
  Button[""Stop Cell Growling"", SelectionMove[InputNotebook[], All, Cell];
   With[{opts = TaggingRules /. 
       Options[NotebookSelection[InputNotebook[]], TaggingRules]},
    SetOptions[NotebookSelection[InputNotebook[]],
     Sequence @@ opts, TaggingRules -> {}]]]}, 
 Saveable -> False, WindowTitle -> ""Growl""]

"
programming - Are there any cases when For[] loops are reasonable?,"
To my mind, there are at least two cases when For loops are ok:

Inside Compile, or in code which is being written with Compile in mind
When your inner loops are vectorized or made efficient by some other means, so that each iteration of the For loop is sufficiently intensive computationally

Many efficient algorithms are procedural by nature and gain their efficiency by side effects and local mutations. When those algorithms contain nested loops, what matters the most is to speed up innermost loop(s). While we mostly tend to move away from For loops, I have no problem with a For loop being an outer loop in a program, as long as innermost loops are optimized. Also, For loops are more flexible than Map or Scan because you can use Break and Continue, and generally are not forced to iterate over all of the elements in a list in a prescribed order. 
That said, I think we should recommend beginners to avoid For loops, just because this would allow them to change their mindset and get to the better understanding of Mathematica programming sooner. I'd say, it is ok to occasionally use For loops for experienced users, but beginners would be better off avoiding them entirely, until they get more experience with the language.
"
"programming - Can this be written well, without loops?","
There are some features of this specific problem one can take advantage of.  The boundary of the x,y,z,n domain represented by val <= max is linear in x,y,z and only quadratic in n; furthermore val increases with each of the variables.  So basically the loops might be done in any order, and the limits might be solved for explicitly.
We'll start with the limit max and the expression val, which can be compiled for the sake of comparison.
max = 5000;
val[x_, y_, z_, n_] := 
  2 (2 n^2 + (y - 2) (z - 2) + x (y + z - 2) + 2 n (x + y + z - 3));
valc = Compile[{{x, _Integer}, {y, _Integer}, {z, _Integer}, {n, _Integer}}, 
   2 (2 n^2 + (y - 2) (z - 2) + x (y + z - 2) + 2 n (x + y + z - 3))];

We can then solve for the limits on the indices z,y,x,n and save them in idxLimit[tag], where tag runs 1 through 4 and corresponds to z,y,x,n in that order.  (Here a function runs through the tags and sets up idxLimit, but it could have been set up with separate formulas just as easily, as in the output below the code.)
Function[{tag}, idxLimit[tag] =
   Simplify[
     Min[{y, x, {}, {}}[[tag]], {z, y, x, n}[[tag]] /. 
       Last@Solve[(val[x, y, z, n] /. Take[{z -> 1, y -> 1, x -> 1}, tag - 1]) == max,
              {z, y, x, n}[[tag]] ]],
     n >= 1]
 ] /@ Range[4];


Next we make the table of the values
a = Normal@SparseArray[Rule @@@ #] &@
    Tally[Flatten[
      With[{i1 = {z, idxLimit[1]},
        i2 = {y, idxLimit[2]},
        i3 = {x, idxLimit[3]},
        i4 = {n, idxLimit[4]}},
       Table[valc @@ {x, y, z, n}, i4, i3, i2, i1] ] ]
     ]; // AbsoluteTiming
(* {1.536007, Null} *)

Below is a table of timings (in sec.) that compares using val instead of valc and ParallelTable (on a 2-core machine).  It also compares the timing of the OP's For-loop program, with and without a compiled val.  The last line are the timings for max = 20000.

Table itself accounts for about 0.876687 sec. (10.003417 for 20K).  Most of the rest of the time is for evaluation valc (about 7-8 sec. in the 20K case) or val.  A smaller chunk is spent collecting the results.  It seemed while I was playing with the problem, that a[[r]]++ suffers from having to evaluate a[[r]] twice, once for reading and once for writing.  Perhaps it doesn't take that much time, but I felt like there was a limit to how fast I could accumulate results in a that way.  The Table way gains a little time at the expense of a lot more memory.
It's debatable whether solving for the limits (to get idxLimit) is clean.  The original val leads to the strange expressions.  Mainly it's a mathematical trick than a programming one, which allows a rather standard conversion of for loops to Table.  The rest of it are just tweaks.
"
parallelization - Wolfram Light Weight Grid and parallel computing,"
I've discovered (at least some of) the answer to this question.

One needs to install the Wolfram lightweight grid manager on local AND remote computers.  This seems a bit confusing as the title of the program that one sees during the installation, refers to this application as ""Wolfram gridMathematica Server with Wolfram Lightweight Grid Manager"".  A bit clearer nomenclature i.e. ""...server/client manager"" would, in my mind make this clearer.
The login on the ""Licensing"" tab of the Wolfram Lightweight Grid Manager"" that opens in a browser requires the user name ""admin"".  This also seems a bit confusing, because while they refer to this user name in the set up, the user does not enter it.  If only ""admin"" works as a user name in this instance why require the user to enter it at all?  I thought it wanted either the administrator's name for the computer or the login for the grid manager.  Also, I don't understand why it requires two sets of user names and passwords to setup and run the manager.
Apparently, while a desktop license of Mathematica includes 2 ""Controlling"" processes and  4 ""Computing"" process (see the following from the Wolfram User Portal:


The number of Processes allowed is formated as (X/Y), where X is the number of Controlling Processes and Y is the number of Computation Processes.
A Controlling Process indicates the number of simultaneous network users of ""seats"" allowed.  A Controlling Process handles input, output, and scheduling for the Computation Processes.
A Computation Process indicates the number of computations that may be
  run simultaneously.)

in discussing this with support earlier today, it appears Mathematica licensing requires  Computation Processes to reside on the same machine as the Controlling Process.
It seems one can have two copies of the same license installed on different machines, but one can only use one of the copies at a time and one can only access the Computation Processes for the license if they reside on the same machine as a copy of the license.
This seems a bit antiquated given Sun Micro Systems' (via John Gage's) recognition a couple of decades ago that ""The network is the computer.""  Why should the location of the Computation Processes matter?
So if I have the correct information from support, to get access kernels on a remote machine one needs a full copy of Mathematica installed on the remote machine.
Update: I just installed a full desktop version of Mathematica on my remote machine and can now see and access its 2 processors from the Preferences >> Lightweight Grid window and see them in action on the Parallel Kernel Status window:

To my mind, this licensing approach does not align well with the vision and promise of distributed processing, which sought to enable people to access computing resources anywhere on a network.  While advanced desktop machines have started to have 4 processors, I'd wager most machines still have only one or two.  Meanwhile lots of people may have a couple of desktops or some combination of desktops and laptops available.  Just a shame we can't make use of them.
Maybe it makes sense to study up on CUDA and GPU.  
Hope this helps.
Jagra

Some additional information from Mathematica support relative to my initial thoughts:
""One needs to install the Wolfram lightweight grid manager on local AND
remote computers"". 

This is incorrect, the lightweight grid manager is only needed on the
  remote computers (or the computers that will be supplying the kernels
  for parallel computation). The only time the lightweight grid manager
  will be required on the local machine is if other machines will be
  launching kernel from this local machine.

""...it appears Mathematica licensing requires Computation Processes to
reside on the same machine as the Controlling Process"".

This is also incorrect. The controlling process is only required on
  the job submission node. The computation nodes can reside across
  multiple machines which do not need to have another controlling
  process. (Basically, they have kernels and no front ends).

""It seems one can have two copies of the same license installed on
different machines."" 

This is incorrect as well. Unless you are running a license manager or
  the lab version (which will not run gridMathematica), you cannot run
  the same license on two machines at any one time. The passwords are
  machine dependent. You will need to call us anytime you need to switch
  machines.

"
front end - How change order of items added to the Palettes menu?,"
Okay, new approach.  My old answer is preserved below for reference.  
I was not aware of this before posting, but there is a MenuPosition option in the Options Inspector, and it does take effect.  You will need to first check Editable so that you can edit the palette.  Here is the active screen:


In the header of a palette .nb file there is this section:
(* Internal cache information:
NotebookFileLineBreakTest
NotebookFileLineBreakTest
NotebookDataPosition[       145,          7]
NotebookDataLength[     28489,        713]
NotebookOptionsPosition[     27870,        688]
NotebookOutlinePosition[     28422,        710]
CellTagsIndexPosition[     28379,        707]
MenuPosition->1000
WindowTitle->Slide Show
WindowFrame->Palette*)

The value of MenuPosition, if present determines the group and ordering of the palette in the menu.  That is, lower values appear higher in the list, and palettes with the same value will be placed in the same group.
"
graphics - Point Renderings Slightly Off in Mathematica,"
Update: simple work-around added at bottom of post.
Analysis of the problem
This appears to be an issue with the default PlotMarkers.  I do not see similar offsets using this:
Show[
 ListPlot[{stationaryPoints, inflectionPoints}, Frame -> True, 
  PlotMarkers -> {{Graphics@{Red, Disk[]}, 
     0.05}, {Graphics@{Blue, Rectangle[]}, 0.05}}],
 Plot[f[x], {x, -Pi - 1, Pi + 1}],
 ImageSize -> 500
]


You can see from this that the default PlotMarkers are actually font based, rather than Graphics primitives:
Graphics`PlotMarkers[] // InputForm
Graphics`PlotMarkers[][[1, 1]] // ToCharacterCode

I believe that these font glyphs are inherently prone to misalignment with Graphics primitives, due to a different rendering pipeline.

Addressing your question about (mis)alignment of PlotMarkers constructed from primitives, I believe this is the result of the chosen antialiasing scheme.  One can see by magnifying a screen capture that orthogonal lines use ""pixel snapping"" or ""hinting"".  This increases apparent sharpness, but sacrifices precise placement.

On my Windows system, a distinct ""judder"" is apparent in the following animation.  Both the placement and the shape of the rectangles changes with ImageSize.
Show[ListPlot[{stationaryPoints, inflectionPoints}, 
          PlotMarkers ->
              {{Graphics@{Red, Disk[]}, 0.05},
               {Graphics@{Blue, Rectangle[]}, 0.05}}], 
     Plot[f[x], {x, -Pi - 1, Pi + 1}],
     Ticks -> None,
     ImageSize -> d
] ~Animate~ {d, 200, 300, 1}

I am not aware of a method to change the 2D antialiasing scheme.  However, one work-around is to rasterize the image at a higher resolution, and then resample to the target size.

Changing the anti-aliasing method using Opacity
I learned from Simon Woods that using Opacity, even with an effectively opaque value of .999 (but not 1), will change the anti-aliasing method that is used for font glyphs.  Therefore we can affect a work-around for this alignment problem by specifying: BaseStyle -> Opacity[.999] or BaseStyle -> {FontOpacity -> 0.999}.
Observe:
Show[Plot[f[x], {x, -Pi - 1, Pi + 1}], 
 ListPlot[{stationaryPoints, inflectionPoints}, PlotStyle -> {{Red}, {Blue}}, 
  PlotMarkers -> {Automatic, 15}, BaseStyle -> Opacity[.999]]]


"
How do I find the elements in a list that return the highest value for a function?,"
While using Ordering as in Mr.Wizard's answer will most likely be the fastest non-compiled solution, it will not return all possible arguments that maximize the return value. Here's a simple way of writing a function that does this:
listMaxArg[f_, list_] := With[{max = f /@ list // Max}, Select[list, f@# == max &]]

Here's an example that compares the two solutions:
a = {{1, 2, 3}, {10}, {6, 4}};
listMaxArg[Total, a] 
(* Out[1]= {{10}, {6, 4}} *)

listMaxArgMrWiz[Total, a]
(*Out[2]= {{6, 4}} *)

"
front end - How to sort cells in a notebook based on cell tags?,"
This is actually something I am working on for real at the moment. This is what i have got so far:
nb = NotebookOpen[""path/to/notebook.nb""];
SelectionMove[nb, All, Notebook];
content = NotebookRead[nb];
NotebookDelete[nb];

For searching based on the number listed as the first tag:
sorted = SortBy[content, 
 Cases[#, HoldPattern[
     Rule[CellTags, {x_ /; StringMatchQ[x, NumberString], __}]] :> 
    ToExpression@x] &]

and for searching based on the word in the second tag:
sorted = SortBy[content, 
 Cases[#, HoldPattern[Rule[CellTags, {_, x_, __}]] :> x] &]

With both of these methods the untagged cells are returned first ...which is ok. Then
Scan[NotebookWrite[nb, #] &, sorted];
NotebookSave[nb];
NotebookClose[nb];

This is a little bit slow but seems to be doing the job.
Edit
So this code seems to be doing the job on the notebooks i needed to use this with. Would still be interested in suggestions from others.
ClearAll[sortNotebook];

Options[sortNotebook] = {""sortby"" -> ""Number""};

sortNotebook[file_String, OptionsPattern[]] := 
 Module[{nb, opt = OptionValue[""sortby""], sorted},

  nb = NotebookOpen[file];
  SelectionMove[nb, All, Notebook];
  content = NotebookRead[nb];
  NotebookDelete[nb];
  Which[
   opt === ""Number"", 
   sorted = 
    SortBy[content, 
     Cases[#, 
       HoldPattern[
         Rule[CellTags, {x_ /; StringMatchQ[x, NumberString], __}]] :>
         ToExpression@x] &],
   opt === ""Task"", 
   sorted = 
    SortBy[content, 
     Cases[#, HoldPattern[Rule[CellTags, {_, x_, __}]] :> x] &],
   opt =!= ""Number"" && opt =!= ""Task"", 
   Print[""you messed up with the option names""]
   ];
  Scan[NotebookWrite[nb, #] &, sorted];
  NotebookSave[nb];
  NotebookClose[nb];
  ]

"
options -  Saving a notebook without output lines,"
In Options Inspector you can change the EvaluationOptions for Selected Notebook or for Global Preferences by adding 
  {""WindowClose"" :>  FrontEndExecute[FrontEndToken[""DeleteGeneratedCells""]]}

to the NotebookEventActions line. 
Screenshots for changing the notebook evaluation options in Options Inspector:
A notebook with Input and Output cells and the Evaluation Options page in Option Inspector 

After editing the NotebookEventActions line in Options Inspector or evaluating 
SetOptions[EvaluationNotebook[], NotebookEventActions -> {""WindowClose"" :> 
 FrontEndExecute[FrontEndToken[""DeleteGeneratedCells""]]}]; 

inside the notebook:

After clicking X on the on the notebooks window frame:

After clicking Yes on the dialog window:

Alternative: you can add 
 SetOptions[EvaluationNotebook[], NotebookEventActions -> {""WindowClose"" :> 
 FrontEndExecute[FrontEndToken[""DeleteGeneratedCells""]]}]; 

to a notebook's initialization cell.
"
front end - How do I programmatically add to contextual menus?,"
There's an option ContextMenu, which you seem to be able to set at cell, notebook, or even box level. They all default to something like
FEPrivate`FrontEndResource[""ContextMenus"", ""something""]

That info seems to be in the ContextMenus.tr file in the $InstallationDirectory, SystemFiles, FrontEnd, TextResources.
In any case, all that that option needs is a list of MenuItem[...]. You can look at that file (or at MenuSetup.tr) to get a hang on the syntax. Then it's just setting the option.
Apart from the brute force method of reading the file, creating your own, adding your Menus, and setting that option, I still haven't found a way to ""append"" the MenuItems. Only to replace... I'll edit if I find something
"
Speeding up export of a matrix to a dat file,"
I suggest you watch the presentation BigData: Demystifying Large Datasets in Mathematica
by Nick Lariviere.  He discusses the various possibilities quite clearly.
"
probability or statistics - Function for Autocorrelation,"
From the help file for ListConvolve, to find the autocorrelation of a list:
data = Table[Mod[i^2, 17], {i, 100}];
autocorrelation = ListConvolve[data, data, {1, 1}];
ListLinePlot[autocorrelation ]


"
programming - Programmatically generate packages from notebook files?,"
Not entirely on topic (and probably well-known), but starting with version 6 (I think) you can very comfortably work with the .m files within the frontend. The frontend parses the package and displays it just like any old notebook. You can use sections and do all the fancy typesetting, generate (temporary) output etc. This is also available under File -> New -> Package (.m).
The code is put into ""Code"" style cells which are Initialization cells, and these are saved (together with text and section information, see Pillsy´s post), stripping any output cells and leaving you with the plain package that works just fine. With the parsing, you also get some helpful formatting and additional gizmos (see image).
So you only maintain one set of packages directly, but with all the benefits of the frontend interface (notice: the parsing can take a few seconds when opening).

And if you are annoyed by the linewrapping behaviour of the package stylesheet, have a look at this thread: Viewing packages in Mathematica
"
graphs and networks - HITS centrality,"
For HITSCentrality you could try 
Pick[Transpose[HITSCentrality[graph1]], VertexList[graph1], 1]

"
programming - How to write a function-defining function which stores the function arguments in a stack?,"
You could name the patterns
DefFn[f_[args___], body_] := 
  f[s : PatternSequence[args]] := WithStackFrame[{f, {s}}, body];

"
performance tuning - Efficient way to turn a subset into a permutation,"
Theoretically, this will have linear complexity:
reshuffle[ab_, kvec_] :=
  Module[{a, copy , bs = Drop[ab, Length[kvec]], n = 0},
    copy = Table[a, {Length[ab]}];
    copy[[kvec]] = Take[ab, Length[kvec]];
    copy /. a :> bs[[++n]]]

In practice, however, I am pretty sure your solution is one of the fastest. A version of my solution can be compiled if your list is e.g. a list of integers or reals, in which case it may be faster.
Here is a compiled version:
reshuffleC =
  Compile[{{ab, _Integer, 1}, {kvec, _Integer, 1}},
     Module[{result, min = Min[ab], i = 1, ctr = 0, bs = Drop[ab, Length[kvec]]},
       result = Table[min - 1, {Length[ab]}];
       result[[kvec]] = Take[ab, Length[kvec]];
       For[i = 1, i <= Length[ab], i++,
         If[result[[i]] == min - 1,
         result[[i]] = bs[[++ctr]]]];
       result], CompilationTarget -> ""C""]

If you have a general list as ab, you can use ab[[reshuffleC[Range[Length[ab]],kvec]]]. 
Here are some benchmarks:
abtest = RandomInteger[{10000000},10000000];
kvec = RandomSample[Range[10000000],5000000];
(res1=reshuffleC[abtest ,kvec]);//Timing
(res2=Reshuffle[abtest ,kvec]);//Timing
res1==res2

(* 
 ==> {0.437,Null}
     {2.797,Null}
      True
*)

"
graphics - Too much vertical space in a CDF file,"
You can easily remove all white space around your CDF app. Simplest way - use CDF Web Deployment Wizard available in Mathematica version 8.0.4. It is designed to remove the white space around interactive content and embed it tigtly into a webpage. Follow File » Deploy » Embed in HTML… Here is the result of this workflow applied to the app from your file SimpleDemos.nb and embeding it into WordPress.
The CDF file can be downloaded from here
As you can see there is no horizontal or vertical white space around the app.
I would also recommend controlling the size of embedded CDF with ImageSize->{w, h} option for your internal graphics in Manipulate[...]. Actual app size on the page will be slightly larger due to Manipulate[...] interface with dimensions provided by the wizard. If you would like detailed instructions follow this video.
"
Reading from a stream of strings and numbers delimited by commas,"
This seems to work and doesn't require conversion
stream = StringToStream[
   ""Apple,Jack,1,123.456\nOrange,Jill,2,456.789\n""];

While[! EndOfFile === (data = 
      Read[stream, Riffle[{Word, Word, Number, Number}, Word],
        TokenWords -> {"",""}] /. {"","" -> Sequence[]}), 
  Print[""Fruit:"", data[[1]], "" Name:"", data[[2]], "" Integer:"", 
    data[[3]], "" Real:"", data[[4]]];];

Close[stream];

"
"Formatting output of OpenAppend[] to match what Export[data,file,"".csv""] would output?","
As @WReach has noted, Export will accept a stream as its first argument so 
file = OpenAppend[""out.txt""]

Export[file, data, ""CSV""];
WriteString[file, ""\n""];

Close[file]

Alternatively you could first use ExportString to write the data into a string in the desired format, then send the string to the file to be appended to using WriteString.
Example:
data = RandomInteger[100, {100, 3}]

file = OpenAppend[""out.txt""]

string = ExportString[data, ""CSV""];

WriteString[file, string]
WriteString[file, ""\n""];

Close[file]

"
debugging - Mathematica Debuggability,"
While I wait for better answers from some very knowledgeable people in the matter on the site, I'll write what I'm thinking...
I think that most of your problems are due to lack of practice with functional thinking rather than lack of debugability itself.

I think one that on the contrary, one of the advantages of programming functionally is that the state of the program is kept on the stack. If you know where you are, you know everything. In imperative programming its harder to know all the variables that keep the state at any point to understand the behaviour. If goto and label are worse for following the flow of a program versus normal loop structures, then functional seems another step ahead. You can always put a function like @LeonidShiffrin's ShowIt where you want to see what's going on, or something similar to print the stack (see the function Stack[_]):
SetAttributes[ShowIt, HoldAll];
ShowIt[code_] := 
   Module[{y}, 
      Print[ToString[Unevaluated[code]], "" = "", y = code]; 
      y]

You answered yourself. Always remember that in Mathematica, code and expressions are the same, so you can always make a ""function"" that saves you all the boilerplate code if you think that certain solution can be done but its hard and makes you type a lot. (You could even take it to the extreme of brutally overload SetDelayed to always add a func[___]:=Throw, but I don't think that's recomended, hehe)

As to how to make the debugging simpler, well... 

Build up from short declarative functions. Comment a lot, Test them before going on chaining 11 of them.
Use Messages
Check out the debugger, at least the Workbench one. They let you add breakpoints, see the stack, and even break on messages
Use functions such as that ShowIt from Leonid, or make your own.
Learn to use Trace and family. I really like a version of it that I think I took from a post by @WReach
TraceViewShort[expr_] := 
 Module[{steps = {}, stack = {}, pre, post}, 
  pre[e_] := (stack = {steps, stack}; steps = {}); 
  post[e_, r_] := (steps = First@stack~Join~{{e, steps, HoldForm[r]}};
     stack = stack[[2]]); SetAttributes[post, HoldAllComplete]; 
  TraceScan[pre, expr, ___, post]; 
  DynamicModule[{focus, show, substep, enter, exit}, focus = steps; 
   substep[{e_, {}, _}, _] := {Null, e, 
     Style[""inert"", {Italic, Small}]}; 
   substep[{e_, _, r_}, 
     p_] := {Button[Style[""show"", Small], enter[p]], e, 
     Style[Row[{""-> "", r}], Small]}; 
   enter[{p_}] := PrependTo[focus, focus[[1, 2, p]]]; 
   exit[] := focus = Drop[focus, 1]; 
   show[{e_, s_, r_}] := 
    Column[{Grid[{{""Expression"", 
         Column@Reverse@focus[[All, 1]]}, {Column[{""Steps"", 
           focus /. {{_} :> Sequence[], _ :> 
              Button[""Back"", exit[], ImageSize -> Automatic]}}], 
         Grid[MapIndexed[substep, s], Alignment -> Left]}, {""Result"", 
         Column@focus[[All, 3]]}}, Alignment -> Left, Frame -> All, 
       Background -> {{LightCyan}}]}]; Dynamic@show@focus[[1]]]]
SetAttributes[TraceViewShort, {HoldAllComplete}]

Check the function arguments. In some cases it may make more sense to use your f[___]:=Throw and in others leave it unevaluated
Consider Assert, it works well with the debugger and doesn't make your code slower because you can turn it off...

Anyway, Mathematica allows you to do almost anything you want. Most of the things you said are not Mathematica limitations but, in the worst case, limitations of the way you're using it. Sometimes that extra freedom has the disadvantage of not giving you guidelines as to what's best.
"
parallelization - CUDA and GPU hardware and compatibility questions?,"
Information we received back from Wolfram Technical Support, which may help others better understand the issues originally raised around CUDA and OpenCL:

In general CUDA is much faster than CPU parallelization CONDITIONALLY and not limited by the limitation of our licenses.
  However, the functions supported in CUDA are limited to numerical functions such as arithmetic operations and fast Fourier transformation, in particular those defined in math.h in C.
  You will need to program most of the solvers by yourself or find the corresponding CUDA libraries from either developer zone or C++ extension
  packages. 
The worst drawback of CUDA code is data flow actually. It will take a
  very long time for data to be copied from RAM to GPU memory. If data
  flow in/out is what you want, you should do that just once or twice in
  the whole process.
So far CUDA is only supported on a local machine, i.e. you cannot use
  the graphics card on other machine. It is not recommended to use two
  graphics cards even on the same machine so far since it is not mature
  under current CUDA tech. 
On the other hand, parallel cpu computation is less optimized in terms
  of clock speed. The limitation comes from how CPU generates threads
  and that the master kernel distributes tasks along the computation.
  However, the parallel kernels using the gridMAtheamtica tech have
  excellent scalability and support all internal functions inside
  Mathematica. This, as a compensation for slower clock speed, saves
  huge amount of time for programming.  Typically for a task involving
  many different functions like nonlinear solver, plot, symbolic
  computation, etc. 
So here are the options:
1) If you have your own solvers and source codes and you know exactly
  how to program in terms CUDA C, typically the economical management
  GPU/CPU memory, CUDA is recommended. 
2) otherwise, CPU parallelization is preferred. 
Something that might be useful in your code: 
a) If you know that the Newtonian method or the like can be applied to
  solve the intersections, you can either specify that in your NSolve or
  FindInstance. Another way is to simply write the code and generate
  CUBIN inside Mathematica. 
ref :: CUDALink/tutorial/Programming
b) NProbabilty and NExpectation are gorgeous function since it is
  functional and symbolic (even though they return numeric value).
  However, they do take significant CPU seconds to compute and
  performance is rather hard to improve. The only way is to distribute
  them on subkernels/other CPU cores.
Note that is not possible to convert functions codes unless there are
  proper CUDA libraries released. 
Last thing about OpenCL and CUDA. CUDA is supposed to be faster than
  OpenCL and more stable. CUDA definitely need NVIDA card while it is
  optional to use GPU in OpenCL. But a OpenCL code without calling GPU
  is a CPU code, which does no good at all.

"
How do I clear all variables with subscripts?,"
Well. You can always clear a certain value by using Unset
Subscript[r, 3]=8;
Subscript[r, 3]=.;

Now, Clear and ClearAll won't work if you used regular = and assigned the values as Subscript's DownValues. But if you used UpValues, it could work
r/:Subscript[r, 3]=8;
ClearAll[r];

"
calculus and analysis - Definite and Indefinite integral give different results for piecewise function,"
When the indefinite integral has discontunities (as is the case for your integrand for some values of q and alpha), substituting the endpoints in the indefinite integral expression gives incorrect results. To get the correct result you need to use the definite integral. 
Please see the section Possible Issues subsection Definite Integral under Integrate in docs. The issue is also discussed at length in this Wolfram Blog entry: Mathematica and the Fundamental Theorem of Calculus.
"
performance tuning - Considerations when determining efficiency of Mathematica code,"
First off, Timing isn't as accurate as AbsoluteTiming because it has a tendency to ignore various things.  Here is a paticularly telling example. Keep in mind that neither will keep track of rendering time or formatting of output, this is purely time spent computing in the kernel.
AbsoluteTiming[x = Accumulate[Range[10^6]]; Pause[x[[1]]]; resA = x + 3;]

==> {1.045213, Null}

Timing[x = Accumulate[Range[10^6]]; Pause[x[[1]]]; resB = x + 3;]

==> {0.031200, Null}

These are identical calculations but Timing ignores Pause so it is way off.
Now lets set up a toy example. Your tests for timings are what I would typically do first when looking for efficiency.
f[x_Integer?Positive] := Accumulate[Range[x]]

g[x_Integer?Positive] := 
   Block[{result = Array[0, x]},
    result[[1]] = 1;
    For[i = 2, i <= x, i++, result[[i]] = result[[i - 1]] + i];
    result
   ]

The AbsoluteTiming is quite different for these two approaches. Clearly the built in function is preferable in this case.
AbsoluteTiming[resf = f[10^6];]

==> {0.015600, Null}

AbsoluteTiming[resg = g[10^6];]

==> {3.432044, Null}

And of course, we should test that these produce equivalent results..
resf == resg

==> True

Now I will mention that there are times when Equal will return False.  This may be acceptable in some situations if say we are only really interested in very low precision, ball-park results.
As for memory consumption, I hope someone else might elaborate on this part. One way to test it is with MemoryInUse.
m1 = MemoryInUse[];
f[10^6];
MemoryInUse[] - m1

==> 8001424

m1 = MemoryInUse[];
g[10^6];
MemoryInUse[] - m1

==> 24000656

Again, the system function wins hands down.
Edit: 
The reason the second method showed such a substantial increase in MemoryInUse is because it doesn't produce a packed array. If we pack the output, it uses the same memory as the first.  This tells me that MemoryInUse only tells us how much memory the result uses and nothing about the amount of memory used in intermediate computations.
m1 = MemoryInUse[];
Developer`ToPackedArray@g[10^6];
MemoryInUse[] - m1

==> 8001472

Edit 2: Here is a function I put together that I'm sure can be made more effective and efficient.  It uses a binary search technique with MemoryConstrained to find the amount of memory requested when evaluating an expression. 
SetAttributes[memBinarySearch, HoldFirst]

memBinarySearch[expr_, min_, max_] :=
 Block[{med = IntegerPart[(max - min)/2], low = min, high = max, 
   i = 1},
  While[True,
   If[MemoryConstrained[expr, med] === $Aborted,
    low = med;
    ,
    high = med;
    ];
   med = IntegerPart[low + (high - low)/2];
   If[Equal @@ Round[{low, med, high}, 2], Break[]];
   ];
  med
  ]

Here it is applied to f and g from above...
memBinarySearch[f[10^6], 1, 10^9]

==> 16000295

memBinarySearch[g[10^6], 1, 10^9]

==> 62499999

Note that memBinarySearch is only accurate to 2 bytes. For some reason (probably related to IntegerPart) it doesn't like to find the exact byte count requested.
"
How to turn a set of strings which represent a list into a 2D list,"
Another solution using StringSplit:
list = {""{H, 1}"", ""{H, 2}"", ""{H, 3}"", ""{Mg, 1}"", ""{Mg, 1}"", ""{Mg, 1}"",
   ""{C, 1}"", ""{C, 1, H, 1}"", ""{N, 1}"", ""{N, 1, H, 1}""};

StringTrim /@ StringSplit[list, {""{"", "","", ""}""}]


{{""H"", ""1""}, {""H"", ""2""}, {""H"", ""3""}, {""Mg"", ""1""}, {""Mg"", ""1""}, {""Mg"", ""1""}, 
 {""C"", ""1""}, {""C"", ""1"", ""H"", ""1""}, {""N"", ""1""}, {""N"", ""1"", ""H"", ""1""}}


"
Dbugging Mathmatica Cod - Mathmatica Stack Exchang,"
I think you got 4 choices:

Workbench. Probably the most useful of the debuggers.
Mathematica has a small debugger: Evaluation -> Debugger
There is DebugTrace from David (perhaps there are other packages)
Use Print, Trace(Scan)[], etc type of functions.

"
Bold face formatting for vectors instead of overarrows like latex \mathbf{}?,"
I am not sure I understand your needs, but consider this:
Format[OverVector[v_]] := Style[HoldForm[v], FontFamily -> ""Arial Black""]

{q, r, OverVector[s], t, u, v}


"
plotting - How do you define the domain of a plot?,"
For simple regions like your interval or a square region, you can just give the appropriate border, as shown by the earlier answers. For completeness, I repeat them here:
Domain $[-3,3]$:
Plot[f[x], {x, -3, 3}]

Domain $[-3,3]\times [-3,3]$:
Plot3D[f[x,y], {x, -3, 3}, {y, -3,3}]

For more complex domains, you have several options:
First, you can explicitly use a function with limited domain, e.g. for the domain $[-2,-1)\cup(1,2]$:
Plot[ConditionalExpression[Sin[x], Abs[x] > 1], {x, -2, 2}]

Or for 2D:
Plot3D[ConditionalExpression[Sin[x y],x<y], {x, -Pi, Pi}, {y, -Pi, Pi}]

Another possibility is to give the region in the plot command:
Plot[Sin[x],{x,-2,2},RegionFunction->(Abs[#] > 1&)]

Plot3D[Sin[x y],{x,-Pi,Pi},{y,-Pi,Pi},RegionFunction->(#1<#2&)]

Finally, for 3D plot you might also use some parametrization of your domain resulting in a square parameter range and use ParametricPlot3D (you can, of course, do that for 2D plots as well, but there it's not as useful):
ParametricPlot3D[Module[{x=r Cos[phi],y=r Sin[phi]},{x, y, Sin[x y]}],
                 {r, 1, 2}, {phi, 0, 3 Pi/2}]

Of course you can also combine those methods, e.g.
ParametricPlot3D[Module[{x=r Cos[phi], y=r Sin[phi]}, {x, y, Sin[x y]}],
                 {r, 1, 2}, {phi, 0, 3 Pi/2},
                 RegionFunction->Function[{x, y, z, r, phi},
                                          x < 1.5 && phi < (r-1) 3 Pi/2]]

"
plotting - Changing the background color of the framed region of a plot,"
You can use the Prolog option with Scaled coordinates:
Plot[Sin[x], {x, 0, 2 π}, Frame -> True,
 Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}
]


Note: Using scaled coordinates lets this work for any PlotRangePadding, and with PlotRangePadding->False:
Plot[Sin[x], {x, 0, 2 π}, Frame -> True, 
 Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}, 
 PlotRangePadding -> .6]


Plot[Sin[x], {x, 0, 2 π}, Frame -> True, 
 Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}, 
 PlotRangePadding -> -.2, PlotRangeClipping -> False]


"
Numrics with Mathmatica - Mathmatica Stack Exchang,"
I think it is important to realize that switching off symbolics (also for numerics) would deprive you of some of the best optimizations Mathematica has to offer. When Mathematica tries to use symbolics on numerical input, that can mean things like term analysis or optimizations for the compiler. Just think about it, this would mean that the compiler, for example, cannot factor out common terms, NIntgrate could not integrate oscillatory integrals because it can not do analysis on the integrand. It does not matter if an analytical solution exists a symbolic analysis can never the less be very useful. Andrew made a good presentation about what is happening under the hood you might find Hybrid Computing interesting.
Seen the benefits just mentioned and the fact that it is not impossible to figure out how to use Mathematica efficiently, make me feel that such a switch is undesirable. I can hopefully help you with a) see below. 
For b) I feel that the typing _?NumericQ is not that bad especially compared to the downsides of not having symbolic analysis. 
c) In some functions you can switch that off via a Method option. You could set these in a file, system options or some such.
My suggestion for your switch is to collect the various items and set them in an init.m file.
Concerning packed array you might find a visual PackedArrayForm helpful.
$Post = Developer`PackedArrayForm

This then gives:
a = Range[20]
""PackedArray""[Integer, ""<"" 20 "">""]

If you then set
a[[1]]=1.;
a

Will give you a list.
{1., 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, \
20}

This allows for a relatively easy distinction between packed and non packed. For the automatic conversion to packed arrays consider this:
Table[Pi, {5}]
{\[Pi], \[Pi], \[Pi], \[Pi], \[Pi]}

If you set (or some more clever variant)
$Pre = Developer`ToPackedArray[N[#]] &

and evaluate
Table[Pi, {5}]
""PackedArray""[Real, ""<"" 5 "">""]

Again, for your switch you could have these in your init.m file.
"
performance tuning - AbsoluteTiming affected by surrounding code,"
As Szabolcs pointed out, I was running into the resolution of the timer in my system in my attempts to micro benchmark.  Also, my attempts at micro benchmarking were incorrect I might add, but more on that later. 
I was able to see the light only after scratching my head for a number of days on Szabolcs' comment and working on a performance package, I finally came across $TimeUnit here. I got the idea to use Pause[10*$TimeUnit] as the code being tested in each case.  Clearly Pause[10*$TimeUnit] is above the resolution of the timer in my system.  Oh, in case you are curious, $TimeUnit is 1/100 on my system (2011 MBP 17"" running Lion).
For those of you who want to play along at home, the following is the updated micro benchmarking code: (btw it is still incorrect).
PrintHeader[] :=
  Print[""        Total    Mean     Min      Max      StdDev ""];

PrintStats[doTimes_List , mapTimes_List] :=
 (
  Print[""Do    "", ""  "", doTotal = Total[doTimes], ""  "", 
   doMean = Mean[doTimes], ""  "", Min[doTimes], ""  "", Max[doTimes], 
   ""  "", StandardDeviation[doTimes]];
  Print[""Map   "", ""  "", mapTotal = Total[mapTimes], ""  "", 
   mapMean = Mean[mapTimes] ""  "", Min[mapTimes], ""  "", Max[mapTimes], 
   ""  "", StandardDeviation[mapTimes]];
  Print[""Do-Map"", ""  "", doTotal - mapTotal, ""  "", doMean - mapMean, 
   ""\n""];
  )

PrintHeader[];
iterations = 1000;
Do[(
   doTimes = {};
   Do[AppendTo[doTimes,
     AbsoluteTiming[Pause[10*$TimeUnit]][[1]]]
    , {iterations}];

   mapTimes = Map[
     AbsoluteTiming[Pause[10*$TimeUnit]][[1]]
      &, Range[1, iterations]];

   PrintStats[doTimes, mapTimes];
   ), {5}];


Results
        Total    Mean     Min      Max      StdDev 
Do      100.339  0.100339  0.100027  0.101277  0.000330
Map     100.343  0.100343  0.100035  0.101294  0.000330
Do-Map  -0.004  -4.*10^-6

Do      100.351  0.100351  0.100036  0.101276  0.000327
Map     100.338  0.100338  0.100035  0.101247  0.000330
Do-Map  0.013  0.000013

Do      100.328  0.100328  0.100025  0.101328  0.000319
Map     100.346  0.100346  0.100027  0.101280  0.000332
Do-Map  -0.018  -0.000018

Do      100.347  0.100347  0.100029  0.101238  0.000330
Map     100.332  0.100332  0.100021  0.101235  0.000338
Do-Map  0.015  0.000015

Do      100.330  0.100330  0.100023  0.101258  0.000318
Map     100.327  0.100327  0.100028  0.101238  0.000324
Do-Map  0.003  3.*10^-6

The results are as expected, there is no longer a consistent difference between the Do an Map implementations.
Incorrect Micro Benchmarking Method
So why are were my two implementations of micro benchmarking above incorrect? I wanted to capture timing values for each call of the code being tested over a large number of iterations so that I could perform various analytics on them (sum, mean, min, max, std dev, plotting, histogram, ...). 
I thought AbsoluteTiming was incredibly precise.  When I evaluated the simple expression 1, AbsoluteTiming[1] returned {0.000014, 1}.  0.000014 is way more precise than $TimeUnit on my system which was 0.01 right?  Wrong!
Lets look at two different ways of micro benching marking the expression 1 for 1000000 iterations. But first, lets establish a base case to help us understand the results.

Base Case
iterations = 1000000;
oneTime = AbsoluteTiming[1][[1]];
expectation = oneTime*iterations;

Print[""oneTime: "", oneTime, ""   expectation for "", iterations, "": "", expectation];

Results:
oneTime: 0.000014   expectation for 1000000: 14.


Collection of Individual AbsoluteTiming Values
individualTimes = Map[AbsoluteTiming[1][[1]] &, Range[1, iterations]];

Print[""Total: "", Total[individualTimes], ""  Min: "", 
 Min[individualTimes], ""  Max: "", Max[individualTimes], ""  Mean: "", 
 Mean[individualTimes], ""  StdDev: "", 
 StandardDeviation[individualTimes]];

Results:
Total: 2.26236  Min: 0.  Max: 0.000167  Mean: 2.26236*10^-6  StdDev: 6.79631*10^-7

First thing we notice is that the Total(2.26236) is less than our expectation(14.) .  Why the difference?  Well first look at the Min(0.) and Max(0.000167), they are out side our oneTime(0.000014), which is good.  If there are a significant number of individual times less than our oneTime value, that could explain the difference. It just so happened that Length[Select[individualTimes, # < oneTime & ]] returned 999939 .  
Anyone know how Min can be 0. ? Is it because the expression was cached? If it was cached, it still would have taken some time.  Maybe the time it took is less than what AbsoluteTiming can observe, hmmmm.

One AbsoluteTiming Value for All Iterations
totalTime = AbsoluteTiming[Do [1, {iterations}]][[1]];

Print[""totalTime: "", totalTime];

Results:
totalTime: 0.015782

Woe wait a minute, the totalTime(0.015782) is no where close to the Total of the individualTimes(2.26236) not to mention our expectation(14.)!  I must have messed something up. Okay let me think about this, could it be AbsoluteTime is not as precise as I originally thought? Ding ding, ding, give that man a cigar! 
As the chaps at Wolfram said it here.  AbsoluteTiming does not have the precision past $TimeUnit. So the oneTime and all of the individually collected timing values were prone to error as a result of the resolution of the timer of the system.  Thanks again Szabolcs!
The the one timing value for all iterations also has the same error, but only since it is only called one time for 1000000 iterations and is less than $TimeUnit (0.01) it has a much smaller effect.  
Okay, yeah I know, I should rerun the One AbsoluteTiming Value for All Iterations with iterations = 1000000000 to get a more accurate value. totalTime: 12.440098 which makes making one call to 1 take 1.2440098*10^-8 seconds, which is a much much much smaller number than $TimeUnit.  Poor AbsoluteTiming, it never stood a chance. ;)
"
overriding the format of 'copy-as' latex?,"
I don't know of a way to do this automatically on Copy as LaTeX.  I also do not know enough about LaTeX to know the right way to make changes.
I should point out that vecX no longer appears in the output of Abs[vecX - vecX'] // TraditionalForm therefore you must base your output on boldVector[x] and not vecX, unless you want to work with a held expression, which I imagine you do not.
The best I can recommend is using your own convert-to-LaTeX function something like this:
myTeX =
 StringReplace[
   ToString @ TeXForm[# /. boldVector -> bvTeX], 
   ""text{bvTeX}"" :> ""EXAMPLE""
 ] &;

Abs[vecX - vecX'] // myTeX


\left|\EXAMPLE(x)-\EXAMPLE(x)'\right|


I am sure this is gibberish.  I simply want to show how this may be approached.
"
plotting - Creating overlapping histogram plots,"
First method
You could make the one in front partially transparent:
bc = RandomVariate[NormalDistribution[], 1000];
bcx = RandomVariate[NormalDistribution[], 1000];

g1 = Histogram[bc, ChartStyle -> {Red}];
g2 = Histogram[bcx, ChartStyle -> {Directive[Blue, Opacity[.5]]}];
Show[g1, g2, PlotRange -> All]


Direct method
The same effect can be achieved by plotting the two distributions in the same plot directly:
Histogram[{bc, bcx}, ChartStyle -> {Red, Blue}]

"
programming - Brackets in output make unable to use output to identify matrix element,"
As far as I understand the question, the main issue is how to swap 2 elements in an array. This can be done using ReplacePart. Consider for example
array = Partition[Range[10], 5]


{{1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}}


and suppose you want to swap the elements at positions 
pos1 = {1, 4};
pos2 = {2, 3};

then you could do something like
ReplacePart[array, Thread[{pos1, pos2} -> Extract[array, {pos2, pos1}]]]


{{1, 2, 3, 8, 5}, {6, 7, 4, 9, 10}}



As for generating the permuted matrix, instead of using For loops you could consider a more functional approach. You could for example do something like this:
Si = {{-1, -1, -1}, {1, -1, -1}, {-1, 1, -1}};
ii = 3; 
jj = 3;

swap[array_, pos1_, pos2_] := 
 ReplacePart[array, 
  Thread[{pos1, pos2} -> Extract[array, {pos2, pos1}]]]

choice[{i_, j_}] := 
 RandomChoice[{{i, Mod[j - 1, ii, 1]}, {Mod[i - 1, ii, 1], j}, {i, 
    Mod[j + 1, ii, 1]}, {Mod[i - 1, ii, 1], j}}]

newArray = Fold[swap[#1, #2, choice[#2]] &, Si, 
  Tuples[{Range[ii], Range[jj]}]]

Here, swap is a function that will swap the elements in array at positions pos1 and pos2. The function choice chooses an arbitrary neighbouring position of position {i,j}. Finally, Fold is used to apply swap to all elements of Si and the resulting matrix is assigned to newarray. If you want to save all the intermediate results, you can replace Fold with FoldList. 
"
equation solving - Mathematica Can't Evaluate This?,"
No, Log is the name of the function and Log[x] is the function applied to x.  Using Log without the argument is accepted by the system because Log is a symbol just like any other, but it does not make any sense.

The correct way to write it is
Solve[Log[x]/x^2 == y, x]

or
Reduce[Log[x]/x^2 == y, x]

The latter tries to give you full solution information, while the former's result may only be valid for certain values of x and y (see below).  The differences are explained in this guide.
The first result you get from Solve is correct for some real values of y as you can check by numerical evaluation:
x /. Solve[Log[x]/x^2 == y, x]

(*
==> {-(I Sqrt[ProductLog[-2 y]])/(Sqrt[2] Sqrt[y]), 
      (I Sqrt[ProductLog[-2 y]])/(Sqrt[2] Sqrt[y])}
*)

% /. y -> 0.05

(* ==> {1.05751 + 0. I, -1.05751 + 0. I} *)

Log[x]/x^2 /. x -> %[[1]]

(* ==> 0.05 + 0. I *)

The second result is not correct for y == 0.05 but it is correct for other values such as y == 1.0 I for which the first result is incorrect.
Mathematica generally assumes that all variables are complex and tried to solve for the this general case.  While the expression does contain an explicit I, it will evaluate to a real value for some real x.
Reduce will try to generate conditions under which the solutions are valid.  We can also specify that we are interested in only positive real values of x:
Reduce[Log[x]/x^2 == y && x > 0, x]

(*
==> (y == 0 && x == 1) || (y < 0 && 
   x == E^(-(1/2) ProductLog[-2 y])) || (0 < y <= 1/(
    2 E) && (x == E^(-(1/2) ProductLog[-1, -2 y]) || 
     x == E^(-(1/2) ProductLog[-2 y])))
*)


Note though that this function has no inverse even for $x \in (0, \infty)$:
Plot[Log[x]/x^2, {x, 0, 10}]


"
plotting - Gridlines of a framed plot with a background cannot be white?,"
Slightly hackish, but you could use Epilog to get the curve on top of the grid, e.g.
pl = Plot[Sin[x], {x, 0, 2 Pi}][[1]];

Plot[ Sin[x], {x, 0, 2 Pi}, 
 PlotStyle -> None, Frame -> True,
 Method -> {""GridLinesInFront"" -> True}, 
 GridLines -> Automatic, 
 GridLinesStyle -> Directive[AbsoluteThickness[2], White],
 Prolog -> {{LightGray, Opacity[0.5], Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}},
 Epilog -> pl]


Edit
Following Mr.Wizard's and Szabolcs' suggestions, an more elegant solution would be:
plot = Plot[Sin[x], {x, 0, 2 Pi}, 
    Frame -> True, GridLines -> Automatic,
    GridLinesStyle -> Directive[AbsoluteThickness[2], White]];

Graphics[{}, Method -> {""GridLinesInFront"" -> True},
 Epilog -> plot[[1]], 
 Prolog -> {{LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}}, 
 Sequence @@ Options[plot]]

This has the advantage that the plot is only generated once. It should work for any plot that doesn't have any Prolog's or Epilog's of itself.
You can even build it into a nice custom function:
myPlot[x_, range_List, opts : OptionsPattern[]] := 
 With[{plot = 
    Plot[x, range, Frame -> True, GridLines -> Automatic, 
     GridLinesStyle -> Directive[AbsoluteThickness[2], White], 
     opts]},
  Graphics[{}, Method -> {""GridLinesInFront"" -> True}, 
   Epilog -> plot[[1]], 
   Prolog -> {{LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}},
    Sequence @@ Options[plot] ] ]

myPlot[Cos[x], {x, 0, 2 Pi}, PlotStyle -> Red]


Or an extended version:
myPlot[x_, type_, range_List, opts : OptionsPattern[]] := 
 With[{plot = 
    Switch[type, Plot, 
     type[x, range, Frame -> True, GridLines -> Automatic, 
      GridLinesStyle -> Directive[AbsoluteThickness[2], White], 
      opts],
     ParametricPlot, 
     type[x, range, Frame -> True, GridLines -> Automatic, 
      GridLinesStyle -> Directive[AbsoluteThickness[2], White], 
      opts],
     ListPlot, 
     type[x, PlotRange -> range, Frame -> True, 
      GridLines -> Automatic, 
      GridLinesStyle -> Directive[AbsoluteThickness[2], White], 
      opts],
     ListLinePlot, 
     type[x, PlotRange -> range, Frame -> True, 
      GridLines -> Automatic, 
      GridLinesStyle -> Directive[AbsoluteThickness[2], White], opts]
     ]},
  Graphics[{}, Method -> {""GridLinesInFront"" -> True}, 
   Epilog -> plot[[1]], 
   Prolog -> {{LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 1}]]}},
    Sequence @@ Options[plot] ] ]

myPlot[RandomVariate[NormalDistribution[], 
  100], ListLinePlot, {Automatic, Full}, PlotStyle -> Red]


"
evaluation - Why does ++++x return an increment of 2 when the value of x is only incremented by 1?,"
TracePrint will show you what happens:
PreIncrement takes it's argument x, evaluates it (let's call the result result), then evaluates x = result+1.  Note that PreIncrement has HoldFirst.
Now ++(++x) evaluates ++x first yielding 2, then evaluates (++x) = 2+1 resulting in an error (trying to assign to PreIncrement) and returning 3.
This also explains why adding yet another layer of PreIncrement will increment the result again.



Here's a self-implemented ++ to make the above more clear.  The behaviour is exactly the same:

"
list manipulation - Simplifying nested If statements,"
In contrast to the very fast methods presented, let me give you a maybe more easy to understand solution (while this in the eye of the beholder). Basically it's sort of the way I would implement it in Haskell. 
Assume you want to solve your problem step by step and in each step you have your data in the form {res, in} where res is your current solution and in is the rest of the input which needs to be processed. The initial situation is that the list res contains your first element and in contains the rest of the input. Let's go through the two possible situations:

Since res is your current output, you always want to compare the last element of this with the first element of your in list. When the absolute difference is larger then 5, you want to append this first element of in to your res list.
In all other cases, you just want to throw away the first element of in and leave res untouched.

You want to iterate this as long as there are elements in your input. Thats all, and you can write it directly down:
step[{res_, in_}] := {Append[res, First[in]], Rest[in]} /; 
  Abs[Last[res] - First[in]] > 5;

step[{res_, in_}] := {res, Rest[in]};

NestWhile[step, {{100}, {102, 103, 99, 106, 107, 104, 112}}, 
 Length[Last[#]] > 0 &]

(* {{100, 106, 112}, {}} *)

You see that after your input list is empty, you have collected your result.
"
fitting - Problem with NonlinearModelFit,"
I have mentioned this in a comment already, but this seems like a good opportunity to provide some related discussion in the form of a full-fledged answer.
In Mathematica 8, we can take advantage of NMinimize to fit this data, using the Method -> NMinimize option of NonlinearModelFit. (This should also have worked in Mathematica 7, but unfortunately NMinimize was not recognised as a valid Method setting until version 8 due to a bug.) In particular, Storn-Price differential evolution, available to NonlinearModelFit using the option
Method -> {NMinimize, Method -> ""DifferentialEvolution""}

has a lot to offer in this case, especially if you know a bit about how differential evolution works. This algorithm, as implemented in Mathematica, is documented at tutorial/ConstrainedOptimizationGlobalNumerical#24713453.
From the documentation, we see that the scaling factor $s$ (called $F$ by Storn and Price in their publication on the method and usually elsewhere) acts as an amplification factor on the scale of the global search. Thus, a large value of $s$ encourages more expansive searching of the parameter space, while small values encourage more intense exploration around local minima. Classically, $s$ can take values between 0 and 2, although Mathematica doesn't enforce this restriction. In practice one finds that values larger than unity cause an extreme expansion of the parameter space under search, which may be counterproductive. A ""large"" value of $s$, then, is something close to 1, and this is what we need in the current case since we may suspect that the initial values chosen for the parameters might be rather far from the global optimum, and do not want to risk falling into some local minimum along the way.
The behaviour of differential evolution with respect to crossover probability, $\rho$ (which, as pointed out by Daniel Lichtblau, is equal to Storn and Price's $1 - CR$), is also very important. Noting that two of the parameters, w and xc, are strongly correlated, and knowing that in such cases vigorous mutation is usually the most effective strategy, we might also consider setting $CR \approx 1$, i.e. $\rho \approx 0$. While the default value of $\rho = 0.5$ does work for this example, if more sine functions are introduced into the model, reducing $\rho$ will be practically mandatory.
Plenty of discussion (indeed, an extensive literature) on tuning the differential evolution parameters, including the (usually) less critical population size parameter, $m$ (a.k.a. $NP$), can be found elsewhere, if necessary. However, it's worth noting that the ""correct"" values may differ between Mathematica's implementation and others, especially for small populations, due to slight differences in the way that the three existing random points are chosen to produce new trial search points.
So, writing down our conclusions from the above, we have:
data = Import[""dat.csv""]; (* with thanks to @Szabolcs *)

fit = NonlinearModelFit[
  data,
  y0 + A Sin[Pi (x - xc)/w],
  {y0, xc, A, w}, x,
  Method -> {NMinimize,
    Method -> {""DifferentialEvolution"",
      ""ScalingFactor"" -> 0.9, ""CrossProbability"" -> 0.1,
      ""PostProcess"" -> {FindMinimum, Method -> ""QuasiNewton""}
    }
  }
]

Where one should note the undocumented in this context, albeit rather obviously existent, Method option for FindMinimum as used by NMinimize as used by NonlinearModelFit (yes, that's right: we are setting a Method's Method's Method!). This serves to hone the parameter values produced by differential evolution given that the latter is, by design in this case, not as efficient for local optimization as other methods. Here ""QuasiNewton"" corresponds to the method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS), but ""LevenbergMarquardt"" could also have been used.
This gives us:

Or, as a list of rules:
{y0 -> 30.4578, xc -> 120.008, A -> 3.62443, w -> -752.712}

This a result consistent (up to the sign of w and the value of the phase factor xc) with that given by Origin. Was it achieved without effort (if this is considered important)? While this is inherently a subjective question, in my opinion, the answer is yes. No manually chosen initial values in sight!
A plot of the resulting model also makes it clear that this is a reasonable outcome (although evidently one could do better with a more involved model):

"
inverse - Changing variables algebraically,"
To visualize y[z] without having to go through inversion, you can use ParametricPlot:
 Manipulate[
 ParametricPlot[{y[x, a, b, c], z[x, a, r]}, {x, 0, 1}, 
 AxesLabel -> {z, y}, AspectRatio -> 1, 
 PlotRange -> {{-10, 10}, Automatic}], 
 {{a, 1}, 0, 5, .1}, {{b, 1},  0, 5, .1}, {{c, 1}, 0, 5, .1}, 
 Delimiter, {{r, 1}, .5, 2, .1}, 
 ControlPlacement -> Left]


"
combinatorics - How to apply a permutation to a symmetric square matrix?,"
How about:
ord = {1, 4, 5, 2, 3}
matrix[[ord, ord]]

(You can convert any permutation (including Cycles) to an index list using PermutationList.)
"
calculus and analysis - Inverting a function in a certain region,"
Something like this is helpful : 
InverseFunction[ConditionalExpression[#1^2, 2 > #1 > 0] &]

yields
ConditionalExpression[Sqrt[#1], 0 <= #1 <= 4] &

Then you can use it as an ordinary function, e.g. :
Integrate[%[x], {x, 1/2, 3/2}]


1/6 (-Sqrt[2] + 3 Sqrt[6]) 


or
D[ConditionalExpression[Sqrt[#1], 1/4 <= #1 <= 9/4] &[x], x]


ConditionalExpression[1/(2 Sqrt[x]), 1/4 <= x <= 9/4]


Plot[ConditionalExpression[Sqrt[#1], 1/4 <= #1 <= 9/4] &[x],
                         {x, 1/4, 9/4}, AxesOrigin -> {0, 0}]


"
graphics - Multiple panel figure from combination of plots,"
Since you give no example, I'm only guessing:
ip = {{30, 10}, {30, 50}};
a = ListContourPlot[
   Table[Sin[i + j^2], {i, 0, 3, 0.1}, {j, 0, 3, 0.1}], 
   ImageSize -> 200, ImagePadding -> ip];
b = ListContourPlot[
   Table[{x = RandomReal[{-2, 2}], y = RandomReal[{-2, 2}], 
     Sin[x y]}, {1000}], 
   FrameLabel -> {""abc"", ""def"", Style[""BIG TEXT"", 30]}, 
   ImageSize -> 200, ImagePadding -> ip];
c = ListContourPlot[RandomReal[1, {10, 10}], InterpolationOrder -> 3, 
   ImageSize -> 200, ImagePadding -> ip];
GraphicsGrid[{{a, b, c}}, Spacings -> {-30, Automatic}]


Here I played with:

ImagePadding -> to make padding around each plot independent of
their legends and labels
Spacings     -> to approach the plots to each other on the grid (see here)

But there are other ways of doing it. If you give an example, I can probably be more specific...
"
"plotting - How to create a histogram of annual events, such as cherry blossom time","
Here are two approaches.  
We'll create a second dataset by shifting the given data by two months:
blossom = {{4, 3}, {4, 22}, {4, 15}, {4, 2}, {4, 18}, {4, 20}, {4, 
    12}, {3, 30}, {4, 4}, {4, 24}, {4, 26}, {3, 4}, {4, 26}, {4, 
    13}, {5, 1}, {4, 4}, {4, 8}, {4, 18}, {4, 9}, {4, 19}, {4, 
    10}, {4, 20}, {4, 3}, {4, 4}, {3, 21}, {4, 19}, {4, 15}, {4, 
    17}, {4, 9}, {4, 17}, {4, 9}, {4, 8}, {4, 23}, {4, 17}, {4, 
    1}, {4, 10}, {4, 15}, {4, 15}, {4, 11}, {4, 15}, {4, 19}, {4, 
    22}, {4, 11}, {4, 4}, {4, 12}, {3, 27}, {3, 24}, {4, 26}, {3, 
    28}, {4, 16}};
ripen = TranslationTransform[{2, 0}][blossom];    


The first method converts the {month, day} into the number of the day in the year (1 for January 1st, 32 for February 1st, etc...) and creates a histogram from that.
DayOfYear[{m_, d_}] := 
 First[DateDifference[{2011, 12, 31}, {2012, m, d}, ""Day""]]

{DayOfYear[{1, 1}], DayOfYear[{2, 1}], DayOfYear[{3, 1}]}


{1, 32, 61}


Histogram[{DayOfYear /@ blossom, DayOfYear /@ ripen}, 20]





The second approach is more involved.  We convert the {month, day} values into absolute times, and then use HistogramList on the combined datasets to get bins and counts without yet constructing the graphic.  We then create a corresponding DateListPlot of the data, for the sole purpose of  getting access to how it creates date axes.  Finally we combine the ticks from the DateListPlot with an actual Histogram, reusing the bins but recalculating the bins for the different datasets, to get the final graphic.
MonthDayToTime[{m_, d_}] := AbsoluteTime[{2012, m, d}]

blossomtimes = MonthDayToTime /@ blossom;
ripentimes = MonthDayToTime /@ ripen;

{bins, counts} = HistogramList[Join[blossomtimes, ripentimes], 20]

points = Transpose[{Riffle[bins, bins], ArrayPad[Riffle[counts, counts], 1]}];
dateplot = DateListPlot[points, Frame -> False, Axes -> True, Joined -> True]

Show[Histogram[{blossomtimes, ripentimes}, {bins}], Options[dateplot, Ticks]]




"
graphics - How to create word clouds?,"
Here's what I came up with

How I did it
First we need a list of words. Here, I've taken the original list ordered by size.
tally = Tally@
   Cases[StringSplit[ExampleData[{""Text"", ""AliceInWonderland""}], 
     Except@LetterCharacter], _?(StringLength@# > 4 \[And] # =!= 
         ""Alice"" &)];
tally = Cases[tally, _?(Last@# > 10 &)];
tally = Reverse@SortBy[tally, Last];
range = {Min@(Last /@ tally), Max@(Last /@ tally)};

words = Style[First@#, FontFamily -> ""Cracked"", FontWeight -> Bold, 
     FontColor -> 
      Hue[RandomReal[], RandomReal[{.5, 1}], RandomReal[{.5, 1}]], 
     FontSize -> Last@Rescale[#, range, {12, 70}]] & /@ tally;

The words are rasterised and cropped to make sure the bounding box is as tight as possible.
wordsimg = ImageCrop[Image[Graphics[Text[#]]]] & /@ words;

To produce the image the words are added one by one using a Fold loop where the next word is placed as close to the centre of the existing image as possible. This is done by applying a max filter to the binarized version of the original image thus turning forbidden pixels white and looking for the black point that is closest to the centre of the image.
iteration[img1_, w_, fun_: (Norm[#1 - #2] &)] := 
 Module[{imdil, centre, diff, dimw, padding, padded1, minpos},
  dimw = ImageDimensions[w];
  padded1 = ImagePad[img1, {dimw[[1]] {1, 1}, dimw[[2]] {1, 1}}, 1];
  
  imdil = MaxFilter[Binarize[ColorNegate[padded1], 0.01], 
    Reverse@Floor[dimw/2 + 2]];
  centre = ImageDimensions[padded1]/2;
  
  minpos = Reverse@Nearest[Position[Reverse[ImageData[imdil]], 0], 
      Reverse[centre], DistanceFunction -> fun][[1]];
  diff = ImageDimensions[imdil] - dimw;
  padding[pos_] := Transpose[{#, diff - #} &@Round[pos - dimw/2]];
  
  ImagePad[#, (-Min[#] {1, 1 }) & /@ BorderDimensions[#]] &@
   ImageMultiply[padded1, ImagePad[w, padding[minpos], 1]]]

Fold[iteration, wordsimg[[1]], Rest[wordsimg]]

You can play around with the distance function. For example for a distance function
fun = Norm[{1, 1/2} (#2 - #1)] &

you get an ellipsoidal shape:
Fold[iteration[##, fun]&, wordsimg[[1]], Rest[wordsimg]]



Updated version
The previous code places new words in the image by approximating them with rectangles. This works fine for horizontally or vertically oriented words, but not so well for rotated words or more general shapes. Luckily, the code can be easily modified to deal with this by replacing the MaxFilter with a ImageCorrelate:
iteration2[img1_, w_, fun_: ( Norm[#1 - #2] &)] := 
 Module[{imdil, centre, diff, dimw, padding, padded1, minpos}, 
  dimw = ImageDimensions[w];
  padded1 = ImagePad[img1, {dimw[[1]] {1, 1}, dimw[[2]] {1, 1}}, 1];
  imdil = Binarize[ImageCorrelate[Binarize[ColorNegate[padded1], 0.05], 
     Dilation[Binarize[ColorNegate[w], .05], 1]]];
  centre = ImageDimensions[padded1]/2;
  minpos = 
   Reverse@Nearest[Position[Reverse[ImageData[imdil]], 0], 
      Reverse[centre], DistanceFunction -> fun][[1]];
  Sow[minpos - centre]; (* for creating vector plot *)
  diff = ImageDimensions[imdil] - dimw;
  padding[pos_] := Transpose[{#, diff - #} &@Round[pos - dimw/2]];
  ImagePad[#, (-Min[#] {1, 1}) & /@ BorderDimensions[#]] &@
   ImageMultiply[padded1, ImagePad[w, padding[minpos], 1]]]

To test this code we use a list of rotated words. Note that I'm using ImagePad instead of ImageCrop to crop the images. This is because ImageCrop seems to clip the words sometimes.
words = Style[First@#, FontFamily -> ""Times"", 
     FontColor -> 
      Hue[RandomReal[], RandomReal[{.5, 1}], RandomReal[{.5, 1}]], 
     FontSize -> (Last@Rescale[#, range, {12, 150}])] & /@ tally;

wordsimg = ImagePad[#, -3 - 
  BorderDimensions[#]] & /@ (Image[
   Graphics[Text[Framed[#, FrameMargins -> 2]]]] & /@ words);

wordsimgRot = ImageRotate[#, RandomReal[2 Pi], 
  Background -> White] & /@ wordsimg;

The iteration loop is as before:
Fold[iteration2, wordsimgRot[[1]], Rest[wordsimgRot]]

which produces

Second update
To create a vector graphics of the previous result, we need to save the positions of the words in the image, for example by adding Sow[minpos - centre] to the definition of iteration2 somewhere towards the end of the code and using Reap to reap the results. We also need to keep the rotation angles of the words, so we'll replace wordsimgRot with
angles = RandomReal[2 Pi, Length[wordsimg]];

wordsimgRot = ImageRotate[##, Background -> White] & @@@ 
   Transpose[{wordsimg, angles}];

As mentioned before, we use Reap to create the position list
poslist = Reap[img = Fold[iteration2, wordsimgRot[[1]], 
  Rest[wordsimgRot]];][[2, 1]]

The vector graphics can then be created with
Graphics[MapThread[Text[#1, Offset[#2, {0, 0}], {0, 0}, {Cos[#3], Sin[#3]}] &,
  {words, Prepend[poslist, {0, 0}], angles}]]

"
programming - Metaprogramming in Mathematica,"
What this answer is and is not
To avoid some confusion and misunderstanding, let me state right away what is the intended status of this answer.
This answer is not

A tutorial to the subject
A systematic, or complete, introduction to the subject
An authoritative answer putting the final word on the subject

This answer hopefully is

An (subjective!) overview of various meta-programming techniques in Mathematica, in the way they are known to me. I want to explicitly state that I am not trying to convey any kind of the ""common wisdom"" here, since the answer is largely based on my own experiences, and I have not seen an overwhelming number of meta-programming examples in Mathematica-related resources I had a chance to get acquainted with (so I may have no idea what the common wisdom is :)).
A collection of (hopefully relevant) links with some minimal explanations, which would allow the reader to see some examples and applications of metaprogramming in Mathematica, or at least examples of what I consider meta-programming in Mathematica.
A possible stub for some future answers, so that this larger one could be eventually rewritten and/or split into more focused and narrow ones, as the interest towards some particular forms of metaprogramming in Mathematica is being developed in our community.

Preamble
Ok, let me give it a shot. I'll start by claiming that Mathematica is very well suited for meta-programming, and one can write much more powerful programs in Mathematica by utilizing it. However, while it allows for very interesting and powerful meta-programming techniques, it does not IMO provide a convenient layer of tools to make these techniques more standard and effortless. Particularly painful is the evaluation control (preventing pieces of code from premature evaluation), because of the absence of the true quotation mechanism (here I will disagree with some other answers), the infinite evaluation model of Mathematica, and a quite complex core evaluator.
Enumerating some meta-programming techniques
There are several forms of meta-programming, so let me give a partial list first, and discuss afterwards

Introspection-based metaprogramming
Reflection-based metaprogramming (like in say, Java)
Run-time code generation
Macros (like in Lisp)
DSL (domain-specific-language) creation
...?

In addition to these, Mathematica has its own meta-programming devices, such as rule-based metaprogramming and the Block-related techniques.
Introspection
Mathematica is IMO very strong here. There are a couple of reasons for this:

Homoiconic language (programs written in own data structures - Mathematica expressions. This is code-as-data paradigm, like Lisp which uses lists for this)

One can access global definitions for symbols stored in OwnValues, DownValues, SubValues, UpVaulues, etc, and various other global properties, programmatically.

Rule-based destructuring techniques (using Cases etc) seriously simplify many introspection-related operations

Mathematica code is ""over-transparent"" - even pure functions are expressions, available to introspection and destructuring, rather than black boxes. This has its downsides (for example, making a functional abstraction leaky in Mathematica, see the end of this answer), but it also allows for things like withGlobalFunctions macro from this answer, where global function definitions are expanded inside pure functions (that macro also illustrates other meta-programming techniques).


Automatic dependency tracking
I will give a single simple explicit example of what I mean by introspection here, and supply some references to more involved cases. The following line of code gives all the symbols used to build a given expression expr, kept unevaluated:
Cases[Unevaluated[expr],s_Symbol:>HoldComplete[s],{0,Infinity},Heads->True]

Note that this will work for any Mathematica expression, including a piece of (perhaps unevaluated) Mathematica code.
A good illustration of introspection-based meta-programming is the symbol dependency analysis. I gave it a shot here, where I fully used all of the above-mentioned features (homoiconic language,  low-level access to symbol's properties, rule-based destructuring). A simpler but practical application of dependency analysis can be found e.g. in the getDependencies function from this answer, where I do use the dependencies to dynamically construct a set of symbols which are encapsulated (not easily available on the top-level) but whose definitions must be saved during the serialization of the list object being constructed.
Working around some language limitations
Sometimes, introspection-based metaprogramming can be also used to go around certain limitations of the language, or to make the language constructs behave in the way you want while minimally affecting them. Some examples off the top of my head: changing the default behavior of SaveDefinitions option for Manipulate,  making patterns to match only children of certain elements, and also two functions from this answer: a function casesShielded which implements a version of Cases that shields certain sub-expressions (matching specific pattern) from the pattern-matcher. and a (rather hacky) function myCases which implements a modified depth-first search, where the head is inspected before the elements (this is not what is happening in standard Cases, which sometimes has unwanted consequences). Yet another example here is the tiny framework I wrote to deal with the leaks of standard lexical scoping mechanism in Mathematica, which can be found here.
Summary
To conclude this section, I think that introspection-based meta-programming is a very useful and powerful technique in Mathematica, and the one that is relatively easy to implement without engaging in a fight with the system. I am also positive that it is possible to factor out the most useful introspection primitives and have a higher-level introspection-based metaprogramming library, and hope such a library will emerge soon.
Reflection - based metaprogramming
This may probably be considered a subset of the introspection-based metaprogramming, but it is particularly powerful for languages which impose more rigid rules on how code is written, particularly OO languages (Java for example). This uniform and rigid structure (e.g. all code is in classes, etc) allows for automatic querying of, for example, the methods called on the object, etc. Mathematica per se is not particularly powerful  here, because ""too many ways of doing things"" are allowed for this to be effective, but one can surely write frameworks and / or DSLs in Mathematica which would benefit from this meta-programming style.
Run-time code generation
This type of meta-programming can be used relatively easily and brings a lot to the table in Mathematica.
Automation and adding convenient syntax
I will give a small example from this answer, where an ability to generate a pure function (closure) at run-time allows us to easily define a version of SQL select with a more friendly Mathematica syntax, and based on the in-memory Mathematica representation of an SQL table as a nested list:
ClearAll[select, where];
SetAttributes[where, HoldAll];
select[table : {colNames_List, rows__List}, where[condition_]] :=
  With[{selF = Apply[Function, Hold[condition] /.
      Dispatch[Thread[colNames -> Thread[Slot[Range[Length[colNames]]]]]]]},
  Select[{rows}, selF @@ # &]];

Please see the aforementioned answer for examples of use. Further developments of these ideas (also based on meta-programming) can be found in this and this discussions.
Making JIT-compiled functions, and using Compile in more flexible ways
An important class of applications of run-time code-generation is in improving the flexibility of Compile. A simple example would be to create a JIT-compiled version of Select, which would compile Select with a custom predicate:
ClearAll[selectJIT];
selectJIT[pred_, listType_] :=
  selectJIT[pred, Verbatim[listType]] = 
    Block[{lst},
     With[{decl = {Prepend[listType, lst]}},
      Compile @@ 
       Hold[decl, Select[lst, pred], CompilationTarget -> ""C"", 
          RuntimeOptions -> ""Speed""]]];

This function actually illustrates several techniques, but let me first show how it is used:
test = RandomInteger[{-25, 25}, {10^6, 2}];
selectJIT[#[[2]] > 0 &, {_Integer, 2}][test] // Short // AbsoluteTiming 
selectJIT[#[[2]] > 0 &, {_Integer, 2}][test] // Short // AbsoluteTiming

(*

 ==> {0.4707032,{{-6,9},{-5,23},{-4,4},{13,3},{-5,7},{19,22},<<489909>>,{11,25},{-6,5},
          {-24,1},{-25,18},{9,19},{13,24}}}

 ==> {0.1250000,{{-6,9},{-5,23},{-4,4},{13,3},{-5,7},{19,22},<<489909>>,{11,25},{-6,5},
          {-24,1},{-25,18},{9,19},{13,24}}}
*)

The second time it was several times faster because the compiled function was memoized. But even including the compilation time, it beats the standard Select here:
Select[test,#[[2]]>0&]//Short//AbsoluteTiming

(*
  ==> {1.6269531,{{-6,9},{-5,23},{-4,4},{13,3},{-5,7},{19,22},<<489909>>,{11,25},{-6,5},
    {-24,1},{-25,18},{9,19},{13,24}}}
*)

The other techniques illustrated here are the use of constructs like Compile@@Hold[...] to fool the variable-renaming scheme (see e.g. this answer for a detailed explanation), and the use of With and replacement rules (pattern-based definitions) as a code-injecting device (this technique is used very commonly). Another example of a very similar nature is here, and yet another, very elegant example is here.
Custom assignment operators and automatic generation of function's definitions
Another class of run-time code-generation techniques (which is somewhat closer to macros in spirit) is to use custom assignment operators, so that you can generate rather complex or large (possibly boilerplate) code from relatively simple specifications. Applications range from relatively simple cases of adding some convenience/ syntactic sugar, such as e.g. here (where we define a custom assignment operator to allow us to use option names directly in code), to somewhat more complex cases like making replacements in definitions at the definition-time, as say in the function lex from this answer (see also the code for a LetL macro below), to quite sophisticated generation of boilerplate code, happening e.g. in JLink behind the scenes (which, for JLink, is a big deal, because this (plus of course the great design of JLink and Java reflection) is the reason why JLink is so much easier to use than Mathlink).
Automating error-handling and generating boilerplate code
Yet another use for run-time code generation (similar to the previous) is to automate error-handling. I discussed one approach to that here, but it does not have to stop there - one can go much further in factoring out (and auto-generating) the boilerplate code from the essential code.
A digression: one general problem with various meta-programming techniques in Mathematica
The problem with this and previous classes of use cases however is the lack of composition: you can not generally define  several custom assignment operators and be sure that they will always work correctly in combinations. To do this, one has to write a framework, which would handle composition. While this is possible to do, the development effort can rarely be justified for simple projects. Having a general library for this would be great, provided that this is at all possible. In fact, I will argue that the lack of composibility (""out of the box"") is  plaguing many potentially great meta-programming techniques in Mathematica, particularly macros.
Note that I don't consider this being a fundamental core language-level problem, since the relevant libraries / frameworks can surely be written. I view it more as a consequence of the extreme generality of Mathematica and it being in a transition from a niche scientific language to a general-purpose one (in terms of its typical uses, not just capabilities), so I am sure this problem has a solution and will eventually be solved.
Proper (macro-like) run-time generation of Mathematica code
A final use case for the run-time code generation I want to mention is, well, run-time Mathematica code generation. This is also similar to macros (as they are understood in Lisp) in spirit, in fact probably the closest to them from all techniques I am describing here. One relatively simple example I discuss here, and a similar approach is described here. A more complex case involving generation of entire packages I used for the real-time cell-based code highlighter described here. There are also more sophisticated techniques of run-time Mathematica code generation - one of which (in a very oversimplified form) I described here
Summary
To summarize this section, I view run-time code generation as another meta-programming technique which is absolutely central to make non-trivial things with Mathematica.
Macros
First, what I mean by macros is probably not what is commonly understood by macros in other languages. Specifically, by macro in Mathematica I will mean a construct which:

Manipulates pieces of Mathematica code as data, possibly preventing them from (premature) evaluation
Expands code at run-time (not ""read-time"" or ""compile-time"", which are not so well defined in Mathematica)

Some simple examples
Here is the simplest macro I know of, which allows one to avoid introducing an intermediate variable in cases when something must be done after the result has been obtained:
SetAttributes[withCodeAfter,HoldRest];
withCodeAfter[before_,after_]:=(after;before)

The point here is that the argument before is computed before being passed in the body of withCodeAfter, therefore evaluating to  the result we want, while the code after is being passed unevaluated (due to the HoldRest attribute), and so is evaluated already inside the body of withCodeAfter. Nevertheless, the returned result is the value of before, since it stands at the end.
Even though the above macro is very simple, it illustrates the power of macros, since this kind of code manipulation requires special support from the language and is not present in many languages.
Tools used for writing macros
The main tools used for writing macros are tools of evaluation control, such as

Hold*- attributes,
Evaluate and Unevaluated
code injection using With and / or replacement rules
Pure functions with Hold - attributes

Even in the simple example above, 2 of these tools were used (Hold-attribute and replacement rules, the latter hidden a bit by using global replacement rules / definitions). The discussion of the evaluation control constructs proper is outside the scope of the present discussion but a few places you can look at are here and here
Typical classes of macros
Macros can widely range in their purpose. Here are some typical classes

Making new scoping constructs or environments (very typical use case)
Used in combination with run-time code generation to inject some unevaluated code
Used in combination with some dynamic scoping, to execute code in some environments where certain global rules are modified. In this case, the ""macro"" - part is used to delay the evaluation until the code finds itself in a new environment, so strictly speaking these are rather custom dynamic scoping constructs.

Examples of new scoping constructs / environments
There are plenty of examples of the first type of macros available in the posts on StackOverlflow and here. One of my favorite macros, which I will reproduce here, is the LetL macro which allows consecutive bindings for With scoping construct:
ClearAll[LetL];
SetAttributes[LetL, HoldAll];
LetL /: Verbatim[SetDelayed][lhs_, rhs : HoldPattern[LetL[{__}, _]]] :=
   Block[{With}, Attributes[With] = {HoldAll};
     lhs := Evaluate[rhs]];
LetL[{}, expr_] := expr;
LetL[{head_}, expr_] := With[{head}, expr];
LetL[{head_, tail__}, expr_] := 
  Block[{With}, Attributes[With] = {HoldAll};
    With[{head}, Evaluate[LetL[{tail}, expr]]]];

What it does is to expand a single declaration like LetL[{a=1,b=a+1,c = a+b},a+b+c] into a nested With at run-time, and it also works for function definitions. I described in more fully here (where some subtleties associated with it are also described), and used it extensively e.g. here. A very similar example can be found in this answer. Yet another example I already mentioned - it is the macro withGlobalFunctions from this answer, which expands all generically-defined (via patterns) global functions. The last example I want to include here (although it also is relevant for the third use case) is a macro for performing a code cleanup, discussed here, and I particularly like the version by @WReach, which I will reproduce here:
SetAttributes[CleanUp, HoldAll]
CleanUp[expr_, cleanup_] :=
  Module[{exprFn, result, abort = False, rethrow = True, seq}, 
    exprFn[] := expr;
    result = 
      CheckAbort[
         Catch[Catch[result = exprFn[]; rethrow = False; result], _, 
           seq[##] &], abort = True];
    cleanup;
    If[abort, Abort[]];
    If[rethrow, Throw[result /. seq -> Sequence]];
    result]

It is not fully ""bullet-proof"", but does a really good job in the majority of cases.
Examples of run-time code generation / new functionality
Actually, many of the above examples also qualify here. I'll add just one more here (in two variations): the abortable table from this answer (I will reproduce the final version here):
ClearAll[abortableTableAlt];
SetAttributes[abortableTableAlt, HoldAll];
abortableTableAlt[expr_, iter : {_Symbol, __} ..] :=
  Module[{indices, indexedRes, sowTag, depth =  Length[Hold[iter]] - 1},
   Hold[iter] /. {sym_Symbol, __} :> sym /. Hold[syms__] :> (indices := {syms});
   indexedRes =  Replace[#, {x_} :> x] &@ Last@Reap[
      CheckAbort[Do[Sow[{expr, indices}, sowTag], iter], Null],sowTag];
   AbortProtect[
      SplitBy[indexedRes, Array[Function[x, #[[2, x]] &], {depth}]][[##,1]] & @@ 
      Table[All, {depth + 1}]
   ]];

(it accepts the same syntax as Table, including the multidimensional case, but returns the partial list of accumulated results in the case of Abort[] -  see examples of use in the mentioned answer), and its version for a conditional Table, which only adds an element is certain condition is fulfilled - it is described here.  There are of course many other examples in this category.
Examples of dynamic environments
Dynamic environments can be very useful when you want to modify certain global variables or, which is much less trivial, functions, for a particular piece of code, so that the rest of the system remains unaffected. The typical constructs used to achieve this are Block and Internal`InheritedBlock.
The simplest and most familiar dynamic environment is obtained by changing the values of $RecursionLimit and / or $IterationLimit inside a Block. Some examples of use for these are in my answer in the discussion of tail call optimization in Mathematica. For a more complex example, see my suggestion for the recent question on convenient string manipulation. Some more examples can be found in my answer to this question. An example of application of this to profiling can be found here.
Again, there are many more examples, many of which I probably missed here.
Problems with writing macros in Mathematica
To my mind, the main problems with writing  and using macros consistently in Mathematica are these:

Hard to control evaluation. No real quotation mechanism (Hold and HoldComplete don't count because they create extra wrappers, and Unevaluated does not count since it is not permanent ans is stripped during the evaluation)
Macros as described above are expanded from outside to inside. Coupled with the lack of real quotation mechanism, this leads to the absence of true macro composition out of the box. This composition can be achieved, but with some efforts
The lack of the real compilation stage (The definition-time does not fully count since most definitions are delayed).

To circumvent these issues, one has to apply various techniques, such as

Trott - Strzebonski in-place evaluation technique to evaluate parts of held expressions in-place (see also this answer for some more details on that)
A technique which I call (for the lack of a better name) ""inverse rule-dressing"", which exploits the properties of delayed rule substitution (delayed, plus intrusive), to inject some unevaluated code. I used it in the first solution in this answer, in more complex way in the SavePointers function in this answer, and in a number of other cases. It has also been used very elegantly  in this answer.
using a custom Hold-like wrapper which is first mapped on (possibly all) parts of an expression, and later removed using rules. Two examples of this techniques are here and here
...

Despite all these techniques being useful, and in total covering most of the needs for macro-writing, the need to use them (often in combinations) and the resulting code complexity shows, to my mind, the serious need for a generic library which would provide simpler means for macro-writing. I would prefer to be able to nest macros and not think about zillion of things that may go wrong because of some unwanted evaluation, but rather about things that really matter (such as variable captures).
Summary
Macros are another very powerful meta-programming technique. While it is possible to write them in Mathematica, it is, as of now, a rather involved undertaking, and composing macros is an even harder task. Because composition in the key, I attribute the fact that macros are not in widespread use in Mathematica programming, to this lack of composition, plus the complexity of writing individual macros. That said, I think this is a very promising direction, and hope that some time soon we will have the tools which would make writing macros a more simple and automatic process.
DSL creation
I won't say almost anything here, except noting that this is entirely possible in Mathematica, and some nice syntax can be added easily via UpValues.
Final remarks
I think that meta-programming is one of the most important and promising directions in the present and future of Mathematica programming. It is also rather complex, and IMO, largely unexplored in Mathematica still. I hope that this justifies this post being so long.
I tried to summarize various approaches to meta-programming in Mathematica, which I am aware of, and give references to examples of these approaches, so that the reader can look for him/herself. Since meta-programming is a complex topic, I did not attempt to write a tutorial, but rather tried  to summarize various experiences of myself and others to produce a kind of a reference.
One may notice that the references are dominated by the code I wrote. One reason for that is that I am a heavy user of meta-programming in Mathematica. Another reason is that everyone remembers own code the most. I have to apologize for not including some other references which did not come to my mind right away. I invite everyone to edit this post and add more references, which I missed.
"
Reference request for neural network programming in Mathematica,"
I've had an interest (as one can see in my other posts) in a wide range of distributed processing and parallel computing approaches and while not seen in any of my posts machine learning approaches as well.  I looked at neural networks some years ago, and while they didn't suit the problems I worked on at the time I remembered the article Duncan and Tweney wrote as useful. A couple of others might also prove useful.
Three references follow:
AI AND STATISTICAL APPLICATIONS
Mathematica: A flexible design environment for neural networks
From the Journal:
Behavior Research Methods, Instruments, & Computers 1997,29 (2). 194-199
https://doi.org/10.3758/BF03204810
From 1997, a few years more recent than Freeman's.
Freely available as a pdf article:

Abstract:
Several neural networks were developed in Mathematica in order to
explore the role of ""spiky"" neurons in neural network memory
simulations. Using Mathematica for this task confirmed its value as a
powerful tool for neural network development: It exhibited distinct
advantages over other environments in programming ease, flexibility
of data structures, and the graphical assessment of network
performance.

One of its authors: Sean C. Duncan has moved from Bowling Green University to Miami University.  He has a website: https://se4n.org/
Its other author: Ryan Tweney remains at Bowling Green University and has his own website: http://personal.bgsu.edu/~tweney/ (Update: Ryan Tweney passed away in 2020; an archived snapshot of his website is available in the Wayback Machine.)
You can find contact information for each of them on their respective websites.  I've always found academics generous with what they know.  The article or contacting them might lead you to better sources of information on this.
Mathematica Neural Networks package.
You can download the pdf of the manual for the Mathematica Neural Networks package.  Pretty extensive, indeed.
The Power of Neural Networks
A review in which Brian Cogan briefly assesses NeuroSolutions from NeuroDimension, and Neural Networks, a Mathematica add-on, from Scientific Computing World March/April 2003
http://www.neurosolutions.com/resources/scw.pdf
"
programming - Very long Refine/Solve batch run,"
I've found with some of my own code that putting in the simplifying equations INTO the solve function speeds things up (sometimes significantly, in the ""I don't know if this is going to finish"" -> seconds timeframe). That is, instead of writing:
Solve[{EquationToSolve==0},{a,b,c}]//Simplify[#,a>0 && b<0 && c>=0]

Write
Solve[{EquationToSolve==0, a>0, b<0, c>=0},{a,b,c}]

I think this has something to do with Mathematica trying to simplify things immediately as it finds solutions, and since it can start simplifying early, the final answer turns out much faster. 
Obviously this is not useful if you're looking for a general solution, but in many cases you can look at many more ""specific"" solutions in the same amount of time it would take you to solve for the general one. 
"
"plotting - Mathematica envelope for the bottom of a plot, a generic function","
You can also create a moving min (and max) and use BSplineCurve to render a smoothed curve.
These could be made more efficient. They find the min and max over a window.
windowMin[data_, w_][pt_] := {pt, 
  Min[Cases[data, {x_, y_} /; pt - w <= x <= pt + w][[All, 2]]]}

windowMax[data_, w_][pt_] := {pt, 
  Max[Cases[data, {x_, y_} /; pt - w <= x <= pt + w][[All, 2]]]}

This function plots the original data with the BSplineCurve envelope. The parameter w sets the window width.
f[w_] := With[{data = Transpose[{xaxis, yaxis}]}, 
  Show[ListLinePlot[data, 
    PlotStyle -> Directive[{Blue, Opacity[.2]}]], 
   With[{pts = Table[windowMin[data, w][t], {t, 0, 10, w - w/10}]}, 
    Graphics[{Red, BSplineCurve[pts]}]], 
   With[{pts = Table[windowMax[data, w][t], {t, 0, 10, w - w/10}]}, 
    Graphics[{Red, BSplineCurve[pts]}]]]]

Some examples...
f[.2]


f[.1]


f[.025]


Edit: In response to the comment, here is a more general form of f which allows for a list of xdata and a list of ydata provided they are of equal length. The min and max of the Tables are chosen to be the range of the x data.
f[xdata_, ydata_, w_] /; Length[xdata] == Length[ydata] := 
 Block[{data = Transpose[{xdata, ydata}], xmin = Min[xdata], 
   xmax = Max[xdata]}, 
  Show[ListLinePlot[data, 
    PlotStyle -> Directive[{Blue, Opacity[.2]}]], 
   With[{pts = 
      Table[windowMin[data, w][t], {t, xmin, xmax, 
        w - w/(xmax - xmin)}]}, Graphics[{Red, BSplineCurve[pts]}]], 
   With[{pts = 
      Table[windowMax[data, w][t], {t, xmin, xmax, 
        w - w/(xmax - xmin)}]}, Graphics[{Red, BSplineCurve[pts]}]]]]

"
numerical integration - Compute integral symbolically or numerically,"
For the symbolic attempt I'd first rationalize to get exact input.
e1 = ((0.000245587 + 0.0000651908 I) E^(-I kx) kx ky (kz^2 - 
        4 \[Pi]^2))/((kx^2 + ky^2) kz) - ((4.00033*10^-17 - 
        3.51178*10^-18 I) E^(-I kx) (kx^3 kz + kx ky^2 kz + 
        kx^2 kz^2 + 4 ky^2 \[Pi]^2))/((kx^2 + ky^2) kz);
e2 = Rationalize[e1, 0]

Out[5]= ((245587/1000000000 + (162977 I)/2500000000) E^(-I kx)
   kx ky (kz^2 - 4 \[Pi]^2))/((kx^2 + ky^2) kz) - (1/((kx^2 + 
    ky^2) kz))(1/24997937670142213 - I/
    284755878785117533) E^(-I kx) (kx^3 kz + kx ky^2 kz + kx^2 kz^2 + 
    4 ky^2 \[Pi]^2)

I believe this does the transformation you do in a different way.
e3 = 
 e2*k^2*Sin[a]*Cos[a] /. {kx -> k*Sin[a]*Cos[b], 
    ky -> k*Sin[a]*Sin[b], kz -> k*Cos[a]} /. k -> 2*Pi

With this, we can now do as below.
In[26]:= Timing[ii = Integrate[e3, {a, 0, Pi/4}, {b, 0, 2*Pi}]]

Out[26]= {158.87, 
 Integrate[(8/284755878785117533 + (8*I)/24997937670142213)*Pi^3*
       (-2*I*Pi*BesselJ[2, 2*Pi*Sin[a]]*Cos[a]^2*Sin[a] + 

     BesselJ[1, 2*Pi*Sin[a]]*(I*(1 + Cos[a]^2) + Pi*Sin[a]*Sin[2*a])), 
     {a, 0, Pi/4}]}

In[28]:= N[ii]

Out[28]= 7.85307*10^-16 + 1.11299*10^-15 I

Whether this is accurate will depend on cancellation error and other vagaries of the quadrature.
"
How can I get Mathematica to solve an equation with multiple variables?,"
If I understand the question correctly, you are looking for the solution of the differential equation 
$$ y''(t)+3y'(t) = 2t^4 $$
in the form
$$ y(t) = t(A_0t^4+A_1t^3+A_2t^2+A_3t+A_4). $$
That is, you need to find the values of the $A_i$ constants that satisfy this equation.  Please clarify if this is what you are asking.

To do this in Mathematica, we can define
y[t_] := t (t^4 Subscript[A, 0] + t^3 Subscript[A, 1] + 
            t^2 Subscript[A, 2] + t Subscript[A, 3] + Subscript[A, 4])

then use SolveAlways:
SolveAlways[y''[t] + 3 y'[t] == 2 t^4, t]


"
import - How to manipulate web pages on Mathematica?,"
The first thing we need to do is to determine how the initial page assembles the parameters and transmits the request to the server.  One way to do this would be to open the initial page using the developer tools in the web browser.  But since this is a Mathematica forum, let's try to use the tools it makes available to us.
We could load the page text and then try to extract the information we need using string manipulation functions.  However, this can get tricky as we must account for line breaks in inconvenient locations, decode HTML entities, and so on.  Instead, we will examine the page's Document Object Model (DOM).  In Mathematica, the DOM is accessed by importing the page using ""XMLObject"" format:
$initialUrl = ""http://www.fundamentus.com.br/buscaavancada.php"";
$dom = Import[$initialUrl, ""XMLObject""];

Fewer and fewer pages these days are using simple HTML forms to send requests to the server -- let's see if this page contains any FORM elements:
$forms = Cases[$dom, XMLElement[""form"", ___], Infinity];
Length @ $forms


2

We are in luck.  Let's look at the attributes of the forms:
Cases[$forms, XMLElement[_, attrs_, _] :> attrs]


{
   {enctype->application/x-www-form-urlencoded,method->get,
      class->busca,action->detalhes.php},
   {enctype->application/x-www-form-urlencoded,method->post,
      class->avancada,name->formbusca,action->resultado.php}
  }

The first form (""detalhes"") uses HTTP GET to get its results.  The second (""resultado"") uses POST.  Resultado sounds promising.  Let's extract the input elements for that form:
Cases[$forms[[2]], XMLElement[""input"", ___], Infinity] // Column


XMLElement[input,{type->text,name->pl_min},{}]
  XMLElement[input,{type->text,name->pl_max},{}]
  XMLElement[input,{type->text,name->pvp_min},{}]
... lines omitted ...
  XMLElement[input,{type->text,name->roe_min},{}]
  XMLElement[input,{type->text,name->roe_max},{}]
  XMLElement[input,{type->text,name->liq_min},{}]
  XMLElement[input,{type->text,name->liq_max},{}]
... lines omitted ...

Yes, this looks like the form that we are interested in.  Let's assemble the components of a request:
$resultUrl = StringReplace[$initialUrl, ""buscaavancada.php"" -> ""resultado.php""]


http://www.fundamentus.com.br/resultado.php

$parameters = {
  ""roe_min"" -> ""0.1""
, ""liq_min"" -> ""500000""
, ""liq_max"" -> ""800000""
};

... and transmit the request using HTTP POST:
$results = Import[
  $resultUrl
, ""Data""
, ""RequestMethod"" -> ""POST""
, ""RequestParameters"" -> $parameters
]


{{{{Página inicial,Investimento consciente,Entre em
  contato},{Detalhes,{Balanço patrimonial,Demonstrativos de
  resultados,Indicadores fundamentalistas},{Balanços em
  Excel,Proventos},Histórico de
  cotações}},{{Papel,Cotação,P/L,P/VP,PSR,Div.Yield,P/Ativo,P/Cap.Giro,P/EBIT,P/Ativ
  Circ.Liq,EV/EBIT,Mrg Ebit,Mrg. Líq.,Liq.
  Corr.,ROIC,ROE,Liq.2meses,Patrim. Líq,Dív.Brut/ Patrim.,Cresc.
  Rec.5a},{{PRTX3,2,72,-38,34,-255,71,905,562,0,00%,1,977,-5,52,-63,14,-2,42,-72,49,-1.434,22%,-2.361,99%,0,35,-3,96%,666,96%,537.768,00,-10.557.000,00,-59,73,0,00%}
... and more ...

This time we have imported using the ""Data"" format which let's Mathematica do all the hard work of extracting the HTML TABLE elements out of the web page.
At this point, we have successfully imported all of the data into Mathematica.  We can now use the usual Mathematica tools to extract and reformat those parts that interest us.  After a bit of experimentation, we can see that the interesting data is the the second element of the first row:
$interesting = $results[[1, 2]];
$interesting // TableForm

 
We can extract the property names:
$propertyNames = $interesting[[1, 2;;]]


{Cotação,P/L,P/VP,PSR,Div.Yield,P/Ativo,P/Cap.Giro,P/EBIT,P/Ativ
  Circ.Liq,EV/EBIT,Mrg Ebit,Mrg. Líq.,Liq.
  Corr.,ROIC,ROE,Liq.2meses,Patrim. Líq,Dív.Brut/ Patrim.,Cresc. Rec.5a}

... and the ticker symbols:
$symbols = $interesting[[2, All, 1]]


{PRTX3,BRTO3,FHER3,PINE4}

... and the data itself:
$data = $interesting[[2, All, 2;;]]


{{2,72,-38,34,-255,71,905,562,0,00%,1,977,-5,52,-63,14,-2,42,-72,49,-1.434,22%,-2.361,99%,0,35,-3,96%,666,96%,537.768,00,-10.557.000,00,-59,73,0,00%},{12,15,3,87,0,68,0,771,2,46%,0,256,4,35,2,62,-0,85,2,97,29,44%,19,90%,1,22,12,50%,17,68%,750.626,00,10.699.600.000,00,0,53,-3,53%},{12,25,4,48,1,38,0,135,0,00%,0,201,-12,78,1,64,-2,14,3,72,8,25%,3,02%,0,98,22,47%,30,87%,686.507,00,429.309.000,00,2,52,7,74%},{12,39,7,58,1,21,0,000,7,39%,0,000,0,00,0,00,0,00,0,00,0,00%,0,00%,0,00,0,00%,15,91%,509.960,00,1.015.080.000,00,0,00,-10,02%}}

Since the numbers and percentages were not in a format that Mathematica recognizes, they were imported as strings.  We need to convert those strings into Mathematica syntax so that we can parse them:
parse[s_String] /; StringMatchQ[s, __~~""%""] :=
  parse[StringDrop[s, -1]] / 100

parse[s_String] /; StringMatchQ[s, (DigitCharacter|""-""|"",""|""."")..] :=
  ToExpression[StringReplace[s, {"","" -> ""."", ""."" -> """"}]]

parse[s_] := s

$data2 = $data /. s_String :> parse[s]


{{2.72,-38.34,-255.71,905.562,0.00,1.977,-5.52,-63.14,-2.42,-72.49,-1434.22,-2361.99,0.35,-3.96,666.96,537768.00,-10557000.00,-59.73,0.00},{12.15,3.87,0.68,0.771,2.46,0.256,4.35,2.62,-0.85,2.97,29.44,19.90,1.22,12.50,17.68,750626.00,10699600000.00,0.53,-3.53},{12.25,4.48,1.38,0.135,0.00,0.201,-12.78,1.64,-2.14,3.72,8.25,3.02,0.98,22.47,30.87,686507.00,429309000.00,2.52,7.74},{12.39,7.58,1.21,0.000,7.39,0.000,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,15.91,509960.00,1015080000.00,0.00,-10.02}}

Note that percentages were converted into fractions.
We can now display the data or manipulate it as we see fit, for example:
TableForm[Transpose @ $data2, TableHeadings -> {$propertyNames, $symbols}]


"
front end - Opening new notebooks with a non-default window size,"
The default window size can be controlled from two different places.  The first is the Global $FrontEnd WindowSize, set through the Option Inspector > Global Preferences or with:
SetOptions[$FrontEnd, WindowSize -> {300, 900}]

The second is the WindowSize of the style sheet itself.  If it is defined, the WindowSize of the style sheet will overrule the setting above.  You set the style sheet size through the Option Inspector > Selected Notebook or by evaluating this inside the style sheet itself:
SetOptions[EvaluationNotebook[], WindowSize -> {300, 900}]

To select the default style sheet, click the button to the right of the setting name, and use the file browser:

"
performance tuning - Finding all elements within a certain range in a sorted list,"
As you said, essentially you need binary search, since you have a sorted list and binary search has a logarithmic complexity.  However, since 

the limiting numbers may not be present in the list
some numbers may be present more than once

we'd need modified binary search. Here is a possible implementation:
(* maximum number smaller than or equal to the limit *)
bsearchMin[list_List, elem_] :=
  Module[{n0 = 1, n1 = Length[list], m},
    While[n0 <= n1,
     m = Floor[(n0 + n1)/2];
     If[list[[m]] == elem, 
         While[list[[m]] == elem, m++]; 
         Return[m - 1]];
     If[list[[m]] < elem, n0 = m + 1, n1 = m - 1]
    ];
    If[list[[m]] < elem, m, m - 1] 
  ];

and
(* minimum number larger than or equal to the limit *)
bsearchMax[list_List, elem_] :=
  Module[{n0 = 1, n1 = Length[list], m},
    While[n0 <= n1,
      m = Floor[(n0 + n1)/2];
      If[list[[m]] == elem, 
         While[list[[m]] == elem, m--]; 
         Return[m + 1]];
      If[list[[m]] < elem, n0 = m + 1, n1 = m - 1]
    ];
    If[list[[m]] > elem, m, m + 1] 
  ];

With the help of these:
window[list_, {xmin_, xmax_}] :=
  With[{minpos = bsearchMax[list, xmin], maxpos =  bsearchMin[list, xmax]},
    Take[list, {minpos, maxpos}] /; ! MemberQ[{minpos, maxpos}, -1]
  ];
window[__] := {};

For example:
lst = {1, 4, 4, 4, 6, 7, 7, 11, 11, 11, 11, 13, 15, 18, 19, 22, 23, 25, 27, 30}

window[lst, {4, 11}]

(* ==> {4, 4, 4, 6, 7, 7, 11, 11, 11, 11} *)

You can Compile functions bsearchMin and bsearchMax, if you expect lots of duplicate elements (this will speed an inner While loop). Compiling them per se won't improve the speed much (unless you call these very often), since the complexity is logarithmic in any case.
This is certainly generally more efficient than Nearest for sorted lists (perhaps unless you have lots of repeated elements, but then you can compile), because Nearest is a general algorithm which can not take into account the sorted nature of the list. I tried on 10^7 elements list,  and it took something 0.0003 seconds for that.
Compiled version
Compiled versions speed up bsearchMin and bsearchMax, but seem not to improve the performance of window[]. See discussion in comments section.  
bsearchMax = Compile[{{list, _Complex, 1}, {elem, _Real}},
  Block[{n0 = 1, n1 = Length[list], m = 0},
    While[n0 <= n1,
      m = Floor[(n0 + n1)/2];
      If[list[[m]] == elem,
        While[m >= n0 && list[[m]] == elem, m--]; Return[m + 1]  ];
      If[list[[m]] < elem, n0 = m + 1, n1 = m - 1]];
    If[list[[m]] > elem, m, m + 1]
  ]
  ,
  RuntimeAttributes -> {Listable},
  CompilationTarget -> ""C""
]

bsearchMin = Compile[{{list, _Complex, 1}, {elem, _Real}},
  Block[{n0=1,n1=Length[list],m = 0},
    While[n0<=n1,
      m=Floor[(n0+n1)/2];
      If[list[[m]]==elem,
        While[m<=n1 && list[[m]]==elem,m++]; Return[m-1]  ];
      If[list[[m]]<elem, n0=m+1, n1=m-1]];
    If[list[[m]]<elem,m,m-1]
  ]
  ,
  RuntimeAttributes -> {Listable},
  CompilationTarget -> ""C""
]

"
functions - Max of a table/list with indeterminate values,"
The first approach would be: 
Max@Cases[tab, Except[Indeterminate]]


3.


If I understand your second need, that would be:
tab /. Indeterminate -> 0.0


{1., 2., 3., 0.}


Edit
Oleksandr's approach  is indeed very fast, for very long lists seems to be over 3-4  times faster then others. Since my first approach was quite straightforward, it is resonable to add another one obvious method which will be very handy (possibly the fastest) when we work with non-numeric lists : 
Max@DeleteCases[l, Indeterminate]

This approach is only a bit slower for numeric lists than that by Oleksandr and probably the best for non-numeric data (when Indeterminates are exceptional cases rather than common).
To test prerformance issues we take a slightly more natural data, namely lists of real numbers with appended Indeterminate's :
l = RandomChoice[RandomReal[100, 20000]~Append~Indeterminate, {10^7}]; 

and use AbsoluteTimings to compare methods, starting with the most efficient :
maxNoIndeterminate[l] // AbsoluteTiming                   (*Oleksandr*)


{0.7070000, 99.9945}


 Max@DeleteCases[l, Indeterminate] // AbsoluteTiming       (*Artes II *)


{1.1150000, 99.9945}


  Max@Cases[l, Except[Indeterminate]] // AbsoluteTiming     (*Artes I *)


 {2.7720000, 99.9945}


  Max[l /. Indeterminate -> -Infinity] // AbsoluteTiming   (*cormullion*)


 {2.8870000, 99.9945}


  Max@Select[l, NumberQ] // AbsoluteTiming                (*David Skulsky*)


 {3.5120000, 99.9945}


"
plotting - Mathematica2tikz an equivalent function,"
This is not a full answer, just a starting point:

I would first write some functions that convert Mathematica graphics to a representation that is really close to the structure TikZ uses (similar to how Mathematica represents C using SymbolicC).  I don't know TikZ, so this should be designed by someone who is quite familiar with it.

Then I'd write a set of functions that can convert this representation to a string that is syntactically correct TikZ code.



Examples:
Extracting lines from a Plot:
This will extract the two lines from the plot:
lines = Cases[Plot[{Sin[x], Cos[x]}, {x, 0, 10}], Line[coords_] :> coords, Infinity]

Knowing exactly what sort of Graphics object Plot likes to generate, we can extract the style too:
Cases[Plot[{Sin[x], Cos[x]}, {x, 0, 10}], {style_, _Line}, Infinity]

Converting a symbolic representation to a string:
Looking at your example TikZ input, we can make something like the coordinate section using
coordList2TikZ[data_?MatrixQ] :=
 ""coordinates{\n"" <>
  StringJoin[
   ""("" <> ToString[#1, CForm] <> "","" <> ToString[#2, CForm] <> "")"" & @@@ data] <>
  ""\n};""

(StringForm will be useful here as well.)
This will take a list of coordinates and output some TikZ code:
coordList2TikZ[{{1, 2}, {3, 4}}]

(* ==>
coodinates{
(1,2)(3,4)
};
*)

You can try coordList2TikZ /@ lines as well.  I do not know what sort of scientific notation TikZ uses, so I just used the C-style 1.23e-5 one.
"
import - Data of badly formatted file,"
Maybe you could do something like this:
First the data is imported as a list of strings. 
import = Import[""exampleFile.txt"", ""List""];

pos is the position of all lines containing the substring ""Ion"". The data of interest is located 3 lines below the lines containing ""Ion"". Therefore we omit the last four lines of import when searching.
pos = Flatten[Position[import[[;; -4]], a_String /; StringMatchQ[a, ""*Ion*""], 1]];

Next we split the strings using the character ""³"" as the delimiter, and we transform the strings into numbers by replacing ""E"" in each substring with ""*10^"" and applying ToExpression.
strings = StringTrim /@ StringSplit[import[[pos + 3]], ""³""];
data = Cases[strings, a_ /; Length[a] >= 5 :> ToExpression[
      StringReplace[a[[3 ;; 5]], ""E"" -> ""*10^""]]];

The first few entries for data are then
data[[;; 5]]


{{7618.6, -0.3894, 0.2726}, {3353.6, -0.0124, 0.03758}, 
   {15268., 64.08, -8.825}, {13317., 38., 16.98}, {5654.9, 0.08338, 0.01426}}


which seems to match the screenshot.
"
List all the directories under the current one,"
Maybe something like
Select[FileNames[""*"", """", Infinity], DirectoryQ]

"
graphics - Poor rendering of fractals,"
I think the lower quality you see has to do with the downscaling of the image. It is generated at 512x512 pixels which you can check if you right mouse click on the image, but it isn't displayed that way. So, if I change this to:
OpenCLFractalRender3D[ImageSize -> 512]

I get
.
As to your second question: of course you can use Mathematica to generate 2D fractals. It has a rich set of drawing primitives. Examples can be found in the manual (for instance, here).
"
parallelization - Nesting Parallel processes,"
This limitation exists, and as far as I can see we have to live with it for now.  It does indeed make it impractical to use Parallel operations inside functions---the functions won't work in parallel kernels.
I recommend you parallelize at the top level unless you have a specific reason to do it at lower levels.  The longer the a ""unit calculation"" that is run in a subkernel, the less parallelization overhead will matter.  This overhead can be significant if you are running the subkernels on different machines from your main kernel (as you seem to be based on your Lightweight Grid question).  Could you give some indication of how long it takes for your functions to finish, and how long the list dataLists is?  If dataLists is long enough compared to the number of processors you have available, then probably parallelization at the highest level will be most efficient.
Alternatively you could just use Off[ParallelMap::subpar].
"
packages - Using GRTensorM 1.2 in Mathematica 8.0,"
I don't have that package, so is a more or less wild guess. There seems to be a fucntion 
grtG`Ndim[metricName]

and it seems as if that does not evaluate. Is kerr a supported metric name? You could look at the NDim funciton and see if you can spot a problem. Maybe ??grt`Ndim gives a clue. Perhaps you know the dimension and can set it outside the package.
"
calculus and analysis - How to specify assumptions before evaluation?,"
Integrate can take the option Assumptions.
Integrate[1/Sqrt[z^2 + u^2], {z, -l, l}, 
  Assumptions -> u > 0 && l > 0 && Element[u | l, Reals]]

 ==> 2 Log[(l + Sqrt[l^2 + u^2])/u]

Alternatively use Assuming.
Assuming[u > 0 && l > 0 && Element[u | l, Reals], 
 Integrate[1/Sqrt[z^2 + u^2], {z, -l, l}]]

==> 2 Log[(l + Sqrt[l^2 + u^2])/u]

"
image processing - Adding controls for multiple functions in Manipulate,"
Since I don't have access to your image I'll use the built in ExampleData test image ""Lena"". The following should accomplish what you want.
helix = ExampleData[{""TestImage"", ""Lena""}];

Manipulate[
 w = GaussianFilter[
   Sharpen[ImageAdjust[helix, {contrast, brightness, gamma}], 
    sharpen], gfilter], {{contrast, 0}, -1, 5, 0.01, 
  Appearance -> ""Labeled""}, {{brightness, 0}, -1, 5, 0.01, 
  Appearance -> ""Labeled""}, {{gamma, 1}, 1, 10, 1, 
  Appearance -> ""Labeled""}, {{sharpen, 1}, 1, 15, 
  Appearance -> ""Labeled""}, {{gfilter, 1}, 1, 15, 
  Appearance -> ""Labeled""}, Delimiter, ""Histogram"", 
 Dynamic[ImageHistogram[w, Appearance -> ""Separated"", 
   ImageSize -> 250]], ControlPlacement -> Left]

Notice that the functions are added just by nesting them.  This could probably be accomplished in a variety of ways but this seems most direct. The added controls are nearly verbatim to the pre-existing ones.
Here is what it produces...

"
probability or statistics - Showing the correlation of two variables using a plot,"
You can also calculate the Coefficient of Determination, R Squared.
This is the same as the correlation squared, but by making use of LinearModelFit you can create some additional graphics.
To make a sample distribution you can use this:
CreateDistribution[] := DynamicModule[{savepts = {{-1, -1}}},
  Dynamic[
   EventHandler[
    ListPlot[pts, AxesOrigin -> {0, 0}, 
     PlotRange -> {{0, 7}, {0, 5}}], 
    ""MouseDown"" :> (savepts = 
       pts = DeleteCases[
         Append[pts, MousePosition[""Graphics""]], {-1, -1}])],
   Initialization :> (pts = savepts)]]

CreateDistribution[]

Just click to add some points.  The data is collected in the variable pts.

Then calculate R Squared:
lm = LinearModelFit[Sort@pts, a, a]; r2 = lm[""RSquared""];
Show[Plot[lm[x], {x, 0, 7}], ListPlot[pts], AxesOrigin -> {0, 0}, 
 PlotRange -> {{0, 7}, {0, 5}}, 
 PlotLabel -> 
  ""The correlation is "" <> 
   If[D[lm[""BestFit""], a] < 0, ""negative"", ""positive""], 
 Epilog -> 
  Inset[Style[
    ""\!\(\*SuperscriptBox[\""R\"", \""2\""]\) = "" <> ToString[r2], 
    11], {1.5, 4.5}]]


Whether the correlation is positive or negative is obtained here from the derivative of the BestFit.
You can add standard deviation bands for sigma = 1, 2 & 3 like this.
lm = LinearModelFit[Sort@pts, {1, x (*, x^2 *)}, x];
{bands68[x_], bands95[x_], bands99[x_]} = 
  Table[lm[""SinglePredictionBands"", 
    ConfidenceLevel -> cl], {cl, {0.6827, 0.9545, 0.9973}}];
Show[ListPlot[Sort@pts], 
 Plot[{lm[x], bands68[x], bands95[x], bands99[x]}, {x, -0.15, 7.2}, 
  Filling -> {2 -> {1}, 3 -> {2}, 4 -> {3}}], AxesOrigin -> {0, 0}, 
 PlotRange -> {{0, 7}, {0, 5}}, ImageSize -> 480, Frame -> True]


Uncomment x^2 for a quadratic fit.

Added note
The linear band calculation steps are detailed here: How to derive SinglePredictionBands
"
functions - Problem when defining variable in Mathematica,"
Use:
domain := {n, 0, 10};
Plot[n, Evaluate[domain]]

Plot has the HoldAll attribute which prevents domain from evaluating:
Attributes[Plot]
{HoldAll, Protected}

"
interpolation - Implicit Interpolating function in Mathematica and its explicit form in small sections,"
Regarding your second question, f may be obtained in general via f=Interpolation[points]. Its derivative is given by f'[.3] (say) This, however, fails for your example because two points with the same x-coordinate appear (as it is a circle). 
For instance, try f = Interpolation[Table[{i, Sin[i]}, {i, 0, 10, .1}]] and then Plot[f'[x], {x, 0, 2 Pi}].
Perhaps you could explain what it is you're actually trying to do.
EDIT: OK, you can do this for f1:
Quiet[f1 = FunctionInterpolation[Sqrt[1 - y^2], {y, -1, 1}]];

and for your F (that I randomly renamed to func)
func = FunctionInterpolation[-1 + 1*(x^2 + y^2), {x, -1.5, 
   1.5}, {y, -1.5, 1.5}]

Note that this is some function that vanishes on the unit circle. If all you want is that F(x,y) vanishes on (eg) the unit circle, there are infinitely many functions satisfying this; one of them is the one you gave.
"
Delete duplicate elements from a list,"
You can use DeleteDuplicates to remove the duplicate elements while preserving the original order:
DeleteDuplicates[{a, 1, 5, 3, 5, x^2, x^2}]
(* {a, 1, 5, 3, x^2} *)

"
equation solving - How to solve for an Z-Score of a T-Distribution?,"
Have you tried FindRoot? It's a numerical function looking for a root given some starting location. In addition to that, you can get around integrating by using CDF instead of PDF in the first place:
FindRoot[CDF[StudentTDistribution[49], y] == 0.95, {y, 1}]


{y -> 1.67655}


If you're interested, the reason why your first approach doesn't work: NIntegrate cannot use placeholders, it has to evaluate to a number in all cases. What you're trying to do is equivalent to NIntegrate[x*y, {x,0,1}], and the program complains that it does not know the full integrand since y is undefined, therefore it cannot be evaluated. The fact that you've wrapped a Solve, which inserts the missing variable (x in your case) after NIntegrate has been evaluated, does not have any impact on that.
"
Selective blurring of areas of image to make seamless tiles,"
img = ExampleData[{""TestImage"", ""Mandrill""}];

This ""rotates"" the image like you did:
rot[img_] := 
 Image@RotateLeft[ImageData[img], Round[Reverse@ImageDimensions[img]/2]]


Let's make a mask ...
mask[img_, margin_] := 
 ImagePad[Graphics[{}, ImageSize -> (ImageDimensions[img] - 2 margin),
    Background -> Black], margin, White]


... and inpaint it:
Inpaint[rot[img], Blur[rot[mask[img, 10]], 3]]


Adjust the parameters (mask thickness, blur radius) to your liking.
It will work better for texture-like images:
img = ExampleData[{""Texture"", ""Bricks3""}]

Inpaint[rot[img], rot[mask[img, 5]]]


Note: often it is better to trace the mask manually, paying attention to features in the image.  Right click the image, and choose Graphics Editing -> Drawing Tools.  Draw the mask.  Then again right click, and choose Graphics Editing -> Create Mask.  I like to use the Freehand Line tool with a very thick line and round caps and joins---it's almost like painting with a brush in a photo editor.
"
time series - Function to calculate and plot sample variogram,"
Lag differences are not the same as second-differencing etc, so Differences is not the right approach. 
test2 = Array[f, 10]

In[23]:= Differences[test2, 3]


Out[23]= {-f[1] + 3 f[2] - 3 f[3] + f[4], -f[2] + 3 f[3] - 3 f[4] + 
        f[5], -f[3] + 3 f[4] - 3 f[5] + f[6], -f[4] + 3 f[5] - 3 f[6] + 
        f[7], -f[5] + 3 f[6] - 3 f[7] + f[8], -f[6] + 3 f[7] - 3 f[8] + 
        f[9], -f[7] + 3 f[8] - 3 f[9] + f[10]}

Building on kguler's answer, here is an alternative way of getting lag-differences. I have written it up as a separate function because it has more general utility than this specific application.
lagdif[l_List, k_Integer?Positive] /; k < Length[l] := 
  Drop[l, k] - Drop[l, -k]

We can then use a similar approach:
dif[list_] := Table[lagdif[list, k], {k, Length[list] - 1}];
dbar[list_] := Mean /@ dif[list];
var[list_] := Variance /@ (Most@(dif[list]));
variogram[list_] := ((Rest@#)/First@#) &@var[list];

Testing with I(1) data (i.e. non-stationary with a single unit root): 
$y_t = y_{t-1} + \epsilon_t$
data = Accumulate[RandomReal[{-1, 1}, 20]];

GraphicsRow[{ListLinePlot[data], ListLinePlot[variogram[data]]}]


This makes me wonder how powerful the variogram is for data with shocks that have bounded support.
"
Locators and Table within a Manipulate are not behaving,"
Ok, I figured it out, sort-of. Here is what was in my original code for the curved Arrow that indicates the angle for the second vector:
angleArrow2 = 
  Graphics[Arrow[Table[{x1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Cos[i], 
      y1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Sin[i]}, {i, 0, theta2, 
      1/100}]]];

The problem was not necessarily with Table, but with the Table iterator. I kept asking myself why the commented-out definition of angleArrow2 worked when the definition with Table did not. I realized that the only difference between the two versions of angleArrow2 was the number of elements in the list within Arrow. So I started to play with the step size in the Table iterator. As I made the step size larger to reduce the number of elements in the list I started to see a hint of correct behavior. In other words, moving the Locator for the second vector DID move only the second vector, but only for a short ""time"". Once I moved the Locator beyond a certain distance (that seemed to depend on the step size in Table) the unwanted behavior appeared again. I.e. the second Locator moved along with the first Locator and changed the size and direction of the first vector instead of the second.
With a fixed step size such as 1/100 as I originally had, or even 1/10 as I eventually tried, the unwanted behavior eventually appeared. So I decided to try a relative step size base on the angle (theta2) and changed my code to read:
angleArrow2 = 
  Graphics[Arrow[Table[{x1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Cos[i], 
      y1 + Min[0.5 Sqrt[x2^2 + y2^2], 0.5] Sin[i]}, {i, 0, theta2, 
      theta2/20}]]];

Now it works beautifully! When one Locator is moved only its associated vector is changed. 
Now, I haven't quite figured out why this works, but a little more thinking may help. If anyone has any ideas on why an absolute step size resulted in the unwanted behavior while a relative step size worked correctly I would love to hear from you. However, I think you really need to evaluate my code at various absolute step sizes to see what I mean. With an absolute step size like 1/10 when you move the second Locator you initially see only the second vector changing, but then suddenly the first vector starts changing instead. Weird!
If you do evaluate my code be sure to Show the two vectors and the angle for the second vector:
Show[{vector1, vector2, angleArrow2}, PlotRange -> {{-4.1, 4.1}, {-4.1, 4.1}}, 
 ImageSize -> 500]

Thank you everyone for your suggestions!
"
programming - Lexicographic ordering of strings in Mathematica,"
I believe you are looking for Order and Ordering.
The 1 indidcates that ""aaa"" comes before ""aaaab"" in canonical ordering:
Order[""aaa"", ""aaaab""]


1


Here Ordering is used to get the position of the first element in the sorted list and the that element is extracted from the list.  This is equivalent to a ""Min"" function.
list = {""aaaa"", ""deaaaf"", ""dfeef"", ""a""};
list ~Extract~ Ordering[list, 1]


""a""


And a ""Max"" function:
list ~Extract~ Ordering[list, -1]


""dfeef""


"
programming - Effective matrix power like algorithm,"
Note:  The method I describe below does not find the optimal solution (i.e. the minimal number of multiplications), but it usually does better than the binary approach, and more importantly: it is very easy to extend it and optimize it for special cases.  We could easily pre-compute those exponents for which it does worse than the simple binary method to say up to 1000 and special case those.
According to the Wikipedia article on the topic:

... the determination of a shortest addition chain seems quite difficult:
  no efficient optimal methods are currently known for arbitrary
  exponents, and the related problem of finding a shortest addition
  chain for a given set of exponents has been proven NP-complete.

Therefore trying to compute the optimial solution within the function (as opposed to precomputing it and making a lookup table) defeats the purpose of using this for optimization.

I did a version of this with C++ template metaprogramming here.
This is a direct translation:
Let f be an associative function, then:
Clear[pow]
(* Syntax: pow[exponent][base] *)
pow[n_][a_] /; Mod[n, 2] == 0 := With[{t = pow[n/2][a]}, f[t, t]]
pow[n_][a_] /; Mod[n, 3] == 0 := With[{t = pow[n/3][a]}, f[f[t, t], t]]
pow[n_][a_] := f[pow[n - 1][a], a]
pow[1][a_] := a

Testing:
f[x_, y_] := (Print[""x""]; x y)

Then pow[10][2] gives
During evaluation of In[389]:= x

During evaluation of In[389]:= x

During evaluation of In[389]:= x

During evaluation of In[389]:= x

Out[389]= 1024

i.e. it was done in four multiplications.  You can think a bit about which is the best subdivision (to 3 or to 2) for different numbers.  It can be manually verified that for exponents under 100, in the case of 33 and 69 (and exponents reducible to these such as $67 = 2\times 33 +1$) it's better not to subdivide into 3 first.  We can easily special-case pow for these by adding the following to the beginning of pow's definition:
pow[33][a_] := f[pow[32][a], a]
pow[69][a_] := f[pow[68][a], a]

Similarly, in the case of e.g. 82 it's better not to subdivide into 2 because $82 - 1 = 3^4$, but use
pow[82][a_] := f[pow[81][a], a]

Another example is that in the case of 85 and 95 it's better to subdivide into 5 first:
pow[85][a_] := pow[13][ pow[5][a] ]

But most of these are just tweaks that will not make a huge difference.
I believe that the value of my implementation lies in the ease of its extension for special cases like these for small exponents.

For the adventurous with a lot of free time, see this paper on Pippenger's algorithm.
"
string manipulation - Position of a particular substring in an imported HTML file,"
The string ""Flux Light Curve"" does not appear as an element of s.  If you are looking for a substring you will need a different function.
If you only want to know the positions of strings which contain ""Flux Light Curve"" as a substring, you might use:
Position[ s, x_ /; StringMatchQ[x, __ ~~ ""Flux Light Curve"" ~~ __] ]

In this ~~ stands for StringExpression.
The output from this:
StringPosition[s, ""Flux Light Curve""]

is a list with many empty lists as elements, because most elements in s do not contain the substring.  You can further process the result as needed.  For example:
x = StringPosition[s, ""Flux Light Curve""];

Position[x, {__Integer}]

DeleteCases[x, {}]

"
syntax - Head and everything except Head?,"
Point #1
Part always wraps element sequences with the original head of the expression.
expr = Hold[1 + 1, 2 + 2, 3 + 3, 4 + 4, 5 + 5];

expr[[{2, 3}]]


Hold[2 + 2, 3 + 3]


For this purpose a single part e.g. 1 is not a sequence but {1} and 1 ;; 1 are:
expr[[1]]

expr[[{1}]]

expr[[1 ;; 1]]


2

Hold[1 + 1]

Hold[1 + 1]


This applies at every level of the extraction:
exp2 = g[h[1, 2], i[3, 4]];

exp2[[  2 , 1  ]]
exp2[[ {2}, 1  ]]
exp2[[  2 ,{1} ]]
exp2[[ {2},{1} ]]


3

g[3]

i[3]

g[i[3]]


I used this nontrivially for Elegant manipulation of the variables list.
Point #2
Consider instead using Extract which wraps sequences in List:
Extract[expr, {{2}, {3}}]


{4, 6}


The third argument of Extract can be used to specify a function to apply to individual elements before they are evaluated:
Extract[expr, {{2}, {3}}, HoldForm]


{2 + 2, 3 + 3}


If you want all parts you can also use Level:
Level[(a + b + c), {1}, Heads -> True]


{Plus, a, b, c}


Or Cases:
Cases[(a + b + c), _, Heads -> True]


{Plus, a, b, c}


Or Replace/ReplaceAll:
(a + b + c) /. head_[body___] :> {head, body}


{Plus, a, b, c}


Point #3
The last point is more tricky and I had to check it myself.  There is a behavior that I also did not expect:
Range[5][[0 ;; 5]]


{}


What I expected was an error as seen here:
Range[5][[0 ;; 4]]

and here:
Range[5][[0 ;; 6]]

When Span is used in Part[x, 0 ;; n] where n is the length of x, Part returns the head of the expression.  Therefore (a + b + c)[[0;;3]] returns Plus[] and Plus[] evaluates to 0.

I believe Span behaves this way because of how it handles non-positive values, and zero-length spans.  Consider:
Range[10][[-2 ;; 10]]


{9, 10}


You can see that it wraps around.  Now consider:
Range[10][[5 ;; 4]]


{}


An empty span returns the head of the expression with no arguments.
Using 0 ;; n where n is the last element in the list, or 0 ;; -1, is also an empty span wrapping around the open end of the list.
Range[10][[0 ;; -1]]


{}


"
How to impose custom style to the edges of a graph,"
For the first part of your question you can use a custom function for the EdgeShapeFunction option of Graph:
Let
   edgeshape[e_, ___] := {Arrowheads[Large], Red, Thick, Arrow[e, 0.2]}

and use as
 Show[Graph[node, edges, VertexCoordinates -> vertexposition, 
 VertexSize -> {""Scaled"", .02}, VertexLabels -> ""Name"", 
 EdgeShapeFunction -> edgeshape], Frame -> True, FrameTicks -> True, 
 ImageSize -> 600]

to get

Graph also takes Graphics options, so you can use
 Graph[node, edges, VertexCoordinates -> vertexposition, 
 VertexSize -> {""Scaled"", .02}, VertexLabels -> ""Name"", 
 EdgeShapeFunction -> edgeshape, Axes -> True, Ticks -> Automatic, 
 TicksStyle -> Directive[Orange, 12], PlotRangePadding -> .1, 
  AxesOrigin -> {0, 0}]

to get

Update: Using Szabolcs's revised answer, adding Frame->True, FrameTicks->All to options
 Graph[node, edges, VertexCoordinates -> vertexposition, 
 VertexSize -> {""Scaled"", .02}, VertexLabels -> ""Name"", 
 EdgeShapeFunction -> edgeshape, Frame -> True, Axes -> False, 
 FrameTicks -> All, FrameTicksStyle -> Directive[Orange, 12]]!


You can also define your custom  tick function. e.g. 
 ticks[min_, max_] := 
 Table[If[EvenQ[i], {i, i, {.01, 0}, Red}, {i, i, {.01, 0},  Blue}], {i, Floor[min],   Floor[max], 10}]

and use it with FrameTicks
 Graph[node, edges, VertexCoordinates -> vertexposition, 
 VertexSize -> {""Scaled"", .02}, VertexLabels -> ""Name"", 
  EdgeShapeFunction -> edgeshape, Frame -> True, Axes -> False, 
 FrameTicks -> ticks, FrameTicksStyle -> Directive[Orange, 12], 
 PlotRangePadding -> 5, ImagePadding -> 30]

to get

From the above answers to your first and third questions, you should be glad that i am not attempting to answer your second question.
"
graphics - Generate a Unit Circle Trigonometry,"
There are a couple tricky points here.  Here's a start, which I imagine you can finish.
markings[t_] := Module[{o={0,0},p={Cos[t],Sin[t]}, 
  t2=Together[t],tFormat, rot},
  tFormat = If[Denominator[t2]=!=1, 
    Row[{Numerator[t2],""/"",Denominator[t2]}]];
  rot = If[TrueQ[Pi/2<Mod[t,2Pi]<3Pi/2],t+Pi,t];
    {{Opacity[0.3],Line[{o,p}]},
     Rotate[Inset[Style[
       Row[{t(180/Pi)Degree, "" = "",tFormat}],
     FontSize->18], p/2],rot], 
     Text[{Cos[t],Sin[t]},p,-1.3p]}
];
Graphics[{
  Circle[{0,0},1],
  Table[markings[t],{t,{Pi/6,Pi/4,2Pi/3}}]
}]


In addition to finishing it, logical enhancements would include: Making the Circle thicker, adjusting the size and/or format of the point labels, adding Points on the boundary, and/or making it dynamic.
Have fun!
"
Is there any way to allow a message to appear more than three times before General::stop shuts it off?,"
You can do something like this:
resetMessages[symbol_] := 
 With[{mysymbol = symbol}, 
  Unprotect[$MessageList]; $MessageList = 
   DeleteCases[$MessageList, HoldForm[MessageName[mysymbol, _]]]; 
  Protect[$MessageList];]

And you will have to call it after each function...
Sqrt[a, b, c, d]; Exp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; \
Exp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; Exp[a, b]; \
resetMessages[Exp]; Sqrt[a, b, c, d]; Exp[a, b]; resetMessages[Exp]; \
Sqrt[a, b, c, d]; Exp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; \
Exp[a, b]; resetMessages[Exp]; Sqrt[a, b, c, d]; Exp[a, b]; \
resetMessages[Exp];

Sqrt::argx: Sqrt called with 4 arguments; 1 argument is expected. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

Sqrt::argx: Sqrt called with 4 arguments; 1 argument is expected. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

Sqrt::argx: Sqrt called with 4 arguments; 1 argument is expected. >>

General::stop: Further output of Sqrt::argx will be suppressed during this calculation. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

Exp::argx: Exp called with 2 arguments; 1 argument is expected. >>

"
A problem with Deploy and Locator in a Manipulate,"
This seems to work:
Manipulate[
 DynamicModule[{vector},
  vector = 
   Graphics[{Green, Arrow[{{0, 0}, Dynamic[p]}], 
     Locator[Dynamic[p, (p = #; x = p[[1]]; y = p[[2]]) &]]}];
  Deploy@Show[vector,
    PlotRange -> {{-2.1, 2.1}, {-2.1, 2.1}}, ImageSize -> 500]],

 Row[{""Ax"", Manipulator[Dynamic[x, (x = #; p[[1]] = x) &], {-2, 2}], 
   Spacer[4], Dynamic[x]}], 
 Row[{""Ay"", Manipulator[Dynamic[y, (y = #; p[[2]] = y) &], {-2, 2}], 
   Spacer[4], Dynamic[y]}],
 {{p, {1, 1}}, None},
 {{x, 1}, None},
 {{y, 1}, None}, TrackedSymbols -> {x, y, p}]

The only difference with the original code is that I've wrapped p with Dynamic in Arrow.
By the way, since p == {x,y}, you can actually replace p with {x, y} making the code a bit more elegant in this case:
Manipulate[
 DynamicModule[{vector},
  vector = 
   Graphics[{Green, Arrow[{{0, 0}, Dynamic[{x, y}]}], 
     Locator[Dynamic[{x, y}]]}];
  Deploy@Show[vector,
    PlotRange -> {{-2.1, 2.1}, {-2.1, 2.1}}, ImageSize -> 500]],
 {{x, 1, ""Ax""}, -2, 2, Appearance -> ""Labeled""},
 {{y, 1, ""Ay""}, -2, 2, Appearance -> ""Labeled""}]

"
front end - CellEvaluationFunction or $PreRead stripping inline cells from text cells,"
You're not going to get this to work on raw TextData cells. The FE evaluates TextData cells using EnterTextPacket, which merely sends a string along. And, so, the contents must be encoded as a string. Which means you're going to lose all of your typesetting structure. So, let's assume that you've embedded the above cell in a typeset cell where we'll have some more choices.  E.g.,
Cell[BoxData[Cell[TextData[{
  ""hello "",
  Cell[BoxData[
   FormBox[
    FractionBox[""3"", ""x""], TraditionalForm]]]
 }]]], ""myText"",
 Evaluatable->True,
 CellEvaluationFunction->myEvalFun]

Now the FE is going to send an EnterExpressionPacket which maintains the full box structure, including inline cells, and that we can work with. From that starting point, I wrote a version of myEvalFun which works for your sample input. It's not very robust...in particular, it assumes that the cell contains one TextData cell with, at most, one level of BoxData cells inside of it. And that the contents of the TextData cell contain nothing other than strings and BoxData cells (other valid TextData contents include StyleBoxes, ButtonBoxes, and TextData cells). But I think it'll give you a good starting point to work from.
myEvalFun[boxes_, form_] := Module[{inlineExprs, val, topExpr},
  inlineExprs = 
   Cases[boxes, 
    Cell[val : BoxData[_], ___] :> 
     ""PP"" <> ToString[TeXForm[ToExpression[val, form]]] <> ""PP"", 
    Infinity];
  topExpr = boxes[[1]] /. Cell[_BoxData, ___] :> ""``"";
  topExpr = 
   topExpr /. {Cell[TextData[{val___String}], ___] :> StringJoin[val],
      Cell[val_String] :> val};
  If[StringQ[topExpr], StringForm[topExpr, Sequence @@ inlineExprs], 
   ""Error""]]

"
front end - Creating a TeXForm/TraditionalForm/etcForm,"
This is far from fully integrated into the system but it is a first order approximation of the behavior of other forms.  Perhaps it will inspire someone else with a better method.
formfunc =
  StringReplace[
    ToString @ #,
    {""["" -> ""("", ""]"" -> "")"", x : DigitCharacter .. :> ""-->"" <> x <> ""<--""}
  ] &;

MakeBoxes[myForm[expr_], StandardForm] := 
  InterpretationBox[#, expr] & @ ToBoxes @ formfunc @ expr

ToString[expr_, myForm] ^:= formfunc[expr]

This provides output that can be re-evaluated to recover the original expression:
2^(1/2) // myForm


""Sqrt(-->2<--)""


This produces a normal String:
ToString[2^(1/2), myForm]


""Sqrt(-->2<--)""


"
front end - Getting the complete Cell expression some input would generate as output,"
I believe that ToBoxes (or possibly MakeBoxes) does what you want.  You would need to wrap the result in a valid Cell expression like this:
celldata = Cell[BoxData @ ToBoxes @ #, ""Output""] &;

Sqrt[2^x] // celldata


Cell[BoxData[SqrtBox[SuperscriptBox[""2"", ""x""]]], ""Output""]


"
plotting - Export to PDF - scaling grids of plots and text size,"
You should investigate in the Scaled function:
lots = GraphicsGrid[
   Table[With[{a = RandomInteger[{1, 17}], 
      b = RandomInteger[{1, 17}]}, 
     ParametricPlot[Sin[t^2] {Cos[a t], Sin[b t]}, {t, 0, 2 \[Pi]}, 
      PlotRange -> {{-1, 1}, {-1, 1}}, Frame -> True, 
      ImageSize -> Scaled[1]]], {15}, {7}]];
Export[""lots.pdf"", lots]


"
evaluation - Defining a ForEach function,"
The key here is learning about evaluation control.  Please see the tutorials linked from this page.

Use TracePrint to see how it is evaluated and you'll understand.
In
ForEach[{m, 3}, {n, 3}]@ToString[m n] 

ToString[m n] is evaluated to ""m n"" before ForEach even sees it.  Also, if m or n have values, this'll break.  Set a HoldAll attribute in the function:
ClearAll[ForEach]
SetAttributes[ForEach, HoldAll]
ForEach[iterators__] := Function[arg, Table[arg, iterators], HoldAll]


For the second part simply requires learning about option handling:
ClearAll[ForEach]
SetAttributes[ForEach, HoldAll]
Options[ForEach] = {Pre -> Null}
ForEach[iterators__, OptionsPattern[]] := 
  Function[arg, Table[OptionValue[Pre]; arg, iterators], HoldAll]

k = 0
ForEach[{n, 3}, {m, 3}, Pre :> k++][ToString@{m, n, k}]


Making this is good as a learning exercise, but I find this construct problematic and fragile.  If you want to use this to solve actual problems, other approaches are better.  Why don't you describe the problem that you want to solve?
"
How get Singular.m package to interact with Singular itself?,"
I found the same issue and resolved it by changing the name of SingularCommand from just Singular to it's full path at line 245 of the Singular.m package.  On my Mac, this was /usr/local/bin/Singular but your system may be different.
"
list manipulation - Select/Delete with Sublist elements?,"
I would use either
Cases[data, {x_, y_} /; Abs[x - y] > 4]

or
With[{diff = Abs[data[[All, 1]] - data[[All, 2]]] - 4}, 
   Pick[data, UnitStep[diff]*Unitize[diff], 1]
]

The first clearly demonstrates what you are trying to do, the second is much faster...
data = RandomInteger[{0, 100}, {10^6, 2}];

(m1 =  Cases[data, {x_, y_} /; Abs[x - y] > 4]); // AbsoluteTiming

==> {2.8393092, Null}

(m2 = 
    With[{diff = Abs[data[[All, 1]] - data[[All, 2]]] - 4}, 
     Pick[data,UnitStep[diff]*Unitize[diff], 1]]); // AbsoluteTiming

==> {0.1248024, Null}

m1 == m2

==> True

Assuming you are working with random data and don't expect equality, the second method can be simplified to...
Pick[data, UnitStep[Abs[data[[All, 1]] - data[[All, 2]]] - 4], 1]

Edit: 
Of course if you want to delete elements where Abs[x-y] > 4 you can modify the Cases definition as 
Cases[data, {x_, y_} /; Abs[x - y] <= 4]

And the Pick method by swapping out the 1 in the last argument with 0.
"
programming - How to distinguish between lists and values?,"
How about putting the results in a list and then removing unneeded braces.?
a = 76.5
b = {4, 5, 12.3}
Flatten[{a}]
Flatten[{b}]


That way you are always dealing with a list of values.

Or simply place braces around numbers (that are not already in a list):
If[NumericQ[x], x = {x}]

"
functions - How to cancel floating point factors?,"
The problem is that symbolic computation doesn't mix well with floating point. If you use Rationalize first to convert to an exact representation, Simplify (or the faster Cancel) will be able to do it's job.
"
calculus and analysis - Finding critical points of a function,"
Slightly more generally than the solution by @Sjoerd, you may look for roots of the reciprocal function - if you are interested in pole-like or root-like singularities:
f[x_] := (1 - 2 x)/(2 Sqrt[x - x^2])

Reduce[1/f[x] == 0, x]

(*
  ==> x == 0 || x == 1
*)

"
front end - automatic coloring of function names,"
The difference in color depends on whether or not it is a recognized symbol: black indicates it is recognized, blue indicates that it is not.  For a symbol to be recognized, it has had to have been input to the kernel, i.e. it has to have been included in an executed cell.  I have had problems in the past when quitting and restarting the kernel where the highlighter doesn't begin to work again, so every user defined symbol is blue regardless of its state.  But, I don't think I encountered it very often in v.7; it was more of a v.6 problem. (I just started using v.8, so I have no experience with it.)
"
plotting - MatrixPlot with Tooltips,"
This is just an elaboration of faleichik's answer. To create a MatrixPlot with tooltip labelling and highlighting of the selected square similar to for example BarChart or BubbleChart you could do something like
matPlot[mat_, opts : OptionsPattern[]] :=
 With[{dim = Dimensions[mat]},
  DynamicModule[{pt = {0, 0}, ij, xy, label, direction},
   direction = 1 - 2 Boole[Thread[# > dim/2]] &;
   LocatorPane[Dynamic[pt],
    Dynamic[xy = Floor[pt];
     ij = {dim[[1]], 1} + Cross[xy];
     label = If[Nand @@ Thread[1 <= ij <= dim], {},
       (* else *)
       {{FaceForm[], EdgeForm[{Thick, LightGray}], Rectangle[xy]},
        Text[Framed[mat ~Extract~ ij, Background -> White],
         direction[xy] + xy, -1.2 direction[xy]]}];
     MatrixPlot[mat, Epilog -> label, opts]],
    AutoAction -> True,
    Appearance -> None]
   ]]

Screenshot
mat = RandomReal[1, {30, 40}];
matPlot[mat, ColorFunction -> ""DeepSeaColors""]


"
graphics - How to hide Box in Graphics3D?,"
This should work as you need to feed the option Boxed -> False to Graphics3D and option should be given after the argument in a function.
splot1 = SphericalPlot3D[
Cos[θ], {θ, 0, Pi}, {ϕ, 0, Pi}, Mesh -> None, 
PlotPoints -> 80];
aGraphicsComplex = splot1[[1]];
Graphics3D[{Lighting -> {{""Point"", RGBColor[1, .9, .9], {2, 2, 4}}}, 
aGraphicsComplex /. 
GraphicsComplex[pts_, objs__] :> 
GraphicsComplex[
 With[{r = 4 Sin[11 (ArcTan[#[[1]], #[[2]]] + #[[3]])]}, {r, r, 
      2} #] & /@ pts, objs]}, Boxed -> False]


"
interoperability - How do I call a 32-bit DLL using .NET/Link and a 64-bit version of Mathematica?,"
The solution is forcing .NET/Link to load its 32-bit executable instead of the 64-bit one.  Since Mathematica communicated with the .NET/Link process through MathLink, it does not matter if the Mathematica kernel is 64 bit and the .NET/Link executable is a 32 bit version.  They are separate processes.  However, the .NET/Link executable must match the DLL that is being loaded.
There is an undocumented option to force loading the 32-bit version of .NET/Link:
UninstallNET[]
InstallNET[""Force32Bit"" -> True]

Now 32-bit DLLs can be loaded through .NET/Link, but 64-bit ones cannot.
"
evaluation - How to make Mathematica re-evaluate a cell after some event?,"
The simplest solution IMHO is using Manipulate. Almost no change in your code is necessary:
Manipulate[
 d = 10000; l1 = {};
 rc := RandomChoice[{a, b} -> {0, 1}];
 c = 1; While[c <= d, AppendTo[l1, rc]; c++];
 Column[
  {
   e = ((Count[l1, _] - Count[l1, 0])/d)*100 // N,
   f = 100 - e
   }
  ],
 {a, 2}, {b, 5000},
 TrackedSymbols -> {a, b}
 ]


"
graphics - Packed Graph or GraphPlot output with non-square layout?,"
Well, this is just a workaround.  Let's make a graph:
g = Graph@Table[i -> Mod[i^3, 300], {i, 1, 300}];

It looks like this:
GraphPlot[g, PackingMethod -> ""ClosestPackingCenter""]


Let's break it into two components, distributing connected components of similar sizes equally between the two:
cc = SortBy[ConnectedComponents@UndirectedGraph[g], Length];

c1 = Flatten[cc[[1 ;; ;; 2]]];
c2 = Flatten[cc[[2 ;; ;; 2]]];

Now let's show them size by side:
GraphicsRow[
 GraphPlot[Subgraph[g, #], PackingMethod -> ""ClosestPackingCenter"", 
    PlotRangePadding -> 0] & /@ {c1, c2},
 Spacings -> 0
 ]


Not perfect, but might be good enough for a paper or presentation.   This will only look good with the ClosestPackingCenter option but that is what you were asking for specifically.

Alternatively, you can use Heike's packing algorithm.  I used the simplest version because it was faster, but you should use the updated version which produces vector images (it'll be a bit more work though).
images = ImageCrop@
     Rasterize[#, ""Image"", ImageSize -> 50, 
      ImageResolution -> 4 72] & /@ (GraphPlot[Subgraph[g, #], 
       PlotRangePadding -> 0] &) /@ Reverse[cc];

padimg = ImagePad[#, 5, White] & /@ images;

iteration[img1_, w_, fun_: (Norm[#1 - #2] &)] := 
 Module[{imdil, centre, diff, dimw, padding, padded1, minpos},
  dimw = ImageDimensions[w];
  padded1 = ImagePad[img1, {dimw[[1]] {1, 1}, dimw[[2]] {1, 1}}, 1];

  imdil = MaxFilter[Binarize[ColorNegate[padded1], 0.01], 
    Reverse@Floor[dimw/2 + 2]];
  centre = ImageDimensions[padded1]/2;

  minpos = Reverse@Nearest[Position[Reverse[ImageData[imdil]], 0], 
      Reverse[centre], DistanceFunction -> fun][[1]];
  diff = ImageDimensions[imdil] - dimw;
  padding[pos_] := Transpose[{#, diff - #} &@Round[pos - dimw/2]];

  ImagePad[#, (-Min[#] {1, 1 }) & /@ BorderDimensions[#]] &@
   ImageMultiply[padded1, ImagePad[w, padding[minpos], 1]]]

fun = Norm[{1, 1/2} (#2 - #1)] &;

Fold[iteration[##,fun]&, padimg[[1]], Rest[padimg]]


Most of the code here is directly copied from her post.

If we make some effort to preserve sizes as well, we get this:

I used this code to generate the images for this (with some manual tweaking):
plots = GraphPlot[Subgraph[g, #]] & /@ Reverse[cc];

images = ImageCrop@
     Image@Show[#, PlotRange -> 2.5 {{-0.1, 1}, {-0.1, 1}}, 
       ImageSize -> 100] & /@ plots;

padimg = ImagePad[#, 5, White] & /@ images;

"
"list manipulation - Conditional Data Selection, efficiency","
EDIT
Apparently, I have misunderstood the problem. Here is the solution which, for smaller tests, produces the results identical to the original one:
getDistantPoints = 
  Compile[{{pts, _Real, 2}, {delta, _Real}},
     Module[{res = Table[{0., 0.}, {Length[pts]}], ctr = 1},
        res[[1]] = pts[[1]];
        Do[
          If[Norm[pts[[i]] - res[[ctr]]] > delta, 
            res[[++ctr]] = pts[[i]]
          ], 
          {i, Length[pts]}];
        Take[res, ctr]],
     CompilationTarget -> ""C"", RuntimeOptions -> ""Speed""]


Clear[GZFastAlt];
GZFastAlt[delta_, data_] :=
  Module[{ldata = data},
     ParallelTable[
       Table[
          getDistantPoints[ldata [[subNO, dispNo, All, ;; 2]], delta],
          {dispNo, Range[Length[ldata [[subNO]]]]}
       ], {subNO, Range[5]}]];

and runs in about 2 seconds on my 6 cores:
(res = GZFastAlt[0.1,allGazesX]);//AbsoluteTiming
{2.2451172,Null}

END EDIT
As a bonus, this keeps things packed, which is a big deal for your data - even in packed form, the computation consumes quite a bit of memory. 
"
output formatting - How to draw a pane with rounded corners?,"
Comments that are answers should be posted as such.
Framed[
  Pane @ Style[""text is here"", Bold, FontColor -> GrayLevel[0.2]],
  Background -> Red,
  RoundingRadius -> 10,
  FrameStyle -> None,
  FrameMargins -> 0
]


"
mathematical optimization - Why is this minimization with Boole functions failing?,"
It switches to NMinimize (a numerical solver) automatically because you have inexact numbers in the expression, which don't go well with symbolic calculations.
Use Rationalize to convert them to exact numbers.
labmda = 1

Minimize[Rationalize[(x1*1 - 1)^2 + (x1*0.823202 + x2*1 - 0.7551)^2 + 
   lambda*(Boole[x1 != 0] + Boole[x2 != 0])], {x1, x2}]

{420574853802/419415383201, {x1 -> 405399957550/419415383201, x2 -> 0}}

Actually I am surprised that Minimize can handle things as general as Boole.
"
Plotting Partial Sums of Fourier Series,"
In the definition of s you're summing from k==0. Since the summand has a term 1/k this gives a divide-by-zero error when calculating the partial sums. The sum should in fact start from k==1 (the zeroth coefficient is taken care of by the constant term in front of the sum). The first few approximations then look like
s[n_, x_] := 
 8/4 + 3/(9 π) Sum[(6 (-1)^k)/(k π) Cos[(k π x)/
        2] + (16 (-1)^k + 13)/(π k) Sin[(k π x)/2], {k, 1, n}]

partialsums = Table[s[n, x], {n, 1, 5}];
Plot[Evaluate[partialsums], {x, -4, 4}]


To compare this with f we plot the s[5,x] and f in the same plot:
Plot[{s[5, x], f[x]}, {x, -2, 2}]


which doesn't seem right to me, so I suspect you made a mistake somewhere in calculating the coefficients.
Calculating coefficients by hand
We could use FourierSeries to calculate the partial sums, but this is very slow, and  doesn't give produce the general equation for the coefficients. Therefore it's better to calculate the coefficients by hand. The $n$-th coefficient can be calculated according to
coeff[0] = 1/4 Integrate[f[x], {x, -2, 2}];
coeff[n_] = 1/4 Integrate[f[x] Exp[I Pi n x/2], {x, -2, 2}]


(1/(2 n^4 π^4))E^(-I n π) (-48 + 48 E^(I n π) - 
 48 I n π + 28 n^2 π^2 - 6 E^(I n π) n^2 π^2 + 
 2 E^(2 I n π) n^2 π^2 + 12 I n^3 π^3 - 
 I E^(I n π) n^3 π^3 - I E^(2 I n π) n^3 π^3)


Then the partial sums are given by
series[m_, x_] := Sum[Exp[-I Pi n x/2] coeff[n], {n, -m, m}]

Plotting the first few approximations:
Plot[Evaluate[Table[series[j, x], {j, 0, 5}]], {x, -6, 6}]


To see how this compares with the original function f:
Plot[Evaluate[{series[5, x], f[Mod[x, 4, -2]]}], {x, -4, 4}]


which looks a lot better than the before.
Edit: Real coefficients
Here, coeff[n] are the coefficients for the Fourier series in exponential form, but these can be easily converted to the coefficients for the $\cos$ and $\sin$ series, a_n and b_n, by doing something like
a[0] = coeff[0];
a[n_] = Simplify[ComplexExpand[coeff[n] + coeff[-n]]];
b[n_] = Simplify[ComplexExpand[I (coeff[n] - coeff[-n])]];

"
plotting - How to improve this code for exploring large matrices?,"
Using mtrxPlot2 from my answer to the cited question inside Pane
   Pane[mtrxPlot2[A, ImageSize -> 9 m, Mesh -> All], {500, 500}, 
   Scrollbars -> True]

one cane exploit the built-in tooltip and copy features of the Get Coordinates Tool (clicking on the graph and hitting ""."" or using the context menu).
mtrxPlot2[mat_, opts : OptionsPattern[]] := 
With[{dims = Dimensions[mat], 
indx = {Clip[Floor[#1[[1]] - #2[[2]]] + 1, {1, #1[[1]]}], 
Clip[Floor[#2[[1]]] + 1, {1, #1[[2]]}]} &}, 
With[{copiedvalues = ""CopiedValueFunction"" -> Function[pt,
{indx[dims, pt], Extract[mat, indx[dims, pt]]}], 
coordtooltips = ""DisplayFunction"" -> Function[pt,
Row[{""mat[["", Row[indx[dims, pt], "",""], ""]]  =  "", 
Extract[mat, indx[dims, pt]]},
 Background -> White, ImageSize -> {Automatic, 30}, 
 ImageMargins -> {{5, 5}, {10, 10}}, Alignment -> Center]]}, 
MatrixPlot[mat, opts, 
CoordinatesToolOptions -> {coordtooltips, copiedvalues}]]]

Screenshot:

"
list manipulation - What is the right way to rotate an array?,"
I realise that this doesn't fully answer the question, but for the special case of square matrices, there's already a suitable function: Image`MorphologicalOperationsDump`SquareMatrixRotate (which, no doubt, is how Sjoerd's suggestion works internally). This is undocumented, of course!
The implementation is the following (modulo some bugs I've fixed--i and j were not localized in the original, leading to problems if you want to rotate a matrix containing these symbols, there were no conditions on the arguments, and [admittedly, a minor point] the rotation matrix was numericized only after inversion, which is inefficient):
SquareMatrixRotate[mat_?MatrixQ, angle_?NumericQ] /; Equal @@ Dimensions[mat] :=
 Module[{
   inv, dim, ct,
   i, j,
   ii, jj
  },
  inv = Inverse@RotationMatrix@N[angle];
  dim = First@Dimensions[mat];
  ct = (dim + 1)/2;
  Table[
   {ii, jj} = MapThread[
     Clip[#1, {1, #2}, {1, 1}] &,
     {Round[inv.{i - ct, j - ct} + {ct, ct}], {dim, dim}}
   ];
   mat[[ii, jj]],
   {i, dim}, {j, dim}
  ]
 ]

Is it in any sense better than your existing methods? Well, you can rotate by an arbitrary angle, although the results may not make much sense for angles for which no ""natural"" rotation is possible. Other than that, I would say no: personally, I would have used Reverse as you did.
"
scoping - Notation for specifying transformation rules,"
I am not an expert on scoping constructs... Replacement rules aren't very respectful of inner scoping constructs, of the expression in which they are replacing. They seem to be respectful however of the scoping constructs of the expression they are building.
So, for example
Hold[val /. x_ /; cond :> res] /. cond :> x

returns
Hold[val /. x_ /; x :> res]

but, like your example
{1, x>0, -x}/.{val_,cond_,res_}:>(val/. x_/;cond:>res)

returns
1/. x$_/;x>0:>-x

In any case, we need to avoid the rescoping. Many ways to do this, but one would be to simply prevent the replacer to see your x_ as a scoped variable when it does the replacing
Attributes[f] = {HoldRest};
f[val_, cond_, res_] := val /. Pattern @@ Hold[x, _] /; cond :> res

In place of Pattern @@ Hold[x, _] you can put anything that evaluates to x_ without having it explicitly. You coudl make your own function, write Pattern[x, Sequence[], _], Union@Pattern[x, _, _], Identity[Pattern][x, _], Evaluate[Pattern][x, _], Reverse[Pattern[_, x]], ToExpression[""x_""], Pattern @@ (x _) (notice the space, could be a +). In those cases that don't hold its arguments, however, you would need to add an Unevaluated to avoid problems if x is defined
@WReach's good suggestions in the comments are based on this too, on hiding the x_ as a scoped variable when the replacement is done, by injecting them later
Edit
Things like Pattern[x, 1 _^1+0] or stuff like that with the same structure (head Pattern2 arguments, won't work because it recognises it as a pattern)
Ok, I said there are many ways, so I'll give another example... Another way to implement the above is to lexically scope your Pattern so it isn't a pattern but you can type it as such. It probably only makes sense if your rhs is big and the lhs is small, but it also has the advantage of working when the pattern is inside held constructs. By the way, I never saw this done so I reserve the right to be suggesting something stupid and abstruse. In any case, its instructive and you wanted to learn, hehe
Attributes[f] = {HoldRest};
With[{rp = Pattern}, Module[{Pattern},
  f[rp[val, _], rp[cond, _], rp[res, _]] := Unevaluated@
     (val /. x_ /; cond :> res)
    /. Pattern :> rp]]

So, when you write your code, you can use x_ as you wish, because it will be interpreted as some Pattern$ASk that's not a scoping contruct. You use rp for those that you wish to become real patterns at definition time and _ those who you want to turn into patterns at execution time.
Another idea is, instead of hiding the scoping variable, hide the scoping constructs until runtime
Attributes[f] = {HoldRest};
With[{Condition = Hold[Condition], RuleDelayed = Hold[RuleDelayed], 
  ReplaceAll = Hold[ReplaceAll]},
 SetDelayed @@ 
  Hold[f[val_, cond_, res_], ReleaseHold[val /. x_ /; cond :> res]]
 ]

In order for the With to work you need to do something like that SetDelayed@@ because that's another scoping construct that With won't go into willingly. So, in this example, you see two layers of the trick.
"
plotting - How to plot Venn diagrams with Mathematica?,"
Based on that outdated notebook, I did the following function:
VennDiagram2[n_, ineqs_: {}] := 
 Module[{i, r = .6, R = 1, v, grouprules, x, y, x1, x2, y1, y2, ve},
  v = Table[Circle[r {Cos[#], Sin[#]} &[2 Pi (i - 1)/n], R], {i, n}];
  {x1, x2} = {Min[#], Max[#]} &[
    Flatten@Replace[v, 
      Circle[{xx_, yy_}, rr_] :> {xx - rr, xx + rr}, {1}]];
  {y1, y2} = {Min[#], Max[#]} &[
    Flatten@Replace[v, 
      Circle[{xx_, yy_}, rr_] :> {yy - rr, yy + rr}, {1}]];
  ve[x_, y_, i_] := 
   v[[i]] /. Circle[{xx_, yy_}, rr_] :> (x - xx)^2 + (y - yy)^2 < rr^2;
  grouprules[x_, y_] = 
   ineqs /. 
    Table[With[{is = i}, Subscript[_, is] :> ve[x, y, is]], {i, n}];
  Show[
   If[MatchQ[ineqs, {} | False], {},
    RegionPlot[grouprules[x, y],
     {x, x1, x2}, {y, y1, y2}, Axes -> False]
    ],
   Graphics[v]
   , PlotLabel -> 
    TraditionalForm[Replace[ineqs, {} | False -> ∅]], 
   Frame -> False
   ]
  ]

Which can have as inequallity any logical expression with subscripts:



EDIT: It works with more than 3 groups!

EDIT2: As Brett says, some cases of 5 doesn't work, like VennDiagram2[5, Subscript[A, 1] && ! (Subscript[A, 2] || Subscript[A, 5]) && Subscript[A, 3] && Subscript[A, 4]], but for example if you change the order to something else it works: VennDiagram2[5, Subscript[A, 1] && ! (Subscript[A, 3] || Subscript[A, 4]) && Subscript[A, 2] && Subscript[A, 5]]. So an intelligent way of sorting the circles should be needed for complex cases.
"
"graphics - Create a ""perspective animation""","
It could be something like this?
outersquare = {{-1, -.8}, {1, .8}};

innersquare = outersquare/10. + {-.1, 0};

corners[sq_] := {sq[[1]], {sq[[1, 1]], sq[[2, 2]]}, 
   sq[[2]], {sq[[2, 1]], sq[[1, 2]]}};

lines[sq_] := Partition[corners[sq], 2, 1, 1];

pointOfSquare[sq_, side_, i_, n_] := 
  With[{line = lines[sq][[side]]}, 
   line[[1]] + (n - i)/n (line[[2]] - line[[1]])];

alllines := 
  With[{n = 20}, 
   Flatten@Table[
     Line[{pointOfSquare[innersquare, side, i, n], 
       pointOfSquare[outersquare, side, i, n]}], {side, 4}, {i, 0, 
      n}]];

rectangle[i_, n_] := 
  With[{factor = Log[i]/Log[n]}, 
   Rectangle @@ (factor innersquare + (1 - factor) outersquare)];

Animate[Graphics[{Red, alllines, EdgeForm[Red], FaceForm[Transparent],
    Table[rectangle[i, 10], {i, 1 + ministep, 10, 1}]}], {ministep, 
  .99, 0, -.01}]


EDIT: Adding ""moving background"":
alllines2[shift_] := 
  With[{n = 20}, 
   Flatten@Table[
     Line[{pointOfSquare[innersquare, side, i, n], 
       pointOfSquare[outersquare, side, i, n]}], {side, 4}, {i, shift,
       n, 1}]];

Animate[Graphics[{Red, alllines2[ministep], EdgeForm[Red], 
   FaceForm[Transparent], 
   Table[rectangle[i, 10], {i, 1 + ministep, 10, 
     1}]}], {ministep, .99, 0, -.01}]

EDIT2: Adding moving points (if you want to take out the red lines, get rid of alllines).
pointInLine[linepoints_, i_, shift_, n_] := 
 If[i + shift < n, 
  With[{factor = Log[i + shift]/Log[n]}, 
   Point[linepoints[[1, 
       1]] + (1 - factor) (linepoints[[1, 2]] - 
        linepoints[[1, 1]])]], {}]

allPoints[linesperside_, shift_, n_] := 
  With[{lines = 
     Flatten@Table[
       Line[{pointOfSquare[innersquare, side, i, linesperside], 
         pointOfSquare[outersquare, side, i, linesperside]}], {side, 
        4}, {i, 0, linesperside}]},
   Flatten[
    Table[pointInLine[line, i, shift, n], {line, lines}, {i, n}]]];

Animate[Graphics[{Red, alllines, Blue, PointSize[Medium], 
   allPoints[4, ministep, 10], EdgeForm[Red], FaceForm[Transparent], 
   Table[rectangle[i, 10], {i, 1 + ministep, 10, 
     1}]}], {ministep, .99, 0, -.01}]

In conclusion, I use as ""move"" factor Log[i+shift]/Log[n], so for each frame, the change from the previous one is that shift value (between 0 and 1).
"
graphics - Drawing Rotated views while ignoring the Bounding box,"
The variation in size is due to variation in camera position and viewing angle. Since ViewPoint uses special coordinates which depend on the bounding box it's better to use ViewVector instead (or even ViewMatrix if you can make it work). To keep the viewing angle fixed you should give an explicit value for ViewAngle. To place the object at the right position in the field of view you could use ViewCentre. For the example above you could do something like
cubes = Table[
  Graphics3D[{Rotate[cube, x, {1, 1, 1}, {0, 0, 0}]}, 
   ViewVector -> {3, 1/2, -2}, 
   ViewAngle -> 35 Degree,
   ViewCenter -> {.5, .5, .5},
   ViewVertical -> {1, 1, 1}, Boxed -> False],
  {x, 0, 2 Pi/3 - Pi/48, Pi/24}]

"
front end - Opening a context menu (with the Menu key),"
This isn't a full answer, but maybe those with more knowledge can take it from here. 
To capture key presses of a particular key, one can do the following:
k=0;
SetOptions[$FrontEndSession, 
 FrontEndEventActions -> {{""KeyDown"", ""q""} :> (++k), PassEventsDown -> True}
]

The previous example increments k each time the letter q is pressed. Note: the ""PassEventsDown"" is important. Without it, q won't ever actually show up in your notebook. 
To do more fun things, you can try to call a front end element with the following:
FrontEndTokenExecute[""CellContextDialog""]

This automatically launches the front end dialog that is mentioned. A full list of Front End Tokens is available here. Putting things together:
SetOptions[$FrontEndSession, 
 FrontEndEventActions -> {{""KeyDown"", ""q""} :> (++k; 
     FrontEndTokenExecute[""CellContextDialog""]), 
   PassEventsDown -> True}
]

There are two problems here:

I don't know if there is a FrontEndToken corresponding to the ""Right Click"" / ""Contxt"" menu
I don't know if there is a name for the Menu Key
I have no idea what I'm doing with the SetOptions[$FrontEndSession]... I might have broken other things. 

Maybe you can hack together something from this!
"
undocumented - What is the complete list of valid Front End Tokens?,"
I got a request to post here the undocumented tokens I already posted in an old answer on SO.
For completion, I merged my list (which is also in the link provided by @Chris) with @Rojo's list. Later, the list was merged with Vladimir's list below and two more tokens were included, so as to have here a repository of all known FE tokens.
Please feel free to update this answer as new tokens are found. 
{
""AboutBoxDialog"",
""Above"",
""AlignBottoms"",
""AlignCentersHorizontally"",
""AlignCentersVertically"",
""AlignLeftSides"",
""AlignRightSides"",
""AlignTops"",
""AllWindowsFront"",
""BackgroundDialog"",
""Balance"",
""Below"",
""BringToFront"",
""CellContextDialog"",
""CellGroup"",
""CellLabelsToTags"",
""CellMerge"",
""CellSplit"",
""CellTagsEditDialog"",
""CellTagsEmpty"",
""CellTagsFind"",
""CellUngroup"",
""Clear"",
""ClearCellOptions"",
""ClearNoAutoScroll"",
""Close"",
""CloseAll"",
""CloseMain"",
""ColorSelectorDialog"",
""ColorsPanel"",
""CompleteSelection"",
""Copy"",
""CopyCell"",
""CopySpecial"",
""CreateCounterBoxDialog"",
""CreateGridBoxDialog"",
""CreateHyperlinkDialog"",
""CreateInlineCell"",
""CreateValueBoxDialog"",
""Cut"",
""CycleNotebooksBackward"",
""CycleNotebooksForward"",
""DebuggerAbort"",
""DebuggerClearAllBreakpoints"",
""DebuggerContinue"",
""DebuggerContinueToSelection"",
""DebuggerFinish"",
""DebuggerResetProfile"",
""DebuggerShowProfile"",
""DebuggerStep"",
""DebuggerStepIn"",
""DebuggerStepInBody"",
""DebuggerStepOut"",
""DebuggerToggleBreakpoint"",
""DebuggerToggleWatchpoint"",
""DeleteBibAndNotes"",
""DeleteBibReference"",
""DeleteGeneratedCells"",
""DeleteIndent"",
""DeleteInvisible"",
""DeleteNext"",
""DeleteNextExpression"",
""DeletePrevious"",
""DeletePreviousWord"",
""DistributeBottoms"",
""DistributeCentersHorizontally"",
""DistributeCentersVertically"",
""DistributeLeftSides"",
""DistributeRightSides"",
""DistributeSpaceHorizontally"",
""DistributeSpaceVertically"",
""DistributeTops"",
""DuplicatePreviousInput"",
""DuplicatePreviousOutput"",
""EditBibNote"",
""EditStyleDefinitions"",
""EnterSubsession"",
""Evaluate"",
""EvaluateCells"",
""EvaluateInitialization"",
""EvaluateNextCell"",
""EvaluateNotebook"",
""EvaluatorAbort"",
""EvaluatorHalt"",
""EvaluatorInterrupt"",
""EvaluatorQuit"",
""EvaluatorStart"",
""ExitSubsession"",
""ExpandSelection"",
""ExpirationDialog"",
""ExplainBeepDialog"",
""ExplainColoringDialog"",
""ExpressionLinewrap"",
""FileNameDialog"",
""FindDialog"",
""FindEvaluatingCell"",
""FindNextMatch"",
""FindNextMisspelling"",
""FindNextWarningColor"",
""FindPreviousMatch"",
""FinishNesting"",
""FixCellHeight"",
""FixCellWidth"",
""FontColorDialog"",
""FontFamilyB"",
""FontPanel"",
""FontSizeDialog"",
""Fraction"",
""FrontEnd`ButtonNotebook[]"",
""FrontEnd`EvaluationNotebook[]"",
""FrontEndHide"",
""FrontEnd`InputNotebook[]"",
""FrontEnd`MessagesNotebook[]"",
""FrontEnd`Private`nb"",
""FrontEndQuit"",
""FrontEndQuitNonInteractive"",
""FrontEndToken[FrontEnd`ButtonNotebook[],\""HyperlinkGo\"",`distance`]"",
""GenerateImageCaches"",
""GenerateNotebook"",
""GeneratePalette"",
""GraphicsAlign"",
""GraphicsBoxOptionsImageSize"",
""GraphicsCoordinatesDialog"",
""GraphicsOriginalSize"",
""GraphicsPlotRangeAll"",
""GraphicsPlotRangeAutomatic"",
""GraphicsPlotRangeFixed"",
""GraphicsRender"",
""Group"",
""HandleShiftReturn"",
""HeadersFootersDialog"",
""HelpDialog"",
""HyperlinkGo"",
""HyperlinkGoBack"",
""HyperlinkGoForward"",
""ImageToAutomatic"",
""ImageToBinary"",
""ImageToBit"",
""ImageToBit16"",
""ImageToByte"",
""ImageToCMYK"",
""ImageToggleAlphaChannel"",
""ImageToggleInterleaving"",
""ImageToGrayscale"",
""ImageToHSB"",
""ImageToReal"",
""ImageToReal32"",
""ImageToRGB"",
""Import"",
""ImportPictures"",
""ImportStyleDefinitions"",
""Indent"",
""InsertBibAndNotes"",
""InsertBibNote"",
""InsertBibReference"",
""InsertClipPlane"",
""InsertMatchingBraces"",
""InsertMatchingBrackets"",
""InsertMatchingParentheses"",
""InsertNewGraphic"",
""InsertObject"",
""InsertRawExpression"",
""InsertSoftReturn"",
""InsertSplitBreak"",
""LicAuthFailureDialog"",
""Linebreak"",
""MacintoshOpenDeskAccessory"",
""MakeSelectionNotSpan"",
""MakeSelectionSpan"",
""MenuListBoxFormFormatTypes"",
""MenuListCellEvaluators"",
""MenuListCellTags"",
""MenuListCommonDefaultFormatTypesInput"",
""MenuListCommonDefaultFormatTypesInputInline"",
""MenuListCommonDefaultFormatTypesOutput"",
""MenuListCommonDefaultFormatTypesOutputInline"",
""MenuListCommonDefaultFormatTypesText"",
""MenuListCommonDefaultFormatTypesTextInline"",
""MenuListConvertFormatTypes"",
""MenuListDisplayAsFormatTypes"",
""MenuListExportClipboardSpecial"",
""MenuListFonts"",
""MenuListFontSubstitutions"",
""MenuListGlobalEvaluators"",
""MenuListHelpWindows"",
""MenuListNotebookEvaluators"",
""MenuListNotebooksMenu"",
""MenuListPackageWindows"",
""MenuListPalettesMenu"",
""MenuListPaletteWindows"",
""MenuListPlayerWindows"",
""MenuListPlugInCommands"",
""MenuListPrintingStyleEnvironments"",
""MenuListQuitEvaluators"",
""MenuListRelatedFilesMenu"",
""MenuListSaveClipboardSpecial"",
""MenuListScreenStyleEnvironments"",
""MenuListStartEvaluators"",
""MenuListStyleDefinitions"",
""MenuListStyles"",
""MenuListStylesheetWindows"",
""MenuListTextWindows"",
""MenuListWindows"",
""ModifyBoxFormFormatTypes"",
""ModifyDefaultFontProperties"",
""ModifyEvaluatorNames"",
""ModifyFontSubstitutions"",
""ModifyNotebooksMenu"",
""ModifyRelatedFiles"",
""MoveBackward"",
""MoveExpressionEnd"",
""MoveForward"",
""MoveLineBeginning"",
""MoveLineEnd"",
""MoveNext"",
""MoveNextCell"",
""MoveNextExpression"",
""MoveNextLine"",
""MoveNextPlaceHolder"",
""MoveNextWord"",
""MovePrevious"",
""MovePreviousExpression"",
""MovePreviousLine"",
""MovePreviousPlaceHolder"",
""MovePreviousWord"",
""MoveToBack"",
""MoveToFront"",
""New"",
""NewCDFNotebook"",
""NewColumn"",
""NewPackage"",
""NewRow"",
""NewText"",
""NextFunctionTemplate"",
""NotebookMail"",
""NotebookMailSelection"",
""NotebookOneNote"",
""NotebookOneNoteSelection"",
""NotebookStatisticsDialog"",
""NudgeDown"",
""NudgeLeft"",
""NudgeRight"",
""NudgeUp"",
""Open"",
""OpenCloseGroup"",
""OpenFromNotebooksMenu"",
""OpenFromNotebooksMenuEmpty"",
""OpenFromPalettesMenu"",
""OpenFromRelatedFilesMenu"",
""OpenHelpLink"",
""OpenSelection"",
""OpenSelectionParents"",
""OpenURL"",
""OptionsDialog"",
""Otherscript"",
""PasswordDialog"",
""Paste"",
""PasteApply"",
""PasteApplyNoAutoScroll"",
""PasteDiscard"",
""PasteDiscardNoAutoScroll"",
""PasteSpecial"",
""Placeholder"",
""PlainFont"",
""PreferencesDialog"",
""PreviousFunctionTemplate"",
""PrintDialog"",
""PrintOptionsDialog"",
""PrintSelectionDialog"",
""PublishToPlayer"",
""Radical"",
""RebuildBibAndNotes"",
""RebuildHelpIndex"",
""RecordSoundDialog"",
""RefreshDynamicObjects"",
""RelatedFilesMenu"",
""RemoveAdjustments"",
""RemoveFromEvaluationQueue"",
""Replace"",
""ReplaceAll"",
""ReplaceFind"",
""ReplaceParent"",
""ResetDefaultsText"",
""ReverseQuote"",
""Revert"",
""RunColorDialog"",
""RunEdgeColorDialog"",
""RunFaceColorDialog"",
""Save"",
""SaveRename"",
""SaveRenameSpecial"",
""ScrollLineDown"",
""ScrollLineUp"",
""ScrollNotebookEnd"",
""ScrollNotebookStart"",
""ScrollPageBottom"",
""ScrollPageDown"",
""ScrollPageFirst"",
""ScrollPageLast"",
""ScrollPageNext"",
""ScrollPagePrevious"",
""ScrollPageTop"",
""ScrollPageUp"",
""SelectAll"",
""SelectGeneratedCells"",
""SelectionAnimate"",
""SelectionBrace"",
""SelectionBracket"",
""SelectionCloseAllGroups"",
""SelectionCloseUnselectedCells"",
""SelectionConvert"",
""SelectionConvertB"",
""SelectionDisplayAs"",
""SelectionDisplayAsB"",
""SelectionHelpDialog"",
""SelectionOpenAllGroups"",
""SelectionParenthesize"",
""SelectionSaveSpecial"",
""SelectionScroll"",
""SelectionSetFind"",
""SelectionSpeak"",
""SelectionSpeakSummary"",
""SelectionUnbracket"",
""SelectLineBeginning"",
""SelectLineEnd"",
""SelectNext"",
""SelectNextExpression"",
""SelectNextLine"",
""SelectNextWord"",
""SelectNotebookWindow"",
""SelectPrevious"",
""SelectPreviousExpression"",
""SelectPreviousLine"",
""SelectPreviousWord"",
""ServerText"",
""SetCitationStyle"",
""SetDefaultGraphic"",
""ShortNameDelimiter"",
""SimilarCellBelow"",
""SoundPlay"",
""SpellCheckerDialog"",
""StackWindows"",
""Style"",
""StyleDefinitionsOther"",
""StyleOther"",
""Subscript"",
""SubsessionEvaluateCells"",
""Superscript"",
""SystemPrintOptionsDialog"",
""Tab"",
""TemplateSelection"",
""TestEvaluateNotebook"",
""TileWindowsTall"",
""TileWindowsWide"",
""ToggleAlignmentGuides"",
""ToggleDebugFlag"",
""ToggleDynamicUpdating"",
""ToggleGrayBox"",
""ToggleOptionListElement"",
""ToggleShowExpression"",
""ToggleTestingFlag"",
""TrustNotebook"",
""Undo"",
""Ungroup"",
""WelcomeDialog"",
""WindowMiniaturize"",
""XInfoDialog"",
""ZoomWindow"",
""$CellContext`inputnb$$"",
""$CellContext`sourceNotebook$$""
}

Quoting John Fultz when he gave the list in Jan 2009:

The list is comparatively complete, excepting option names (which can
  also be used as tokens)
The MenuList tokens don't do anything.  They're just menu
  placeholders.  Here's something interesting you can do with them...
DynamicModule[{font}, 
 Row[{PopupMenu[Dynamic[font], 
    FE`Evaluate[FEPrivate`GetPopupList[""MenuListFonts""]]], Spacer[20],
    Style[""The quick brown fox"", 20, FontFamily -> Dynamic[font]]}]]

FE`Evaluate[FEPrivate`GetPopupList[#]]& returns values appropriate
  for  PopupMenu, and several FE interfaces take advantage of this, so
  it's unlikely to  change in the future (although I wouldn't be
  surprised if such useful  functionality makes its way into much
  simpler a top-level function some day).

Edit by Jacob
Let's call the list that was here before I made my edit originalList. The list found by Vladimir (vladimirList), contains most of the items in originalList. The items that were in originalList, but not in vladimirList (Complement[originalList, vladimirList]) are the following.
{""FrontEnd`ButtonNotebook[]"",""FrontEnd`EvaluationNotebook[]"",
""FrontEnd`InputNotebook[]"",""FrontEnd`MessagesNotebook[]"",
""FrontEnd`Private`nb"",
""FrontEndToken[FrontEnd`ButtonNotebook[],\""HyperlinkGo\"",`distance`]"",
""$CellContext`inputnb$$"",""$CellContext`sourceNotebook$$""}

I am not sure how these items work and they seem to be different from other tokens. Probably reading the quote by John Fultz is a good first step towards understanding them. 
The vladimirList contains a lot of tokens that were not present in the original list. So great work by Vladimir. Even if you do not understand/like the ""special tokens"" that are in Complement[originalList, vladimirList], please realise that vladimirList is not exhaustive anyway, as it also does contain
{""SelectNextExpression"", ""SelectPreviousExpression""};

"
equation solving - Solve in terms of specific variables,"
Well, I'm not an expert on this and I always fight when I do these stuff, but this is what I think.
You are using symbols in your equations. To Mathematica, this probably means that they are something unkown but that something could be anything. If you put the symbols as last arguments, those are the ONLY symbols it will try to ""generate conditions"" to make the equations fit, for ANY value of the other symbols... (this is a generality. Read the long help then. You can set domain specifications, or quantifiers like Exists)
So, for example, 
Solve[x == y && x == -y, x]

will give an empty list even though y=0 is a solution. So in that case you have two options. Either specify y as a symbol to solve too
In[22]:= Solve[x == y && x == -y, {x, y}]

Out[22]= {{x -> 0, y -> 0}}

or use some version that will generate the conditions on y
Solve[x == y && x == -y]


{{x -> 0, y -> 0}}
  or

Reduce[x == y && x == -y]


y == 0 && x == 0

You could also explicitly ask solve to eliminate y
Solve[x == y && x == -y, x, {y}]

which is equivalent to
Solve[Exists[y, x == y && x == -y], x]


{{x -> 0}}
  Back to your case. Conclusion: either use reduce or add more symbols to the variable list. I can definitely find values for a2x, T, m1, g, that make the last two equations impossible to be satisfied.

"
performance tuning - Are there rules of thumb for knowing when RandomVariate is more efficient than RandomReal?,"
In general you should use RandomVariate for distributions and RandomReal for uniforms. Often RandomVariate calls RandomReal or RandomInteger under the hood but it varies on a distribution by distribution basis. After loading any necessary symbols, on evaluation, any timing differences should be negligible. 
RandomVariate is intended to give the flexibility to not have to think of whether the distribution is continuous or discrete (or mixed), it has also been optimized for each distribution in the system. One should always be able to use RandomInteger or RandomReal if the type is known ahead of time (and is not mixed or fuzzy in some way e.g. EmpiricalDistribution) but again, most of the overhead is in initializing the generator so if you are generating a large number of random numbers you shouldn't notice a big difference in timings after evaluating both RandomVariate and RandomReal/RandomInteger.
"
How to extract and assign output of Free-Form input to a variable?,"
You can use a slightly different query: (convert 1 atm to pascals)/pascals

The number in this case is a regular number (not a string or some other exotic construction.)

If you instead use Wolfram|Alpha query (shortcut ==), you get a lot of results:

with a + icon on the right of each.  Clicking on the + gives a menu where you can choose a format:

In particular the 'Number data' format will then paste something like
WolframAlpha[""convert 1 atm to pascals"", {{""Result"", 1}, ""NumberData""}]


101325


into the notebook.  This doesn't help you much the first time, but can be used programmatically for subsequent calculations.
"
differential equations - PDE Boundary Conditions,"
You may be able to to this with an ""EventLocator"". Have a look at the documentation: tutorial/NDSolveEventLocator. Unfortunately, you do not give all information in your post, i.e the all functions. Those, however, would be needed to give a definite answer.
"
output formatting - Rearranging a Polynomial,"
You were definitely on the right track with MonomialList. Here is a solution. Others will probably find nicer ways. Using the trick found here, we first define a Format that looks like ""Plus"" but doesn't rearrange things:
Format[myPlus[expr__]] := Row[Riffle[{expr}, ""+""]]

With this format in hand, we can wrap your original function in the following:
myPolynomial[n_Integer] := myPlus @@ RotateRight[Sort@MonomialList[psd[n]], n]

The Sort places things in what MMA considers canonical order. Lucky for us, it happens to put all the $\sigma_{1,2} w_1w_2$-like terms together first. Then we rotate the list using RotateRight. Since we know there will be n functions of the type $w_1^2\sigma_1^2$, we rotate it that many places. Using the non-rearranging form of plus, we get the desired result!
"
linear algebra - Trying to simplify Root expressions from the output of Eigenvalues,"
The reason why you can't get a simple expression for eigenvalues is that the characterisitc polynomial of matrixA is not factorizable (in general) to lower order polynomials, unlike for matrixB.   
CharacteristicPolynomial[matrixA, x] // Factor


CharacteristicPolynomial[matrixB, x] // Factor


There is no general method of solving sixth order polynomial equations, unlike for forth order ones. 
In general, you can still simplify a bit the expression for eigenvalues of matrixA adding an option Quartics -> True to Eigenvalues :
Eigenvalues[matrixA, Quartics -> True]


"
design patterns - How can one define a custom data object?,"
Format is what you are looking for: Create a data structure, something like this:
mkMyData[d1_, d2_] := MyData[d1, d2]
GetD1[a_MyData] := a[[1]]
GetD2[a_MyData] := a[[2]]
Format[MyData[d1_, d2_]] := ""MyData[<"" <> ToString[Length[d1] + Length[d2]] <> "">]""

Call the constructor:
data = mkMyData[Range[5], q]

(*
    ""MyData[<5>]""
*)
Call a selector:
GetD1[data]

(*
    {1, 2, 3, 4, 5}
*)
"
list manipulation - Count number of sublists with a total not greater than a given max,"
This is not really the same algorithm, but
ClearAll[v];
v[t_, data_] :=
   Block[{v},
     v[_?Negative, _] := 0;
     v[_, 0] := 1;
     v[tl_, n_] := v[tl, n] =
        v[tl - data[[n]], n - 1] + v[tl, n - 1];
     v[t, Length[data]]
   ];

You may need to increase the $RecursionLimit for larger lists.
"
combinatorics - Advanced Tupling,"
Here's a moderately parallelizable solution.  It constructs the tuples sequentially so that, at the end, you can be assured the first element is from the first list, the second from the second, etc. 
newTuples[t_, x_] := Flatten[
    ParallelTable[Append[s, #] & /@ Complement[x, s], {s, t}], 1];
Timing[ts = Fold[newTuples, {{}}, {a, b, c, d, e, f}];]

Let's unwind this. Fold builds the output one step at a time.  After processing a, the output is just a list of the elements of a, each as a singleton vector (""1-tuple""):
{{1}, {2}, {3}, {4}, {5}, <<...>> {26}, {28}}

To process b, newTuples will loop (via ParallelTable) over all the 1-tuples it has just created.  For each such 1-tuple s, Complement obtains the elements of b that would not cause any duplication (""x"" refers to b at this stage, and later to c, d, etc.).  Each of these elements is systematically tacked on to the current 1-tuple (via Append) to create a set of unique new 2-tuples.  For example, when working on the 1-tuple {2}, the first thing we do is remove 2 from b.  Then each remaining element of b is tacked on to {2}, giving {{2,3}, {2,4}, <<...>>, {2,41}}.
Once ParallelTable has augmented each 1-tuple into a list of 2-tuples in this manner, Flatten restructures the table of lists of 2-tuples as a single list: 
{{1,2},  {1,3},  {1,4}, <<...>>,  {1,41},
         {2,3},  {2,4}, <<...>>,  {2,41},
 {3,2},          {3,4}, <<...>>,  {3,41},
<<...>>
 {28,2}, {28,3}, {28,4}, <<...>>, {28,41}}

Fold then repeats this procedure, augmenting each 2-tuple with new elements of c, then augmenting the resulting 3-tuples with elements of d, etc, until it has processed all six lists.
When there is lots of duplication among lists, this sequential strategy will be more sparing of RAM (and CPU cycles) than a more direct method, because it avoids creating a large list from which the qualifying 6-tuples will be selected: at each stage, the list of intermediate tuples is as small as possible.
Timing was 37 seconds (3.33 GHz Xeon 3580) and RAM usage was approximately 1.5 GB.  (It goes a little faster if you process the smaller lists first.)  The output has 12,336,674 elements.  Testing on short lists gave correct results.  Try, for example,
Fold[newTuples, {{}}, {{0, 1}, {2, 3, 4}, {5}, {6, 7}, {6, 7}, {6, 7, 8}}] 

It should produce 2*3*1*2*1*1 = 12 6-tuples and indeed it does.

BTW, before attempting such a procedure generally it's a good idea to estimate how large the output might be, as in
Times @@ (Length /@ {a, b, c, d, e, f})

The output, 15874232, is the number of tuples that would be generated with duplicates allowed.  Much larger answers would indicate extreme caution is needed, lest Mathematica grab all your RAM in its effort to complete the calculation.
"
probability or statistics - Efficient way to generate random points with a predefined lower bound on their pairwise Euclidean distance,"
This is not an efficient answer but it is fun to play with so I thought I'd post it. For efficiency the use of Nearest might provide a good starting point.
g[n_, {low_, high_}, minDist_, step_: 1] := 
 Block[{data = RandomReal[{low, high}, {n, 2}], temp, happy, sdata, 
   hdata},

  While[True,
   temp = ((Nearest[data][#, 2][[-1]] & /@ data));
   happy = 
    Boole@Thread[MapThread[EuclideanDistance, {temp, data}] > minDist];
   hdata = Pick[data, happy, 1];
   sdata = Pick[data, happy, 0];
   If[sdata === {}, Break[]];
   sdata += RandomReal[{-step, step}, {Length[sdata], 2}];
   data = Join[sdata, hdata];
   ];
  data
  ]

The idea is to do an initial sampling and then allow the points that are too close to ""walk"" somewhere else. The function takes a desired number of points n, a low and high value for the data range, the minimum acceptable distance between points minDist and a step argument which allows points to ""walk"" up to a certain distance in the x and y directions.
Its especially fun to watch dynamically.
g[150, {0, 30}, 1.5, 1]

Edit: Per suggestion of Yves Klett the points are colored by relative happiness (green being more happy, red being less happy).

Edit 2: 
Now for a more serious attempt at something efficient..
findPoints =
  Compile[{{n, _Integer}, {low, _Real}, {high, _Real}, {minD, _Real}},
   Block[{data = RandomReal[{low, high}, {1, 2}], k = 1, rv, temp},
    While[k < n,
     rv = RandomReal[{low, high}, 2];
     temp = Transpose[Transpose[data] - rv];
     If[Min[Sqrt[(#.#)] & /@ temp] > minD,
      data = Join[data, {rv}];
      k++;
      ];
     ];
    data
    ]
   ];

And to test it for benchmarking...
npts = 350;
minD = 3;
low = 0;
high = 100;

AbsoluteTiming[pts = findPoints[npts, low, high, minD];]

==> {0.0312004, Null}

Check that the min distance is less than the threshold.
Min[
  MapThread[
   EuclideanDistance, {pts, Nearest[pts][#, 2][[-1]] & /@ pts}]] > minD

==> True

Check that I generated the correct number of points..
Length[pts] == npts

==> True

"
Defining an integer-valued function on an integer domain,"
Try 
f[x_ /; MemberQ[Range@12, x]] := Switch[x, 2, 28, 4 | 6 | 9 | 11, 30, _, 31]

"
plotting - Labels and tickmarks inside Frame,"
You could do something like this:
Plot[Sin[x], {x, 0, 10}, Frame -> True,
 Epilog -> {Table[Text[i, {i, -1}, {0, -1}], {i, Range[0, 10, 2]}],
  Table[Text[NumberForm[i, {2, 1}], {0, i}, {-1, 0}], {i, Range[-1, 1, .5]}]},
 FrameTicksStyle -> (FontOpacity -> 0),
 ImagePadding -> {{1, 1}, {1, 1}}]


"
front end - What is modifying an init.m that changes menu Palettes order?,"
mathStatica does not alter, nor seek to alter, the MenuSortingValue. In fact, mathStatica does not alter or seek to alter, in any way, how or where the mathStatica palette is listed in the palette menu... this is left entirely to default Mathematica behaviour.
The reason the mathStatica palette appears out of alphabetical order in the Palettes menu seems to be simply because all the other palettes start with an Upper case letter, whereas the mathStatica palette starts with a lower case 'm'. Stated simply: this appears to be a bug in Mathematica's menu sorting algorithm.
The mathStatica palette name is set under:
  Preferences --> Notebook options  -->  Window properties -->  WindowTitle -> ""mathStatica""

If this setting is changed from lower case ""mathStatica"" to upper case ""MathStatica"", and no other change is made, then the ""MathStatica"" palette appears alphabetically in the palette menu, as Prof Murray Eisenberg desires it to appear, rather than at the end of the palette list. If Wolfram 'update' their menu sorting algorithm, the desired menu appearance should be attained automatically.
(If anyone wants an adjusted palette with upper case WindowTitle MathStatica, just let me know, and I can send you a copy.)
"
front end - How does AutoStyleWords work?,"
A very similar question came up internally at WRI, so I have a nearly ready-made answer. In that case, the fellow wanted to highlight certain loop constructs, like Do and For in his code automatically. Here's how I responded.
In a fresh notebook, Format->Edit Stylesheet..., then paste and interpret the
cells below at the bottom of the stylesheet.  And voila, you'll got purple Dos and Fors in the notebook the stylesheet modified.
{
Cell[StyleData[""Input""],
 AutoStyleWords->{""Do""->""MyStyle"", ""For""->""MyStyle""}],

Cell[StyleData[""MyStyle""],
 FontColor->RGBColor[0.5, 0, 0.5]]
}

Some caveats about using this:

The thing on the rhs of the rule must be a named style (a slightly archaic and embarrassing limitation in a modern FE, but that's the way it is in v8).
There's a bug (fixed for future versions) in the validation of this option which can cause a crash if you feed it values formatted in any way other than this.
This will only work in typeset cells
This will only work to style things which are lexically word-type tokens. You cannot, for example, auto-style two words in sequence, a subexpression with an operator, or a substring of a word token.

"
Conditional numerical integration boundaries,"
A better option than using Boole would be to use Piecewise. Using that you can define a function that returns 0 when your conditions aren't met and otherfunc otherwise. 
So, define a function otherfunc2 and integrate that:
otherfunc2[x_, y_, z_, t_] := 
 Piecewise[
  {
   {otherfunc[x, y, z, t],
    z1[t] <=z<= z2[t] && y1[t, z] <=y<= y2[t, z] && x1[t, z, y] <=x<= x2[t, z, y]},
   {0, True}
   }
  ] 

"
packages - Differential geometry add-ons for Mathematica,"
Atlas 2 for Mathematica is the add-on for doing modern differential geometry calculations.
The tool is available on DigiArea website and Wolfram Research website.
The tool works with Mathematica 8 and Mathematica 9. 
Calculations are coordinate free

First of all in the atlas tool all calculations are coordinate free. That means calculations are performed in terms of tensors, vectors and p-forms. 
Not their components!
For example conformally flat metric tensor of sphere is presented as:

where  are coframe 1-forms and symbol - tensor product operator.


Standard differential geometry notations

Secondly, the package uses standard differential geometry notations for exterior derivative, covariant differentiation, tensor product etc. It is really helpful to see the same results/formulas on the screen and in my textbooks.

Example with Lie derivative calculation:



Example with exterior derivative calculation:



Example with tensor product calculation:


Atlas is very user-friendly and doesn't bog down with a lot of programming which is really importance for people interested in learning.
There are a lot of predefined operators to declare various DG objects. 
Just for example Invariants operator automatically calculates invariants of a mapping:    

for an embedding of a curve - the curve's normalized moving frame and the curve's curvatures
for an embedding or immersion - the second fundamental form and mean curvature vector
for a submersion - A and T invariants, the mean curvature vector of corresponding fibers, the integrability obstruction of corresponding horizontal distribution and the riemannian obstruction (if the submersion is not a riemannian one).



Visualization of n-dimensional objects

The package has Visualize function that visualizes n-dimensional differential geometry objects using different Mathematica plot functions. The function allows quickly visualize an object and its projections. See some examples.
For example visualization of projections for Mobius strip.




Differential Geometry Library

The tool gives access to Differential Geometry Library directly from Mathematica.The library has over 550 objects for differential geometry and its applications and frequently updated. The are hundreds of Exact Solutions of Einstein's Field Equations and atlas's graphical user interface (see below) allows calculate any of the objects/Exact Solutions just in few seconds.
Currently, the library has 6 categories:

2D Coordinate Systems
3D Coordinate Systems
Plane Curves
Space Curves
Surfaces
Exact Solutions of Einstein's Field Equations


For instance:






Graphical user interfaces

There is a bunch of neat applications which included into the tool: 


Atlas palette - Mathematica palette, allows manipulate, visualize and calculate entities for any of the objects from the library.


extends the keyboard with typesetting of characters and atlas symbols
gives access to the differential geometry library
generates notebook for any of the library objects that fully prepared to calculate differential geometry quantities for this entity

Atlas Wizard - solves differential geometry problems on the fly even if you have a little knowledge in the topic.


Video and Screencasts

Exact Solutions of Einstein's Equations with Atlas 2 for Mathematica
Atlas Palette Usage - Differential Geometry Library Usage
Atlas Palette Usage - Code generation and Typesetting
2D Coordinate System changing

"
How to set up new types for pattern matching strings?,"
I suggest to use lexical environments, in particular the function makeCustomEnvironment which I posted in this answer
ClearAll[makeCustomEnvironment];
SetAttributes[makeCustomEnvironment, HoldAll];
makeCustomEnvironment[values : (_Symbol = _) ..] := 
      Function[code, With @@ Hold[{values}, code], HoldAll];

now, define a custom environment:
env = makeCustomEnvironment[Consonant = _?ConsonantQ, Vowel = _?VowelQ]

And use it:
env@StringReplace[""badge"",
    Shortest[pre__]~~c:Consonant..~~v:Vowel~~EndOfString:>pre<>""-[""<>c<>""]-[""<>v<>""]""]

(*
  ==> ""ba-[dg]-[e]""
*)

Note that the literals Consonant and Vowel don't acquire any global values, and have special meaning only for the code literally present inside the env environment. You can view this solution as a simple example of Mathematica meta-programming.
EDIT
Another alternative (which I like less, but still) is to use UpValues:
ClearAll[Consonant, Vowel]
Consonant /: f_[left___, Consonant, right___] := 
    f[left, _?ConsonantQ, right];
Vowel /: f_[left___, Vowel, right___] := f[left, _?VowelQ, right];

In this case, you can run your code without any wrappers, but I personally would still go for local environments (note that I defined the above pretty carelessly for any f - for example, you won't be able to Clear Consonant or Vowel easily now. If you choose this method, you may want to narrow the set of f-s in the above).
And of course, you can just simply use assignments
ClearAll[Consonant, Vowel]
Consonant = _?ConsonantQ;
Vowel     = _?VowelQ;

but this will likely exclude the use of symbols Consonant and  Vowel in other capacities in some other pieces of your code, since they now have global values. This may also not work if they are used inside functions which hold their arguments, since they are replaced by their values as a result of their evaluation, in this method. 
"
packages - Compile for deployment,"
I am not aware of such functionality ""out of the box"", but you can use various symbol dependency frameworks (I have my version published here, although at present it does contain some bugs), to figure out a set of symbols being used. You will need a few auxiliary functions to extract all symbols used in a notebook, and prepare boxed form of the code for them, from their global properties. 
Here is some code which can get you started:
ClearAll[getCodePieces];
getCodePieces[nb : (_NotebookObject | Automatic) : Automatic] :=
  With[{nbl = If[nb === Automatic, EvaluationNotebook[], nb]},
    Flatten@
      Cases[NotebookGet[nbl], Cell[BoxData[boxes_], ""Input"", ___] :>
         ToExpression[boxes, StandardForm, HoldComplete], Infinity]];

ClearAll[getDependentSymbols];
getDependentSymbols[nb : (_NotebookObject | Automatic) : Automatic] :=  
  Union@Flatten[depends /@ getCodePieces[nb]]; 

ClearAll[createCodeBoxes];
createCodeBoxes[HoldComplete[sym_Symbol]] :=
  Module[{optionCode, attributeCode, dsocode, ocode, ucode, boxDefs},
   optionCode = 
     If[# === {}, {}, MakeBoxes[Options[sym] = #]] &@
        Options[Unevaluated[sym]];
   attributeCode = 
     If[# === {}, {}, MakeBoxes[SetAttributes[sym, #]]] &@
        Attributes[sym];
   boxDefs[defOper_] :=
     If[# === {}, {},
        Replace[#, (Verbatim[HoldPattern][lhs_] :> rhs_) :> 
             MakeBoxes[defOper[lhs, rhs]], {1}] &@#
     ] &;   
   dsocode = 
     boxDefs[SetDelayed][
        Flatten[{OwnValues[sym], DownValues[sym], SubValues[sym]}]];
   ucode = boxDefs[UpSetDelayed][UpValues[sym]];
   If[# === {}, {}, RowBox[Join[#, {"";"", ""\n""}]]] &@
      Flatten@
         Riffle[Flatten[{optionCode, attributeCode, ucode,dsocode }], 
            {"";"", ""\n""}]];

Clear[makeNbCode];
makeNbCode[nb : (_NotebookObject | Automatic) : Automatic] :=
  Cell[BoxData[#], ""Input""] &@
     RowBox[Flatten[createCodeBoxes /@ getDependentSymbols[nb]]];

This depends on my dependency-tracking framework, particularly the depends function, from the mentioned answer. You use it as (I assume the evaluation notebook for simplicity):
CellPrint@makeNbCode[]

Note that the above code is not complete and will miss certain definitions (e.g. those for Format, default values, etc) - so treat this as a starting point. I tested this on a few examples, seems to work fine. Note also that this will keep the symbol names, including the namespaces / contexts they belong to. Finally, not that one can not fully reconstruct the original code from global properties, bacause the global properties do not encode the information on whether or not the definition was given as immediate or delayed. This should not matter much here, since definitions are used in the way they are stored in the global rule base, though.
An alternative approach would be to get the set of symbols your notebook depends on, as above, but then, rather than reconstructing code from in-memory definitions, find the set of packages you need, load them as Get[...,""HeldExpressions""], and then search the held code of those packages. This may be somewhat more robust, but a little more complex to implement well (although not really very difficult).
Both approaches rely on the fact that your kernel state reflects the fully-working (loaded into memory) functionality that you want to extract - so the recommended use is to first load everything and run your functionality, and then use any of the above methods. If you want to have more ""static analysis"", this is also possible, but again a bit more complex, and your notebook must be self-contained (loading all needed packages, etc).
"
graphics - Avoiding white lines inside filled area in RegionPlot exported as PDF or PS,"
The suggestion to use Antialiasing->False doesn't really solve the problem. I don't have a single solution that's appropriate in all cases, but I think one of the approaches I list on the following web page will work: 
Avoiding artifacts in shaded contour and density plots
Edit:
The following method from the linked article solves the problem:
Instead of exporting the image (assumed to be stored in im1), export the modified graphics
im1 /. {EdgeForm[], r_?(MemberQ[{RGBColor, Hue, CMYKColor, GrayLevel}, Head[#]] &), i___} :> {EdgeForm[r], r, i}

This replaces the invisible edges of the polygons (EdgeForm[]) in your graphic (called im1 here) by edges of default thickness and with a color matching at least one of the neighboring polygons. The new edges then help fill any empty space between the shaded areas.
Edit 2
My solution relies on finding colored polygons without colored edges by looking for EdgeForm[] followed by a color in the graphic im1. 
Based on the answer by Mr. Wizard and kguler here, one can also make the above work better with custom colors and future additions to the built-in color choices:
colorQ = FreeQ[Quiet@Darker@#, Darker] &;
im1 /. {EdgeForm[], r_?colorQ, i___} :> {EdgeForm[r], r, i}

Edit 3
Thanks to @becko for pointing out that there is a new command ColorQ in version 10 that can do the same as above. So you can replace colorQ in the previous edit with ColorQ.
"
differential geometry - Shape operator vs second fundamental form,"
For the sake of clarity I will restrict my answer to the special case of (regular, embedded) surfaces in $\mathbb R^3$.
The difference between shape operator and second fundamental form is that the first is an operator, while the second is a bilinear form. Specifically, if $n$ is the outward normal to your surface $S \subset \mathbb R^3$, we may define the shape operator $S$ by the rule $$S(X) = D_X n$$ while the second fundamental form is given by $$II(X,Y) = D_X n \cdot Y$$
Here $D_x n$ is the directional derivative of $n$ in the direction $X$. Note that some authors use a negative sign in the definition of shape operator, and may also use the same name for both objects. If you know about tensors and type change, then the second fundamental form is what you get when you change the type of the shape operator from $(1,1)$ to $(0,2)$.
If you are interested in coordinate formulas and/or other applications, I would recommend Ted Shifrin's book, available on his website: ""Differential Geometry: A first Course in Curves and Surfaces"".
"
list manipulation - Efficiently Visualising Very Large Data Sets (without running out of memory),"
Showing humongous data by screen-fulls can be done using Manipulateas follows:
(* generate some data to show *)
res = Tuples[{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}, 7];

(* size of the data*)
ByteCount[res]

(* ==> 1003290792 *)

screenNumbers = 100;
Manipulate[
 Take[res, {i screenNumbers + 1, (i + 1) screenNumbers}], {i, 0, 
  Length[res]/screenNumbers - 1, 1}
]


Since the slider slides over 100,000's of values in a short distance you can slow down its movement using the modifier keys when you drag the slider.

The resulting slider can be finely manipulated by holding down the Alt key (or Option on Macintosh) while dragging the mouse. This causes the slider to move at 1/20 the rate of the mouse. The slider can be even more finely manipulated by also holding the Shift and/or Ctrl keys. [Last bullet of the More Information part of the Slider doc page]

Scrolling through the 1GB of data is almost instantaneous.
"
random - RandomVariate from 2-dimensional probability distribution,"
Mathematica v8 does not provide support for automated random number generation from multivariate distributions, specified in terms of its probability density functions, as you have already discovered it. 
At the Wolfram Technology conference 2011, I gave a presentation ""Create Your Own Distribution"", where the issue of sampling from custom distribution is extensively discussed with many examples. 
You can draw samples from the particular distribution at hand by several methods. Let
di = ProbabilityDistribution[
   Beta[3/4, 1/2]/(Sqrt[2] Pi^2) 1/(1 + x^4 + y^4), {x, -Infinity, 
    Infinity}, {y, -Infinity, Infinity}];

Conditional method
The idea here is to first generate the first component of the vector from a marginal, then 
a second one from a conditional distribution:
md1 = ProbabilityDistribution[
   PDF[MarginalDistribution[di, 1], x], {x, -Infinity, Infinity}];

cd2[a_] = 
  ProbabilityDistribution[ 
   Simplify[PDF[di, {a, y}]/PDF[MarginalDistribution[di, 1], a], 
    a \[Element] Reals], {y, -Infinity, Infinity}, 
   Assumptions -> a \[Element] Reals];

Then the conditional method is easy to code:
Clear[diRNG];
diRNG[len_, prec_] := Module[{x1, x2},
  x1 = RandomVariate[md1, len, WorkingPrecision -> prec];
  x2 = Function[a, RandomVariate[cd2[a], WorkingPrecision -> prec]] /@
     x1;
  Transpose[{x1, x2}]
  ]

You can not call it speedy:
In[196]:= AbsoluteTiming[sample1 = diRNG[10^3, MachinePrecision];]

Out[196]= {20.450045, Null}

But it works:

Transformed distribution method
This is somewhat a craft, but if such an approach pans out, it typically yields the best performing random number generation method. We start with a mathematical identity
$$
\frac{1}{1+x^4+y^4} = \int_0^\infty \mathrm{e}^{-t(1+x^4+y^4)} \mathrm{d} t = \mathbb{E}_Z( \exp(-Z (x^4+y^4))) 
$$
where $Z \sim \mathcal{E}(1)$, i.e. $Z$ is exponential random variable with unit mean.
Thus, for a random vector $(X,Y)$ with the distribution in question we have
$$
   \mathbb{E}_{X,Y}(f(X,Y)) = \mathbb{E}_{X,Y,Z}\left( f(X,Y) \exp(-Z X^4) \exp(-Z Y^4) \right)
$$
This suggests to  introduce $U = X Z^{1/4}$ and $V = Y Z^{1/4}$. It is easy to see, that the probability density function for $(Z, U, V)$ factors:
$$
f_{Z,U,V}(t, u, v) = \frac{\operatorname{\mathrm{Beta}}(3/4,1/2)}{\sqrt{2} \pi^2} \cdot \frac{1}{\sqrt{t}} \mathrm{e}^{-t} \cdot \mathrm{e}^{-u^4} \cdot \mathrm{e}^{-v^4}
$$
It is easy to generate $(W, U, V)$, since they are independent. Then $(X,Y) = (U, V) W^{-1/4}$, where $f_W(t) =  \frac{1}{\sqrt{\pi}} \frac{1}{\sqrt{t}} \mathrm{e}^{-t}$, i.e. $W$ is $\Gamma(1/2)$ random variable.
This gives much more efficient algorithm:
diRNG2[len_, 
  prec_] := (RandomVariate[NormalDistribution[], len, 
       WorkingPrecision -> prec]^2/2)^(-1/4) RandomVariate[
   ProbabilityDistribution[
    1/(2 Gamma[5/4]) Exp[-x^4], {x, -Infinity, Infinity}], {len, 2}, 
   WorkingPrecision -> prec]

Noticing that $|W|$ is in fact a power of gamma random variable we can take it much further:
In[40]:= diRNG3[len_, prec_] := 
 Power[RandomVariate[GammaDistribution[1/4, 1], {len, 2}, 
     WorkingPrecision -> 
      prec]/(RandomVariate[NormalDistribution[], len, 
        WorkingPrecision -> prec]^2/2), 1/4] RandomChoice[
   Range[-1, 1, 2], {len, 2}]

In[42]:= AbsoluteTiming[sample3 = diRNG3[10^6, MachinePrecision];]

Out[42]= {0.7230723, Null}

Rejection method
Here the idea is to sample from a relatively simple to draw from hat distribution. It is again a craft to choose a good one. Once the one is chosen, we exercise the rejection sampling algorithm:

In the case at hand, a good hat is the bivariate T-distribution with 2 degrees of freedom, 
as it is easy to draw from, and it allows for easy computation of the scaling constant:
In[49]:= Maximize[(1/(1 + x^4 + y^4))/
  PDF[MultivariateTDistribution[{{1, 0}, {0, 1}}, 2], {x, y}], {x, y}]

Out[49]= {3 Pi, {x -> -(1/Sqrt[2]), y -> -(1/Sqrt[2])}}

This gives another algorithm:
diRNG4[len_, prec_] := Module[{dim = 0, bvs, u, res},
  res = Reap[While[dim < len,
      bvs = 
       RandomVariate[MultivariateTDistribution[{{1, 0}, {0, 1}}, 2], 
        len - dim, WorkingPrecision -> prec];
      u = RandomReal[3/2, len - dim, WorkingPrecision -> prec];
      bvs = 
       Pick[bvs, 
        Sign[(Total[bvs^2, {2}]/2 + 1)^2 - u (1 + Total[bvs^4, {2}])],
         1];
      dim += Length[Sow[bvs]];
      ]][[2, 1]];
  Apply[Join, res]
  ]

This one proves to be quite efficient as well:
In[77]:= AbsoluteTiming[sample4 = diRNG4[10^6, MachinePrecision];]

Out[77]= {0.6910000, Null}

"
evaluation - Exporting held expressions through JSON,"
The short answer is that, as @FJRA noted in the comment, only certain types are supported. Which types? Enter the long answer.
Why the converter behaves as it does
Long answer: JSON supports only certain types, and their nested combinations, as defined e.g. here. Mathematica converter maps JSON objects to lists of rules, arrays to lists, strings to strings, plus has some special cases for True, False and Null. Once Mathematica JSON converter sees a general expression, it does not know what to do with it.
The problem with the ""obvious"" solution to convert to string and store as a string is that there will be no automatic way (without imposing some additional conventions) to tell which strings are really strings and which are stringified Mathematica expressions. So, IMO, the converter is doing the right thing.
Digging deeper
You can actually quite easily trace the execution the the functions of interest. If we use my debug function (from here), as
debug@Export[
   Environment[""USERPROFILE""] <> ""\\AppData\\Local\\test.json"", 
   HoldComplete[{1, 2, 3}], ""JSON""]

It will quickly tell us to look at the function  System`Convert`JSONDump`iexportJSON, which in turn points to System`Convert`JSONDump`toString. Inspecting the DownValues of the latter, you will see the procedure I described above.
Making the JSON import - export more liberal (for illustration purposes only !)
If you really want to make the JSON import - export more liberal, so that, upon seeing an unrecognized general expression, it somehow converts it to string for export, and back to expression during import, here is one way:
ClearAll[withLiberalJsonTostring];
SetAttributes[withLiberalJsonTostring, HoldAll];
withLiberalJsonTostring[code_] :=
   Block[{dv = DownValues[System`Convert`JSONDump`toString], 
         System`Convert`JSONDump`toString},
      DownValues[System`Convert`JSONDump`toString] = Most[dv];
      System`Convert`JSONDump`toString[expr_, _Integer] :=
       StringJoin[
          ""StringifiedOpen"",
          StringReplace[ToString[FullForm@expr],
            {""["" :> ""EscapeOpen"", ""]"" :> ""EscapeClose"", "","" :> ""EscapeComma""}],
          ""StringifyClose""
       ];
      code];

and the import counterpart:
ClearAll[withLiberalJsonImport];
SetAttributes[withLiberalJsonImport, HoldAll];
withLiberalJsonImport[code_] :=
   With[{result = code},
      result /. 
        s_String :> 
          StringReplace[
             s, 
            {""EscapeOpen"" :> ""["", ""EscapeClose"" :> ""]"", ""EscapeComma"" :> "",""}
          ] /. 
        s_String /; StringMatchQ[s, ""StringifiedOpen"" ~~ __ ~~ ""StringifyClose""] :>
            ToExpression@ StringReplace[s, ""StringifiedOpen"" | ""StringifyClose"" :> """"]
   ]; 

Note that the escaping strings are arbitrary, and this will break if these particular strings are also used in different capacities in the JSON expression.
With this, we can do:
withLiberalJsonTostring[
  Export[Environment[""USERPROFILE""] <> ""\\AppData\\Local\\test.json"", 
  {1, 2, HoldComplete[{1, 2, 3}]}, 
  JSON""]]

and
withLiberalJsonImport@
   Import[Environment[""USERPROFILE""] <> ""\\AppData\\Local\\test.json"", ""JSON""]

(* 
  ==> {1, 2, HoldComplete[{1, 2, 3}]}
*)

Note that I don't really recommend this method as robust, just posted this code for an illustration, and to aid the understanding of the matter. This is not robust on many grounds, incuding dependence on implementation details, the escaping procedure being arbitrary and not really robust, etc.
A robust solution would be to write an alternative converter (importer / exporter) to JSON, which would do the thing you want, and use that intead. Also, please have a look at the solution by @celtschk, which is a lot cleaner and simpler.
EDIT
As @celtschk pointed out in the comments, escaping is not really necessary if we add extra string quatation marks. The mechanism to distinguish strings from stringified expressions (to be converted back to expressions during import) is still needed however.
"
programming - What does the construct f[x_] := f[x] = ... mean?,"
It is a simple way to implement Memoization. The trick is that if you define a function as
f[x_]:=f[x]=ExpensiveFunctionOf[x]

then when you for the first time call e.g. f[3], it will evaluate as
f[3]=ExpensiveFunctionOf[3]

which will evalulate the expensive function, and assign the result to f[3] (in addition to giving it back, of course). So if e.g. ExpensiveFunctionOf[3] evaluates to 7, it will assign f[3]=7.
The next time you call f[3], it will find that newly created definition of f[3] and use that in preference to the general rule. This means it will return the value 7 without calculating ExpensiveFunctionOf[3] a second time.
"
evaluation - How to pass a symbol name to a function with any of the Hold attributes?,"
How about this:
list = {1, 2, 3};
ToExpression[""list"", InputForm, Hold] /. Hold[v_] :> AppendTo[v, 3]


{1, 2, 3, 3}

list


{1, 2, 3, 3}

"
"graphics - Labeling a bar chart, changing how rotated labels are centered","
By default the Axis position that you're using centers the label under the bar along the axis. For long text that's rotated at a slant, it generally looks bad.  (It works fine for horizontal and vertical text, however.)

Here's one approach, using a different second argument for Placed:
Module[{
    labels = {""Learning focused"", ""Positively oriented"", ""Continuous"", 
              ""Timely"", ""Clear criteria"", ""Flexible"", ""Suited to student level""}, 
    data = {8, 6, 4, 5, 5, 9, 9}
    }, 
    BarChart[data, 
        ChartLabels -> Placed[
            labels, 
            {{0.5, 0}, {0.9, 1}}, 
            Rotate[#, (2/7) Pi] &
            ], 
        PlotRange -> {Automatic, {0, 10}}, Ticks -> {None, Range[0, 10, 2]}, 
        ImagePadding -> {{20, 0}, {95, 0}}
    ]
]


The first part of the argument, {0.5, 0}, says to place the label halfway across the bar, at the bottom.
The second part of the argument, {0.9, 1}, says what part of the label at the first part. In this case it's near, but not quite at, the right-top corner.  
It's not exactly at the corner, because I think it looks better if the top of the ""ink"" is centered below the bars, and that won't be the actual corner unless your label ends with "">"" or something similar.

Here's a second approach, using a different third argument of Placed:
Module[{
    labels = {""Learning focused"", ""Positively oriented"", ""Continuous"", 
              ""Timely"", ""Clear criteria"", ""Flexible"", ""Suited to student level""}, 
    data = {8, 6, 4, 5, 5, 9, 9}
    }, 
    BarChart[data, 
        ChartLabels -> Placed[
            labels, 
            Axis, 
            Block[{text = Rotate[#, (2/7) Pi]}, 
                Row[{text, Invisible[text]}, 
                    ""\[NegativeMediumSpace]""]
            ]&
            ], 
        PlotRange -> {Automatic, {0, 10}}, Ticks -> {None, Range[0, 10, 2]}, 
        ImagePadding -> {{20, 0}, {95, 0}}
    ]
]

This uses the normal axes positioning, but for each label, it creates an object that has the label and an invisible copy of the label side-by-side so that the center of the object is the end of the visible label. (I used a negative space between the objects, because again I think it looks better.) The nice thing about this approach is that the basic idea can be used for labels for ticks on axes that don't otherwise allow specific placements.

"
"graphics - ErrorBars with BarChart, ChartLabels are not working?","
In the original code, chartData is of the form {{value1 -> error1}, {value2 -> error2}, ... }, but it should be of the form {value1 -> error1, value2 -> error2, ... }. To get the right labels you could do something like (note the missing brackets in chartData)
chartData = 
 MapThread[#1 -> #2 &, {RandomReal[1, 10], RandomReal[0.1, 10]}];

BarChart[chartData, 
 ChartElementFunction -> errorBar[""Rectangle""], 
 ChartLabels -> Placed[labels, Axis, Rotate[#, Pi/2] &]]


"
import - How do you skip missing data values in a data file?,"
Missing data is encoded in Mathematica using the inert function Missing. It can take  several forms (Missing[""reason""]):

Typical examples of ""reason"" include ""NotApplicable"", ""Unknown"",
  ""NotAvailable"", ""Nonexistent"", ""Indeterminate"", ""Variable"",
  ""Disputed"", or ""TooLarge""

You can filter your data using DeleteCases:
DeleteCases[data, _Missing]

Lists with empty fields can be cleaned as follows:
DeleteCases[{1, 2, , 3, 4}, Null]

(*
==> {1, 2, 3, 4}
*)

"
groebner bases - Equation solving with GroebnerBasis,"
""[O]nly a little""?? You just went from a system of 6 equations in 6 variables to a 20 x 20 system. I have to wonder what a big enlargement might be.
You might try
soln = NSolve[polys]

But that also could well hang.
A better possibility in terms of likelihood of completing might be to use local methods such as FindRoot, provided you have some idea of where the relevant (for your purposes) solutions might live.
Followup:
NSolve gave a result after a couple of hours.
In[13]:= Timing[soln = NSolve[polys];]

NSolve::sfail: Subsystem could not be solved for 
    152533 g[1][1, 1]   14327 g[1][1, 2]   171802 g[1][2, 1]
    ----------------- + ---------------- + ----------------- - 
         122535              17505              122535
     113492 g[1][2, 2]   24775 g[1][3, 1]   1475 g[1][3, 2]
     ----------------- + ---------------- - --------------- + <<11>> + 
          122535              24507              1167
     38732 h[2][1, 2]   22301 h[2][2, 1]   145171 h[2][2, 2]
     ---------------- - ---------------- + ----------------- at value 
          24507              17505              122535
                                        17        -20
    6.6504175107872416688377351747276 10   + 0. 10    I
    . The likely cause is failure to detect zero due to low precision. The
     likely effect is the loss of one or more solutions. Increasing
     WorkingPrecision might prevent some solutions from being lost.

Out[13]= {7651.893734, Null}

In[14]:= soln//Length

Out[14]= 110

I believe some of the solutions are numeric gibberish. Others seem plausible though I've not tested them all. Here is one that appears to be reasonable.
{g[1][2, 1] -> 0.877177885546412, g[1][2, 2] -> -0.731787453222285, 
 g[2][2, 1] -> 1.514048096489015, g[2][2, 2] -> 4.056151212079698, 
 g[1][3, 1] -> -0.2520687271834896, g[2][3, 1] -> 0.19110251804564718, 
 g[1][3, 2] -> 5.450124929865966, g[2][3, 2] -> 5.157856942595859, 
 g[1][1, 1] -> -0.3067458899627449, g[2][1, 1] -> 0.11152252700132087, 
 g[1][1, 2] -> 1.4198327350185431, g[2][1, 2] -> 0.9644105684773703, 
 h[1][2, 1] -> -0.06568699865868881, h[1][2, 2] -> 1.1040449897211426, 
 h[2][2, 1] -> 0.016672054541611605, h[2][2, 2] -> 0.94417450922692, 
 h[1][1, 1] -> 0.877177885546412, h[1][1, 2] -> -0.731787453222285, 
 h[2][1, 1] -> 1.514048096489015, h[2][1, 2] -> 4.056151212079698}

Residuals are on the order of 10^(-14) and smaller.
"
linear algebra - Obtaining a thin/compact SVD,"
You can find the full svd, then use the number of nonzero singular values to recover the thin svd.
thinSVD[mat_] := Module[
  {u, w, v, wprime, len},
  {u, w, v} = SingularValueDecomposition[mat];
  wprime = DeleteCases[w, {_?(# == 0 &) ..}];
  len = Length[wprime];
  wprime = wprime[[All, 1 ;; len]];
  {u[[All, 1 ;; len]], wprime, v[[All, 1 ;; len]]}
  ]

Here is a fairly standard example.
In[66]:= m = N[{{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}];
{ut, wt, vt} = thinSVD[m]
Chop[ut.wt.Transpose[vt] - m](*want zeros*)

Out[67]= {{{-0.214837, -0.887231}, {-0.520587, -0.249644}, {-0.826338,
    0.387943}}, {{16.8481, 0.}, {0., 1.06837}}, {{-0.479671, 
   0.776691}, {-0.572368, 0.0756865}, {-0.665064, -0.625318}}}

Out[68]= {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}}

"
workbench - MUnit creating a hierarchy of TestSuites,"
Here are two ideas: 

In the documentation there is an example of how to write a test suite, a collection of tests.
Try to load the MUnit package (I think it is somewhere in Workbench) from Mathematica. Then define
runTests[] := Map[TestRun, FileNames[""path/to/testFiles/*.mt""]]


and call 
runTests[]

"
front end - How to copy hyperlink addresses using the keyboard,"
What will trigger it
select a hyperlink and use a shortcut, in case of wrong selection you will get Beep[]
What will happen
If[
   MatchQ[#, {_}], 
   CopyToClipboard[First[#]], 
   Beep[]
] &[
     Cases[
        CurrentValue[""SelectionData""], 
        _[ButtonData, {x_, _}] :> x, 
        Infinity
     ]
]

How to implement it

With joker.m from the Shortcuts` package
Analogous steps like in Wrapping highlighted text in chosen brackets. Is there no keyboard command for this?
The second solution is your initial approach, editing KeyEventTranslations.tr
At the moment of loading those files the FrontEnd doesn't know @:>_ and all other fancy syntactic features. So we have to put there crude expressions:


 Item[  
    KeyEvent[""r"", Modifiers -> {Control}],
    KernelExecute[ 
        Function[
            If[
                MatchQ[Slot[1], List[Blank[]]], 
                CopyToClipboard[First[Slot[1]]], 
                Beep[]
            ]
        ][
        Cases[
            CurrentValue[""SelectionData""], 
            RuleDelayed[
               Blank[][ButtonData, List[Pattern[x, Blank[]], Blank[]]],  
               x
            ],
            Infinity
        ]]      
    ], MenuEvaluator -> Automatic
],

This works well.

Short 2.
Or just put there
 KernelExecute[ Needs[""MyShortcuts`""]; MyShortcuts`CopyAdress[] ]

after saving MyShortcuts.m with this definition somewhere on $Path.
Shortcuts` package uses this approach.

"
evaluation - How to inject an evaluated expression into a held expression?,"
Here are a couple of alternatives to Trott-Strzebonski in @R.M's answer:
Hold[{3,4,5|6}] /.
  Verbatim[Alternatives][x__] :> RuleCondition@RandomChoice@List@x


Hold[{3, 4, 5}]

Hold[{3,4,5|6}] /.
  Verbatim[Alternatives][x__] :> Block[{}, RandomChoice@List@x /; True]


Hold[{3, 4, 6}]

They operate on the same principle as Trott-Strzebonski (i.e. RuleCondition), but express the effect in different ways.
"
"performance tuning - Working with large data, pass-by-reference, compiled functions","
As Leonid already commented, your code should not be especially slow. However one reason why your code may be slow is that you use Part to extract values, do some calculations and then insert the result. I would try using a wholesale approach and calculate all nodes at the same time by doing, e.g. (may need tweaking since I don't know the structure of your objects),
ti = 3.0*bulkMod*dilitation/volState*refMagState;
td = 15.0*shearMod/volState*devElongState;
forceState = ti + td;

internalForce += Total /@ forceState*volumes[[families]];
internalForce[[families]] -= forceState*volumes;

This way you do everything at once. I can try and help some more if you post examples of the data structures, especially what families and volumes return.
"
programming - How to efficiently Append a result of an operation on each element of a list to itself,"
My proposition:
list = RandomReal[1., {100000, 3}];

newlist = Transpose[{Sequence @@ Transpose[list],
    list[[All, 2]] list[[All, 3]]}];

A little benchmark using other answers:
In[51]:= list = RandomReal[1., {1000000, 3}];

In[52]:= newlist = 
   Transpose[{Sequence @@ Transpose[list], 
     list[[All, 2]] list[[All, 3]]}]; // AbsoluteTiming

Out[52]= {0.056405, Null}

In[53]:= newlist2 = {##, Times[##2]} & @@@ list; // AbsoluteTiming

Out[53]= {0.970229, Null}

In[54]:= newlist3 = 
   Append[#, #[[2]] #[[3]]] & /@ list; // AbsoluteTiming

Out[54]= {0.454465, Null}

In[55]:= insertHereThis[list_List, here_Integer, this_] := 
 Insert[#, this[#], here] & /@ list

In[56]:= newlist4 = 
   insertHereThis[list, 2, #[[2]] #[[3]] &]; // AbsoluteTiming

Out[56]= {0.438192, Null}

In[57]:= func = Join[#, Partition[#[[All, -1]] #[[All, -2]], 1], 2] &;

In[58]:= newlist5 = func[list]; // AbsoluteTiming

Out[58]= {0.053084, Null}

In[60]:= newlist6 = 
   ArrayFlatten[{{#, Transpose[{times[#, 2, 3]}]}}] &[
    list]; // AbsoluteTiming

Out[60]= {0.022477, Null}

EDIT: Added new answer (Mr.Wizard's), which now is the fastest in my machine.
EDIT2: Added Leonid's compiled version, and he is right, it is twice faster!
"
"programming - How to match two sets of data over 1 or more identifier, of unequal length?","
I don't know sql and the formats for set1 and set2 are somewhat unclear to me so I could be completely missing the point but maybe you could do something like this for the Inner Join query
intersect[set1_, set2_] := Module[{expCodes},
  expCodes = Intersection[set2[[All, 1]], set1[[All,1]]];
  Reap[Sow[#2, #1] & @@@ set1;
     Sow[#2, #1] & @@@ set2, expCodes, Flatten[{#1, #2}, 1] &][[2, 
     All, 1]]]

and this for the Left Join query
join[set1_, set2_] := Module[{expCodes},
  expCodes = set1[[All, 1]];
  PadRight[Reap[Sow[#2, #1] & @@@ set1;
     Sow[#2, #1] & @@@ set2, expCodes, Flatten[{#1, #2}, 1] &][[2, 
     All, 1]],
   Automatic, Null]]

Example data:
set1 = Table[{i, RandomInteger[10, 3]}, {i, 10}]
set2 = Table[{i, ""Type "" <> ToString[i]}, {i, RandomSample[Range[10], 3]}]


{{1, {9, 0, 4}}, {2, {3, 9, 4}}, {3, {9, 2, 5}}, {4, {1, 10, 5}}, 
   {5, {6, 4, 6}}, {6, {2, 1, 4}}, {7, {6, 5, 6}}, {8, {7, 3, 1}}, 
   {9, {9, 4, 9}}, {10, {6, 6, 2}}}

{{5, ""Type 5""}, {3, ""Type 3""}, {7, ""Type 7""}}


Then intersect gives
intersect[set1, set2]


{{3, {9, 2, 5}, ""Type 3""}, {5, {6, 4, 6}, ""Type 5""}, {7, {6, 5, 6}, ""Type 7""}}


and join
join[set1, set2]


{{1, {9, 0, 4}, Null}, {2, {3, 9, 4}, Null}, {3, {9, 2, 5}, ""Type 3""}, 
   {4, {1, 10, 5}, Null}, {5, {6, 4, 6}, ""Type 5""}, {6, {2, 1, 4}, Null}, 
   {7, {6, 5, 6}, ""Type 7""}, {8, {7, 3, 1}, Null}, {9, {9, 4, 9}, Null}, 
   {10, {6, 6, 2}, Null}}


This should be expandable to selection on multiple columns by adjusting the definition of expCodes in the definitions of intersect and join.
"
replacement - How to implement a regular grammar?,"
The following code defines the function randomSentence.  It uses recursive descent to generate a sentence from a grammar expresssed as rules:
ClearAll[randomSentence, randomCount]
randomCount[] := RandomVariate[GeometricDistribution[0.5]]

SetAttributes[randomSentence, HoldAll]
randomSentence[rules_, expr_] :=
  Module[{generate}
  , SetAttributes[generate, HoldAll]
  ; Replace[#[[1, 1]] :> #& /@ GatherBy[rules, First], (_ :> r_) :> r, {3}] /.
      (a_ :> {b___}) :> (generate[a] := generate[Alternatives[b]])
  ; generate[a_Alternatives] :=
      generate @@ RandomChoice[List @@ Hold /@ Unevaluated @ a]
  ; generate[(r:(Repeated|RepeatedNull))[e_]] :=
      Hold @@ Evaluate @ ConstantArray[0, randomCount[] + Boole[r===Repeated]] /.
        0 :> generate[e] /.
        Hold -> Composition[generate, List]
  ; generate[l_List] := StringJoin @@ generate /@ Unevaluated @ l
  ; generate[x:_[___]] := generate /@ Unevaluated @ x
  ; generate[x_] := x
  ; generate[expr]
  ]

Here is the species grammar, adapted (sic) to the form required by randomSentence:
ClearAll[f, g, h, i]
f[x___] := x <> ""er"";
g[x___] := x <> ""ed"";
h[x___] := x <> ""ing"";
i[x___] := x <> ""y"";

$rules =
  { ""Species"" :> ""Animal"" | ""Plant""
  , ""Species"" :> f@""Action""
  , ""Species"" :> {""Color"" | ""Type"", ""-"", ""Species""}

  , ""Attribute"" :> ""Type"" | ""Color""
  , ""Attribute"" :> {""Animal"", ""-"", f@""Action""}
  , ""Attribute"" :> {""Color"" | ""Type"", ""-"", g@""Part""}
  , ""Attribute"" :> i@""Plant""
  , ""Attribute"" :> {""Plant"" | ""Animal"", ""-"", h@""Action""}

  , ""Animal"" :> ""warble""|""shrew""|""whale""|""caiman""|""babuin""|""bat""|""bug""
  , ""Plant"" :> ""bush""|""moss""|""fern""|""grass""|""squash""|""seed""
  , ""Part"" :> ""back""|""head""|""finger""|""tail""|""ear""|""wing""|""thorn""
  , ""Color"" :> ""black""|""red""|""white""|""blue""|""silver""|""crimson""|""dark""
  , ""Type"" :>  ""long""|""cross""|""sharp""|""thick""|""heavy""|""fluffy""|""big""|""wild""
  , ""Action"" :> ""jump""|""kill""|""stalk""|""sting""|""climb""|""crawl""|""eat""
  };

Here is a sample use of the function (note that there is no need to explicitly specify the terminals, non-terminals and functions):
Table[randomSentence[$rules, {{""Attribute"", "" ""}..., ""Species""}], {10}] // Column


bug
  bat-climbing moss
  red-heavy-cross-dark-thick-stalker
  babuin
  squashy heavy-killer
  killer
  seed
  squashy white-fingered heavy-red-whale
  climber
  squashy thick-winged stinger

How It Works
The trickiest part of this problem is to make sure that none of the function expressions in the grammar are evaluated until they are needed -- and even then they may require some preprocessing of their arguments.  To make this possible, randomSentence must not evaluate the rules or sentence form passed to it:
SetAttributes[randomSentence, HoldAll]
randomSentence[rules_, expr_] :=

We are going to use a helper function called generate.  Again, it must not evaluate any expressions prematurely:
  Module[{generate}
  , SetAttributes[generate, HoldAll]

generate will be able to convert any grammar expression into a string.  There are many types of grammar expressions.  First, we will teach generate how to deal with each of the non-terminal symbols.  We group all of the rules into lists, one for each nonterminal.  Then we convert each of those groups into definitions for generate as if
they had been specified using Alternatives in the original grammar:
  ; Replace[#[[1, 1]] :> #& /@ GatherBy[rules, First], (_ :> r_) :> r, {3}] /.
      (a_ :> {b___}) :> (generate[a] := generate[Alternatives[b]])

Alternatives expressions are processed by selecting a random alternative from the list and then applying generate to that choice:
  ; generate[a_Alternatives] :=
      generate @@ RandomChoice[List @@ Hold /@ Unevaluated @ a]

Repeated expressions are processed by generating the repeated expression a random number of times.  RepeatedNull allows zero occurrences whereas Repeated will have at least one.  The tortured logic in this operation is due to the need to make sure that each repetition is not evaluated before it has been duly interpreted as a grammar expression.  Also, it is important to ensure that each repetition is generated independently:
  ; generate[(r:(Repeated|RepeatedNull))[e_]] :=
      Hold @@ Evaluate @ ConstantArray[0, randomCount[] + Boole[r===Repeated]] /.
        0 :> generate[e] /.
        Hold -> Composition[generate, List]

Each grammar expression in a list is evaluated independently and then the results are joined together:
  ; generate[l_List] := StringJoin @@ generate /@ Unevaluated @ l

Any function call must be made after the arguments have been individually generated:
  ; generate[x:_[___]] := generate /@ Unevaluated @ x

Anything else is passed unchanged (presumably strings):
  ; generate[x_] := x

Now that generate is defined, all that remains is to use it:
  ; generate[expr]
  ]

randomSentence uses the helper function randomCount to generate a random repetition counts.  For this example, we are using a geometric distribution where the probability of each successive count is half that of its predecessor.  Adjust this distribution to suit your taste.
randomCount[] := RandomVariate[GeometricDistribution[0.5]]

"
front end - Is there a way to require confirmation for execution of certain cells?,"
Perhaps there are better ways, but one I am aware of is by using CellEvaluationFunction option for a given cell. Here is code to generate some example cell with the behavior similar to what you presumably desire:
CellPrint[
   Cell[BoxData[RowBox[{""100"", ""!""}]], ""Input"", 
     CellEvaluationFunction -> 
       (Module[{res = ChoiceDialog[""Evaluate this cell?""]}, 
          If[res, ToExpression[#]]] &)
   ]
]

A very informative account on CellEvaluationFunction, and the one I originally learned about it from, is this answer by @WReach.
EDIT
Here is a more elaborate version, which would also highlight the cell in question:
makeCell[] :=
 With[{tag = ToString[Unique[]] <> DateString[]},
    CellPrint[
      Cell[BoxData[RowBox[{""100"", ""!""}]], ""Input"", CellTags -> tag,
        CellEvaluationFunction ->
          ( 
             Module[{result = Null, thiscell, oldbackgr},
               NotebookLocate[tag];
               thiscell = NotebookSelection[];
               oldbackgr =  Background /. Options[thiscell] /. Background -> None;                   
               SetOptions[thiscell, Background -> LightGreen];
               If[ChoiceDialog[""Evaluate this cell?""], result = ToExpression[#]];
               SetOptions[thiscell, Background -> oldbackgr];
               SelectionMove[EvaluationNotebook[], After, Cell];
               result
             ] &)
      ]]]

You can execute makeCell[] to see what this does.
"
random - Going Beyond Pseudorandom Numbers,"
You cannot, by principle, get true randomness through a deterministic algorithm, no matter how sophisticated. If you need true random numbers, you'll have to collect some physical randomness. I don't know about an OS-independent way to do that, but on Linux, the pseudo-file /dev/random collects entropy from various sources.
Of course, unless you are implementing cryptography, you'll most likely not really need true randomness (and even there you generally only need it to seed the cryptographically secure pseudo-random number generator, unless you are generating an one-time pad).
"
list manipulation - Clustering of space-time data,"
Finding the cluster centers is the hard part.  There are zillions of ways to do this, such as standardizing $(x,y,t)$ and applying some (almost any) kind of cluster analysis.  But these data are special: the eye movement has a measurable speed.  The gaze is resting if and only if the speed is low.  The threshold for ""low"" is physically determined (but can also be found in a histogram of the speeds: there will be a break just above 0).  That yields the very simple solution: fixations occur at the points of low speed. 
It's a good idea to smooth the original data slightly before estimating the speeds:
data = Transpose[Import[""f:/temp/gazeSeq_1.dat""]];
smooth = MovingAverage[#, 5] & /@ data;
delta = Differences /@ smooth;
speeds = Prepend[Norm[Most[#]]/Last[#] & /@ Transpose[delta], 0];
Histogram[Log[# + 0.002] & /@ speeds]


The bimodality is clear.  The gap is around $\exp(-6)-0.002\approx 0.0005$.  Whence
w = Append[smooth, speeds];
ListPlot[#[[1 ;; 2]] & /@ Select[Transpose[w], Last[#] < 0.0005 &], 
 PlotStyle -> PointSize[0.015]]


There are the gaze fixations.  having found them, the clustering is (almost) trivial to do (because each fixation now exists as a contiguous sequence of observations in the original data, from which it is readily split off: this respects the time component as well as the spatial ones).  This method works beautifully for all seven of the sample datasets.
One advantage of this approach is that it can detect clusters of very short gaze fixations, even those of just two points in the dataset.  These would likely go unnoticed by most general-purpose or ad hoc solutions.  Of course you can screen them out later if they are of little interest.
"
parallelization - Filling global arrays in parallel calculations,"
Please see the answer I gave here.

Parallelization works well and reliable only if you use constructs with no side effects.    This is an essential point when using Mathematica's parallel computing tools.  If you are not sure what a side effect is, please read about it.
This explains why For won't be auto-parallelized.

The reason why the function b does not seem to change f is that f will be changed only on the parallel kernels, but the results won't be sent back to the main kernel.  It is not even clear which f should be sent back.  The one on kernel 1 or the one on kernel 2?  (Obviously you want them merged in a special way, but there is no way for the computer to guess how.)  I discuss this issue as well here.

You can use SetSharedVariable[f] to force all accessed to f to be synchronized through the main kernel.  This will give you the desired result, but it will hurt performance because of the constant communication between the main kernel and subkernels.  It is also a potential source of errors because two different subkernels might change the same value in f.
I recommend you never change any ""global"" variables from parallel calculations.  This is always a potential source of mistakes and when done properly, it will reduce performance.  Instead formulate your problem without using side effects.  Your specific example would look like ParallelTable[k+1, {k, num}].  Think about if you can do this with your actual problem as well.
"
graphics - Generating graphs interactively (GUI),"
You could do create a simple graph editing tool to create a graph from scratch by doing something like this. To add edges you just click and drag.
DynamicModule[{pt1, pt2, ind1, ind2, pts = {}, edges = {}, cedge = {}},
 Manipulate[
  EventHandler[
   Dynamic@Graphics[
     {Line[pts[[#]] & /@ edges],
      cedge, {Red, PointSize[Medium], Point[pts]}}, PlotRange -> 1],
   {""MouseDown"" :>
     (pt2 = pt1 = Round[MousePosition[""Graphics""], 0.1];
      ind1 = PadRight[Flatten[Position[pts, pt1]], 1, Length[pts] + 1][[1]]),
    ""MouseDragged"" :>
     (pt2 = Round[MousePosition[""Graphics""], 0.1]; 
      cedge = {Gray, Dashed, Line[{pt1, pt2}]}),
    ""MouseUp"" :>
     (pt2 = Round[MousePosition[""Graphics""], 0.1];
      If[ind1 == Length[pts] + 1, AppendTo[pts, pt1]];
      ind2 = PadRight[Flatten[Position[pts, pt2]], 1, Length[pts] + 1][[1]];
      If[ind2 == Length[pts] + 1, AppendTo[pts, pt2]];
      If[ind1 =!= ind2, AppendTo[edges, {ind1, ind2}]];
      cedge = {})}],

  Row[{Button[""Paste"",
     Print[Graph[Range[Length[pts]], edges, VertexCoordinates -> pts]]],
   Button[""Clear"", pts = {}; edges = {}]}]]]

Screenshot:

Pasted graph:

"
programming - Cycles of length N in a graph,"
With the following obvious replacements for the two graphs: PetersenGraph[5, 2] --> yourgraph, and CycleGraph[5] --->CycleGraph[n] for general n where 
  yourgraph=AdjacencyGraph[yourAdjacencyMatrix]

You can use the first example from the docs on SubGraph section Applications: 
  {g, h} = {PetersenGraph[5, 2], CycleGraph[5]};
  Grid[{{g, h}}]


Select the subgraphs isomorphic to CycleGraph[5]:
  s = Subsets[Range[VertexCount[g]], {VertexCount[h]}];
  Select[Subgraph[g, #] & /@ s, IsomorphicGraphQ[#, h] &];

and view
  Grid[Partition[
  HighlightGraph[g, #] & /@ 
  Select[Subgraph[g, #] & /@ s, IsomorphicGraphQ[#, h] &], {5}]]


EDIT: A function to select cyclic subgraphs with k vertices
 ClearAll[cyclicSubgraphs];
 cyclicSubgraphs[grph_Graph, k_Integer] := 
 Select[Subgraph[grph, #] & /@ Subsets[Range[VertexCount[grph]], {k}], 
 IsomorphicGraphQ[#, CycleGraph[k]] &]

Example:
Row[HighlightGraph[SetProperty[GraphData[{""Antiprism"", 6}], {VertexLabels -> ""Name"", 
 VertexSize -> Medium, ImagePadding -> 20, ImageSize -> 300}], #] & /@ 
 cyclicSubgraphs[GraphData[{""Antiprism"", 6}], 8])]


"
polynomials - Gröbner basis on a particular set of equations,"
Your question cannot realistically be answered. One almost never knows what specifically comprises such an impediment.
Here is a Groebner basis for your system of polynomials, computed for degree reverse lexicographic order. It takes some time to do this. Not sure if it will run in reasonable time directly; I used a numeric approximation and rationalized (have not validated the result but I'm fairly sure it is correct).
gb2 = {a[15], (-3*a[12])/2 + a[8]*a[12] + a[16]/2 + (3*a[20])/2, a[6]/2 + a[6]*a[8] - (3*a[10])/2 - a[19]/2, 
 (-17*a[6])/18 - (35*a[7])/9 + (23*a[10])/6 + a[8]*a[10] + (29*a[19])/6 - (61*a[8]*a[19])/9, 
 (17*a[12])/18 + (35*a[13])/9 + (35*a[16])/18 - (61*a[8]*a[16])/9 - (29*a[20])/6 + a[8]*a[20], 
 -a[12]/3 + (5*a[13])/6 + a[8]*a[13] + (7*a[16])/6 - (8*a[8]*a[16])/3 - a[20]/2, 
 a[6]/3 - (11*a[7])/6 + a[7]*a[8] + a[10]/2 + (3*a[19])/2 - (8*a[8]*a[19])/3, -(a[6]*a[12]) + a[10]*a[12] + a[12]*a[19], 
 (52*a[12])/21 - a[3]*a[12] + a[9]*a[12] + (125*a[13])/21 + (52*a[16])/21 - (208*a[8]*a[16])/21 + a[12]*a[18] - (52*a[20])/7, 
 -(a[6]*a[12]) + a[6]*a[16] + a[12]*a[19], -(a[12]*a[19]) + a[6]*a[20], (52*a[6])/21 - a[3]*a[6] + (125*a[7])/21 + a[6]*a[9] - 
  (52*a[10])/7 + a[6]*a[18] - (52*a[19])/7 + (208*a[8]*a[19])/21, -(a[7]*a[12]) + a[6]*a[13], 
 (24*a[6])/7 - a[3]*a[6] + (115*a[7])/28 + a[6]*a[9] - (183*a[10])/28 - (211*a[19])/28 + a[3]*a[19] + (101*a[8]*a[19])/14, 
 (-202*a[6])/63 - (1805*a[7])/252 - a[6]*a[9] + (787*a[10])/84 + a[3]*a[10] + (871*a[19])/84 - (1679*a[8]*a[19])/126, 
 (20*a[12])/21 - a[9]*a[12] - (155*a[13])/84 - (235*a[16])/84 + a[3]*a[16] + (113*a[8]*a[16])/42 + (25*a[20])/28, 
 (-46*a[12])/63 - a[3]*a[12] + a[9]*a[12] - (305*a[13])/252 - (121*a[16])/252 + (431*a[8]*a[16])/126 + (163*a[20])/84 + 
  a[3]*a[20], (-47*a[12])/42 - a[4]*a[12] - (199*a[13])/42 + a[3]*a[13] - (34*a[16])/21 + (136*a[8]*a[16])/21 + (34*a[20])/7, 
 (-47*a[6])/42 - a[4]*a[6] - (199*a[7])/42 + a[3]*a[7] + (34*a[10])/7 + (34*a[19])/7 - (136*a[8]*a[19])/21, 
 (22*a[6]^2)/105 + (a[6]*a[7])/3 - (19*a[6]*a[10])/35 - (92*a[6]*a[19])/105 + a[10]*a[19] + a[19]^2/3, 
 (a[6]*a[12])/3 - (a[7]*a[12])/3 - a[12]*a[19] + (a[16]*a[19])/3 + a[19]*a[20], 
 (121*a[6])/84 - (a[3]*a[6])/2 + (a[4]*a[6])/2 + (253*a[7])/168 - (137*a[10])/56 - (137*a[19])/56 + (169*a[8]*a[19])/84 + 
  a[9]*a[19], (377*a[6])/84 - (a[3]*a[6])/2 - (a[4]*a[6])/2 + (1277*a[7])/168 + a[6]*a[9] - (649*a[10])/56 - (649*a[19])/56 + 
  (1193*a[8]*a[19])/84 + a[18]*a[19], (a[6]*a[12])/2 - (a[7]*a[12])/2 - a[12]*a[19] + a[13]*a[19], 
 (23*a[6]^2)/70 - (a[6]*a[7])/2 + (6*a[6]*a[10])/35 - (29*a[6]*a[19])/35 + a[7]*a[19], 
 (26627*a[6])/8064 - (a[3]*a[6])/2 - (a[4]*a[6])/2 + (73307*a[7])/16128 + a[6]*a[9] - (39499*a[10])/5376 - 
  (39499*a[19])/5376 + a[4]*a[19] + (65243*a[8]*a[19])/8064, (227*a[6]^2)/315 - (4*a[6]*a[7])/9 - (134*a[6]*a[10])/105 + 
  a[10]^2 - (52*a[6]*a[19])/315 - a[19]^2/9, (-2*a[6]*a[12])/3 - (a[7]*a[12])/3 + a[10]*a[16] + a[12]*a[19] + (a[16]*a[19])/3, 
 (-4*a[6]*a[12])/9 + (4*a[7]*a[12])/9 - (a[16]*a[19])/9 + a[10]*a[20], (-713*a[6])/252 + (a[3]*a[6])/2 - (a[4]*a[6])/2 - 
  (2789*a[7])/504 - a[6]*a[9] + (1321*a[10])/168 + a[9]*a[10] + (1321*a[19])/168 - (2537*a[8]*a[19])/252, 
 (263*a[6])/252 - (a[3]*a[6])/2 + (a[4]*a[6])/2 + (1619*a[7])/504 - (631*a[10])/168 + a[10]*a[18] - (631*a[19])/168 + 
  (1367*a[8]*a[19])/252, -(a[6]*a[12])/2 - (a[7]*a[12])/2 + a[10]*a[13] + a[12]*a[19], 
 (47*a[6]^2)/70 - (a[6]*a[7])/2 - (41*a[6]*a[10])/35 + a[7]*a[10] - (6*a[6]*a[19])/35, 
 (-86531*a[6])/24192 + (a[3]*a[6])/2 - (a[4]*a[6])/2 - (329051*a[7])/48384 - a[6]*a[9] + (159307*a[10])/16128 + a[4]*a[10] + 
  (159307*a[19])/16128 - (304859*a[8]*a[19])/24192, (22*a[12]^2)/105 + (a[12]*a[13])/3 - (92*a[12]*a[16])/105 + a[16]^2/3 - 
  (19*a[12]*a[20])/35 + a[16]*a[20], (169*a[12])/84 + (a[3]*a[12])/2 - (a[4]*a[12])/2 - a[9]*a[12] + (277*a[13])/168 + 
  (23*a[16])/168 - (361*a[8]*a[16])/84 + a[9]*a[16] - (233*a[20])/56, (121*a[12])/84 - (a[3]*a[12])/2 + (a[4]*a[12])/2 + 
  (253*a[13])/168 - (73*a[16])/168 - (169*a[8]*a[16])/84 + a[16]*a[18] - (137*a[20])/56, 
 (23*a[12]^2)/70 - (a[12]*a[13])/2 - (29*a[12]*a[16])/35 + a[13]*a[16] + (6*a[12]*a[20])/35, 
 -(a[6]*a[12])/2 - (a[7]*a[12])/2 + a[7]*a[16] + a[12]*a[19], (6659*a[12])/8064 + (a[3]*a[12])/2 - (a[4]*a[12])/2 - 
  a[9]*a[12] - (22693*a[13])/16128 - (27947*a[16])/16128 + a[4]*a[16] + (14629*a[8]*a[16])/8064 + (437*a[20])/5376, 
 (227*a[12]^2)/315 - (4*a[12]*a[13])/9 - (52*a[12]*a[16])/315 - a[16]^2/9 - (134*a[12]*a[20])/105 + a[20]^2, 
 (263*a[12])/252 - (a[3]*a[12])/2 + (a[4]*a[12])/2 + (1619*a[13])/504 + (841*a[16])/504 - (1367*a[8]*a[16])/252 - 
  (631*a[20])/168 + a[9]*a[20], (-89*a[12])/252 - (a[3]*a[12])/2 - (a[4]*a[12])/2 + a[9]*a[12] + (211*a[13])/504 + 
  (137*a[16])/504 + (41*a[8]*a[16])/252 + (73*a[20])/168 + a[18]*a[20], 
 (47*a[12]^2)/70 - (a[12]*a[13])/2 - (6*a[12]*a[16])/35 - (41*a[12]*a[20])/35 + a[13]*a[20], 
 (a[6]*a[12])/2 - (a[7]*a[12])/2 - a[12]*a[19] + a[7]*a[20], (-26627*a[12])/24192 - (a[3]*a[12])/2 - (a[4]*a[12])/2 + 
  a[9]*a[12] - (41051*a[13])/48384 - (11989*a[16])/48384 + (65243*a[8]*a[16])/24192 + (39499*a[20])/16128 + a[4]*a[20], 
 (2*a[12])/7 + (a[3]*a[12])/2 - (a[4]*a[12])/2 - a[9]*a[12] + a[13]/14 + a[9]*a[13] + (2*a[16])/7 - (8*a[8]*a[16])/7 - 
  (6*a[20])/7, (-26*a[6])/21 + (a[3]*a[6])/2 - (a[4]*a[6])/2 - (125*a[7])/42 - a[6]*a[9] + a[7]*a[9] + (26*a[10])/7 + 
  (26*a[19])/7 - (104*a[8]*a[19])/21, 1733/1602 - (641*a[3])/534 + (95*a[3]^2)/801 + (3775*a[4])/801 - (440*a[3]*a[4])/267 + 
  (94481*a[6]^2)/100926 - (7325*a[6]*a[7])/14418 - (182*a[8])/89 + (182*a[8]^2)/89 + (67*a[9])/178 + (424*a[3]*a[9])/801 - 
  (803*a[8]*a[9])/267 + a[9]^2 - (7201*a[6]*a[10])/16821 + (94481*a[12]^2)/100926 - (7325*a[12]*a[13])/14418 - 
  (72878*a[12]*a[16])/50463 + (7325*a[16]^2)/7209 - (1405*a[18])/534 + (424*a[3]*a[18])/801 + (803*a[8]*a[18])/267 - 
  (346*a[9]*a[18])/267 + a[18]^2 - (72878*a[6]*a[19])/50463 + (7325*a[19]^2)/7209 - (7201*a[12]*a[20])/16821, 
 (26*a[12])/21 - (a[3]*a[12])/2 - (a[4]*a[12])/2 + a[9]*a[12] + (125*a[13])/42 + (26*a[16])/21 - (104*a[8]*a[16])/21 + 
  a[13]*a[18] - (26*a[20])/7, (58*a[6])/21 - (a[3]*a[6])/2 - (a[4]*a[6])/2 + (253*a[7])/42 + a[6]*a[9] - (58*a[10])/7 + 
  a[7]*a[18] - (58*a[19])/7 + (232*a[8]*a[19])/21, -5455/12816 + (1931*a[3])/4272 - (169*a[3]^2)/6408 + (1627*a[4])/1602 - 
  (572*a[3]*a[4])/267 - (39349*a[6]^2)/807408 + (23765*a[6]*a[7])/57672 + (881*a[8])/1068 - (881*a[8]^2)/1068 - 
  (2169*a[9])/1424 + (7489*a[3]*a[9])/6408 + a[4]*a[9] + (2311*a[8]*a[9])/2136 - (97787*a[6]*a[10])/269136 - 
  (39349*a[12]^2)/807408 + (23765*a[12]*a[13])/57672 + (372059*a[12]*a[16])/807408 - (23765*a[16]^2)/28836 - 
  (1885*a[18])/4272 + (7489*a[3]*a[18])/6408 + a[4]*a[18] - (2311*a[8]*a[18])/2136 - (610*a[9]*a[18])/267 + 
  (372059*a[6]*a[19])/807408 - (23765*a[19]^2)/28836 - (97787*a[12]*a[20])/269136, 
 (47*a[12]^2)/70 - (3*a[12]*a[13])/2 + a[13]^2 - (6*a[12]*a[16])/35 - (6*a[12]*a[20])/35, 
 (a[6]*a[12])/2 - (3*a[7]*a[12])/2 + a[7]*a[13], (-26*a[12])/21 + (a[3]*a[12])/2 - (3*a[4]*a[12])/2 - (125*a[13])/42 + 
  a[4]*a[13] - (26*a[16])/21 + (104*a[8]*a[16])/21 + (26*a[20])/7, (47*a[6]^2)/70 - (3*a[6]*a[7])/2 + a[7]^2 - 
  (6*a[6]*a[10])/35 - (6*a[6]*a[19])/35, (-26*a[6])/21 + (a[3]*a[6])/2 - (3*a[4]*a[6])/2 - (125*a[7])/42 + a[4]*a[7] + 
  (26*a[10])/7 + (26*a[19])/7 - (104*a[8]*a[19])/21, -63037/230688 + (24473*a[3])/76896 - (5191*a[3]^2)/115344 + 
  (77081*a[4])/57672 - (10073*a[3]*a[4])/4806 + a[4]^2 - (20304931*a[6]^2)/581333760 + (7875295*a[6]*a[7])/33219072 + 
  (9641*a[8])/19224 - (9641*a[8]^2)/19224 - (3891*a[9])/2848 + (131599*a[3]*a[9])/115344 + (29083*a[8]*a[9])/38448 - 
  (78341821*a[6]*a[10])/387555840 - (20304931*a[12]^2)/581333760 + (7875295*a[12]*a[13])/33219072 + 
  (316245187*a[12]*a[16])/1162667520 - (7875295*a[16]^2)/16609536 - (46891*a[18])/76896 + (131599*a[3]*a[18])/115344 - 
  (29083*a[8]*a[18])/38448 - (2864*a[9]*a[18])/2403 + (316245187*a[6]*a[19])/1162667520 - (7875295*a[19]^2)/16609536 - 
  (78341821*a[12]*a[20])/387555840, -3/4 + (3*a[3])/4 + (3*a[6]^2)/8 + 2*a[8] - (3*a[3]*a[8])/2 - (3*a[8]^2)/2 + a[8]^3 + 
  (3*a[8]*a[9])/4 - (3*a[6]*a[10])/8 - (3*a[12]^2)/8 + (3*a[12]*a[16])/8 - (3*a[18])/4 + (3*a[8]*a[18])/4 - (3*a[6]*a[19])/8 + 
  (3*a[12]*a[20])/8, -3/4 + (3*a[3])/4 + 2*a[8] - a[3]*a[8] - 2*a[8]^2 + a[3]*a[8]^2 - a[9]/4 - (a[8]*a[9])/2 - (3*a[18])/4 + 
  (a[8]*a[18])/2, (-5*a[6])/4 - (5*a[7])/2 + (15*a[10])/4 + (15*a[19])/4 - (11*a[8]*a[19])/2 + a[8]^2*a[19], 
 (-5*a[12])/4 - (5*a[13])/2 - (3*a[16])/4 + (7*a[8]*a[16])/2 + a[8]^2*a[16] + (15*a[20])/4, 
 11501/4272 - (4217*a[3])/1424 + (575*a[3]^2)/2136 + (122405*a[4])/1068 - (19585*a[3]*a[4])/89 - (1007425*a[6]^2)/38448 + 
  (1106575*a[6]*a[7])/38448 - (1821*a[8])/356 + (93*a[3]*a[8])/2 + (435*a[4]*a[8])/4 - (14733*a[8]^2)/356 - 
  (49223*a[9])/1424 + (12895*a[3]*a[9])/2136 + 180*a[4]*a[9] - (14135*a[8]*a[9])/712 + a[8]^2*a[9] + (135*a[9]^2)/4 - 
  (16525*a[6]*a[10])/6408 + (12989045*a[12]^2)/269136 + (1106575*a[12]*a[13])/38448 - (1310755*a[12]*a[16])/67284 - 
  (1106575*a[16]^2)/19224 - (159373*a[18])/1424 + (469465*a[3]*a[18])/2136 - (80917*a[8]*a[18])/712 - (80585*a[9]*a[18])/356 + 
  (132125*a[6]*a[19])/2403 - (1106575*a[19]^2)/19224 - (3455845*a[12]*a[20])/44856, 
 -15817/4272 + (3829*a[3])/1424 + (2165*a[3]^2)/2136 - (126565*a[4])/1068 + (19685*a[3]*a[4])/89 + (6846695*a[6]^2)/269136 - 
  (1085975*a[6]*a[7])/38448 + (2997*a[8])/356 - (93*a[3]*a[8])/2 - (435*a[4]*a[8])/4 + (13557*a[8]^2)/356 + 
  (51123*a[9])/1424 - (18035*a[3]*a[9])/2136 - 180*a[4]*a[9] + (14527*a[8]*a[9])/712 - (135*a[9]^2)/4 + 
  (125855*a[6]*a[10])/44856 - (13194325*a[12]^2)/269136 - (1085975*a[12]*a[13])/38448 + (1398125*a[12]*a[16])/67284 + 
  (1085975*a[16]^2)/19224 + (163481*a[18])/1424 - (474605*a[3]*a[18])/2136 + (79101*a[8]*a[18])/712 + a[8]^2*a[18] + 
  (81385*a[9]*a[18])/356 - (1806065*a[6]*a[19])/33642 + (1085975*a[19]^2)/19224 + (3466025*a[12]*a[20])/44856, 
 227/534 - (199*a[3])/178 + (185*a[3]^2)/267 - (35*a[4])/1068 + (80*a[3]*a[4])/89 - (665*a[6]^2)/9612 - 
  (3445*a[6]*a[7])/9612 - (14*a[8])/89 - a[4]*a[8] + (14*a[8]^2)/89 + a[4]*a[8]^2 + (647*a[9])/356 - (425*a[3]*a[9])/267 - 
  (121*a[8]*a[9])/89 + (685*a[6]*a[10])/1602 - (665*a[12]^2)/9612 - (3445*a[12]*a[13])/9612 - (695*a[12]*a[16])/2403 + 
  (3445*a[16]^2)/4806 + (163*a[18])/356 - (425*a[3]*a[18])/267 + (121*a[8]*a[18])/89 + (160*a[9]*a[18])/89 - 
  (695*a[6]*a[19])/2403 + (3445*a[19]^2)/4806 + (685*a[12]*a[20])/1602, 70657/4272 - (18737*a[3])/1424 - (7223*a[3]^2)/2136 + 
  (814915*a[4])/1068 - (130405*a[3]*a[4])/89 - (6698009*a[6]^2)/38448 + (7374425*a[6]*a[7])/38448 - (6401*a[8])/178 + 
  (1227*a[3]*a[8])/4 + a[3]^2*a[8] + (2885*a[4]*a[8])/4 - (96757*a[8]^2)/356 - (339915*a[9])/1424 + (105425*a[3]*a[9])/2136 + 
  1200*a[4]*a[9] - (84397*a[8]*a[9])/712 + (873*a[9]^2)/4 - (14092*a[6]*a[10])/801 + (12304915*a[12]^2)/38448 + 
  (7374425*a[12]*a[13])/38448 - (2465245*a[12]*a[16])/19224 - (7374425*a[16]^2)/19224 - (1063001*a[18])/1424 + 
  (3136943*a[3]*a[18])/2136 - (541451*a[8]*a[18])/712 - (538343*a[9]*a[18])/356 + (7036217*a[6]*a[19])/19224 - 
  (7374425*a[19]^2)/19224 - (1639945*a[12]*a[20])/3204, 22159/1424 - (18573*a[3])/1424 - (1793*a[3]^2)/712 + (61120*a[4])/89 - 
  (117345*a[3]*a[4])/89 - (14078993*a[6]^2)/89712 + (2211575*a[6]*a[7])/12816 - (2994*a[8])/89 + (1113*a[3]*a[8])/4 + 
  (2595*a[4]*a[8])/4 - (87081*a[8]^2)/356 - (305731*a[9])/1424 + (31507*a[3]*a[9])/712 + 1080*a[4]*a[9] - 
  (76705*a[8]*a[9])/712 + a[3]*a[8]*a[9] + (783*a[9]^2)/4 - (29209*a[6]*a[10])/1869 + (3685885*a[12]^2)/12816 + 
  (2211575*a[12]*a[13])/12816 - (737155*a[12]*a[16])/6408 - (2211575*a[16]^2)/6408 - (955761*a[18])/1424 + 
  (940553*a[3]*a[18])/712 - (487199*a[8]*a[18])/712 - (484237*a[9]*a[18])/356 + (14780009*a[6]*a[19])/44856 - 
  (2211575*a[19]^2)/6408 - (491455*a[12]*a[20])/1068, 21011/1424 - (17097*a[3])/1424 - (1957*a[3]^2)/712 + (121735*a[4])/178 - 
  (117285*a[3]*a[4])/89 - (14083381*a[6]^2)/89712 + (2217475*a[6]*a[7])/12816 - (2871*a[8])/89 + (1113*a[3]*a[8])/4 + 
  (2595*a[4]*a[8])/4 - (87573*a[8]^2)/356 - (307439*a[9])/1424 + (31903*a[3]*a[9])/712 + 1080*a[4]*a[9] - 
  (74405*a[8]*a[9])/712 + (783*a[9]^2)/4 - (29978*a[6]*a[10])/1869 + (25796807*a[12]^2)/89712 + (2217475*a[12]*a[13])/12816 - 
  (5137241*a[12]*a[16])/44856 - (2217475*a[16]^2)/6408 - (952869*a[18])/1424 + (940237*a[3]*a[18])/712 - 
  (489499*a[8]*a[18])/712 + a[3]*a[8]*a[18] - (484469*a[9]*a[18])/356 + (14802853*a[6]*a[19])/44856 - (2217475*a[19]^2)/6408 - 
  (3443261*a[12]*a[20])/7476, 416159/25632 - (116359*a[3])/8544 - (33541*a[3]^2)/12816 + (560560*a[4])/801 - 
  (717005*a[3]*a[4])/534 - (258204115*a[6]^2)/1614816 + (10125205*a[6]*a[7])/57672 - (37475*a[8])/1068 + (2269*a[3]*a[8])/8 + 
  (2641*a[4]*a[8])/4 + a[3]*a[4]*a[8] - (530873*a[8]^2)/2136 - (622243*a[9])/2848 + (577657*a[3]*a[9])/12816 + 
  1099*a[4]*a[9] - (468767*a[8]*a[9])/4272 + (801*a[9]^2)/4 - (8433875*a[6]*a[10])/538272 + (474432137*a[12]^2)/1614816 + 
  (10125205*a[12]*a[13])/57672 - (190926397*a[12]*a[16])/1614816 - (10125205*a[16]^2)/28836 - (5840587*a[18])/8544 + 
  (17241661*a[3]*a[18])/12816 - (2975533*a[8]*a[18])/4272 - (1479353*a[9]*a[18])/1068 + (541709855*a[6]*a[19])/1614816 - 
  (10125205*a[19]^2)/28836 - (252645959*a[12]*a[20])/538272, -a[6]^2/140 + (a[6]*a[7])/2 - (69*a[6]*a[10])/140 + 
  (a[6]*a[19])/140 - a[19]^2/2 + a[8]*a[19]^2, -(a[16]*a[19])/2 + a[8]*a[16]*a[19], 
 a[12]^2/140 - (a[12]*a[13])/2 - (a[12]*a[16])/140 - a[16]^2/2 + a[8]*a[16]^2 + (69*a[12]*a[20])/140, 
 1360511/68352 - (393735*a[3])/22784 - (89653*a[3]^2)/34176 + (14068805*a[4])/17088 - (2248755*a[3]*a[4])/1424 - 
  (809530465*a[6]^2)/4306176 + (127195375*a[6]*a[7])/615168 - (120847*a[8])/2848 + (21441*a[3]*a[8])/64 + 
  (49875*a[4]*a[8])/64 - (1666555*a[8]^2)/5696 - (5861477*a[9])/22784 + (1813747*a[3]*a[9])/34176 + 1290*a[4]*a[9] - 
  (1500619*a[8]*a[9])/11392 + (15215*a[9]^2)/64 + a[8]*a[9]^2 - (3368215*a[6]*a[10])/179424 + (1487977835*a[12]^2)/4306176 + 
  (127195375*a[12]*a[13])/615168 - (298805105*a[12]*a[16])/2153088 - (127195375*a[16]^2)/307584 - (18304903*a[18])/22784 + 
  (54059773*a[3]*a[18])/34176 - (9329613*a[8]*a[18])/11392 - (9279521*a[9]*a[18])/5696 + (849949045*a[6]*a[19])/2153088 - 
  (127195375*a[19]^2)/307584 - (198195455*a[12]*a[20])/358848, 774529/68352 - (216953*a[3])/22784 - (61835*a[3]^2)/34176 + 
  (8144155*a[4])/17088 - (1303885*a[3]*a[4])/1424 - (469418015*a[6]^2)/4306176 + (73766225*a[6]*a[7])/615168 - 
  (69697*a[8])/2848 + (12447*a[3]*a[8])/64 + (28845*a[4]*a[8])/64 - (968389*a[8]^2)/5696 - (3414171*a[9])/22784 + 
  (1066061*a[3]*a[9])/34176 + 750*a[4]*a[9] - (846901*a[8]*a[9])/11392 + (8721*a[9]^2)/64 - (1956065*a[6]*a[10])/179424 + 
  (861334549*a[12]^2)/4306176 + (73766225*a[12]*a[13])/615168 - (172485487*a[12]*a[16])/2153088 - (73766225*a[16]^2)/307584 - 
  (10600697*a[18])/22784 + (31355075*a[3]*a[18])/34176 - (5422259*a[8]*a[18])/11392 - (5385759*a[9]*a[18])/5696 + 
  a[8]*a[9]*a[18] + (492890795*a[6]*a[19])/2153088 - (73766225*a[19]^2)/307584 - (114808177*a[12]*a[20])/358848, 
 1461919/153792 - (421379*a[3])/51264 - (98891*a[3]^2)/76896 + (7264295*a[4])/19224 - (580030*a[3]*a[4])/801 - 
  (840225875*a[6]^2)/9688896 + (65497975*a[6]*a[7])/692064 - (260135*a[8])/12816 + (1233*a[3]*a[8])/8 + (1425*a[4]*a[8])/4 - 
  (1715131*a[8]^2)/12816 - (2015183*a[9])/17088 + (1871267*a[3]*a[9])/76896 + (1777*a[4]*a[9])/3 - (1531063*a[8]*a[9])/25632 + 
  a[4]*a[8]*a[9] + (431*a[9]^2)/4 - (25581925*a[6]*a[10])/3229632 + (1536148885*a[12]^2)/9688896 + 
  (65497975*a[12]*a[13])/692064 - (619177235*a[12]*a[16])/9688896 - (65497975*a[16]^2)/346032 - (18884147*a[18])/51264 + 
  (55781771*a[3]*a[18])/76896 - (9625265*a[8]*a[18])/25632 - (2392367*a[9]*a[18])/3204 + (1757197525*a[6]*a[19])/9688896 - 
  (65497975*a[19]^2)/346032 - (817706845*a[12]*a[20])/3229632, (320*a[12])/63 - a[12]^3 + (640*a[13])/63 + (320*a[16])/63 - 
  (1280*a[8]*a[16])/63 + a[12]^2*a[16] - (320*a[20])/21 + a[12]^2*a[20], (a[6]^2*a[12])/2 - (a[6]*a[7]*a[12])/2 - 
  a[6]*a[12]*a[19] + a[12]*a[19]^2, -(a[6]*a[12]^2)/2 + (a[7]*a[12]^2)/2 + a[12]*a[16]*a[19], 
 (-608*a[12])/147 + a[12]^3/2 - (1216*a[13])/147 - (a[12]^2*a[13])/2 - (608*a[16])/147 + (2432*a[8]*a[16])/147 - 
  a[12]^2*a[16] + a[12]*a[16]^2 + (608*a[20])/49, (-2141*a[12])/588 - (3*a[3]*a[12])/4 + (a[3]^2*a[12])/2 + (a[4]*a[12])/4 - 
  (a[3]*a[4]*a[12])/2 + a[9]*a[12] - a[3]*a[9]*a[12] + a[9]^2*a[12] - (1144*a[13])/147 - (572*a[16])/147 + 
  (2288*a[8]*a[16])/147 + (572*a[20])/49, (-221*a[12])/588 - (3*a[3]*a[12])/4 + (a[3]^2*a[12])/2 + (a[4]*a[12])/4 - 
  (a[3]*a[4]*a[12])/2 + a[9]*a[12] - a[3]*a[9]*a[12] + a[4]*a[9]*a[12] - (184*a[13])/147 - (92*a[16])/147 + 
  (368*a[8]*a[16])/147 + (92*a[20])/49, (320*a[6])/63 - a[6]^3 + (640*a[7])/63 - (320*a[10])/21 + a[6]^2*a[10] - 
  (320*a[19])/21 + a[6]^2*a[19] + (1280*a[8]*a[19])/63, (-608*a[6])/147 + a[6]^3/2 - (1216*a[7])/147 - (a[6]^2*a[7])/2 + 
  (608*a[10])/49 + (608*a[19])/49 - a[6]^2*a[19] - (2432*a[8]*a[19])/147 + a[6]*a[19]^2, 
 (419*a[6])/588 - (3*a[3]*a[6])/4 + (a[3]^2*a[6])/2 + (a[4]*a[6])/4 - (a[3]*a[4]*a[6])/2 + (136*a[7])/147 + a[6]*a[9] - 
  a[3]*a[6]*a[9] + a[6]*a[9]^2 - (68*a[10])/49 - (68*a[19])/49 + (272*a[8]*a[19])/147, 
 (97*a[6])/196 - (3*a[3]*a[6])/4 + (a[3]^2*a[6])/2 + (a[4]*a[6])/4 - (a[3]*a[4]*a[6])/2 + (24*a[7])/49 + a[6]*a[9] - 
  a[3]*a[6]*a[9] + a[4]*a[6]*a[9] - (36*a[10])/49 - (36*a[19])/49 + (48*a[8]*a[19])/49, 
 8117/5340 - (711*a[3])/356 + (1972*a[3]^2)/1335 - a[3]^3 - (404*a[4])/267 + (121*a[3]*a[4])/89 - (591149*a[6]^2)/1177470 - 
  (4625*a[6]*a[7])/19224 - (1363*a[8])/445 + (1363*a[8]^2)/445 + (597*a[9])/356 - (2452*a[3]*a[9])/1335 + a[3]^2*a[9] + 
  (1207*a[8]*a[9])/890 + (1165907*a[6]*a[10])/1569960 - (591149*a[12]^2)/1177470 - (4625*a[12]*a[13])/19224 + 
  (1231471*a[12]*a[16])/4709880 + (4625*a[16]^2)/9612 + (5399*a[18])/1780 - (2452*a[3]*a[18])/1335 + a[3]^2*a[18] - 
  (1207*a[8]*a[18])/890 + (64*a[9]*a[18])/89 + (1231471*a[6]*a[19])/4709880 + (4625*a[19]^2)/9612 + 
  (1165907*a[12]*a[20])/1569960, -1166467/128160 + (75307*a[3])/8544 - (13609*a[3]^2)/64080 + a[3]^3/2 - 
  (9488027*a[4])/25632 + (3035287*a[3]*a[4])/4272 - (a[3]^2*a[4])/2 + (9522942379*a[6]^2)/113037120 - 
  (85692415*a[6]*a[7])/922752 + (200153*a[8])/10680 - (6003*a[3]*a[8])/40 - 351*a[4]*a[8] + (175331*a[8]^2)/1335 + 
  (101651*a[9])/890 - (34595*a[3]*a[9])/1602 - a[3]^2*a[9] - 579*a[4]*a[9] + (79729*a[8]*a[9])/1335 - (546*a[9]^2)/5 + 
  a[3]*a[9]^2 + (649585639*a[6]*a[10])/75358080 - (17589529901*a[12]^2)/113037120 - (85692415*a[12]*a[13])/922752 + 
  (14184418127*a[12]*a[16])/226074240 + (85692415*a[16]^2)/461376 + (3856139*a[18])/10680 - (5693467*a[3]*a[18])/8010 + 
  (392947*a[8]*a[18])/1068 + (7821119*a[9]*a[18])/10680 - (40040526433*a[6]*a[19])/226074240 + (85692415*a[19]^2)/461376 + 
  (18724567159*a[12]*a[20])/75358080, 95051/64080 - (4277*a[3])/4272 + (143*a[3]^2)/8010 - a[3]^3/2 + (10019*a[4])/25632 + 
  (161*a[3]*a[4])/4272 + (a[3]^2*a[4])/2 - (34854541*a[6]^2)/113037120 - (509585*a[6]*a[7])/922752 - (39503*a[8])/10680 + 
  (39503*a[8]^2)/10680 + (1837*a[9])/2848 + (28481*a[3]*a[9])/64080 + (9557*a[8]*a[9])/21360 + 
  (64852469*a[6]*a[10])/75358080 - (34854541*a[12]^2)/113037120 - (509585*a[12]*a[13])/922752 - 
  (55139243*a[12]*a[16])/226074240 + (509585*a[16]^2)/461376 + (46669*a[18])/42720 + (28481*a[3]*a[18])/64080 - 
  (9557*a[8]*a[18])/21360 - (907*a[9]*a[18])/2136 + a[3]*a[9]*a[18] - (55139243*a[6]*a[19])/226074240 + 
  (509585*a[19]^2)/461376 + (64852469*a[12]*a[20])/75358080, -6752417/4101120 + (669701*a[3])/273408 - 
  (2671829*a[3]^2)/2050560 + a[3]^3/2 - (9574447*a[4])/205056 + (1532833*a[3]*a[4])/17088 - (a[3]^2*a[4])/2 + 
  (3850112213*a[6]^2)/361718784 - (85429445*a[6]*a[7])/7382016 + (468209*a[8])/170880 - (24069*a[3]*a[8])/1280 - 
  (11259*a[4]*a[8])/256 + (1098001*a[8]^2)/68352 + (17558459*a[9])/1367040 - (1087453*a[3]*a[9])/2050560 - a[3]^2*a[9] - 
  (887*a[4]*a[9])/12 + a[3]*a[4]*a[9] + (1735367*a[8]*a[9])/227840 - (17219*a[9]^2)/1280 + (3499277*a[6]*a[10])/3767904 - 
  (7057018279*a[12]^2)/361718784 - (85429445*a[12]*a[13])/7382016 + (1435487737*a[12]*a[16])/180859392 + 
  (85429445*a[16]^2)/3691008 + (61578841*a[18])/1367040 - (182293411*a[3]*a[18])/2050560 + (10473297*a[8]*a[18])/227840 + 
  (31283207*a[9]*a[18])/341760 - (4018077509*a[6]*a[19])/180859392 + (85429445*a[19]^2)/3691008 + 
  (936921757*a[12]*a[20])/30143232, (-6791*a[6])/896 + (3*a[6]^3)/4 - (24959*a[7])/1792 - (3*a[6]^2*a[7])/4 + 
  (38541*a[10])/1792 - (a[6]*a[12]^2)/4 + (a[7]*a[12]^2)/4 + (38541*a[19])/1792 - a[6]^2*a[19] - (24959*a[8]*a[19])/896 + 
  a[16]^2*a[19] + a[19]^3, (-6791*a[12])/896 - (a[6]^2*a[12])/4 + (a[6]*a[7]*a[12])/4 + (3*a[12]^3)/4 - (24959*a[13])/1792 - 
  (3*a[12]^2*a[13])/4 - (11377*a[16])/1792 + (24959*a[8]*a[16])/896 - a[12]^2*a[16] + a[16]^3 + a[16]*a[19]^2 + 
  (38541*a[20])/1792, 183097/16020 - (70685*a[3])/8544 - (500621*a[3]^2)/128160 + (3*a[3]^3)/4 + (52935505*a[4])/102528 - 
  (4229873*a[3]*a[4])/4272 - (3*a[3]^2*a[4])/4 - (7564272227*a[6]^2)/64592640 + (481295435*a[6]*a[7])/3691008 - 
  (1095331*a[8])/42720 + (67419*a[3]*a[8])/320 + (63033*a[4]*a[8])/128 - (15810211*a[8]^2)/85440 - (9377989*a[9])/56960 + 
  (18900251*a[3]*a[9])/512640 - a[3]^2*a[9] + (12879*a[4]*a[9])/16 - (1468459*a[8]*a[9])/17088 + (98233*a[9]^2)/640 + a[9]^3 - 
  (572265257*a[6]*a[10])/43061760 + (98006554411*a[12]^2)/452148480 + (481295435*a[12]*a[13])/3691008 - 
  (78095727247*a[12]*a[16])/904296960 - (481295435*a[16]^2)/1845504 - (86272807*a[18])/170880 + 
  (127300691*a[3]*a[18])/128160 - (21963923*a[8]*a[18])/42720 - (174955669*a[9]*a[18])/170880 + 
  (31973884679*a[6]*a[19])/129185280 - (481295435*a[19]^2)/1845504 - (104643496799*a[12]*a[20])/301432320, 
 -840029/256320 + (65447*a[3])/17088 - (19399*a[3]^2)/64080 - a[3]^3/4 - (18158765*a[4])/102528 + (91111*a[3]*a[4])/267 + 
  (a[3]^2*a[4])/4 + (18218466373*a[6]^2)/452148480 - (166368295*a[6]*a[7])/3691008 + (251057*a[8])/42720 - 
  (23043*a[3]*a[8])/320 - (21561*a[4]*a[8])/128 + (5650367*a[8]^2)/85440 + (3127683*a[9])/56960 - (5157367*a[3]*a[9])/512640 - 
  (4463*a[4]*a[9])/16 + (491297*a[8]*a[9])/17088 - (33081*a[9]^2)/640 + (1441099843*a[6]*a[10])/301432320 - 
  (33949317947*a[12]^2)/452148480 - (166368295*a[12]*a[13])/3691008 + (27138403619*a[12]*a[16])/904296960 + 
  (166368295*a[16]^2)/1845504 + (29704589*a[18])/170880 - (21831221*a[3]*a[18])/64080 + (1884709*a[8]*a[18])/10680 + 
  (60124613*a[9]*a[18])/170880 + a[9]^2*a[18] - (77197165021*a[6]*a[19])/904296960 + (166368295*a[19]^2)/1845504 + 
  (36219622723*a[12]*a[20])/301432320, -354851893/36910080 + (24762505*a[3])/2460672 - (22134121*a[3]^2)/18455040 + 
  (3*a[3]^3)/4 - (652538555*a[4])/1845504 + (104303741*a[3]*a[4])/153792 - (3*a[3]^2*a[4])/4 + 
  (1312270017869*a[6]^2)/16277345280 - (5868675745*a[6]*a[7])/66438144 + (29456641*a[8])/1537920 - (183161*a[3]*a[8])/1280 - 
  (85671*a[4]*a[8])/256 + (381222601*a[8]^2)/3075840 + (439571293*a[9])/4101120 - (356475041*a[3]*a[9])/18455040 - 
  a[3]^2*a[9] - (19933*a[4]*a[9])/36 + (70233365*a[8]*a[9])/1230336 - (394573*a[9]^2)/3840 + a[4]*a[9]^2 + 
  (5231480819*a[6]*a[10])/678222720 - (2415218261551*a[12]^2)/16277345280 - (5868675745*a[12]*a[13])/66438144 + 
  (488696352013*a[12]*a[16])/8138672640 + (5868675745*a[16]^2)/33219072 + (4231973069*a[18])/12303360 - 
  (12508156079*a[3]*a[18])/18455040 + (2157110207*a[8]*a[18])/6151680 + (2146869467*a[9]*a[18])/3075840 - 
  (1375047787697*a[6]*a[19])/8138672640 + (5868675745*a[19]^2)/33219072 + 
(321086984923*a[12]*a[20])/1356445440};

You can check, e.g. via NSolve, that the solution set has positive dimension.
In[93]:= Timing[sol = NSolve[gb2];]

During evaluation of In[93]:= NSolve::infsolns: Infinite solution set has dimension at least 1. Returning intersection of solutions with (78848 a[3])/86491-(52050 a[4])/86491+(57827 a[6])/86491+(148851 a[7])/172982+(101463 a[8])/172982+(188769 a[9])/172982-(191343 a[10])/172982-(89087 a[12])/86491+(78339 a[13])/86491+(140033 a[15])/172982-(83945 a[16])/86491-(56554 a[18])/86491+(83206 a[19])/86491-(107131 a[20])/172982 == 1. >>

During evaluation of In[93]:= NSolve::infsolns: Infinite solution set has dimension at least 2. Returning intersection of solutions with (67842 a[3])/95609-(184441 a[4])/191218-(97766 a[6])/95609-(184729 a[7])/191218+(93018 a[8])/95609-(59375 a[9])/95609+(147179 a[10])/191218+(81420 a[12])/95609-(60031 a[13])/95609+(156301 a[15])/191218+(130811 a[16])/191218+(94526 a[18])/95609-(2863 a[19])/2854+(54539 a[20])/95609 == 1. >>

During evaluation of In[93]:= NSolve::infsolns: Infinite solution set has dimension at least 3. Returning intersection of solutions with -((81281 a[3])/77135)+(86849 a[4])/77135-(65291 a[6])/77135+(177769 a[7])/154270-(76583 a[8])/77135-(130181 a[9])/154270-(15303 a[10])/15427+(54742 a[12])/77135+(64317 a[13])/77135+(83022 a[15])/77135+(70919 a[16])/77135-(30099 a[18])/30854-(80873 a[19])/77135-(70654 a[20])/77135 == 1. >>

During evaluation of In[93]:= General::stop: Further output of NSolve::infsolns will be suppressed during this calculation. >>

Out[93]= {3.13, Null}

In[94]:= sol

Out[94]= {{a[15] -> 0., a[10] -> 0., a[20] -> 34.7986, 
  a[13] -> 34.7986, a[7] -> 12.0763, a[18] -> 11.9732, 
  a[4] -> 11.9732, a[16] -> 0., a[19] -> 12.0763, a[9] -> 0., 
  a[8] -> 0., a[3] -> 12.9732, a[6] -> 12.0763, 
  a[12] -> 34.7986}, {a[15] -> 0., a[10] -> -1.32805, 
  a[20] -> -1.52477, a[13] -> -1.52477, a[7] -> -1.32805, 
  a[18] -> -0.727061, a[4] -> -0.727061, a[16] -> -1.52477, 
  a[19] -> -1.32805, a[9] -> -0.727061, a[8] -> 0.5, 
  a[3] -> -0.954122, a[6] -> -2.65611, 
  a[12] -> -3.04955}, {a[15] -> 0., a[10] -> 1.47403, a[20] -> 0., 
  a[13] -> 1.84961, a[7] -> 1.47403, a[18] -> 0., a[4] -> 0.644773, 
  a[16] -> 1.84961, a[19] -> 0., a[9] -> 0.644773, a[8] -> 1., 
  a[3] -> 1.64477, a[6] -> 1.47403, a[12] -> 1.84961}}

If you run NSolve directly on the original set, it might in fact go to completion. But expect it to take considerable time-- I've had it running for a few hours now, with the end only dimly in sight.
"
sorting - Ordring problm - Mathmatica Stack Exchang,"
This is probably because by default Sort doesn't just use numerical values, it includes structure information as well. From the doc:

Numeric expressions are sorted by structure as well as numerical value:

In[1]:= Sort[{Sqrt[2], 1, 2, 1/Sqrt[2]}]

Out[1]= {1, 2, 1/Sqrt[2], Sqrt[2]}


Sort by numerical value only:

In[2]:= Sort[{Sqrt[2], 1, 2, 1/Sqrt[2]}, Less]

Out[2]= {1/Sqrt[2], 1, Sqrt[2], 2}

along with the following doc:

Sort usually orders expressions by putting shorter ones first, and then comparing parts in a depth-first manner. 

gives us a hint why. If you run TreeForm /@ {0, 20 Sqrt[5], 40 Sqrt[5], 20 Sqrt[5], 20 Sqrt[10]}, you'll see that the last layer (Rational) is the same for all four Sqrts. Then the next depth down is the Power, in which 10 is the outlier, and is greater than 5, so will be placed last. Finally, comparing {20, 40, 20} will give the ordering {1, 3, 2}, which when put together with the original list gives you the ordering:
In[77]:= Ordering[{0, 20 Sqrt[5], 40 Sqrt[5], 20 Sqrt[5], 20 Sqrt[10]}]

Out[77]= {1, 2, 4, 3, 5}

"
animation - Incorporating an additional graphics element when using Animate and ParametricPlot3D,"
I think the simplest way is to include a Show:
Animate[
  Show[
    ParametricPlot3D[{{Cos[α t], Sin[α t], 
      Sqrt[1 - α^2] t}, {Cos[α t], 
      Sin[α t], -Sqrt[1 - α^2] t}}, {α, -1, 1}, 
    PlotRange -> {{-1, 1}, {-1, 1}, {-2 π, 2 π}}], 

    Graphics3D[Cylinder[{{0, 0, -2 π}, {0, 0, 2 π}}, 1]]
  ], 
{t, 0, 2 π}, AnimationRunning -> False]


Show returns a graphics object that can be further customized in a similar way to ParametricPlot3D.
EDIT I really liked the animation, but think the Cylinder by default masks the function. Perhaps the following is easier to see:
Animate[
  Show[
    ParametricPlot3D[{{Cos[α t], Sin[α t], 
      Sqrt[1 - α^2] t}, {Cos[α t], 
      Sin[α t], -Sqrt[1 - α^2] t}}, {α, -1, 1}, 
      PlotRange -> {{-1, 1}, {-1, 1}, {-2 π, 2 π}}, 
      Axes -> False, BoxStyle -> Opacity[0]], 
    Graphics3D[{EdgeForm[None], Yellow, Opacity[0.2], 
      Cylinder[{{0, 0, -2 π}, {0, 0, 2 π}}, 1]}]
  ], 
{t, 0, 2 π}, AnimationRunning -> False]


"
evaluation - Mathematica rule substitution memory,"
While I am not able to explain why there is a difference between the two methods, I would like to suggest using
t = Block[{x=0, y=0}, p];

Block will set a value to x and y only temporarily, and avoids the use of Clear.
Some more things that can be useful for you:

When you start working, use $HistoryLength = 0 to avoid remembering past results and wasting memory (note that Mathematica sometimes remembers full results even when the input was ended in a semicolon!)
Use Share[] occasionally.  It seems that with your polynomial this will help a lot more than in other cases.  After reading in the polynomial, it frees 60 MB for me immediately.

"
calculus and analysis - Why does Mathematica give the wrong answer when integrating?,"
Looks like a bug that ran off in the development version of Mathematica.
In[1]:= Integrate[Exp[I Cos[b - c]] Cos[b], {b, 0, 2 Pi}]//InputForm

Out[1]//InputForm= (2*I)*Pi*BesselJ[1, 1]*Cos[c]

In[2]:= %/.c->.5

Out[2]= 0. + 2.42645 I

"
programming - Are there advantages to using additional arguments of common functions rather than alternative ways of calculating with lists?,"
I can think of several main advantages of additional arguments:

Efficiency
More concise and readable code
Better abstraction level
Less chances for bugs.

In brief, I think that the first reason is bad most of the time, the second and third are valid, and the last may or may not be valid. Let us now consider these arguments.
I start with efficiency. My opinion here is that, on one hand, this is one of the major factors in real-life Mathematica programming (or at least, in my experience), while on the other hand, it should not be. I really blame the execution model of Mathematica here (yes, I know many reasons why  with Mathematica it can not currently be the other way, but, from the pragmatic point of view of the user of it as a general-purpose programming language - as opposed to a computer algebra system or rewrite engine - I could not care less), because the performance differences between implemented in C built-in functions and top-level user-defined functions are often huge, and this makes performance non-uniform and hard to understand. We all spend lots of time on micro-benchmarking, while that time could have been spent much more productively on some really important things. So, while in practice the performance factor often dominates the decision to use these extra arguments (or even introduce them in the function's syntax), I think this is conceptually wrong one and should have a status of a widely used work-around to compensate for  the current language limitations regarding performance. A real way out would IMO be to extend Compile so that much wider subset of the language could become compiled rather than interpreted, which is of course a much harder task.
Next point is concise and readable code. This one is a very valid one IMO. However, using extra arguments does not always lead to that, because often what they do is rather obscure. So, I think that some balance is needed here. It also depends on how well these extra arguments are designed, in the sense that it should be relatively easy to understand what they do in some code, perhaps by consulting the docs. In any case, there are IMO many use cases where the use of extra arguments may be justified from this point of view. Good examples here are IMO SortBy and SplitBy, particularly with their extended (multi-level) functionality (they also may improve performance, but I don't view this as  their major advantage).
What I mean by better abstraction level is that extra arguments may allow to group a lot of related functionality into one ""super-function"" (e.g. Partition), which means that the code using it does recognize in the particular use of it an instance of a more general operation, conceptually. This may be useful in the same way as abstract classes are useful in OOP. This however requires a really careful and very well thought out design for such functions. There are quite a few Mathematica functions which, I think, satisfy this criteria.
Less chances for bugs: since built-ins are used (assuming that built-ins are having on the average less bugs than the code you write, which is probably true for most users, because built-ins were written by experts, and had more chances to be tested, being exposed to many users and undergone the QA precess). This may not be as clear-cut, however, in cases when these extra arguments are hard to understand, since using them may induce more bugs because of that.
So, my conclusions would be these: if the code using those arguments is more readable, natural and concise (this is subjective, of course), they are probably worth using, in that particular piece of code. I have seen many instances where this is indeed the case. But, if all they give is a speed increase, especially at the expense of code clarity, they are probably not worth using (or at least, it is not worth to spend excessive amounts of time searching for them and reorganizing code), except when this piece of code is speed-critical. 
A very large class of use cases when they are used to only boost the performance I view as a necessary evil, but, while I think that the expert-level performance-tuning skills must currently include the knowledge of these arguments / use cases, I also think that this is unfortunate and leads to massive learning / memorizing effort on the side of a practitioner,  which could be better spent elsewhere, were the language performance model more uniform. I actually don't think that this problem is characteristic to Mathematica only, most high-level languages probably have similar issues. What makes  Mathematica stand out IMO is that, being extremely high-level,  it has a very large range of the possible performance differences between different solutions, which may easily span several orders of magnitude.
"
graphics - Effects of single-point and multi-point calls of Point on plot range,"
I'm tempted to blame this on AbsoluteOptions, because it is known to be buggy (I filed a bug report on it in January). I also tried the following
FullGraphics@Show[pl1, Frame -> True]


which shows that the incorrect PlotRange value is in fact used internally, making this a pretty significant bug. 
I would suggest filing a bug report blaming it on AbsoluteOptions (it's just a guess, but hey - we don't have the source code...)
Update
I think the case against AbsoluteOptions is becoming stronger with the following tests. That means, I'm now pretty confident that the issue in this question is not inherent to the argument-list version of Point. 
Consider the three-dimensional version of the question, with 
pts = RandomReal[10, {30, 3}];
pl1 = Graphics3D[Point@pts];
pl2 = Graphics3D[Point /@ pts];

The results of AbsoluteOptions[pl1, PlotRange] and AbsoluteOptions[pl2, PlotRange] show the same discrepancy as in the 2D case. 
If I now replace the 3D points by spheres, I can use the same two methods of feeding it the points:
sph1 = Graphics3D[Sphere[pts, .05]];
sph2 = Graphics3D[Sphere[#, .05] & /@ pts];

However, the results of 
AbsoluteOptions[sph1, PlotRange]

and 
AbsoluteOptions[sph2, PlotRange]

now both show the incorrect result {PlotRange -> {{0., 1.}, {0., 1.}, {0., 1.}}}. What I would infer from this is that it is not the listability property itself that is causing a wrong PlotRange calculation. Note: I say ""infer"" - not ""conclude"", because it's not conclusive...
Update 2
For completeness, I sent a bug report to Wolfram in which I gave these examples and stated that AbsoluteOptions doesn't work properly here. Wolfram support confirmed the bug.
"
Deleting parts of a large list,"
I think that one of the reasons your code isn't working is that Delete doesn't actually modify the original list so during every iteration in your Table you're actually working with the original list, not the one that was returned from the previous iteration. One way to solve this is to set CompleteQuarterlyStatData to the result of Delete in every iteration but a more functional way would be to do something like this instead
DeleteCases[CompleteQuarterlyStatData, {_, {}}, {3}]

I would suggest that you familiarise yourself with the use of Patterns in Mathematica. 
Edit
This is probably not the most efficient method, but you could try something like. It seems to work for the example posted by the OP at least.
list = {
        {
         {{{""Australia"", ""GDP""}, {}}, {{""Korea"", ""GDP""}, -2.45}, 
          {{""USA"", ""GDP""}, -2.34}}, 
         {{{""Australia"", ""GDP""}, 2.34}, {{""Korea"", ""GDP""}, 1.23}, 
          {{""USA"", ""GDP""}, 1.45}}}, 
        {
         {{{""Greece"", ""Imports""}, 3.25}, {{""Turkey"", ""Imports""}, {}}, 
          {{""USA"", ""Imports""}, -2.64}}, 
         {{{""Greece"", ""Imports""}, -1.23}, {{""Turkey"", ""Imports""}, 3.56}, 
          {{""USA"", ""Imports""}, -1.56}}
        }
       };   

DeleteCases[list, Alternatives @@ Cases[list, {a_, {}} :> {a, _}, {3}], {3}]


{
   {
    {{{""Korea"", ""GDP""}, -2.45}, {{""USA"", ""GDP""}, -2.34}}, 
    {{{""Korea"", ""GDP""}, 1.23}, {{""USA"", ""GDP""}, 1.45}}}, 
   {
    {{{""Greece"", ""Imports""}, 3.25}, {{""USA"", ""Imports""}, -2.64}}, 
    {{{""Greece"", ""Imports""}, -1.23}, {{""USA"", ""Imports""}, -1.56}}
   }
  }


"
evaluation - How to REALLY Hold arguments and capture FullForm?,"
Ok, what you have here is some classic example of what is called ""Evaluation leaks"". So, first, the corrected code:
ClearAll[capture]
SetAttributes[capture, HoldAllComplete];
capture[expr_ /; AtomQ[Unevaluated[expr]]] := 
    {Head[Unevaluated[expr]], expr};
capture[head_[args___]] := {head, capture /@ Unevaluated[{args}]};

Now, you can inspect it and compare to your version, to see that you had three such ""leaks"": in the pattern-testing AtomQ (which does not hold its arguments), in the r.h.s. Head[expr], since Head also does not hold them, and, perhaps most importantly, in capture/@{args}, since Map does not hold its arguments either. 
So, evaluation leaks are cases when some code which wasn't supposed to evaluate, actually does. Some most frequent situations which lead to evaluation leaks are either when the code is being passed to / anylized by a function which does not hold it properly, or when some parts of held code are extracted during destructuring (e.g. by Cases), not being wrapped in a holding wrapper head.
The standard thing to do to prevent the evaluation once is to wrap your code in Unevaluated, which I did above. To prevent evaluation in a  persistent manner, we usually wrap an expression in Hold, HoldComplete, or perhaps some custom holding wrappers with Hold-attributes, but in such cases you have to take care to strip the holding wrapper when no longer needed. 
Some more involved examples of parse-like functions which avoid evaluation leaks can be found in this answer (function depends) and also here (function parse). The problem of evaluation leaks is a very frequent one once you start working with pieces of unevaluated code, which is particularly common when writing parser-like functions, macros, and other metaprogramming-related functions. You can look at some references in my recent answer on metaprogramming, for some more links to code where prevention of evaluation leaks was essential.
"
programming - Listing subgraphs of G isomorphic to SubG,"
Update: I now recommend using the IGraph/M package instead of the R interface. It offers the following functions for finding subgraphs:

IGSubisomorphicQ tests for subgraph isomorphism, supports multigraphs as well.
IGVF2FindSubisomorphisms lists all matching subgraphs found, supports vertex and edge coloured graphs.
IGLADFindSubisomorphisms lists all matching subgraphs founds, supports vertex colouring, supports looking only for induced sugraphs.


Daniel is completely correct that this is a hard problem and will usually take a very very long time.  However, the igraph library does have a function for it and you can call it through this package.  Please read the instructions on how to set up the package, then do this:
{g, subG} = {PetersenGraph[5, 2], EdgeAdd[CycleGraph[5], 5 <-> 6]}

res = IGraph[""graph.get.subisomorphisms.vf2""][g, subG];

HighlightGraph[g, Subgraph[g, #]] & /@ Round[res + 1]


Use graph.count.subisomorphisms.vf2 to just count the subgraphs but not retrieve them.
"
evaluation - Efficiently evaluating a held expression directly from a list,"
What costs you so much time is your unnecessary packaging of ReleaseHold into an anonymous function. ReleaseHold[#]& is semantically identical to ReleaseHold but much more time expensive. If you replace it with ReleaseHold, the map version is only slightly slower than the direct version (and I guess that's because of the Map logic which has to work with lists of arbitrary length).
Here's what I get after removing the unnecessary anonymous function:
Do      total: 22.849438   per iteration: 2.2849438*10^-6
DoMap   total: 24.159825   per iteration: 2.4159825*10^-6

"
Undocumented Dynamic Function question,"
After your last comment, maybe you should assing the value of cyL[change[x]] to another variable in the dynamic, and use it outside. Something like this:

"
version 8 - Wavelet Packet Transform in Mathematica 7 and 8,"
After consulting a friend of mine P.M. I can tell you this. First of all as @Szabolcs @ruebenko already mentions - in order to get a comparison with Wavelet explorer (v7) to v8, you can go to the following link in the documentation center which shows how the syntax has changed:
http://reference.wolfram.com/mathematica/Compatibility/tutorial/WaveletExplorer.html
For the problem at hand, if you want location of the spike, perhaps using continuous wavelet transform might give the result easily. Here is an example:
data = N@Table[Sin[4 \[Pi] t] + 2 Exp[-10^5 (1/3 - t)^2], {t, 0, 1, 0.001}];
cwd = ContinuousWaveletTransform[data, PaulWavelet[5], {8, 8}];
ws = WaveletScalogram[cwd, ColorFunction -> ""AvocadoColors""];
posData = Abs[{3, 1} /. cwd[{3, 1}]];
positionOfSpike = Position[posData, Max[posData]];
Print[""Spike is at  "" <> ToString[positionOfSpike[[1, 1]]]]
Row[{ws, ListLinePlot[posData, PlotRange -> All]}]


However, for multiple spikes, he may have to make careful use of a local FindMaximum. Another useful thing is this:
data = N@Table[
    Sin[4 \[Pi] t] + 2 Exp[-10^5 (1/3 - t)^2], {t, 0, 1, 0.001}];
dwd = DiscreteWaveletPacketTransform[data, Automatic, 5];
Manipulate[
 tmp = WaveletThreshold[
   WaveletBestBasis[dwd, {""Threshold"", bestBasisThreshold}], {""Hard"", 
    waveletThreshold}];
 recon = InverseWaveletTransform[tmp];
 GraphicsRow[{ListLinePlot[recon, PlotLabel -> ""Reconstruction""], 
   ListLinePlot[data - recon, PlotLabel -> ""Error""]}, 
  ImageSize -> 500], {bestBasisThreshold, 0.001, 0.99, 
  Appearance -> ""Labeled""}, {waveletThreshold, 0.001, 0.99, 
  Appearance -> ""Labeled""}]


The manipulate above shows the interplay between wavelet best basis and wavelet threshold. For more information, we would recommend going to the documentation page:
WaveletBestBasis > Applications > Compressions.
and go through the examples.
"
syntax - Explanation on why Compile statement works only if input and output sizes work,"
This had been piquing my curiosity for a few days, but I finally found why!
The reason is a tiny sentence hidden in the documentation of Compile, which has drastic consequences I had not realized before:

Ordinary Mathematica code can be called from within compiled code. Results obtained from the Mathematica code are assumed to be approximate real numbers, unless specified otherwise by the third argument of Compile.

So, there you have it: if you use
Compile[{{m, _Real, 2}}, Fourier[m]]

then compilation assumes that Fourier returns a real values. When you evaluate this, and the returned values turn out to be complex, you get your error message:

CompiledFunction::cfex: Could not complete external evaluation at instruction 1; proceeding with uncompiled evaluation.

When you specify that Fourier returns complex values, using the third argument to Compile, 
things work better as you found out.

Also, you can fully confirm that the issue here is with the number type (i.e. real vs. complex) rather than the rank, by trying your first code with FourierDST, which returns real numbers and does not emit the error:
Compile[{{m, _Real, 2}}, FourierDST[m]] @ Table[N[i - j], {i, 4}, {j, 4}]

"
plotting - Plot Indefinite integral,"
You could do the indefinite integral and put in the limits
afterwards. E.g., on Linux I get a speed-up of about 14 for 
one integral (I have no time to do more right now ...)
Mathematica 8.0 for Linux x86 (64-bit)
Copyright 1988-2011 Wolfram Research, Inc.

In[1]:= !!i
Print[""timing 1: "", 
First @ AbsoluteTiming[
  Pw3 = ExpandAll[(Exp[-0.25/t]/t)*
     Integrate[
      Exp[-((Tan[60*Degree]^2*
           (z + 30)^2)/(4*t))]*
       (1 + 2*Sum[Exp[-(n^2*Pi^2*t)/
            100^2]*Cos[0.8*n*Pi]*
           Cos[n*(Pi/2) - n*Pi*
            (z/100)], {n, 1, 100}]), 
      {z, -50, 50}]]; ]
];
Print[""timing 2 : "", 
First @ AbsoluteTiming[
  nPw3 = Expand[(Exp[-0.25/t]/t)*
     ((#1 /. z -> 50) - (#1 /. 
         z -> -50) & )[
      ParallelMap[(ExpandAll[Integrate[#1, z]] & ),
       (TrigToExp[Expand[
          Exp[-((Tan[60*Degree]^2*
            (z + 30)^2)/(4*t))]*
           (1 + 2*Sum[Exp[-(n^2*Pi^2*
            t)/100^2]*Cos[0.8*n*Pi]*
            Cos[n*(Pi/2) - n*Pi*
            (z/100)], {n, 1, 
            100}])]])]] ]; ]
]
Print[""check "", Chop[Pw3 - nPw3]]

In[1]:= <<i
timing 1: 75.121517
Launching kernels...       Mathematica 8.0 for Linux x86 (64-bit) Copyright 1988-2011 Wolfram Research, Inc.                                                                                                            
timing 2 : 5.255553                                                                                                                    
check 0                                                                                     

"
graphics - How to partition a disk into individually spaced bricks?,"
This is far from perfect, but can be easily improved. The method is simple: building up the disk line-by-line by finding enough words of appropriate sizes to fill up each line. There is plenty of room to optimize spacing, but since it already gives a densely packed circle, I leave it as it is for the moment.
Updated code: now it runs much faster as only a minimal amount of image processing is involved.
First, specify style, number of rows and a set of words:
style = {FontFamily -> ""Helvetica"", 
   FontSize -> 12}; (* list of style specifications for framed words *)
colorStyle = ""BlueGreenYellow""; (* color background of bricks *)
margins = 3; (* frame margins for bricks *)
rows = 20; (* number of rows of bricks *)
words = RandomSample[DictionaryLookup[{""Latin"", ""*""}], 200];

Unfortunatly, to measure the exact length of words, one has to convert them to raster images, as there is no direct font-to-curve conversion is available out of the box, and font vectorization is even slower than simply rasterizing each word. However, thanks to Pillsy's clever shortcut, this part can be made lightning fast too:
getTextLength[texts_List] := 
  With[{data = Rasterize[Column@texts, ""Data""]},
   With[{black = {0, 0, 0}}, Cases[data, 
      line : {black, black, __} :> Count[line, black]]][[1 ;; ;; 2]]];

lengths = getTextLength@(Framed[#, FrameMargins -> margins, 
      BaseStyle -> style] & /@ words); (* word lengths in pixels *)
wordHeight = Last@ImageDimensions@Rasterize@
    Framed[First@words, FrameMargins -> margins, 
     BaseStyle -> style];(* word height in pixels - this is assumed to be the same for each word *)
lineHeight = N[2/rows]; (* disk is in the {-1, 1} interval,total height is 2 *)
wordLengths = (#*(lineHeight/wordHeight)) & /@ lengths;
(* convert pixel lengths to coordinate lengths *)

The following two functions help on positioning and finding suitable words, respectively:
(* get width of each line of bricks in the disk *)
getX[y_] := Sqrt[1 - (y - lineHeight/2)^2];
lineWidths = 
  Table[{(getX@y)*2, -getX@y, y - lineHeight/2}, {y, -1 + lineHeight, 
    1, lineHeight}];

(* function to find a word that fits a given width w, and removes word from word & length lists *)
getWord[w_] := Module[{word, length, pos, coord},
   pos = Position[wordLengths, a_ /; a <= w, 1, 1][[1, 1]];(* 
   find a word that fits the given width *)
   word = words[[pos]];
   length = wordLengths[[pos]];
   words = Delete[words, pos];(* remove word from global list *)
   wordLengths = Delete[wordLengths, pos]; (* 
   remove length from global list *)
   {word, length}
   ];

Now iterate through each line of the disk and fill them up with words:
wordCoordinates = 
  Module[{defW, space, x, y, pos, word, length, coord, found = {}, 
      evenly},
     {defW, x, y} = #;
     space = defW;
     While[(* 
      look for words in lexicon until given width is filled up *)
      space > 0 \[And] Min@wordLengths <= space,
      {word, length} = getWord@space;
      AppendTo[found, {word, {x + length/2 + defW - space, y}}];
      space = Max[0, space - length];
      ];
     evenly = 
      Table[{0, {space*i/(Length@found - 1), 0}}, {i, 0, 
        Length@found - 1}];(* shift entries if there is leftover space *)
     found + evenly
     ] & /@ lineWidths;

Put everything together. Note, that choosing an appropriate image size is important:
diskBricks = Graphics[{
   Module[{color = Lighter@ColorData[colorStyle]@RandomReal[]},
      Mouseover[

       Text[
        Framed[First@#, FrameMargins -> margins, 
         BaseStyle -> Prepend[style, FontColor -> Black], 
         Background -> Lighter@color, FrameStyle -> None], Last@#],
       Text[
        Framed[First@#, FrameMargins -> margins, 
         BaseStyle -> Prepend[style, FontColor -> GrayLevel@.9], 
         Background -> Darker@color, FrameStyle -> Black], Last@#]
       ]

      ] & /@ Flatten[wordCoordinates, 1]
   }, Axes -> False, ImageSize -> 500]


"
differential equations - NDSolve Problem,"
This is a very frequently asked question, but I agree it might not be so easy to find out what is happening.  The solution is defining the functions as
f[x_ ? NumericQ] := ...

to prevent them from evaluating for non-numerical arguments
"
image processing - Using ImageCapture to access a USB webcam in linux,"
Yes it is possible, but it is not natively supported. Therefore, the way through ImageCapture will not work here. Nevertheless, no one prevents you to use a library like opencv to access the webcam. With a MathLink wrapper you can write a routine to catch frames from the cam and transfer them as Image to Mathematica.
When opencv is initialized and has opened your cam, the pure catching routine is in the simplest case very short:
void catchFrame(void){
  if(!frame){
    MLPutSymbol(stdlink,""$Failed"");
    return;
  }
  long dims[3],size,mu;
  int *bm;

  dims[0]=frame->height;
  dims[1]=frame->width;
  dims[2]=frame->nChannels;
  size=dims[0]*dims[1];
  mu=size*dims[2];
  bm=new int[mu];
  for(long i=0; i<size; i++) {
    bm[3*i]=(unsigned char)frame->imageData[3*i+2];
    bm[3*i+1]=(unsigned char)frame->imageData[3*i+1];
    bm[3*i+2]=(unsigned char)frame->imageData[3*i];
   } 
  MLPutFunction(stdlink,""Image"",2); 
  MLPutIntegerArray(stdlink,bm,dims,NULL,3);
  MLPutString(stdlink,""Byte"");

  delete[] bm;
  }

I admit that this approach is not as simple as calling ImageCapture, but if you are willing to install opencv and cweb I could send you an implementation. It was once written by Jens-Peer Kuska and I only made it work for Mathematica 8.0 and its Image-framework.
Update
I made a pure C version (without CWeb) and added a detailed how-to-use comment. You can download the file from here and with a bit of luck you can use images from your webcam in a few minutes.
"
graphics - Producing a bar chart with height and color determined by two distinct lists,"
Here's one approach, where we compute the heights using the first part of the results from Tally, and the colors using the second part.  Then it's just a simple use of ChartStyle.
list = Sort@RandomInteger[{1, 10}, 20]

(*
==> {1, 2, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10}
*)

{height, color} = Transpose[Tally[list]]

(*
==> {{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {1, 3, 1, 1, 2, 1, 1, 7, 1, 2}}
*)

color = ColorData[""Rainbow""] /@ Rescale[color];

BarChart[height, ChartStyle -> color, BarSpacing -> 0, 
 ChartBaseStyle -> EdgeForm[]]


"
How to match a pattern with a pattern?,"
Use Verbatim. It was explicitly designed as an escaping mechanism for patterns. In this particular case:
Cases[rules, 
  _?(MatchQ[First@#, 
       b | a | (Verbatim[Alternatives][elems___] /; MemberQ[{elems}, a | b])] &
    )
]

will do the trick.
"
import - Difficulties with Importing PDFs in Mathematica,"
If it's really scanned images, then you could try this:
pages = Import[""yourfile.pdf"", {""PDF"", ""Images""}]

Otherwise, I'd suggest running the file through ghostscript or another distiller to clean up the potentially malformed PDF code first. The command would look like this:
gs -dSAFER -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile=newfile.pdf badfile.pdf

Edit
Since you mentioned that you're on Mac OS X and also appear to be able to view the PDF file in Preview.app, there is an even simpler way: 
If you're on Lion: Open the PDF in Preview, and export it as multipage TIFF. This can be done under the File > Export menu. The resulting file can be imported in Mathematica and yields a list of images.
Another possible approach that works for all OS X versions is to open the PDF in Preview and print it to a file. With that method, you could also select only the pages you really need by highlighting them in the Thumbnail view, and then choosing File > Print Selected Pages.... The PDF-printed file would hopefully have been processed to get rid of the errors. 
"
Fitting fractional complex data with NonlinearModelfit,"
This is, at least in principle, a duplicate of jVincent's answer and the one I gave here. The general approach has been suggested by various people over the years, although I first encountered it here courtesy of Daniel Lichtblau the first time I needed to fit several datasets simultaneously.
I've been meaning to post this package for a while, ideally after having generalized it further, but given that generalization is somewhat complicated, and yet this remains a common question, I think on balance it's probably worthwhile to post the code as it stands. Despite certain limitations (listed below), it seems good enough for most applications that require fitting complex data.
BeginPackage[""TransformedFit`""];

ClearAll[TransformedParameter];
SetAttributes[TransformedParameter, HoldRest];

Unprotect[TransformedFit]; ClearAll[TransformedFit];

Unprotect[ComplexFit]; ClearAll[ComplexFit];

Begin[""`Private`""];

(* Transform numeric quantities rather than renaming them *)
TransformedParameter[t_, num_?NumericQ] := t[num];

(* Generate unique symbols for each transformed parameter -- this avoids difficulties
caused by overzealous common subexpression elimination when the models are compiled *)
TransformedParameter[t_, p_] := TransformedParameter[t, p] =
   With[{sym = Unique[""TransformedParameter$"", Temporary]},
    (* Unset memo when cleared to facilitate garbage collection *)
    sym /: clear : (Clear | ClearAll | Remove)[___, sym, ___] :=
     clear /; (TransformedParameter[t, p] =.; True);

    (* Display as the parameter by itself if the transformation is Identity *)
    sym /: MakeBoxes[sym, form_] :=
     With[{boxes = MakeBoxes[p, form]},
       InterpretationBox[boxes, sym]
      ] /; t === Identity;

    sym /: MakeBoxes[sym, form_] :=
     With[{boxes = MakeBoxes[t[p], form]},
      InterpretationBox[boxes, sym]
     ];

    sym
   ];

ClearAll[$FitFunctions];
$FitFunctions = If[$VersionNumber >= 7,
   {FindFit, NonlinearModelFit},
   {FindFit}
  ];

Options[TransformedFit] = {
   ""FitFunction"" -> First[$FitFunctions],
   ""Transformation"" -> Identity,
   ""ParameterTransformation"" -> Identity,
   ""Hold"" -> False
  };

TransformedFit::cons = 
  ""The constraint(s), `1`, should be given in terms of the transformed parameters only."";

TransformedFit[
    data_, {model_, cons_}, pars_, vars_,
    opts___
   ] /; Internal`DependsOnQ[cons, pars] :=
  Message[TransformedFit::cons, cons];

(* Deal with data given as ordinate values only *)
TransformedFit[
   data_?VectorQ, model_, pars_, vars_,
   opts : OptionsPattern[{TransformedFit, Sequence @@ $FitFunctions}]
  ] :=
  TransformedFit[
   Transpose[{Range@Length[data], data}], model, pars, vars,
   opts
  ];

TransformedFit[
   data_?MatrixQ, {model_, cons_} | {model_} | model_, pars_, vars_,
   opts : OptionsPattern[{TransformedFit, Sequence @@ $FitFunctions}]
  ] :=
  With[{
    fitFunction = If[MemberQ[$FitFunctions, #], #, First[$FitFunctions]] & @ OptionValue[""FitFunction""],
    transformations = List@OptionValue[""Transformation""]~Flatten~1
   },
   Block[{
     transformedData,
     transformedParameters, unusedParameterMask, parameterRules,
     transformedModel,
     i
    },
    (* TRANSFORM DATA *)
    With[{
      abscissae = Take[data, All, {1, -2}],
      ordinates = Take[data, All, {-1}]
     },
     transformedData = {
         ConstantArray[Range@Length[transformations], {Length[abscissae], 1}]~Transpose~{2, 3, 1},
         ConstantArray[abscissae, Length[transformations]],
         Through@transformations[ordinates]
        }~Flatten~{{2, 3}, {1, 4}};
     ];

    (* TRANSFORM PARAMETERS *)
    transformedParameters = Outer[
       TransformedParameter,
       transformations, {pars}~Flatten~1
      ] // Transpose;
    With[{
      (* Original and transformed parameters without initial guesses *)
      originalParameterNames = Replace[pars, {p_, __?NumericQ} :> p, {1}],
      transformedParameterNames = Replace[transformedParameters, {p_, __?NumericQ} :> p, {2}]
     },
     With[{
        (* Representations of the original parameters in terms of their transformations *)
        parameterRepresentations = OptionValue[""ParameterTransformation""] @@@ transformedParameterNames
       },
       unusedParameterMask = MapThread[
         Composition[Thread, Unevaluated, FreeQ],
         {parameterRepresentations, transformedParameterNames}
        ];
       Clear @@  Flatten@Pick[transformedParameterNames, unusedParameterMask];
       parameterRules = Thread[originalParameterNames -> parameterRepresentations];
      ];
    ];

    (* TRANSFORM MODEL *)
    With[{
      reparameterizedModel = model /. parameterRules,
      KroneckerDelta = If[Equal[##], 1, 0] & (* compilable *)
     },
     transformedModel = Inner[
        #1[reparameterizedModel] KroneckerDelta[i, #2] &,
        transformations, Range@Length[transformations]
       ];
    ];

    (* PERFORM FIT *)
    If[TrueQ@OptionValue[""Hold""], Composition[Hold, fitFunction], fitFunction][
     transformedData,
     {transformedModel, cons},
     Pick[transformedParameters, unusedParameterMask, False]~Flatten~1,
     {i, vars}~Flatten~1,
     FilterRules[{opts}, Options[fitFunction]]
    ]
   ]
  ];

Protect[TransformedFit];

ClearAll[coordinateSystemRules];
coordinateSystemRules[""Cartesian""] = Sequence[
   ""Transformation"" -> {Re, Im},
   ""ParameterTransformation"" -> (#1 + I #2 &)
  ];
coordinateSystemRules[""Polar""] = Sequence[
   ""Transformation"" -> {Abs, Arg},
   ""ParameterTransformation"" -> (#1 Exp[I #2] &)
  ];
coordinateSystemRules[""Real""] = Sequence[
   ""Transformation"" -> {Re, Im},
   ""ParameterTransformation"" -> (#1 &)
  ];
coordinateSystemRules[""Imaginary""] = Sequence[
   ""Transformation"" -> {Re, Im},
   ""ParameterTransformation"" -> (I #2 &)
  ];
(* Default to Cartesian coordinates *)
coordinateSystemRules[_] = coordinateSystemRules[""Cartesian""];

Options[ComplexFit] = {
   ""CoordinateSystem"" -> Automatic
  };

ComplexFit[
   data_, model_, pars_, vars_,
   opts : OptionsPattern[{ComplexFit, TransformedFit, Sequence @@ $FitFunctions}]
  ] :=
  TransformedFit[
   data, model, pars, vars,
   coordinateSystemRules@OptionValue[""CoordinateSystem""],
   FilterRules[{opts}, Except[""CoordinateSystem"" | ""Transformation"" | ""ParameterTransformation""]]
  ];

Protect[ComplexFit];

End[];

EndPackage[];

Package (.m) and notebook files are also available.
The primary limitations are:

the Weights option is not (directly) supported, because it isn't clear to me how one should transform the weights in general when splitting a complex-valued function into a multivalued real mapping
the returned FittedModel objects still contain a reference to an index, i, that labels the coordinates (e.g. real line/imaginary line, modulus/argument, or whatever applies to any other coordinate system one may choose), because the structure of these objects is undocumented and I didn't yet figure out how to split them up
the transformation is done quite rigidly and is not currently versatile enough to cater for all foreseeable situations

Anyway, let's give it a try:
ComplexFit[
  Table[{i, I + 3*i^2 I}, {i, 0, 10}],
  a + b*x^2 I, {a, b}, x,
  ""FitFunction"" -> NonlinearModelFit
 ][""ParameterConfidenceIntervalTable""]


Or, in polar coordinates:
ComplexFit[
  Table[{i, I + 3*i^2 I}, {i, 0, 10}],
  a + b*x^2 I, {a, b}, x,
  ""FitFunction"" -> NonlinearModelFit,
  ""CoordinateSystem"" -> ""Polar""
 ][""ParameterConfidenceIntervalTable""]


And, just for fun, here's an example using FindFit instead of NonlinearModelFit, and where the parameters and the initial guesses of their values are explicitly complex:
ComplexFit[
 Table[{x, (17.381 + 53.249 I) x^(1.897 + 0.632 I)}, {x, -10, 10}],
 (a x^b), {{a, 20 + 50 I}, {b, 2 + 0.5 I}}, x
]
(* -> {Re[a] -> 17.381, Im[a] -> 53.249, Re[b] -> 1.897, Im[b] -> 0.632} *)

This is also useful for fitting real-valued data where the model may become erroneously complex-valued for certain values of the parameters. For example, from the other question:
ComplexFit[
 {{0.0, 100.0}, {0.02, 81.87}, {0.04, 67.03},
  {0.06, 54.88}, {0.08, 44.93}, {0.10, 36.76}},
 a b^t, {a, b}, t,
 ""CoordinateSystem"" -> ""Real""
]
(* -> {Re[a] -> 100.004, Re[b] -> 0.0000452493} *)

"
plotting - Arrows on axes in Plot3D,"
Here is a simple way to do this:
arrowAxes[arrowLength_] :=
  Map[{Apply[RGBColor, #], Arrow[Tube[{{0, 0, 0}, #}]]} &, 
   arrowLength IdentityMatrix[3]]

This function draws three axes with arrows. To apply it:
Graphics3D[{Sphere[], arrowAxes[3]}]


This doesn't have axis labels, though. 
To add labels by leveraging the built-in axes, one compromise (to save the work of making all labels by hand) would be to do the following:
Graphics3D[{Sphere[{1, 1, 1}], arrowAxes[3]}, Axes -> True, 
 Boxed -> False, AxesOrigin -> {0, 0, 0}, AxesStyle -> Opacity[0], 
 TicksStyle -> Opacity[1]]


Edit
In my attempt at a labeled set of axes above, I deliberately set the axes to be invisible but left the ticks visible. You may find it more visually consistent to keep the default axes visible, together with the new 3D arrow-axes. For this, one could replace AxesStyle above with this: AxesStyle -> MapThread[RGBColor, IdentityMatrix[3]].
"
output formatting - hat not big enough,"
This answer is just a quick hack. I think that to make true extensible character might not be something that an end-user can do... 
Anyway, redefine the formatting for OverHat using
OverHat /: MakeBoxes[OverHat[a_], form_] := 
 With[{s = First[Rasterize[a, ""RasterSize""]], 
   ab = MakeBoxes[a]}, With[{sl = N[2 Log[2 s]]},
   InterpretationBox[OverscriptBox[ab, 
     TagBox[GraphicsBox[LineBox[{{-s, 0}, {0, sl}, {s, 0}}], 
       ImageSize -> {s, Automatic}], ""LongOverHat"", 
      Selectable -> False]], OverHat[a]]]]

Then, just type in the expression as per normal, e.g., 
,
and then select the OverHat expression and reformat the boxes using the menu command Cell > Convert To > Standard From 
(which can also be done using the shortcut 
CtrlShiftN) to get 
. The FullForm of this expression is OverHat[abc].
Here's an example showing how the modified OverHat scales for longer expressions

The MakeBoxes command also works with TraditionalForm (CtrlShiftT), but you might want to modify it to include an 
AdjustmentBox[..., BoxBaselineShift -> b] in order to get the vertical spacing looking right.
"
kernel - Aborting evaluation when the memory exceeds a certain limit,"
Since one may not always accurately predict when MemoryContrained is needed, I recommend setting up a watch-dog task.  Belisarius described how to do this here in answer to my question.  I will reproduce it below as answers that are merely links are discouraged.


In Mathematica 8 you could start a memory watchdog, something along
  the lines of:
maxMemAllowed        = 1.3 1024^3; (*1.3 GB*);
intervalBetweenTests = 1; (*seconds*)
iAmAliveSignal       = 0;
Dynamic[iAmAliveSignal]
RunScheduledTask[
       If[MemoryInUse[] > maxMemAllowed , Quit[], iAmAliveSignal++],      
       intervalBetweenTests];

Remember to run
RemoveScheduledTask[ScheduledTasks[]];

to disable it.

"
evaluation - Making a symbol's new definitions be tried before all previously defined ones,"
I will suggest a solution for DownValues - based definitions, but it may be generalized to other types of definitions as well. I will only consider a case of a single symbol, but again, the generalization is rather straightforward. You will also have to execute your code in a special dynamic environment. 
A first ingredient of my suggestion is a (slightly modified) symbol-cloning functionality described here:
Clear[GlobalProperties];
GlobalProperties[] := 
 {OwnValues, DownValues, SubValues, UpValues, 
    NValues, FormatValues, Options, DefaultValues, Attributes};

ClearAll[clone];
Attributes[clone] = {HoldAll};
clone[s_Symbol, new_Symbol] :=
  With[{clone = new, sopts = Options[Unevaluated[s]]},
    With[{setProp = (#[clone] = (#[s] /. HoldPattern[s] :> clone)) &},
      Map[setProp, DeleteCases[GlobalProperties[], Options]];
      If[sopts =!= {}, Options[clone] = (sopts /. HoldPattern[s] :> clone)];
      HoldPattern[s] :> clone]]

Here comes my suggested dynamic environment then:
ClearAll[withUserDefs];
SetAttributes[withUserDefs, HoldAll];
withUserDefs[sym_Symbol, {defs__}, code_] :=
  Module[{s, inSym},
    clone[sym, s];
    Block[{sym},
     defs;
     sym[args___] /; ! TrueQ[inSym] :=
        Block[{sym, inSym = True},
          clone[s, sym];
          With[{result = sym[args]},
             result /; result =!= Unevaluated[sym[args]]
          ]
        ];
     code]];

What is happening here: first, we clone the original symbol. Then, we Block it, and run the definitions which we want to override the previous ones. Then, we add a catch-all definition which uses the Villegas-Gayley trick, but also Block-s the symbol in question again, and inside the inner Block uses the clone to effectively ""unblock"" the symbol to its original defs by reverse-cloning it, and  run those. The extra trick to use With and a shared local variable result is needed to avoid infinite iteration in cases when neither user-defined nor previous rules apply.
Here comes an example:
ClearAll[f];
f[1] = 10;
f[x_] := x^2;
f[x_, y_] := x + y;

And now:
withUserDefs[f, {f[x_] := x^4}, {f[1], f[2], f[1, 2], f[1, 2, 3]}]

(* 
  ==> {1, 16, 3, f[1, 2, 3]}
*)

you can see that in the first two cases, the modified definitions were used, in the third one the original definition was used, and the last one did not match any and evaluated to itself.
One can nest these constructs, and the inner one will override the outer ones then. For example:
withUserDefs[f, {f[x_] := x^4}, 
   withUserDefs[f, {f[1] := 100}, 
     {f[1], f[2], f[1, 2], f[1, 2, 3]}]]

(* 
  ==> {100, 16, 3, f[1, 2, 3]}
*)

You can ask why I wasn't just using the Villegas-Gayley trick by itself, which is much simpler. The answer is that there is no guarantee that the ordering of definitions will be right with it, even if we manually reorder them, and moreover, cases like f[1] = 10 are immune to all reorderings of DownValues and will always be at the top, so can not be dealt with at all, within a pure Villegas-Gayley approach - but can be successfully dealt with in this more complex one.
The suggested approach is as good as the symbol's cloning procedure is. For SubValues, UpValues etc, it should be modified. The full solution involving all possible global rules and multiple symbols will likely look more complex, but I just wanted to illustrate the idea in the simplest possible setting. Also, we probably can not count on such generalization to be fully robust.
"
latex - Unable to convert $\TeX$ input into mathematica,"
Edit
An updated version of this answer is here. I forgot that there was some duplication when I posted the linked answer, but the material in that answer is more recent so I'll update that one and leave this post unchanged.
End edit
The conversion from $\LaTeX$ in general is rather quirky, but I don't see a failure of the kind you see. 
However, there is in fact something wrong: The $\LaTeX$ syntax you're entering is completely valid and it should be interpreted as the square root of the product of two variables, x and y. However, Mathematica (my version is 8.0.4) incorrectly outputs a single variable xy instead of a product. 
So there is really a bug in how products are interpreted. The work-around is to put thin spaces in your $\LaTeX$ code explicitly, as in
ToExpression[""\\sqrt{x\\,y}"",TeXForm]

Now the question still is why your conversion failed. My only explanation for that would be that before executing the ToExpression, you might have had a global variable by the name xy defined in Mathematica, for which it turned out to be impossible to take the square root. You could test this by first typing Clear[xy,x,y] and then re-trying the conversion from $\LaTeX$.
Edit
To expand a little on the quirks of $\LaTeX$-to-Mathematica conversion, here are some more points to watch out for:

To translate integrals properly, Mathematica expects the integration variable in the $\LaTeX$ code to be preceded by \\, d. Only with the additional space will it recognize the d as the differential part of the integral.
Express derivatives using the \\partial symbol ($\partial$):     ToExpression[""\\frac{\\partial^2 f(x)}{\\partial x^2}"", TeXForm, Hold]
In the above code, the argument Hold prevents evaluation so you can copy the expression from the output cell if desired (you can later apply ReleaseHold to evaluate the expression)
All matrices and vectors must be written in list form using escaped curly brackets, as in \\{x,y,f (z)\\}. The conversion of array environments or commands such as \pmatrix to Mathematica produces wrong formatting.
To group expressions, use only round parentheses, i.e., \\left( and \\right), not square [...] or curly {...} brackets. The latter are interpreted differently by Mathematica. 

I copied this list from this my web page where I also collected some notes on the reverse process of getting equations out of Mathematica.
Edit 2
A comment by RM below brings to mind another point that is related more to $\LaTeX$: some novice authors write lazy expressions like $volume = length \times area$ and wonder why the typeset equation has unnatural-looking character spacing inside the ""words"" used here as variables. The reason is that $\TeX$ considers each single character in a sequence such as volume to be a single variable and applies the corresponding horizontal spacing rules to them. 
Not knowing this feature, you may think that Mathematica has every right to interpret x y and likewise xy as the name of a single variable ""xy"". However, that goes against the rules of the $\TeX$ language and is therefore an incorrect translation. 
"
plotting - How to plot two sets of data on one ListLinePlot,"
Instead of ListLinePlot[ list1, list2 ] use ListLinePlot[ {list1, list2} ].
"
numerical integration - NDSolve does not give me the expected solution,"
If your friend used MATLAB's ode15s solver, then your equations are most likely stiff, and the default NDSolve options are unlikely to give you a numerically stable result unless your step sizes are insanely small. You'll need a stiff solver instead. 
For examples on how to proceed in Mathematica, look at tutorial/NDSolveStiffnessTest. Specifically, explore the methods ""StiffnessSwitching"", ""StiffnessTest"" and ""NonStiffTest"". Since you haven't described your system, there is nothing more I can say at this point, but these hints should give provide a good starting point for you. 
"
"compatibility - Internal ""Periodical"" functions in version 7","
You can turn this then into a package, and change the lower-case to uppercase... Hope it works well enough for your goals. If not, we'll improve it in time
AppendTo[$ContextPath, ""Internal`""];

ClearAll[""`private`*""];
SetAttributes[`private`count, HoldRest];
`private`count[_, expr_, count_Symbol][id_, ___] /; 
  Block[{$scheduledTask = `private`getST[id]}, expr; ++count]/;False := Null
e : `private`count[i_, _, count_Symbol][id_, endFun : _ : (Null &)] /;
   count === i := (Remove[count]; RemovePeriodical[e]; endFun[])
`private`count[___][___] := Null

`private`getST[id_] /; 
  MemberQ[scheduledTasks[], scheduledTaskObject[id, ___]] := 
 First@Cases[scheduledTasks[], scheduledTaskObject[id, ___]]
`private`getST[_] := $Failed;

`private`STQ[scheduledTaskObject[id_, expr_, time_, start_, _]] := 
 Length[Cases[scheduledTasks[]/. HoldPattern@\[Infinity] -> \[Infinity], 
    scheduledTaskObject[id, expr, time, start, _]/. HoldPattern@\[Infinity] -> \[Infinity]]] >= 1
`private`STQ[___] := False;

`private`startScheduledTask[
   st : scheduledTaskObject[id_, 
     expr_, {time_, count_}, (start_ /; start <= AbsoluteTime[]) | 
      Automatic, _]] := 
  Module[{counter = 0}, ClearAttributes[counter, Temporary];
   AddPeriodical[`private`count[count, expr, counter][
     id, `private`startStop[id, False] &], time]];

`private`startScheduledTask[
  st : scheduledTaskObject[id_, expr_, {time_, count_}, start_, _]] :=
  start - AbsoluteTime[] /. 
  remaining_ :> 
   With[{pst := `private`startScheduledTask[
       scheduledTaskObject[
        """", `private`startScheduledTask[
         scheduledTaskObject[id, expr, {time, count}, Automatic, 
          False]], {remaining, 1}, Automatic, 
        False]]}, `private`extraTasks[id] = Hold[pst]; pst]

ClearAll[createScheduledTask, startScheduledTask, 
  stopScheduledTask, $scheduledTask, removeScheduledTask, 
      scheduledTasks, scheduledTaskObject, runScheduledTask];
    $scheduledTask::usage = """"; scheduledTaskObject::usage = """";
SetAttributes[{createScheduledTask, runScheduledTask}, HoldFirst];
SetAttributes[scheduledTaskObject, HoldAll];
SetAttributes[{stopScheduledTask, removeScheduledTask}, Listable];


scheduledTasks[] = {}; `private`idCounter = 0;
`private`startStop[st : (sto : scheduledTaskObject)[__], 
   b : True | False] := st /. sto[rest__, _] :> sto[rest, b];
`private`startStop[id_Integer, b : True | False] := 
  scheduledTasks[] = 
   scheduledTasks[] /. 
    e : scheduledTaskObject[id, rest__] :> `private`startStop[e, b];

createScheduledTask[expr_, {time_, count_: 1}, 
   start_: Automatic] := ++`private`idCounter /. 
    c_ :> scheduledTaskObject[c, expr, {time, count}, start, 
      False] /. sto_ :> (AppendTo[scheduledTasks[], sto]; sto);

createScheduledTask[expr_, time_: 1, rest___] := 
  createScheduledTask[expr, {time, \[Infinity]}, rest];

startScheduledTask[
  st : scheduledTaskObject[
     id_, __]?`private`STQ] := (`private`startStop[id, 
   True]; `private`startScheduledTask[st]; Null /; False)
startScheduledTask[s_] := s;

stopScheduledTask[
  st : scheduledTaskObject[id_, 
     expr_, {time_, 
      count_}, __]?`private`STQ] := (Periodicals[] /. {HoldForm[
      i : `private`count[sth__][id, __]] :> 
     Quiet@RemovePeriodical[i]}; `private`extraTasks[id] /. 
   Hold[`private`startScheduledTask[
      scheduledTaskObject[_, e_, ___]]] :> Quiet@RemovePeriodical[e];
  Quiet[`private`extraTasks[id] =.];
  `private`startStop[id, False]; Null /; False)

stopScheduledTask[st_] := st;

runScheduledTask[stuff___] := 
  startScheduledTask@createScheduledTask@stuff~`private`startStop~True;

removeScheduledTask[
  st : scheduledTaskObject[
     id_, __]?`private`STQ] := (stopScheduledTask[st]; 
  scheduledTasks[] = (DeleteCases[scheduledTasks[], 
     scheduledTaskObject[id, __]]); st)
removeScheduledTask[_] := $Failed;

In case you are interested to copy or as reference, here go the usage messages
ToExpression[#, InputForm, Function[name, name::usage, HoldAll]] & /@ 
 Names[""System`*Sche*""]

returns, copied as plain text
{CreateScheduledTask[expr] creates a task that will repeatedly evaluate expr once per second.
CreateScheduledTask[expr,time] creates a task that will repeatedly evaluate expr every time seconds.
CreateScheduledTask[expr,{time}] creates a task that will evaluate expr once after time seconds.
CreateScheduledTask[expr,{time,count}] creates a task that will try evaluating expr once every time seconds up to count times total.
CreateScheduledTask[expr,timespec,start] creates a task that will evaluate expr according to timespec starting at start time.,RemoveScheduledTask[obj] remove the obj from the list of currently set tasks.,ResetScheduledTask[obj] resets scheduled task object obj to the original parameter values.
ResetScheduledTask[obj,timespec]  resets scheduled task timing to timespec.
ResetScheduledTask[obj,timespec,offset] resets scheduled task time offset to offset.,RunScheduledTask[expr] schedules and starts a task that will repeatedly evaluate expr once per second.
RunScheduledTask[expr,time] schedules and starts a task that will repeatedly evaluate expr every time seconds.
RunScheduledTask[expr,{time}] schedules and starts a task that will evaluate expr once after time seconds.
RunScheduledTask[expr,{time,count}] schedules and starts a task that will try evaluating expr once every time seconds up to count times.
RunScheduledTask[expr,timespec,start] schedules a task that will automatically start at start time.,ScheduledTaskObject[id,expr,spec,...]  is a task object specifying future evaluation of expr according to spec.,ScheduledTasks[]  returns a list of ScheduledTaskObject expressions that represent current tasks.,StartScheduledTask[obj] starts the task represented by obj.,StopScheduledTask[obj] deactivates the task obj.,$ScheduledTask returns the current ScheduledTaskObject. }

"
front end - Copy TraditionalForm output to TraditionalForm input while keeping formatting,"
I'm not understanding, or I can't reproduce the behaviour of the pasting of the first part, please post a more concrete example. As to the 0.3333 issue, you could set the NumberMarks option of the input cells to False. Also, if you really meant that you wanted it copied as 0.3333 when your output had been 0.333333 you should also change PrintPrecision to 4
To change the options, a way would be to go to Format-Edit stylesheet, write Input in the box and press enter. Then, select the cell, go to Format->Options inspector. Check that ""Selection"" is set, search for the mentioned options and edit them
After these changes, any machine precision number you type in an Input cell, once you append a ""`"" mark, will be displayed as a rounded number, without the ""`"", and with PrintPrecision digits. However, you won't be losing precision in your calculations
"
programming - Programmatic formatting for Mathematica code,"
Update November 3, 2013
Finally, the formatter has been made much more robust by adding a custom function like MakeBoxes, names CodeFormatterMakeBoxes, to construct simplified box representation. This solves the main problem that the formatter does not currently support many boxes, since CodeFormatterMakeBoxes constructs the pure RowBox-based representation.
Also, added functions CodeFormatterPrint which prints definitions for a given function / symbol, and CodeFormatterSpelunk to make system spelunking easier.
Some things to try:
Import[""https://raw.github.com/lshifr/CodeFormatter/master/CodeFormatter.m""]

and then
CodeFormatterPrint[RunThrough]

CodeFormatterSpelunk[RunThrough]

Basically, the difference is only that CodeFormatterPrint does retain long (fully-qualified) symbol names, while CodeFormatterSpelunk does not. Some more details on spelunking in my answer here.
Update 19th of June, 2013
Code formatter has been extended to support spaces in place of tabs, variable - width tabs and an overall offset. 
This made it possible finally to start using it for code formatting here on SE - check this out!
Also, several other improvements and several bugs fixed.

Short answer
Yes.
Code formatter
While I will be most happy to see other answers to this question, and will hope that there will be better answers than this one, I am also glad to announce the alpha version of the Mathematica code formatter, which I was working on for some time.
The project
The code formatter lives here, and the specific file (package) can be downloaded using 
this link. The code fomatter resides in a package CodeFormatter.m, and has currently two public functions: FullCodeFormat and FullCodeFormatCompact. Both take a piece of code converted to boxes, and return the box form of formatted code. The README file in the project contains the brief description of how to use them, and the  notebook which is included in the project contains many more examples.
Stealing from README, the typical way to use this is to define a helper function like this one:
prn = CellPrint[Cell[BoxData[#], ""Input""]] &

and then, use it like:
prn@FullCodeFormat@MakeBoxes@
   Module[{a, b}, a = 1; Block[{c, d}, c = a + 1; d = b + 2]; b]

Screenshots
These are some screenshots of code pieces processed by FullCodeFormat.




Further plans/development
There are a number of things I plan to add to the formatter and /or develop based on it, such as

Develop the palette to paste code to SE, based on the formatter (this will come out very soon)
Support more boxes
Refactor the code to eliminate the code duplication and better separate the DSL layer
Add more ways to format code

I will start accepting pull requests soon, perhaps after I do the main code refactoring I currently plan. Meanwhile, please do fork me on GitHub if you are interested in playing with this.
Comments, suggestions, bug reports
All welcome. For bug reports, I have not decided yet what would be the best place to put them, but the Issues section on GitHub project repository seems appropriate.
A simplified bare-bones code formatting engine
Here, I will try to explain my approach, and provide a minimal functioning code-formatting ""engine"", which is a simplified version of the one I referred to above. The motivation for this section (and in fact, for placing the entire post here rather than on meta for example), is to make the code of the formatter accessible, and explain it in simple terms. This would allow you to fork the project and modify the formatter easier to suit your needs, should you wish to do so.
Design problems and choices
The main idea here is that while parsed expression is a bit too high-level for the formatting purposes, plus tries to evaluate all the time, the box-level is a bit too low-level, and the formatter based on that has a danger of not being robust. 
Therefore, I take the box input, and create an intermediate inert Mathematica expression representation with preprocess and preformat (see below). The formatting procedure itself has two stages: the format proper - which only decides where to put new lines and tabs, and the tabification stage (tabify), which ""executes"" the tabification instructions given by format at the previous stage. 
This architecture is because there is a certain impedance mismatch between the statement ""I want to move this block of several lines of code one or more tabs to the right"", and the actual way to achieve that with boxes (I suspect, this was one of the major obstacles for implementing code formatter - since I am sure, many people tried that). By separation of these two stages, it was possible to make this tabification abstraction reasonably robust. The final stage is post-formatting (postformat). It takes the result produced by format and tabify, and converts that back to boxes.
By using this 3-layer architecture, I am able to make high-level description of the actual formatting rules, in the definitions of format only, and the rest is taken care of by other layers. This makes the formatter both more robust (because, for example, the tabification engine is rather general and does not depend on specific formatting rules, including those I may wish to add later), and more easily extensible. In a sense, I implemented a very small DSL for code formatting. 
Settings and preprocessing
Now, the code. First comes the only setting we will have here:
$maxLineLength = 70;

this defines the maximal length of line of code, and is used by the formatter to decide which long lines need dissection. 
Next comes the pre-processing function, which serves to remove spaces and tabs possibly existing in the box expression:
ClearAll[preprocess];
preprocess[boxes_] :=
  boxes //.
      {RowBox[{(""\t"" | ""\n"") .., expr___}] :> expr} //.
      {
        s_String /; StringMatchQ[s, Whitespace] :> Sequence[],
            RowBox[{r_RowBox}] :> r
      };

Converting boxes to intermediate inert representation
Now, we will define the heads of our inert intermediate representation, to which we want to transform the original box expression:
ClearAll[$blocks, blockQ];
$blocks = {
   CompoundExpressionBlock, GeneralHeadBlock, GeneralBlock, 
   StatementBlock, NewlineBlock, FinalTabBlock, GeneralSplitHeadBlock,   
   SuppressedCompoundExpressionBlock, CommaSeparatedGeneralBlock     
};

blockQ[block_Symbol] :=    MemberQ[$blocks, block];

The following function will translate the box expression into this intermediate language. It is very simplistic and misses many important cases - a more comprehensive one is in the code of the CodeFormatter` - but it illustrates the general structure. Note that is is recursive, moving from outside to inside.
ClearAll[preformat];

preformat[RowBox[elems : {PatternSequence[_, "";""] ..}]] :=
  SuppressedCompoundExpressionBlock @@ Map[
      Map[preformat, StatementBlock @@ DeleteCases[#, "";""]] &,
      Split[elems, # =!= "";"" &]];

preformat[RowBox[elems : {PatternSequence[_, "";""] .., _}]] :=
  CompoundExpressionBlock @@ Map[
      Map[preformat, StatementBlock @@ DeleteCases[#, "";""]] &,
      Split[elems, # =!= "";"" &]];

preformat[RowBox[elems : {PatternSequence[_, "",""] .., _}]] :=
  CommaSeparatedGeneralBlock @@ 
    Map[preformat, DeleteCases[elems, "",""]];

preformat[RowBox[elems_List]] /; ! FreeQ[elems, ""\n"" | ""\t"", 1] :=
  preformat[RowBox[DeleteCases[elems, ""\n"" | ""\t""]]];

preformat[RowBox[{head_, ""["", elems___, ""]""}]] :=
  GeneralHeadBlock[preformat@head, 
    Sequence @@ Map[preformat, {elems}]];

preformat[RowBox[elems_List]] :=
  GeneralBlock @@ Map[preformat, elems];

preformat[block_?blockQ[args_]] :=
  block @@ Map[preformat, {args}];

preformat[a_?AtomQ] := a;

preformat[expr_] :=
    Throw[{$Failed, expr}, preformat];

You can see that it treats only  few selected heads like CompoundExpression separately, plus has rules for general heads.
Formatting
Next will come two helper functions, used in formatting to determine whether or not a given line of code is too long and needs to be split. The first one, maxLen, determines the maximal length of the code line in an expression, accounting for the fact that it may already have been split into several lines.
Clear[maxLen];
maxLen[boxes : _RowBox ] :=
  Max@Replace[
      Split[Append[Cases[boxes, s_String, Infinity], ""\n""], # =!= ""\n"" &],
      {s___, (""\t"" | "" "") ..., ""\n""} :> 
        Total[{s} /. {""\t"" -> 4, ss_ :> StringLength[ss]}],
      {1}];

maxLen[expr_] :=
  With[ {boxes = postformat@expr},
       maxLen[boxes] /; MatchQ[boxes, _RowBox ]
   ];

maxLen[expr_] :=
  Throw[{$Failed, expr}, maxLen];

Note that maxLen uses not yet defined postformat, which is perhaps a bit stronger coupling between components than desirable, and is a design short-cut to be removed. The next one is a simple convenience function:
ClearAll[needSplitQ];
needSplitQ[expr_, currentTab_] :=
  maxLen[expr] > $maxLineLength - currentTab;

Now comes the main formatting function, format. All specific formatting rules are included here. It takes an intermediate inert expression as a first argument, and the current number of tabs inserted, as a second one. It is also essentially recursive, and processing an expression from outside to inside.
ClearAll[format];
format[expr_] :=  format[expr, 0];    

format[TabBlock[expr_], currentTab_] :=
  TabBlock[format[expr, currentTab + 4]];

format[NewlineBlock[expr_, flag_], currentTab_] :=
  NewlineBlock[format[expr, currentTab], flag];    

format[(ce : (CompoundExpressionBlock | 
    SuppressedCompoundExpressionBlock))[elems__], 
    currentTab_] :=
  With[ {formatted = Map[format[#, currentTab] &, {elems}]},
       (ce @@ Map[NewlineBlock[#, False] &, formatted]) /; 
         !FreeQ[formatted, NewlineBlock]
  ];

format[StatementBlock[el_], currentTab_] :=
    StatementBlock[format[el, currentTab]];

format[expr : GeneralHeadBlock[head_, elems___], currentTab_] :=
  With[ {splitQ = needSplitQ[expr, currentTab]},
       GeneralSplitHeadBlock[
           format[head, currentTab],
           Sequence @@ Map[
               format[If[ splitQ,
                             TabBlock@NewlineBlock[#, False],
                             #
                         ], 
                   currentTab] &,
               {elems}]] /; splitQ
   ];

(* For a generic block, it is not obvious that we have to tab, so we don't*)
format[expr : (block_?blockQ[elems___]), currentTab_] :=
  With[ {splitQ = needSplitQ[expr, currentTab]},
       block @@ Map[
           format[If[ splitQ,
                         NewlineBlock[#, False],
                         #
                     ], currentTab] &,
           {elems}]
   ];

format[a_?AtomQ, _] := a;

You can see that format uses two new block types: NewlineBlock and TabBlock, and the former also accepts a flag which can be True or False. This flag, when being set to True, forces the formatter to create a new line, while when being set to False, tells the formatter to propagate the new line request deeper into the expression. The TabBlock directive also accepts a similar flag. The reason that the flags are needed in this approach is that it is not straightforward to implement the abstraction such as ""move this piece of code one tab to the right"" on the box level, for example because each new line in the boxes must be tabbed separately. 
In any case, format does only part of the job, because it only instructs what must be done. It has a companion, tabify, which actually executes the instructions of format:
ClearAll[tabify];
tabify[expr_] /; ! FreeQ[expr, TabBlock[_]] :=
    tabify[expr //. TabBlock[sub_] :> TabBlock[sub, True]];

tabify[(block_?blockQ /; ! MemberQ[{TabBlock, FinalTabBlock}, block])[
elems___]] :=
    block @@ Map[tabify, {elems}];

tabify[TabBlock[FinalTabBlock[el_, flag_], tflag_]] :=
  FinalTabBlock[tabify[TabBlock[el, tflag]], flag];

tabify[TabBlock[NewlineBlock[el_, flag_], _]] :=
  tabify[NewlineBlock[TabBlock[el, True], flag]];

tabify[TabBlock[t_TabBlock, flag_]] :=
  tabify[TabBlock[tabify[t], flag]];

tabify[TabBlock[(block_?blockQ /; ! MemberQ[{TabBlock}, block])[ 
     elems___], flag_]] :=
  FinalTabBlock[
    block @@ Map[tabify@TabBlock[#, False] &, {elems}],
    flag];

tabify[TabBlock[a_?AtomQ, flag_]] :=
  FinalTabBlock[a, flag];

tabify[expr_] :=  expr;

You can see that it introduces another tab-related block, FinalTabBlock - which is a block that signifies the need to tab a particular line by one tab, and is inert in the sense that once TabBlock is converted to FinalTabBlock, it does not any more actively influence the work of tabify. 
Post-formatting
The final stage of the formatting procedure is to take the  expression  processed with format and tabify. We need one helper function which serves to prevent the addition of several new lines (""gaps"" in the formatted code) , by determining whether or not the next line of code starts with a new line (if so, the NewlineBlock directive around it is ignored): 
ClearAll[isNextNewline];
isNextNewline[_NewlineBlock] := True;

isNextNewline[block : (_?blockQ | TabBlock)[fst_, ___]] :=
  isNextNewline[fst];

isNextNewline[_] := False;

Here is finally the code for the inverse converter from the inert intermediate representation to boxes, postformat:
ClearAll[postformat];
postformat[GeneralBlock[elems__]] :=
  RowBox[postformat /@ {elems}];

postformat[CompoundExpressionBlock[elems__]] :=
  RowBox[Riffle[postformat /@ {elems}, "";""]];

postformat[SuppressedCompoundExpressionBlock[elems__]] :=
  RowBox[Append[Riffle[postformat /@ {elems}, "";""], "";""]];

postformat[GeneralHeadBlock[head_, elems___]] :=
  RowBox[{postformat@head, ""["", 
      Sequence @@ Riffle[postformat /@ {elems}, "",""], ""]""}];

postformat[GeneralSplitHeadBlock[head_, elems___]] :=
  With[ {formattedElems = postformat /@ {elems}},
       RowBox[{postformat@head, ""["",
           Sequence @@ Riffle[Most[formattedElems], "",""],
           Last[formattedElems], ""]""}]
   ];

postformat[GeneralBlock[elems___]] :=
  RowBox[Riffle[postformat /@ {elems}, "",""]];

postformat[StatementBlock[elem_]] :=
  postformat[elem];

postformat[NewlineBlock[elem_?isNextNewline, False]] :=
  postformat@elem;

postformat[CommaSeparatedGeneralBlock[elems__]] :=
  RowBox[Riffle[postformat /@ {elems}, "",""]];

postformat[NewlineBlock[elem_, _]] :=
  RowBox[{""\n"", postformat@elem}];

postformat[FinalTabBlock[expr_, True]] :=
  RowBox[{""\t"", postformat@expr}];

postformat[FinalTabBlock[expr_, False]] :=
  postformat@expr;

postformat[a_?AtomQ] :=  a;

postformat[arg_] :=
  Throw[{$Failed, arg}, postformat];

It is also necessarily recursive, and the code should be pretty much self-documenting.
The final function
The function which brings it all together is very simple:
ClearAll[fullCodeFormat];
fullCodeFormat[boxes_] :=
  postformat@tabify@format@preformat@preprocess@boxes;

Examples and limitations
This very simplified version of the formatter is quite limited. However, it can handle a few not so trivial examples. Here is a rather non-trivial one to try:
prn@fullCodeFormat@MakeBoxes[
   Compile[{{data, _Real, 2}}, 
     Module[{means = Table[0., {maxIndex}], num = Table[0, {maxIndex}], 
        ctr = 0, i = 0, index = 0, resultIndices = Table[0, {maxIndex}], 
          indexHash = Table[0, {maxIndex}]}, 
      Do[index = IntegerPart[data[[i, 2]]];
       means[[index]] += data[[i, 1]];
       num[[index]]++;
       If[indexHash[[index]] == 0, indexHash[[index]] = 1;
       resultIndices[[++ctr]] = index];, {i, Length[data]}];
       resultIndices = Take[resultIndices, ctr];
       Transpose[{resultIndices, 
       means[[resultIndices]] + num[[resultIndices]]}]],(*Module*)
       CompilationTarget -> ""C"", RuntimeOptions -> ""Speed""]]

here is a screenshot of what you should see as a result (prn is defined as prn = CellPrint[Cell[BoxData[#], ""Input""]] &):

Because of the way the final function is written, it is very easy to inspect what is happening in the intermediate stages. For example, you can only apply
format@preformat@preprocess@boxes

to see what format is doing.
This simplified formatter has a number of limitations, so don't expect it to work nicely on code involving e.g. function definitions through SetDelayed, some complex patterns, etc. The real code formatter in the CodeFormatter` package, while having the same core, has a number of additional rules to handle more cases.
"
warning messages - Indeterminate expression. Where?,"
Since you define f[m_,x_] by Sum[a[m,n,x],{n,0,Infinity}] so there are terms in the sum like 0^0 because :
a[0,n,1]=1/2^n ((-1)^n)/((2n)!) Sum[Binomial[0,l] (0-2l)^(2n),{l,0,0}] x^(2n)

When there is a[0,n,1] you start the sum with Sum[Binomial[0,l] (0-2l)^(2n),{l,0,0}] and the first term in the definition of f[m_,x_] is with n==0.
Edit
To prevent generating of messages one can define a[m,n,x] and f[m,x] this way : 
a[m_Integer, n_Integer, x_] /; n > 0 := 
  1/2^n (-1)^n/((2 n)!) Sum[ Binomial[m, l] (m - 2l)^(2n), {l, 0, m}] x^(2 n)
a[m_Integer, 0, x_] := 1
f[m_Integer, x_] := Sum[ a[ m, n, x], {n, 0, Infinity}]

"
list manipulation - How can I multiply matrix and vector element wise like Numpy?,"
The problem is that Mathematica wants to match up $v$ with the rows of $C$. In order to get what you want, you can do:
S=Transpose[Transpose[C]/v]

"
list manipulation - Does Mathematica have advanced indexing?,"
Using a little Mathematica pattern matching, I think you can get similar performance as @Szabolcs's answer while having nice Matlab-style syntax:
replaceWhere[cond_, selectTrue_, selectFalse_] := 
   With[{evaluatedCondition = evaluateTensorCondition[cond]},
        selectTrue*evaluatedCondition + selectFalse*(1 - evaluatedCondition)]

replaceWhere[cond_, selectTrue_] := replaceWhere[cond, selectTrue, 0]

evaluateTensorCondition[a_ > b_] := UnitStep[a - b]    

evaluateTensorCondition[a_ < b_] := UnitStep[b - a]

evaluateTensorCondition[a_ && b_] := 
    evaluateTensorCondition[a]*evaluateTensorCondition[b]

evaluateTensorCondition[a_ || b_] := 
    UnitStep[evaluateTensorCondition[a]+evaluateTensorCondition[b]-1]

(implementing more comparison and logical operators should be straightforward)
Usage:
replaceWhere[T > 15, L, 0]

returns a new list, where every index that is greater than 15 in T is set to 0 , the other elements are the same as L. And it should have similar performance as @Szabolcs's answer, because all the conditions are just transformed into vectorizable tensor operations. (I haven't timed it, though.) 
Note that this works for arbitrarily complex expressions, and the last two parameters can be tensors or scalars:
replaceWhere[(T > 5 && T < 15) || Sin[L]<Cos[T], L, L*2]

If you evaluate this expression symbolically:
Clear[T, L]
replaceWhere[(T > 5 && T < 15) || Sin[L] < Cos[T], L, 0]

you get one long tensor expression composed of UnitStep's
Out = L UnitStep[-1 + UnitStep[15 - T] UnitStep[-5 + T] + UnitStep[Cos[T] - Sin[L]]]

So ""under the hood"" Mathematica will do the same operations as in @Szabolcs's answer. You just get a more readable syntax.

If you don't want to do all those fancy syntax manipulations, you can always use MapThread to combine higher dimensional arrays in any way you'd like. For your question, this would be:
MapThread[If[#1 > 15, 0, #2] &, {T, L}, 2]

This takes the 2d-Tensors (last argument 2) T and L (second argument {T, L}), passes the corresponding elements in the two tensors to a function (first argument If[#1 > 15, 0, #2] &) and returns a new tensor containing the return value of that function. This is slower than @Szabolic's answer, but it is also a lot more flexible.
"
function construction - Can SetDelayed (:=) be compiled?,"
Compile can't handle SetDelayed. 
In your specific case, you might be able to avoid the need for SetDelayed altogether through the use of Boole.
kd[m_, n_] :=If[m == n, 1, 0] can be replaced by Boole[n==m]. (or as FJRA pointed out in comments, by KroneckerDelta.)
cosfun[m_, n_] := 
 If[m == n, 0, (1 - Cos[(m + n) π])/((m + n) π) + 
  ((Cos[(m - n) π] - 1)/((m - n) π))]

can be replaced by  
Boole[m == n] (1 - Cos[(m + n) π])/((m +  n) π) + 
 ((Cos[(m - n) π] - 1)/((m - n) π)) (-I A2 m Pi/L)

Giving
eenew = Compile[{{μ, _Real}, {NNN, _Integer}}, 
  Module[{NN = NNN}, (* do you even need this placeholder for the input? *)
   mm = Table[Boole[m == n] (MM - B2 k k - B1 (m Pi/L)^2), {m, 1, NN}, {n, 1, NN}]; 
   kz =  Table[Boole[m != n] (1 -  Cos[(m + n) π])/((m + n) π) + 
     ((Cos[(m - n) π] - 1)/((m - n) π)) (-I A2 m Pi/L), 
     {m, 1, NN}, {n, 1, NN}]; 
   kxM =   Table[Boole[m == n] A1 k, {m, 1, NN}, {n, 1, NN}]; 
  μM = Table[Boole[m == n] μ, {m, 1, NN}, {n, 1, NN}]; 
   HH =    ArrayFlatten[{{μM + mm, 0 mm, kz, kxM}, 
      {0 mm, μM + mm, kxM, -kz}, {kz, kxM, μM - mm,0 mm}, 
      {kxM, -kz, 0 mm, μM - mm}}]; 
  ees = Table[Eigenvalues[HH], {k, -.1, .1, .01}]]] 

What is k for in this last line? There is no way for the iterator to matter for HH.
This doesn't give the error involving SetDelayed anymore.
"
numerical integration - NIntegrating within an Ellipsoid,"
Why not use elliptical coordinates? That's what they are there for. 
For example, if your function is f[x_,y_], then you define the coordinate transformation 
x[u_, v_]:= Cos[v] Cosh[u];
y[u_, v_]:= Sin[v] Sinh[u];

The Jacobian is Sin[v]^2 + Sinh[u]^2, so you simply do the integral like this:
NIntegrate[
 f[x[u, v], y[u, v]] (Sin[v]^2 + Sinh[u]^2), {u, 0, 1}, {v, 0, 2 Pi}]

That's the basic idea. You can always rotate and scale your function arguments to fit within this particular ellipse which has axis lengths of Cosh[1] and Sinh[1], respectively. You can also adjust the integration limit in {u, 0, 1} to something other than 1 depending on the eccentricity of the ellipse. These steps are easy once you understand the coordinate system. 
You can also do all this using the VectorAnalysis package, but I'd say that is overkill for this relatively simple problem.
Rescaling to a circle in 2D
In fact, you may also want to look into just rescaling your x and y coordinates to fit into a circle and use polar coordinates... (that also generalizes more easily to higher dimensions).
There isn't exactly one built-in function to do the rescaling, but you can probably find all you need by starting at this post. I'll just describe the logic:
Assume you have already figured out the semimajor and -minor axes (vec1 and vec2) as well as the center (in a variable center) of the ellipse. Then you can figure out the rotation angle required to make vec1 the x-axis, leading to a rotation R. The scale transformation T that you need is given by the lengths of vec1 and vec2, resp. 
Now compose your function f[x,y] with these transformations. This transformation introduces a Jacobian given by the product Norm[vec] * Norm[vec2]. 
The final step is to go to polar coordinates which introduces an additional factor r (the radial coordinate). 
Polar coordinates are probably best in this case, unless you plan on doing other manipulations with your function that go beyond integration.
Edit
Turns out it's almost more difficult to describe the transformations in words than it is to do it in Mathematica. So I'm adding the code now:
rescaling = Composition[TranslationTransform[center], 
   RotationTransform[{{1, 0}, vec1}], 
   ScalingTransform[{Norm[vec1], Norm[vec2]}]]

This is now used in the integral of your function which I assume to be defined as 
f[{x_, y_}] := ...

(note that the argument is a single list representing the point). With this, it only remains to write the integral
integrand = Composition[f, rescaling];
polarIntegrand[r_?NumericQ, a_?NumericQ] := 
     integrand[{r Cos[a], r Sin[a]}] r;
NIntegrate[
  polarIntegrand[r,a], 
   {r, 0, 1}, {a, 0, 2 Pi}] Norm[vec1] Norm[vec2]

Here, I've tweaked the integrand a little to make sure we don't get slowed down by Mathematica attempting to symbolically simplify it. The ?NumericQ rules that out. That should be all you need.
"
list manipulation - Defining a string based sort function,"
If all the entries in your array are strings, then one way to sort it is to do something like this:
order[str_String /; 
   StringMatchQ[str, ""T"" ~~ (DigitCharacter | ""p"") .. ~~ ""K""]] := 1
order[str_String /; 
   StringMatchQ[str, ""Vg"" ~~ DigitCharacter .. ~~ ""V""]] := 2
order[str_String /; StringMatchQ[str, ""Ch"" ~~ DigitCharacter ..]] := 3
order[a_] := a

#[[Ordering[order /@ #]]] & /@ list

This method uses the fact that numbers come before strings in an ordered list.
"
linear algebra - Composition of functions,"
The function your looking for is Composition which does exactly what you would like it to do. For instance,
{rot1, rot2} = MapThread[RotationTransform, {{theta1,theta1},{point1,point2}}]
composed = Composition @@ %


Composition[
     RotationTransform[theta1, point1], 
     RotationTransform[theta1, point2]
  ]


which can then be used like rot1 and rot2 would, e.g. composed[ {x, y, z} ]. From some experiments, it seems that Composition will combine multiple TransformationFunction into a single TransformationFunction, e.g.
Composition[ RotationTransform[ Pi/2 ], RotationTransform[ Pi/2] ] ]

simplifies to 
RotationTransform[ Pi ]


Here is a specific example using the following rotations
RotationTransform[Pi/2, {1, 0}]
RotationTransform[Pi/2, {1, 1}]
composed = Composition @@ {%, %%}

which gives the output (it's in picture form as the output is displayed using boxes):

Now, applying them one at a time to a triangle, using the following code
FoldList[
  {EdgeForm[Black], White, #2[#1]} &, 
   Polygon[{{1, 0}, {0, Sqrt[3]}, {-1, 0}}], 
  {# &, 
   GeometricTransformation[#, RotationTransform[Pi/2, {1, 0}]] &, 
   GeometricTransformation[#, RotationTransform[Pi/2, {1, 1}]] &}
][[2 ;;]] //
GraphicsRow[
 Graphics[#, Frame -> True, PlotRange -> {{-3, 3}, {-3, 3}}] & /@ # 
]&

gives

Using the composition directly via
Graphics[{
   EdgeForm[Black], White, 
   GeometricTransformation[
       Polygon[{{1, 0}, {0, Sqrt[3]}, {-1, 0}}], 
       composed]
  }, Frame -> True, PlotRange -> {{-3, 3}, {-3, 3}}]

gives the identical end result

Two things to note here. First, the functions are entered into Composition in reverse order of application, i.e. the first function to be applied is last, and the last function is first. Second, I made use of GeometricTransformation to apply the rotations to a Graphics primitive.
"
packages - $InputFileName backwards compatibility,"
You can try
System`Private`$InputFileName

Seems to work on M7, not sure about M6.
"
web access - Mathematica Import functions fails for data download from website,"
The user agent (requester_id) probably isn't the issue. Indeed, Mathematica does not appear as a standard browser to web servers (it identifies itself as Mathematica), but that usually isn't an issue for normal HTML pages. And indeed Squid can solve problems if your page is testing for a specific browser (see also an earlier question on user agents)
For pages that are partly generated by a Javascript script this is different, as Mathematica does not interpret Javascript. I don't think you can get this to work.
"
"performance tuning - Making a ""cached"" version of `Manipulate[]`?","
The following code demonstrates a bit of caching. The initialization code is run only once, because the variable cached which is saved in the Manipulate remembers the cached state. So when you copy the Manipulate into an empty notebook and open this in a fresh session, the cached plots stored in the saved variable plot (stored because of the SaveDefinitions option) won't be calculated again. 
Remove the cached = True line and insert a Print[""Init""] before the Plot command to see that plot is recalculated when the notebook  containing the Manipulate is opened and viewed in a fresh session (without explicitly executing any code).
DynamicModule[{cached, plot},
 Manipulate[
  plot[[kx, ky]],
  {kx, 1, 10, 1},
  {ky, 1, 10, 1},
  Initialization :> {
    If[\[Not] TrueQ[cached],
     plot = 
      Table[Plot3D[
        Sin[kx x] Cos[ky y], {x, 0, \[Pi]}, {y, 0, \[Pi]}], {kx, 10}, {ky, 10}];
     cached = True
     ]},
  SaveDefinitions -> True,
  SynchronousInitialization -> False
  ]
 ]


"
probability or statistics - Most efficient way to obtain samples from high-dimensional multivariate distributions?,"
Multivariate distributions do not require any named variables. My hunch is that your confusion in this regard is due to the excessive use of {{1, ρ}, {ρ, 1}} in the documentation for MultivariateTDistribution. You might've missed the fact that in most cases, the value for ρ is being substituted via a Table or a ParallelTable. 
You can directly input your covariance matrix (and any additional parameters depending on the distribution) and call RandomVariate to draw from that. For your example:
Σ = With[{ρ = 0.2}, SparseArray[{i_, i_} -> 1, {100, 100}, ρ]];
x = RandomVariate[MultivariateTDistribution[Σ, 10], {100}];

This will generate 100 samples of multivariate T distributed random vectors, each of length 100.
"
curated data - WordData for other languages,"
The current references for WordData can be seen online.
If you would like to suggest an addition, there is a link where you can suggest additional functionality.
"
custom notation - How to use subscript in pattern names?,"
You can use Symbolize, from the Notation package following the tutorial as you did.
Then, just take the precaution of writing the pattern with its head explicit, such as: Pattern[xr, _]
The problem is that Mathematica can't interpret the short notation for patterns (xr_ for example) if it has a box structure before the ""_""
"
performance tuning - Plot on command within DynamicModule?,"
If you want the user to have absolute control over updates...say, by having an explicit Update button, then you can do so by adding an independent variable to control the updating and changing your Dynamic so that it only tracks that variable. Here, I introduce a variable update, which is an integer. Its value and type don't matter...what matter is that the Dynamic only updates when that variable does:
DynamicModule[{a = 0, b = 0, update = 0}, 
 Column[{Slider[Dynamic[a]], Slider[Dynamic[b]], 
   Button[""Update"", update++], 
   Dynamic[update; Plot[Sin[(a + 1) t + \[Pi] b], {t, 0, 2 \[Pi]}], 
    TrackedSymbols :> {update}]}]]

"
front end - Detecting double click events,"
You can use a combination of MouseDown and MouseClickCount as in the following examples: 
example 1: double-click increments the value of j:
j = 1; EventHandler[Panel[Dynamic[j]], 
""MouseDown"" :> If[CurrentValue[""MouseClickCount""] == 2, ++j]]

example 2: double-click toggles the text color:
DynamicModule[{col = Green}, 
  EventHandler[
    Style[""text"", FontColor -> Dynamic[col]], 
   {""MouseDown"" :> 
      If[CurrentValue[""MouseClickCount""] == 2, 
         (col = col /. {Red -> Green, Green -> Red})]}
  ]]

"
list manipulation - What's the most intelligent way to store the information of a selfmade graph?,"
This might be a suitable use case for UpValues. UpValues (/:) associate the definition with the inner symbol, rather than the outer function, and can be used as a kind of tag. So you can define your data:
a5 /: parents[a5] = {a1, a4};
a5 /: name[a5] = ""mila"";
a74 /: parents[a74] = {a2, a55, a71};
a74 /: name[a74] = ""bob"";

The other question is how you are going to store the original data to be loaded into the UpValues. In your question you suggested it would be some sort of text file. I assume it is the form
a4 ""alice"" a3 a2
a9 ""carol"" a6 a4

so you can Import it into a normal Mathematica matrix.
You could then write a function to process the imported data. Notice the use of Repeated (..) in the Pattern (:). The With construct seemed to be necessary to avoid certain errors firing.
makeDef[d : {{_Symbol, _String, __Symbol}..}] := 
With[{nn = First[#]},  
 (UpValues[nn] = {name[nn] -> #[[2]], 
   parents[nn] -> Drop[#, 2]})] & /@ d

The output from this looks strange but the UpValues are then correct.
And then a simple function like this
makeFamilyGraph[p_List] := 
 Graph[Flatten[Thread[parents[#] -> #] & /@ p], 
  VertexLabels -> (# -> name[#] & /@ p)]

Gives output like this:
makeFamilyGraph[{a4, a5, a9, a74}]


"
programming - Importing Zip files,"
The documentation for the MIME type ZIP does not seem to say much about what you want to do, but luckily the first thing I tried worked! 
First, I saved your zip file onto my desktop. Then, I extracted the first level of file names (note that ""FileNames"" is the default option, so is not explicitly needed)
In[1]:= fn1 = Import[""/home/simon/Desktop/RV120312.zip"", ""FileNames""]
Out[1]= {""today_rv.zip""}

Then the second level of file names
In[2]:= fn2 = Import[""/home/simon/Desktop/RV120312.zip"", {fn1[[1]], ""FileNames""}]
Out[2]= {""TGENTRADES.M3"", ""CCONTRGRP.C2"", ""CCONTRTYP.C2"", \
    ""CCONTRACTS.C2"", ""CCONTRSTAT.C2"", ""CTHEORPRICES.C2"", ""CDELTAS.C2"", \
    ""CINTRASPR.C2"", ""CINTERSPR.C2"", ""CVALARRAYS.C2"", ""CYIELDCURVE.C2"", \
    ""CVOLATILITYSKEW.C2"", ""MCONTRACTS.M3""}

Finally, I extracted, for example, the third file in the inner archive
In[4]:= Import[""/home/simon/Desktop/RV120312.zip"", {fn1[[1]], fn2[[3]]}]
Out[4]= {{""\""20120312\"";\""C2\"";\""20\"";\""0100\"";\""FuturoC IBEX MINI\"";1;1"", 
  ""00;\""EUR\"";\""1\"";\""FFICSX\""""}, {...}, ....}

I think that this final Import defaulted to a CSV import, when you seem to want to separate elements by semicolons ("";""), so you should use:
In[5]:= Import[""/home/simon/Desktop/RV120312.zip"",{fn1[[1]], fn2[[3]], ""Table""}, 
           ""FieldSeparators""->"";""] // Short[#,3]&
Out[5]//Short= {{20120312, C2, 20, 100, FuturoC IBEX MINI, 
                 1, 1,00, EUR, 1, FFICSX}, <<916>>, 
                {20120312, C2, VI, 240, Contado VIVENDI, 
                 1, 1,00, EUR, 2, ESXXXX}}


Note that you could, e.g., use a While loop to automate the digging down to the lowest level of the archive.
"
performance tuning - Speeding up a slow indefinite integral,"
If you break it up as below it will be considerably faster. The idea is to use symbolic integration on the inner integral (Why? Because we can, and it makes this faster).
In[263]:= 
i1[n_, t_] = 
 Integrate[
  Exp[-((z^2 + (200*n - z)^2)/(4*t))] + 
   Exp[-((z^2 + (100 + 200*n - z)^2)/200)], {z, -50, 50}, 
  Assumptions -> {t > 0, -4 <= n <= 4}]

Out[263]= (5*Sqrt[Pi]*(-Erf[10*n] + Erf[10*(1 + n)]))/
  E^(25*(1 + 2*n)^2) + 
   (Sqrt[Pi/2]*Sqrt[t]*(Erf[(25*Sqrt[2]*(1 - 2*n))/Sqrt[t]] + 
           Erf[(25*Sqrt[2]*(1 + 2*n))/Sqrt[t]]))/E^((5000*n^2)/t)

In[264]:= i2[t_] = Sum[i1[n, t], {n, -4, 4}];

In[265]:= 
pwd[y_] := (1/(4*Sqrt[Pi]))*
  NIntegrate[Exp[-1/(4*t)]/t^(3/2)*i2[t], {t, 0, y}]

The tabulation for the interpolation should complete in something approximating reasonable time. Well, within several hours, in any case, if counting by hundreds is any indication.
In[272]:= Timing[tabulate = Table[{y, pwd[y]}, {y, 0, 100000, 100}];]

Out[272]= {150.71, Null}

"
curated data - Computing Many Slow I/O Operations,"
As Szabolcs mentions, the simplest way to do this is to start a new kernel and push this bulk of data acquisition to that kernel and let it run in the background. There are good examples in the documentation in tutorial/ConcurrencyManagingParallelProcesses.
For your specific case, here's an example following the above:
LaunchKernels[1];
j = ParallelSubmit[{#, FinancialData[#, ""DividendYield""]} & /@ 
   Take[FinancialData[""NYSE:*""], 30]];


Parallel`Developer`QueueRun[]
Out[3]= True


You can continue working as usual in your main kernel.
"
polynomials - GroebnerBasis without specifying variables,"
If the (ordered) list of variables is not specified, GroebnerBasis will order the variables as it encounters them. I remark that, as this depends on implementation details, it can be version dependent.
The question (which I should have anticipated) was raised as to how one might get the ""variables"" that GroebnerBasis sees, and in the same order. It can be done with a non-System-context function GroebnerBasis`DistributedTermsList. It will both rewrite the polynomials in an internal format (as its name implies), and also give the variables in the order it is using them. One must specify CoefficientDomain -> Rationals in order to force it to create new variables rather than treat unspecified ones as part of the coefficient field (the default behavior).
Here is a simple example.
polys = {3*y*z - 5, 2*x^2 + y + z^3 - 1, x*y - 2};
Variables[polys]    
Out[1]= {x, y, z}

GroebnerBasis`DistributedTermsList[polys, CoefficientDomain -> Rationals]
Out[2]= {{{{{1, 1, 0}, 3}, {{0, 0, 0}, -5}}, {{{1, 0, 0}, 1}, {{0, 3, 0}, 1}, 
    {{0, 0, 2}, 2}, {{0, 0, 0}, -1}}, {{{1, 0, 1},1}, {{0, 0, 0}, -2}}}, {y, z, x}}

"
Problm with Compil Function - Mathmatica Stack Exchang,"
Not a proper answer, but I just want to comment that the procedure carried out by @rcollyer can be automated to a large extent. Here is a code for a simplistic common subexpression eliminator:
ClearAll[csub];
csub[expr_Hold, rules_List, limitCount_] :=
  With[{newrule = 
     Replace[
       If[# =!= {} && #[[-1, -1]] > 1, #[[-1, 1]], {}] &@
         SortBy[Tally[
           Cases[expr,          
             x_ /; Depth[Unevaluated[x]] > 2 && 
               LeafCount[Unevaluated[x]] > limitCount :> Hold[x],
             Infinity]],
           Last],
       Hold[x_] :> (HoldPattern[x] -> Unique[])]
    },
    csub[expr /. newrule, Append[rules, newrule], limitCount] /; 
        newrule =!= {}];

csub[Hold[expr_], rules_, _] :=
 Append[
   Thread[
     (rules /. (Verbatim[HoldPattern][x_] -> var_) :> Hold[var := x]), 
     Hold
   ],
   Unevaluated[expr]
  ] /. Hold[defs_, exp_] :> Hold[LetL[defs, Hold[exp]]]

where the LetL macro implements the sequential With construct, defined as
ClearAll[Let];
SetAttributes[Let, HoldAll];
Let /: (lhs_ := Let[vars_, expr_ /; cond_]) := 
   Let[vars, lhs := expr /; cond]
Let[{}, expr_] := expr;
Let[{head_}, expr_] := With[{head}, expr]
Let[{head_, tail__}, expr_] := With[{head}, Let[{tail}, expr]]

I discussed is more here. Using
held = Hold[If[your-expression]]

setting the threshold to say 10 (I played with this a bit), and executing
csub[held,{},10]

we get this:
Hold[
  letL[{
    $3 := #1[[2]] - #1[[1]], $4 := #1[[1, 2]] - #1[[2, 2]], 
    $5 := #1[[2, 1]] - #1[[1, 1]], $6 :=  Sqrt[$3[[1]]^2 + $3[[2]]^2], 
    $7 := (#1[[1, 3 ;; 4]].{$4, $5} {$4, $5})/
       (Sqrt[$4^2 + $5^2] Sqrt[$4^2 + $5^2]), 
    $8 := #1[[2, 3 ;; 4]].$3[[{1, 2}]]
    }, 
    Hold[
       If[(list[[2]] - list[[1]])[[{1, 2}]] != {0, 0}, 
          (
           Flatten[{
             #1[[1, 1 ;; 2]] + $7 + ($8 $3[[{1, 2}]])/($6 $6), 
             $7 + (($8 $6) $3[[{1, 2}]])/$6
           }] &) /@ {{list[[1]], list[[2]]}, {list[[2]],list[[1]]}}, 
         (Flatten[{#1[[{1, 2}]] + #1[[{3, 4}]], #1[[{3, 4}]]}] &) /@ list]
       ]
    ]
  ]

If you now apply ReleaseHold to the above, you recover your code, wrapped in Hold. Note that while I tried automatic minimization of Leafcount for the above, it turns out to give smaller thresholds than what seems to be the easiest for us to read. The real metric here should include some penalty for long chains of dependencies, since they are hard for us humans to digest.
"
performance tuning - Transferring a large amount of data in parallel calculations,"
There are two performance problems here. The first is relatively minor: MultinormalDistribution[μ, Σ] is evaluated in each slave kernel, returned to the master kernel, and sent back to the slave kernels as part of the RandomVariate call. In your example, this is a packed array of about 80KB in size: not large, yet not small either, and this behaviour may become an issue in other contexts. This is easily solved by specifying Method -> ""CoarsestGrained"" as an option to ParallelTable. However, while certainly representing an improvement, this setting unfortunately has little impact on overall behaviour in the current case.
The second issue is both more subtle and more serious, and comes from the handling of aborted evaluations by the Parallel` package. The essence of it is that all results returned to the master kernel by the slaves are checked for aborted evaluations using MemberQ[res, $Aborted]. Here, res is a large matrix in the form of a packed array $\approx$160MB in size, and the unpacking of this by MemberQ accounts for the poor performance and considerable memory consumption of this example. The peak memory consumption does not persist, however, since after the absence of $Aborted has been verified, the intermediate (unpacked) results are discarded.
To demonstrate more concretely the source of problem, we examine the file
FileNameJoin[{$InstallationDirectory, ""AddOns"", ""Applications"", ""Parallel"", ""Combine.m""}]

and note that we can change the behaviour of this example using only the excerpt (which is complete with original comments, but repackaged to be a stand-alone modification of the relevant code, as well as slightly reformatted):
BeginPackage[""Parallel`Combine`""];
Begin[""`Private`""];

Needs[""Parallel`Parallel`""];
Needs[""Parallel`Kernels`""];

(* Additional required contexts -- O. R. *)
Needs[""Parallel`Protected`""];
Needs[""Parallel`Developer`""];

parallelIterateE[orig_, iter_, comb_, f_, expr_,
                 it : {w1_}, others___, {meth_, dist_, ___}] :=
 With[{nk = $KernelCount, items = Internal`GetIteratorLength[it, orig]},
  Module[{batches, batchsize, sizes, res},
   If[ !IntegerQ[items] || items < 0, (* cannot do it if symbolic *)
    Message[orig::nopar1, HoldForm[orig[expr, {w1}, others]]];
    Return[iter[expr, {w1}, others]]
   ];
   (* handle Method option *)
   grokMethodOption[orig, Evaluate[items], nk, batches, batchsize, meth];
   sizes = makeSizes[items, nk, batches, batchsize];
   (* send definitions *)
   Parallel`Protected`AutoDistribute[{f, expr, others}, orig, dist];

   parStart;
   With[{
     chunks = HoldComplete @@ sizes /.
      u1_Integer :> f[iter[expr, {u1}, others]]
    },       
    res = If[
     batches === 1,
     ParallelDispatch[chunks],
     ConcurrentEvaluate[chunks]
    ];
   ];
   res = If[
    (* Here lies the problem -- O. R. *)
    MemberQ[res, $Aborted],
    $Aborted,
    comb @@ res
   ]; (* remote abort received *)
   parStop;

   res
  ]
 ]

End[];
EndPackage[];

(I should stress that the above is only one example of this code pattern as used in Combine.m; it also appears in other places not relevant to this example.)
Modifying this, either by removing the MemberQ call, or simply by commenting out res, and then running it (after loading the Parallel` package) to modify the definitions made in Combine.m can be seen to restore the expected performance. 
Unfortunately, although one might think up a more performant (or at least non-unpacking) but semantically equivalent replacement, such as
Block[{$Aborted := Abort[]}, CheckAbort[res, $aborted]] === $aborted

this won't work since $Aborted is Locked. In any case, for obvious reasons, I hesitate to suggest modifying Combine.m in order to fix this problem, so attempting a workaround seems to be the best option here.
Edit: the workaround
As promised in the edit comment I left when I deleted my initial (incorrect) attempt at a workaround, here is a potential (this time, hopefully correct) solution to the problem of MemberQ unpacking. It is different in spirit to @Szabolcs's approach, being based on a modification of the original MemberQ rather than a reimplementation, so I feel it is worth posting as well. However, the same caveat applies: modifying System` functions is something which should be attempted with great care and only as a last resort. This method is based on the replacement of any packed arrays that appear in the first argument of MemberQ with an opaque list when the second argument is a symbol. I think it's safe, but there may be a situation I've overlooked, so I still advise caution.
withModifiedMemberQ[expr_] :=
 Module[{doneQ, unmatchable},
  Internal`InheritedBlock[{MemberQ},
   Unprotect[MemberQ];
   (* Can uncomment this if we want to print out the MemberQ calls:
   mq:MemberQ[args___]/;(Print@HoldForm[mq];True):=mq;
   *)
   MemberQ[list_, patt_Symbol, args___] /; !TrueQ[doneQ] :=
    Block[{doneQ = True},
     MemberQ[
      Unevaluated[list] /. _List?Developer`PackedArrayQ -> {unmatchable},
      Unevaluated[patt],
      args
     ]
    ];
   Protect[MemberQ];
   expr
  ]
 ];
SetAttributes[withModifiedMemberQ, HoldAllComplete];

Let's test it. For this I've uncommented the definition that prints out the calls to MemberQ so that its operation will produce some debug output. (Note also that Range returns a packed array.)
On[""Packing""];

MemberQ[Range[5], $Aborted]
(* (message) Developer`FromPackedArray::unpack: Unpacking array in call to MemberQ.
   False *)

withModifiedMemberQ@MemberQ[Range[5], $Aborted]
(* (prints) MemberQ[{1, 2, 3, 4, 5}, $Aborted]
   (prints) MemberQ[{unmatchable$1305}, $Aborted]
   False *)

withModifiedMemberQ@MemberQ[Range[5], 1]
(* (prints) MemberQ[{1, 2, 3, 4, 5}, 1]
   (message) Developer`FromPackedArray::unpack: Unpacking array in call to MemberQ.
   True *)

So it looks okay. Now let's comment out the debug output (otherwise the front end will probably lock up) and try it on the problematic ParallelTable call:
On[""Packing""];

withModifiedMemberQ@AbsoluteTiming[
 Join @@ ParallelTable[
  RandomVariate[
   MultinormalDistribution[\[Mu], \[CapitalSigma]], 
   200000
  ], {2}
 ];
]
(* {2.8593750, Null} *)

No unpacking messages are printed, and the performance issue is fixed. (On my computer, the version using the unmodified MemberQ takes 5.6 seconds.)
"
"graphics - Graph stories, 3-d volumes","
Warning: It appears that in version 9 this tends to crash the kernel.  Beware and save your work before trying!

Here's a starting point.  It needs a lot more polish.
First, make a bottle:
{p1, p2, p3, p4} = Table[{i, 0.5}, {i, 4}];
if = Interpolation[{{0, 1/2}, p1, p2, p3, p4, {5, 1/2}}];

Column[{
  LocatorPane[
   Dynamic[{p1, p2, p3, 
     p4}, ({p1, p2, p3, p4} = #; 
      if = Interpolation[{{0, 1/2}, p1, p2, p3, p4, {5, 1/2}}]) &], 
   Dynamic@Plot[if[x], {x, 0, 5}, PlotRange -> {{0, 5}, {0, 1}}]],
  Dynamic[
   bottle = 
    RevolutionPlot3D[{if[x], x}, {x, 0, 5}, PlotStyle -> Opacity[0.5],
      Mesh -> None]]
  }]


Then fill it and animate it:
volume = Derivative[-1]@FunctionInterpolation[if[x]^2, {x, 0, 5}]

Table[Rasterize@
   Show[bottle, 
    RevolutionPlot3D[{0.95 if[x], x}, {x, 0, 
      InverseFunction[volume][t]}, Mesh -> None, 
     PlotStyle -> Blue]], {t, 0.1, volume[5], 0.1}] // ListAnimate


"
probability or statistics - RandomVariate with a Discrete Distribution,"
This is a multinomial distribution.  Obtain your bootstrap sample quickly as in this example:
z = RandomReal[{0, 1}, 10];
z = z / (Plus @@ z) (* Generate an example set of values for  z0^, ..., z8^, q *)
f = MultinomialDistribution[2^28, z];
Timing[RandomVariate[f, 1000];]

(1.342 seconds).
"
performance tuning - Update only one element in a dynamic grid?,"
Studying various parts of the your code I found that having an array hold your images seems to be the main cause of delay for some reason not directly clear to me. Using normal variables (which can be done easily by putting the DynamicModule deeper in the hierarchy) the process gets much quicker:
Grid[
 Table[
  DynamicModule[
   {g = Image[RandomReal[{0.5, 1}, {16, 16, 3}]]},
   Button[
    Dynamic[g],
    g = Image[RandomReal[1, {16, 16}]],
    ImageSize -> Full, Appearance -> None
    ]
   ], {i, 19}, {j, 19}
  ], Spacings -> {0, 0}
 ]


You can still see the ugly white lines that are also in your original code (but not in your alternative). Have to find out how to remove these...
"
equation solving - How to find regions that satisfy this inequality?,"
[Please please please...post actual cut-and-pastable code.]
Here is a method that is, unfortunately, impractical. But it sometimes gives results if you are patient.
isEmpty[a_?NumericQ, b_?NumericQ] := Module[{finst},
  finst = 
   FindInstance[(3*x + y Exp[x*y])*(x \[Minus] a) + (6*y + 
         x*Exp[x*y])*(y \[Minus] b) < 0, {x, y}];
  If[ListQ[finst],
   If[Length[finst] == 0, True, False]
   , $Failed]
  ]

In[306]:= isEmpty[1, 3]

Out[306]= False

Here is a start on a method that uses contpur plotting. One must settle for a finite range on {x,y} for this; I use -+10 for both.
isEmpty2[a_?NumericQ, b_?NumericQ] := Module[{cplot},
  cplot = 
   ContourPlot[(3*x + y Exp[x*y])*(x \[Minus] a) + (6*y + 
         x*Exp[x*y])*(y \[Minus] b) == 0, {x, -10, 10}, {y, -10, 10}, 
    ContourShading -> False, Frame -> None]
  ]

It just gives a picture but i guess those better versed in Mathematica's Graphics might be able to extract at True/False therefrom. It would of course not be a guaranteed resutl, since plotting uses numeric approximation methods.
It gives a nice result for a=-4, b=-1.

--- edit ---
A comment asks about a specific set of inputs for {a,b}. Not one to duck such a test, I'll show a result with FindRoot. Here we find an {x,y} pair for which the expression of interest is negative (equal to -0.2), by setting y first to 0. I did this because the contour plot indicated there was a negative region in that general vicinity.
In[339]:= FindRoot[((3*x + y Exp[x*y])*(x - a) + (6*y + 
        x*Exp[x*y])*(y - b) /. {a -> -1.0643, b -> -.15, 
     y -> 0.}) == -.2, {x, .1}]

Out[339]= {x -> -0.0634401}

--- end edit ---
"
scoping - Find variable name from DumpSave on a scoped variable,"
You can open the MX file in an ASCII editor. The variable name is there in plain text (interpolation$511 in my case). The rest is binary gibberish.
So given an MX file with a single variable with the $ suffix, the following expression can be used to access that variable directly:
getExpression[filename_] := Module[{a}, 
   ToExpression[(a = StringCases[Import[filename, ""Text""], 
   WordCharacter ... ~~ ""$"" ~~ NumberString][[1]])];
   << (filename);
   ToExpression[a]
  ]

E.g.,
result = getExpression[""interpolation.mx""]
  (* InterpolatingFunction[{{1,10}},<>] *)

Evaluating the variable name before reading it with Get (or <<) seemingly overcomes the Temporary attribute discussed in Leonid`s answer. As a (perhaps unwanted) side-effect of the above expression, the original variable remains defined.
This approach could probably be extended to work with multiple variables and expressions in one MX file.
"
plotting - How do I speed up Plot when the independent variable is in the Numerical expression,"
You are solving the eigenvalue problem for every point in the plot. If it is feasible to work out the analytical expression for the eigenvalues with kx as a symbol, then calculate that outside the plot and plot the solution.
HH = H /. {μ -> 1, Δ -> .3, L -> 11, ky -> 0};
eHH=Eigenvalues[HH]]];
Plot[Re[Sort[eHH]], {kx, -2 π/11, 2 π/11}, PlotPoints -> 10]

You could also try
Plot[Re[Sort[Evaluate@Eigenvalues[HH]]], {kx, -2 π/11, 2 π/11}, PlotPoints -> 10]

But seriously, if you only want ten plot points, precalculate the eigenvalues and then use ListPlot or ListLinePlot.
eHHlist= With[{HH = H /. {μ -> 1, Δ -> .3, L -> 11, ky -> 0}}, 
 Table[Re[Sort[Eigenvalues[HH]]], {kx, -2 π/11, 2 π/11, 2  π/55}]  ]
ListPlot[eHHlist]

"
programming - Basic questions about running Mathematica,"
Heike's code produces a graphics output. So if you run it inside a raw kernel (which is what the math command does on linux), it won't display any graphics. Instead you'll see something like --Graphics-- on your screen. To actually display the output, you'll need to load the JavaGraphics package as <<JavaGraphics` before the plot command (this needs to be done only once per session).
Jens has more on running Mathematica without a front-end. Brett Champion also notes the following:

When using JavaGraphics`, graphics are rendered by a child front end and converted to a bitmap format. So most new features of graphics are supported. The exception is that if there are interactive aspects to the graphic (tooltips, mouse-overs, Dynamics), they will effectively be ignored. Visualization functions sometimes have problems since in order for them to work correctly, they have to handle Show and DisplayFunction just right. If you do run across problems with a visualization function when using JavaGraphics` , please file it as a bug. 

As for the rest of the questions, I'll refer you to the official documentation that Sjoerd shared, as there is no need to duplicate information.
"
numerics - Meaning of backtick in floating-point literal,"
The backtick is a short-hand to mark the precision of your output. If it is not followed by any number, it denotes machine precision. You can denote arbitrary precision by including a number, as for example, 0.3`20.
By default, these are not displayed in StandardForm, which is why you see them only when copying, at which point it gets converted to InputForm. You can show them with NumberMarks -> True. For example:
Sqrt[2] // N
(* 1.4142135623730951 *)

InputForm[Sqrt[2] // N, NumberMarks -> True]
(* 1.4142135623730951` *)

"
"How to generally match, unify and merge patterns?","
In my opinion, this is a very good and worthwhile question, but certainly not easy to answer. I don't have a full solution by any means, but as far as the comparison/matching part is concerned, the undocumented function Internal`ComparePatterns may be of substantial assistance. What follows is a short summary of what I know about this function, which exists in Mathematica 7 and 8, but not version 5.2. I would guess that it is new-in-6 and used in the implementation of OptionsPattern and related functions.
Internal`ComparePatterns[p, q] (where p and q are patterns) operates somewhat like MatchQ, except that rather than simply True or False to signify agreement or disagreement, multiple (namely, five) possibilities exist to describe the relationship p has to q:

Identity
Two patterns are considered identical if they match verbatim up to, but not including, naming. This relation should obviously be transitive and commutative, and I haven't observed any counterexamples so far. An example could be:
Internal`ComparePatterns[a_, b_]
(* -> ""Identical"" *)

It is also aware of attributes that affect pattern matching. Here we attempt to mask the Orderless attribute of Plus (and thus possibly confuse Internal`ComparePatterns) by wrapping it in HoldComplete:
Internal`ComparePatterns[
 HoldComplete[x_Real + y_Integer],
 HoldComplete[y_Integer + x_Real]
]
(* -> ""Identical"" *)

Pattern names are not completely ignored, however, and seem to be taken into account where appropriate:
Internal`ComparePatterns[x_Real + y_Integer, x_Integer + y_Real]
(* -> ""Incomparable"" *)

Equivalence
If p has the same meaning as q but is not structurally identical, the patterns are considered equivalent:
Internal`ComparePatterns[a | b, b | a] (* Alternatives is not Orderless *)
(* -> ""Equivalent"" *)

Internal`ComparePatterns[a : y_ + x_, b : (f : Plus)[x_, y_]]
(* -> ""Equivalent"" *)

However, determination of this relationship is not completely robust. Patterns that are sufficiently structurally different sometimes will not be considered equivalent even if they manifestly are:
Internal`ComparePatterns[a : y_ + x_, b : (f : Plus | Plus)[x_, y_]]
(* -> ""Specific"" *)

Here are two more examples of patterns that are equivalent, but where the relationship is misstated. The second of these is particularly interesting:
Internal`ComparePatterns[Repeated[_, Infinity], Repeated[_]]
(* -> ""Specific"" *)

Internal`ComparePatterns[Repeated[_, {1, Infinity}], Repeated[_, Infinity]]
(* -> ""Identical"" *)

Specificity
In some circumstances, Internal`ComparePatterns is able to determine when one pattern is a special case of another:
Internal`ComparePatterns[_h, _]
(* -> ""Specific"" *)

However, this situation is often misdiagnosed with equivalent patterns, which will instead be identified as special cases of each other:
Internal`ComparePatterns[__, (_) ..]
(* -> ""Specific"" *)

Internal`ComparePatterns[(_) .., __]
(* -> ""Specific"" *)

Disjointness
What is more reliably stated is when one pattern is exclusive of another, i.e. there are no expressions that could be matched by both:
Internal`ComparePatterns[_a, _b]
(* -> ""Disjoint"" *)

Incomparability
Finally, we have the situation whereby the patterns are either unrelated, or Internal`ComparePatterns simply does not know how to interpret their relationship:
Internal`ComparePatterns[a | b, b | c]
(* -> ""Incomparable"" *)

Notably, it seems to be the case that Internal`ComparePatterns works entirely inside the pattern matcher, so that conditional patterns (which need to invoke the main evaluation loop), if not identical, are generally incomparable (by this mechanism):
Internal`ComparePatterns[_ /; True, _ /; Sequence[True]]
(* -> ""Incomparable"" *)

Internal`ComparePatterns[_?(True &), _ /; True]
(* -> ""Incomparable"" *)


Now let's try it on the examples:
Internal`ComparePatterns[a | b, b | a]           (* -> ""Equivalent"" -- correct *)
Internal`ComparePatterns[a | b, c | b | a]       (* -> ""Specific"" -- correct *)
Internal`ComparePatterns[a | b | c, b | a]       (* -> ""Incomparable"" -- correct *)
Internal`ComparePatterns[a | b | (c : b), b | a] (* -> ""Incomparable"" -- incorrect, but: *)
Internal`ComparePatterns[a | (c : b), b | a]     (* -> ""Equivalent"" -- correct *)
Internal`ComparePatterns[{a ..}, {a ..}]         (* -> ""Identical"" -- correct *)
Internal`ComparePatterns[{a ..}, {a ...}]        (* -> ""Specific"" -- correct *)
Internal`ComparePatterns[{a ...}, {a ..}]        (* -> ""Incomparable"" -- correct *)

So, Internal`ComparePatterns fails only in one case, and its answer is still technically correct as it is the result of the inability of the function to see the relationship between these patterns (Internal`ComparePatterns[a | b | b, b | a] gives ""Specific"" rather than ""Equivalent"") and not a statement about the expressions they will match.
I should finish by saying that I wasn't able to find any concrete examples of where Internal`ComparePatterns is actually used in Mathematica, which should give one pause considering its occasional mistakes. However, it may be that I didn't find it because I wasn't trying hard enough, rather than because it isn't used anywhere. Here is code for a hook that can be installed (using $Pre = withHookedComparePatterns) during normal usage. If you're lucky enough to stumble on a function that uses Internal`ComparePatterns, the call stack and the call itself will be printed out at that point, which will help to identify what its use case is, if any. Anyone finding any examples is welcome to edit this answer to include them below (marking as Community Wiki at the same time, if desired).
ClearAll[withHookedComparePatterns];
SetAttributes[withHookedComparePatterns, HoldAll];
Begin[""System`Private`""];
withHookedComparePatterns[expr_] :=
  Internal`InheritedBlock[{Internal`ComparePatterns},
   Unprotect[Internal`ComparePatterns];
   cp : Internal`ComparePatterns[___] /;
     StackInhibit[Print[{Stack[], HoldForm[cp]}]; True] := cp;
   Protect[Internal`ComparePatterns];
   StackBegin[expr]
  ];
End[];

"
assumptions - simplify assuming a variable equals zero,"
You can use /. (ReplaceAll) : 
% /. a->0

Simplify[%,a=0] produces an error ( this  expression a = 0 cannot be used as an assumption)  because it means just setting the value zero to the variable a, in another form Set[ a, 0], see Set.
In some cases, when there are more variables which depends on another ones you may need the repeated replacement for applying rules repeatedly until the expression no longer changes, then you would rather use ReplaceRepeated, (//.)  e.g. :
% //. {a -> b + 1, b -> 2}

"
plotting - plot function against composite variable,"
Here's an approach that uses Rationalize to turn a real number into a rational number, and extracts the numerator and denominator to be used when evaluating f[x,y].
f[x_, y_] := y^2/x^2 Exp[x/y] + 5 x/y

g[xy_?NumericQ] := 
    With[{r = Rationalize[xy, 0]}, 
        f[Numerator[r], Denominator[r]]
        ]

Plot[g[xy], {xy, 0, 2}]


A few notes:

the definition of g doesn't need to know what f is.
I used Rationalize[x, 0] to make sure the result is rational, avoiding cases like  Rationalize[0.123423789] returning 0.123423789.
I used _?NumericQ to make sure g is only defined for numbers, since Rationalize[x,0] will return x, which I want to avoid.

"
assignment - MapThread gives different results from ToExpression when trying to assign variables from a list,"
I believe it is because Set has attribute HoldFirst.  The FullForm of what you are attempting would look like...
Set[ToExpression[data[[1,1]]],1]

The ToExpression doesn't get a chance to evaluate before trying to assign the value.  You can use Evaluate if you insist on doing it this way.
Evaluate[ToExpression[data[[1, 1]]]] = data[[2, 1]]

"
plotting - InterpolationOrder for ContourPlot,"
The most efficient way to carry out your task, which is to plot a contour map of a kernel density of your points, is by converting the points to raster format and using a Fast Fourier Transform to convolve them with a density kernel.  But that takes some work.  If you're willing to wait a few seconds, the whole procedure is (less efficiently) built into Mathematica's SmoothKernelDistribution function.
Here is an example taken, with minor changes (to make it more interesting), directly from the help page:
(* Create some data--around 10,000 points--for the illustration *)
data = Join @@ Table[RandomVariate[BinormalDistribution[m, {1/2, 1/2}, 0], 1500], 
        {m, RandomReal[{1, 9}, {7, 2}]}];

(* Create a rough (D1) and smooth (D2) density for contouring *)
D1 = SmoothKernelDistribution[data, 0.02]; (* Takes a few seconds *)
D2 = SmoothKernelDistribution[data, 0.5];  (* Takes a few more seconds *)

(* Plot the points and their densities *)
points = ListPlot[data, PlotRange -> {{0, 10}, {0, 10}}, AspectRatio -> 1];
TableForm[{
  Prepend[
   Table[
     ContourPlot[
       Evaluate@PDF[D, {x, y}], {x, 0, 10}, {y, 0, 10}, 
       PlotRange -> All, 
       ColorFunction -> ""TemperatureMap""], 
     {D, {D1, D2}}
 ], points]
}]


"
Creating a table/Matrix during a For loop,"
Typically the best way to accumulate results from an arbitrary process is to use Sow and Reap.
I picked four functions of i as an example.  Since there are four, I Partition at the end into subsets of four:
Reap[
  For[i = 1, i < 10, i++, Sow[i]; Sow[i^2]; Sow[i!]; Sow[N@Log@i]];
][[2, 1]] ~Partition~ 4


{{1, 1, 1, 0.},
 {2, 4, 2, 0.693147},
 {3, 9, 6, 1.09861},
 {4, 16, 24, 1.38629},
 {5, 25, 120, 1.60944},
 {6, 36, 720, 1.79176},
 {7, 49, 5040, 1.94591},
 {8, 64, 40320, 2.07944},
 {9, 81, 362880, 2.19722}}


If you can formulate your code to do a single Sow for each row it will be cleaner:
Reap[
  For[i = 1, i < 10, i++, Sow[{i, i^2, i!, N@Log@i}]];
][[2, 1]]


Brett Champion recommended that I show the two argument from of Sow, which groups results according to explicit tags.

Sow[e, tag]
  specifies that e should be collected by the nearest enclosing Reap whose pattern matches tag.  
Sow[e, {tag1, tag2, ...}]
  specifies that e should be collected once for each pattern that matches a tagi. 

(See this answer for a powerful use of the multiple tag form.)
Here is an example using this in place of Partition in the case of separate Sow expressions per loop.
Reap[
 For[i = 1, i < 10, i++, Sow[i, i]; Sow[i^2, i]; Sow[i!, i]; Sow[N@Log@i, i]];
][[2]]


Also, with a few exceptions it is better to avoid For in Mathematica and use constructs such as Table, Do, Array, Map, NestWhile, FixedPointList and others.  I chose to answer your direct question rather than to answer with what I think you should use instead.  If you are interested in alternative ways to write your program you should post a new question to that effect with an example For loop you wish to optimize.
"
sorting - Sort data after specific ordering (ascending/descending) in multiple columns,"

Caveat lector: Incorrect results are generated by this solution, e.g.,
sortByColumn[{{""a"", 1, 1}, {""b"", 2, 3}, {""a"", 3, 2}}, {1, 1, -1}]
returns 
{{""a"", 1, 1}, {""b"", 2, 3}, {""a"", 3, 2}}
when the correct result is obviously 
{{""a"", 1, 1}, {""a"", 3, 2}, {""b"", 2, 3}}
I've commented on the answer to bring it to the attention of the author, 
  however seeing as they've not been here in some time, I'm also putting this here: I think a highly upvoted and accepted answer needs to be correct. - ciao

Here is my contribution, which has the following benefits over previous answers:

It sorts both numbers and non-numeric structures
You can sort any column (not just the first, followed by the second, etc)
You can sort in either direction (ascending / descending)
Original order is kept: if you sort on the second column, the first entry will follow the order of the original list. See the example with {0,-1}
Edit also allow specifying the priority of the columns. So given {-1,1} for the ordering, you can specify {1,2} to give the higher priority to the second column. 

The code is as follows, including my usage code for my own comments. 
Clear[sortByColumn]
sortByColumn::usage = 
  ""Arguments: [Table, Direction, Priority]. Returns the list sorted \
by the directions for each column specified in `Direction`. For \
ascending order, use `1`, and for descending order, use `-1`. For \
sorting more than one column, input `Direction` as a list. For \
example, Direction={-1,1} will sort the first column in descending \
order followed by the second column in ascending order, ignoring any \
other column. To sort on the second column, use {0,1} for the syntax.

  When sorting two or more columns, you can provide the `Priority` \
for which column should be sorted first. For example, \
`sortByColumn[data,{-1,1},{1,2}]` would sort first in ascending order \
on the second column (because it has a higher priority) and then in \
descending order on the first column."";

sortByColumn[list_?MatrixQ, dir : _Integer | {__Integer}, priority_: {}] := 
 Module[{l = Length@list[[1, All]], w, p, d},
  w = Reverse@Range@l;
  p = If[Length@priority > 0, PadRight[Flatten@{priority}, l], 
    p = Range@l];
  w = w[[Ordering@p]];
  d = PadRight[Flatten@{dir}, l];
  Sort[list, NonNegative@Total[(w d MapThread[Order, {##}])] &]]

For example, using the data set provided by Mr. Wizard:
data={{""a"", 1, 1}, {""a"", 1, 5}, {""a"", 1, 3}, 
      {""c"", 2, 1}, {""b"", 2, 2}, {""b"", 2, 3}, 
      {""c"", 3, 1}, {""a"", 3, 2}, {""a"", 3, 3}};
data[[All, 2]] = data[[All, 2]] /. {1 -> ""q"", 2 -> ""r"", 3 -> ""s""};

Here are the results of some trial runs. First the original:
{a,q,1}
{a,q,2}
{a,q,3}
{c,r,1}
{b,r,2}
{b,r,3}
{c,s,1}
{a,s,2}
{a,s,3}

The result of sortByColumn[data,-1]. 
{c,r,1}
{c,s,1}
{b,r,2}
{b,r,3}
{a,q,1}
{a,q,2}
{a,q,3}
{a,s,2}
{a,s,3}

Result of sortByColumn[data,{0,-1}]
{c,s,1}
{a,s,2}
{a,s,3}
{c,r,1}
{b,r,2}
{b,r,3}
{a,q,1}
{a,q,2}
{a,q,3}

And finally, the result the OP wanted, sortByColumn[data,{1,-1,1}]
{a,s,2}
{a,s,3}
{a,q,1}
{a,q,2}
{a,q,3}
{b,r,2}
{b,r,3}
{c,s,1}
{c,r,1}

An example showing the use of the priority argument: sortByColumn[data, {-1, 1}, {1, 2}]
{a,q,1}
{a,q,5}
{a,q,3}
{c,r,1}
{b,r,2}
{b,r,3}
{c,s,1}
{a,s,2}
{a,s,3}

"
plotting - Why is my plot cut off?,"
If you fix the syntax errors in Plot and Export, and change the ordering of the two graphics in Show everything works fine. The source of problem you are having is: Show uses the options from the first graphics object, and automatic values of image padding for your g1 does not leave space for the frame labels of g2 to show. So, the following minor changes in your code should fix the problem.
  g1 = Plot[x, {x, 0, 100}, AspectRatio -> 1] ;

  g2 = ListContourPlot[data, FrameLabel -> {""label1"", ""label2""}, 
  PlotLabel -> ""title"", AspectRatio -> 1, 
  DataRange -> {{0, 100}, {0, 100}}] ;

  g3 = Show[{g2, g1}]

  Export[""test.pdf"", g3, ImageResolution -> 600]

produces the correct pdf file that shows the frame labels.
Notes:

Everything looks great on the computer.


Not quite... With Show[{g1,g2}] you get the following on the screen:

where
 data = RandomReal[{0, 10}, {20, 2}];

is used as data input for ListContourPlot. 
Using Show[{g2,g1}] you get:

Finally, although the resulting pdf file shows the plot and frame labels

you probably still want to play with various values for ImagePadding as Szabolcs suggests to adjust the spaces on the four sides of the graph.
"
Dealing with numbers too large for machine precision in Graphics,"
I wonder whether I have understood your question correctly because I know you'll be aware of Clip
data = 
 Clip[#, {-$MaxMachineNumber, $MaxMachineNumber}] & /@ {0, Exp[1000.]}

(*
==> {0, 1.797693135*10^308}
*)

Precision /@ data

(*
==> {\[Infinity], MachinePrecision}
*)


data = RandomReal[10, {10, 2}]~Join~{{0, Exp[1000.]}};

Graphics[Point[data], PlotRange -> {0, 10}]


data = Map[Clip[#, {-$MaxMachineNumber, $MaxMachineNumber}] &, data, 2]

(*
==> {{1.712790207, 2.900090032}, {2.659619591, 
  7.829120544}, {1.961467042, 3.28800444}, {8.391594058, 
  6.895205615}, {7.272335729, 5.320941734}, {2.663140973, 
  0.988927991}, {3.408201238, 2.47708199}, {7.951584505, 
  7.102838229}, {6.826916007, 5.639933047}, {5.307337319, 
  1.629710693}, {0, 1.797693135*10^308}}
*)

Graphics[Point[data], PlotRange -> {0, 10}]


"
How can I compare a dynamic variable with a literal in Mathematica?,"
Manipulate will work. This simple alarm will sound for 1 minute or shorter period if you hit reset:
Manipulate[If[Refresh[DateList[], UpdateInterval -> 1][[4 ;; 5]] == 
 {hours, minutes} && oo, EmitSound[Sound[SoundNote[""C"", 1]]]];
 Text@Style[DateString[], 20], {{hours, 0}, Range[25] - 1}, {{minutes, 0}, 
 Range[61] - 1}, {{oo, True, ""alarm""}, {True -> ""ON"", False -> ""OFF""}}]


"
numerical integration - Boosting the performance of expensive NIntegrate by feeding in a cheap approximation of the integrand,"
Would it be a solution to evaluate $L$ at a set of points $x_i$ and morph $G$ with a function $G_m$ in such a way that $G_m[x]G[x]=L[x]$ for those points? That is, with $G_m[x]$ defined as the interpolated function through the set of points ${x_i,L[x_i]/G[x_i]}$. 
For example, let your two functions be:
l[x_] := PDF[GammaDistribution[5, 2], x]
g[x_] := PDF[NormalDistribution[8, (3 E^4)/(16 Sqrt[2 \[Pi]])], x]

They share the same maximum, and are somewhat similar but not closely:
Plot[{l[x], g[x]}, {x, 1, 20}, Frame -> True, Axes -> False]


Then with:
gm = Interpolation[Table[l[x]/g[x], {x, 1, 21}]];

the plots are much more similar:
Plot[{l[x], gm[x] g[x]}, {x, 1, 20}, Frame -> True, Axes -> False]

 
NIntegrate[l[x], {x, 1, 20}]

(*
==> 0.9705751963
*)

NIntegrate[g[x], {x, 1, 20}]

(*
==> 0.9550846595
*)

NIntegrate[gm[x] g[x], {x, 1, 20}]

(*
==> 0.9703985212
*)

In this case, the result of integrating the morphed 'el cheapo' function is within 0.02% of the value of the 'expensive' function. Of course, for this to work the functions should be sufficiently smooth and G should never get too close  to zero.
The set $x_i$ could be obtained with the EvaluationMonitor option in the integration of $G$:
 Last@ Reap[
   NIntegrate[g[x], {x, 1, 20}, EvaluationMonitor :> Sow[x]]]

    (*
    ==> {{1.151189079, 1.891291464, 3.335416098, 5.384541554, 7.843511075, 
  10.5, 13.15648893, 15.61545845, 17.6645839, 19.10870854, 
  19.84881092, 1.07559454, 1.445645732, 2.167708049, 3.192270777, 
  4.421755537, 5.75, 7.078244463, 8.307729223, 9.332291951, 
  10.05435427, 10.42440546, 10.57559454, 10.94564573, 11.66770805, 
  12.69227078, 13.92175554, 15.25, 16.57824446, 17.80772922, 
  18.83229195, 19.55435427, 19.92440546}}
    *)

This set is for one reason or another a meaningful set and could be used as anchorpoints for the interpolating function.

Actually, now that I come to think about it a bit more, this may not be so useful in many cases as the number of evaluations of the expensive function may not be drastically reduced. We need to evaluate the sample points and this set may be as large as the set NIntegrate might need.  So, this saves time only if we can reduce the number of points used in the interpolation function. But if we could halve that set this would save a factor $2^n$ for $n$-dimensional functions. 
"
list manipulation - n-fold symbolic integral in Mathematica,"
Use Sequence to paste in the range in Integrate :
Remove[intCube]
intCube[n_, a_] := 
Module[{xvars, range, expression}, 
    xvars = Table[Symbol[""x"" <> ToString[i]], {i, 1, n}];
    range = Table[{xvars[[i]], 0, a}, {i, 1, n}];
    (* range=Row[Riffle[range,"",""]]; *)
    Print[range];
    expression = Product[xvars[[i]], {i, 1, n}]; Print[expression]; 
    Integrate[expression, Sequence @@ range]
];

{{x1,0,a},{x2,0,a}}

x1 x2

a^4/4

"
replacement - Fill out blanks with a upcoming number in a list?,"
You could do something like this
list = Append[RandomReal[5, 30] /. a_ /; a < 2 :> """", 1.]


{3.82088, """", 2.17919, 2.38081, """", """", 4.54655, """", """", 3.97074, """",
 3.72551, 4.75268, """", """", """", """", """", """", """", """", 2.74955, """", """",
 4.98933, 2.40911, 3.72805, """", 4.50331, 4.75458, 1.}


Reverse[FoldList[#2 /. {"""" -> #1} &, Last[list], Reverse[Most[list]]]]


{3.82088, 2.17919, 2.17919, 2.38081, 4.54655, 4.54655, 4.54655,
 3.97074, 3.97074, 3.97074, 3.72551, 3.72551, 4.75268, 2.74955,
 2.74955, 2.74955, 2.74955, 2.74955, 2.74955, 2.74955, 2.74955,
 2.74955, 4.98933, 4.98933, 4.98933, 2.40911, 3.72805, 4.50331,
 4.50331, 4.75458, 1.}


"
plotting - Plot does not plot over the specified range,"
I'm assuming you want to use the same PlotRange for cell (2,2) as for the other cells.
You can change the order: show Plot before ListPlot.  Note that Plot will now set the PlotRange; as I understand it, the first function called by Show controls the graphics settings (if there should be a conflict).
Show[Plot[cumulativeGauss[x, fit2[[1]], fit2[[2]]], {x, 0, 30},  
           PlotRange -> {{0, 30}, {0, 1}}],
     ListPlot[data2]
    ]

The following questions remain: 

""Why isn't the full plot range displayed when ListPlot comes before Plot?
""Why can't you specify the PlotRange in Show as follows?""
Show[Plot[cumulativeGauss[x, fit2[[1]], fit2[[2]]], {x, 0, 30}],
      ListPlot[data2], PlotRange -> {{0, 30}, {0, 1}}]
 According to the documentation, this latter approach should work  (but it does not):


Either of these result in the following:


Edit
You can display the data points beneath the model using. Note, however that the points will lie beneath the axes.
Plot[cumulativeGauss[x, fit2[[1]], fit2[[2]]], {x, 0, 30},  
     PlotRange -> {{0, 30}, {0, 1}},
     PlotRangePadding -> {{.3, 3}, {0.1, 0}},
     Prolog -> {Red, PointSize[Large], Point[data2]}]


"
Crating Lists From Loops - Mathmatica Stack Exchang,"
Generally, the solution to this kind of problems is using Table:
Table[Count[col7, i], {i, 100}]

However, in this case I suggest Tally or BinCounts:
Tally[col7]

BinCounts[col7, {0, 100, 1}]

Tally will not list elements that don't appear at all.
"
plotting - Styling ticks in a plot,"
This works, but it does require some manual tweaking 
Histogram[data, BarOrigin -> Left, Axes -> False, 
 Frame -> {{True, None}, {True, None}}, 
 FrameTicks -> {{Transpose[{a, 
      Row[{#, Pane["""", {10, Automatic}]}] & /@ a, 
      Table[{-0.02, 0}, {i, Length[a]}]}], 
    None}, {Transpose[{b, 
      Pane[#, {Automatic, 20}, Alignment -> {Center, Bottom}] & /@ b, 
      Table[{-0.02, 0}, {i, b}]}], None}}]


"
front end - Prevent text from wrapping in a notebook,"

You can also set option PageWidth -> Infinity for the Cell or Notebook, e.g.:
SetOptions[EvaluationNotebook[], PageWidth -> Infinity]

"
front end - Collapse a section of a huge function,"
The Mathematica Front End does not have this feature.  Wolfram Workbench does though.
However, it is possible to collapse cell groups in notebooks by double clicking their brackets.  This is useful.
For navigating functions, the Ctrl+. key combination (extend selection) is extremely useful.
"
graphics - Is there an option to plot the Z axis reversed (as shown in the figure)?,"
Mathematica graphics is interactive. Just drag & rotate the plot with mouse till you flip it up side down. You also can do this programmatically:
Plot3D[Sin[x y]^2, {x, -2, 2}, {y, -2, 2}, ViewPoint -> {-1, -2.5, -1}, 
ViewVertical -> {0, 0, -1}]


Here is how I got these options - if you are curious. Produce Mathematica 3D graphics object and play with it by rotating it around. As soon as you like its orientation excute
Options[%]

And get something like this:
Out[2] = {Axes -> True, BoxRatios -> {1, 1, 0.4},  Method -> 
{""RotationControl"" -> ""Globe""}, PlotRange -> {{-2, 2}, {-2, 2}, {0., 1.}}, 
PlotRangePadding -> {Scaled[0.02], Scaled[0.02], Scaled[0.02]},  
ViewPoint -> {-1, -2.5, -1}, ViewVertical -> {0, 0, -1}}

Options ViewPoint and ViewVertical will be most important for your particular case. You can use them now in your code to avoid the need to adjust graphics interactively every time.
NOTE (thanks to @Heike comment below):
In some cases if Options[%] does not work you may try this:

which will produce the set of options I showed above.
"
plotting - How can I make an X-Y scatter plot with histograms next to the X-Y axes?,"
Here's my solution, which constructs the three components and uses Inset to combine them into a single graphic.  I've taken some care so that:

the coordinate systems should line up across the plots (check the gridlines)
as many graphics and plotting options are respected without breaking the layout
the graphic can be reasonable resized


customPlot[data_, o___] := 
 Block[{xmin, xmax, ymin, ymax, x, y, mainplot, xhist, yhist, 
   opts = Flatten[{o}]},
  {x, y} = Transpose[data];
  xhist = HistogramList[x, 50];
  yhist = HistogramList[y, 50];
  {xmin, xmax} = Through[{Min, Max}[First[xhist]]];
  {ymin, ymax} = Through[{Min, Max}[First[yhist]]];
  mainplot = 
   ListPlot[data, Frame -> {{False, True}, {False, True}}, 
    Axes -> False, FrameTicks -> None, AspectRatio -> 1, 
    PlotRange -> {{xmin, xmax}, {ymin, ymax}}, 
    PlotRangePadding -> Scaled[0.02], ImagePadding -> {{None, 1}, {None, 1}},
    FilterRules[opts, Options[ListPlot]], 
    FrameStyle -> GrayLevel[0.3], GridLines -> Automatic, 
    GridLinesStyle -> Directive[Gray, Dotted]];
  xhist = 
   Histogram[x, {First[xhist]}, 
    Frame -> {{True, True}, {True, False}},
    FrameTicks -> {{None, None}, {Automatic, None}}, Axes -> False, 
    AspectRatio -> 1/3, ImagePadding -> {{1, 1}, {None, All}},
    FilterRules[opts, Options[Histogram]], 
    GridLines -> {Automatic, None}, FrameStyle -> GrayLevel[0.3], 
    GridLinesStyle -> Directive[Gray, Dotted]];
  yhist = 
   Histogram[y, {First[yhist]}, 
    Frame -> {{True, False}, {True, True}}, Axes -> False, 
    FrameTicks -> {{Automatic, None}, {None, None}}, AspectRatio -> 3,
    BarOrigin -> Left, ImagePadding -> {{All, None}, {1, 1}},
    FilterRules[opts, Options[Histogram]], 
    GridLines -> {None, Automatic}, FrameStyle -> GrayLevel[0.3], 
    GridLinesStyle -> Directive[Gray, Dotted]];
  Graphics[{{Opacity[0], Point[{{360, 360}, {-120, -120}}]},
    Inset[mainplot, {0, 0}, {Left, Bottom}, {360, 360}],
    Inset[xhist, {0, 0}, {Left, Top}, {360, Automatic}],
    Inset[yhist, {0, 0}, {Right, Bottom}, {Automatic, 360}]},
   PlotRange -> {{-120, 360}, {-120, 360}}, 
   FilterRules[opts, Options[Graphics]], 
   ImagePadding -> {{30, 1}, {30, 1}}]
  ]

Now to create some data and try it out:
d = RandomVariate[BinormalDistribution[{0, 0}, {1, 2}, 0.4], 100];

customPlot[d]




customPlot[d, 
   PlotStyle -> Directive[PointSize[Large], Orange], 
   ChartStyle -> Orange, ChartElementFunction -> ""FadingRectangle"", 
   FrameStyle -> White, Background -> Black]




"
import - Organizing similar datasets using Contexts or otherwise,"
I think, using contexts here is a sensible suggestion, particularly because you want to use several variables. One possible alternative is to set up a struct-like data structure, where encapsulation mechanism is based on Module-generated persistent variables. There were many discussions related to emulation of structs in Mathematica, but, given the encapsulation aspect, I will refer you to this answer. Contexts do have an advantage that the symbols encapsulated with them can be easily serialized (e.g. with Save or DumpSave), but a disadvantage that it is not clear how to construct these long variable names automatically without using strings (should you wish to automate things).
In any case, the reason that your function does not work is because the parsing is done first, before any code executes, and all your symbols are already created in the current (most likely Global`) context, so these are used also inside Begin and End. While I don't see how you can avoid creation of such symbols  (except explicit use of Remove, or if you use your code in a string form), here is a work-around to create the symbols you need in a proper context:
ClearAll[contextWrap];
SetAttributes[contextWrap, HoldFirst];
contextWrap[code_, context_String] :=
   With[{boxed = MakeBoxes[code]},
     Block[{$ContextPath},
       BeginPackage[context];
         Quiet@ReleaseHold@MakeExpression@boxed;
       EndPackage[];
     ]
  ]; 

Basically, this converts the code into the boxed form, and delays its parsing until runtime. I used similar technique in this answer. Here is an example:
contextWrap[a = 1; b = 2; c = 3, ""MyContext`""]

MyContext`a

(* 
   1
*)

There is no shadowing here because the context MyContext` was not kept on the $ContextPath. So,  in your case, you'd need something like
contextWrap[
   dataRaw=Import[cityName~~"".csv""];
   data=Differences[dataRaw];
   dataMax=Max[dataRaw];,
   ToLowerCase[cityName]~~""`""
]

If you absolutely want to avoid the side effect of creation of new symbols in the current context, I can refer you to the hack based on $PreRead, which I posted in this MathGroup thread.
"
plotting - Can I make a plot with gradient filling?,"
How about this?
bankerPlot[data_] := ListLinePlot[
  data,
  AxesOrigin -> {0, 0},
  Prolog -> Polygon[Join[data, Reverse[data.DiagonalMatrix[{1, 0}]]],
    VertexColors -> Join[
      Blend[{Black, Blue}, #] & /@ Normalize[data[[All, 2]], Max],
      ConstantArray[Black, Length[data]]
      ]
    ],
  PlotStyle -> White,
  Background -> Black,
  AxesStyle -> White
  ]

bankerData = Transpose[{Range[100], Accumulate[RandomReal[{-1, 1}, 100]] + 10}];
bankerPlot[bankerData]


"
equation solving - Backsubstituting solution into FindRoot,"
You can use FoldList or NestList to use the solution of a step as the starting value for the next step. Please check the documentation on these two functions for detailed examples of how they are used.  
  FoldList[FindRoot[{#2 x == 1, y x == #2/2},{{x, #1[[1, 2]]}, {y, #1[[2, 2]]}}] &,
  {x -> 0.5, y -> 0.5}, Range@10]

It gives:

{{x -> 0.5, y -> 0.5}, {x -> 1., y -> 0.5}, {x -> 0.5, y -> 2.}, 
  {x -> 0.333333, y -> 4.5}, {x -> 0.25, y -> 8.}, {x -> 0.2, y -> 12.5}, 
  {x -> 0.166667, y -> 18.}, {x -> 0.142857, y -> 24.5}, 
  {x -> 0.125, y -> 32.}, {x -> 0.111111, y -> 40.5}, {x -> 0.1, y -> 50.}}


NestList is a little more complicated:
  NestList[
  {#[[1]] + 1, FindRoot[{(#[[1]] + 1)  x == 1, y x == (#[[1]] + 1)/2}, 
  {{x, #[[2, 1, 2]]}, {y, #[[2, 2, 2]]}}]} &, 
  {0, {x -> 0.5, y -> 0.5}}, 10]

which produces

 {{0, {x -> 0.5, y -> 0.5}}, {1, {x -> 1., y -> 0.5}}, {2, {x -> 0.5,y -> 2.}}, 
   {3, {x -> 0.333333, y -> 4.5}}, {4, {x -> 0.25, y -> 8.}}, 
   {5, {x -> 0.2, y -> 12.5}}, {6, {x -> 0.166667, y -> 18.}}, 
   {7, {x -> 0.142857, y -> 24.5}}, {8, {x -> 0.125, y -> 32.}}, 
   {9, {x -> 0.111111, y -> 40.5}}, {10, {x -> 0.1, y -> 50.}}}


You can get the second parts of the rows by adding the following code at the end:
  NestList[...] // Last /@ # &

"
"graphics - How can the {x,y,z} points that fall on the outer boundary of a set of values be selected and smoothly surfaced?","
Not sure about the creation of a ""smooth"" surface. But from Mma help, you may create a convex hull in 3D by using TetGenConvexHull
Needs[""TetGenLink`""]
data3D = RandomReal[{0, 1}, {100, 3}];
Graphics3D[Point[data3D]];
surface = TetGenConvexHull[data3D];
(* TetGenConvexHull was changed sometime between 8.0.0 and 8.0.4.
   Uncomment the following line only if you are using 8.0.4. *)
(* surface = Last[surface] *)
Graphics3D[GraphicsComplex[data3D, Polygon[surface]]]


HTH ... I am not really sure ...
To get the points in the convex hull, you could use for example:
  pointss = data3D[[Union@Flatten@surface]]

"
front end - Make the selection become the button you click,"
Try:
Button[""Select this cell"", SelectionMove[ButtonNotebook[], All, EvaluationCell]]

"
front end - SubTitle and SubSubTitle do not group by default,"
In the course of researching this question, I discovered an answer.
Looking at the Option Inspector -> Cell Options -> General Properties for each of the cells shown above, reveals the option: CellGroupingRules. Unfortunately, there is little in terms of documentation for this option.
Upon inspection, CellGroupingRules has the value of {""TitleGrouping"", 0}, {""TitleGrouping"", 10}, and {""TitleGrouping"", 20} for the three title cells, respectively, in order of appearance. The Section cells, down to the SubSubSection have CellGroupingRules = {""SectionGrouping"", x} where x goes from 30 to 50 as you descend the hierarchy. So, obviously, the number indicates the level in the hierarchy. A Text cell (7th in the hierarchy) has CellGroupingRules = ""NormalGrouping"". 
Changing CellGroupingRules on SubSubTitle to {""SectionGrouping"", 20} appears to do the trick. For whatever reason, ""TitleGrouping"" implies that sub-titles are not to be included in the grouping.
"
Palette with editable InputField,"
The following code should fix the problem:
CreatePalette[Pane[InputField[""Enter a string""]], WindowFloating -> False,
WindowClickSelect -> True];

But as we figured out it is not!
I read all available information about WindowClickSelect and WindowFloating options in Mathematica documentation. 
I didn't find any notices that we can't use the options simultaneously. 
I also didn't find any cautions that we can't use the options with Mathematica palettes.
Thus, such unexpected behavior is probably a bug in Mathematica.
I advice to contact Wolfram support team regarding this bug.
"
packages - Function to compute the probability of exactly one event occurring out of N independent events,"
Pr[independentProbabilities__] := 
 Block[{x, len = Length[{independentProbabilities}]},
  Probability[Sum[x[i], {i, len}] == 1, 
   Thread[x /@ Range[len] \[Distributed] 
     BernoulliDistribution /@ {independentProbabilities}]]
  ]

So
In[19]:= Pr[0.1, 0.22, 0.17, 0.28]

Out[19]= 0.414007

Or, doing the math
PrV2[independentProbabilities__] := 
 Total[Times @@@ ((1 - 
       ConstantArray[{independentProbabilities}, 
        Length[{independentProbabilities}]]) + 
     DiagonalMatrix[2 {independentProbabilities} - 1])]

"
plotting - How to show values of points on surface plotted with ContourPlot3D,"
The location that the mouse is pointing to on a 3D surface can be found by starting with MousePosition[""Graphics3DBoxIntercepts""].  This will give you the two points where the line perpendicular to the screen at the mouse pointer intersects the three-dimensional bounding box.
We can calculate the intersection of this line with the surface to find a point.  Here is a simple implementation to track that point dynamically:
fun defines the surface:
fun[{x_, y_, z_}] := x^3 + y^2 - z^2

Let's plot it:
plot = ContourPlot3D[
   fun[{x, y, z}] == 0, {x, -2, 2}, {y, -2, 2}, {z, -2, 2}]

Now let's try to find the intersection of the mouse pointer with the surface using FindRoot.  There might be several intersections, so I specified the box intersection point closer to the viewer as a starting point for FindRoot (t == 0 in the code).  This does not guarantee that the closest (i.e. visible) point will be found, but it makes it more likely.
Show[plot,
 Graphics3D[{
   Red,
   Dynamic@Quiet@Check[
      Sphere[#, Scaled[0.01]]& @ Module[{p1, p2, t},
        {p1, p2} = MousePosition[{""Graphics3DBoxIntercepts"", Graphics3D}];
        (p2 - p1) t + p1 /. FindRoot[fun[(p2 - p1) t + p1], {t, 0, 0, 1}]
        ],
      {}]}]
 ]


Now that we have the point on the surface, you can do with it whatever you want (calculate another functions, etc.)  You can use EventHandler to just record clicks instead of tracking values dynamically.

To address your other question about how to get a number of points on the surface.  One way is to use FindInstance.
FindInstance[
 fun[{x, y, z}] == 0 && Thread[-2 < And[x, y, z] < 2, And], {x, y, 
  z}, Reals, 10]

This will give you 10 points that are precisely on the surface (this uses exact calculations).  Let's show them:
Show[plot, Graphics3D[{Red, Sphere[{x, y, z}, Scaled[0.01]] /. %}]]

To get the points generated by ContourPlot3D, extract them from the GraphicsComplex object is creates.  These coordinates will not be quite as precise as they are meant for visualization only.
First@Cases[plot, GraphicsComplex[points_, ___] :> points, Infinity]

Let's show those points:
Graphics3D@Point[%]


"
number theory - Do we really know the reliability of PrimeQ[n] (for $n>10^{16}$)?,"
I and a number of others have proved that there are no BPSW-pseudoprimes below $2^{64}$. This builds on the work of Jan Feitsma around 2009. In particular this means that, barring programming errors, PrimeQ is correct for all values below $1.844\cdot10^{19}.$
"
"variable definitions - Why can't I define vector v as having subscripted elements v_1, v_2, v_3...?","
You could also use something like OverVector, since 
OverVector[v] = {Subscript[v,1],Subscript[v,2],Subscript[v,3]}

isn't recursive, and so won't cause problems. 
This takes a bit more effort to input

Type Ctrl+& and then Esc vec Esc to enter directly

but if you're interested in the typeset forms it might be worth it.
"
plotting - ParametricPlot3D creates a blank graphic in this case,"
You are dividing by zero at a point where there is a singularity anyway.
Mathematica handles this in the 2D case:
ParametricPlot[{v Cosh[u/v], u}, {u, -1, 1}, {v, -1, 1}]


You can get the graphic you are looking for by breaking up the plot into pieces, avoiding the zone near $v=0$. ParametricPlot3D allows you to show multiple objects in the same plot pretty simply.
ParametricPlot3D[{{v Cosh[u/v], v Cosh[u/v], u},
 {-v Cosh[u/-v], -v Cosh[u/-v], u}}, {u, -1, 1}, {v, 0.1, 1}, 
 Mesh -> None]


Adapting b.gatessucks's suggestion of using Exclusions, I have found that you also need to specify PlotRange and PlotPoints to get a sensible graphic.
ParametricPlot3D[{v Cosh[u/v],  v Cosh[u/v], u}, {u, -1, 1}, {v, -1, 1},
 Mesh -> None, Exclusions -> {0, 0}, 
 PlotRange -> {{-4, 4}, {-4, 4}, {-1, 1}}, PlotPoints -> 100]


"
shortcut key for traverse command history in a Mathematica session in a terminal?,"
I use the command line kernel quite often and use it in conjunction with rlwrap. This allows for history, command line completion, and command line editing. A convenient addition - all one would desire.
"
import - Organizing similar datasets using DownValues instead of Contexts,"
Since no other answer has been posted yet I'll give my opinion.
Using DownValues, which I believe is a hash table of sorts, is the normal and accepted way to store this kind of information in Mathematica, to the best of my knowledge.  I cannot think of any real disadvantages compared to direct symbol assignment.
Either form (direct assignment or DownValues) may take up considerably more memory than storing the information in large array, packed or sparse if possible.  The nature of the data and how it is accessed best determine which method to use.
The other option you should be aware of is to use replacement rules.  When optimized using Dispatch this will be similar to DownValues in many ways, but it allows different usages and has strengths that can make it superior in some applications.
data = Dispatch @ {""Madrid"" -> 7, ""Paris"" -> 2, ""Porto"" -> 4, ""Perth"" -> 1};

{""Madrid"", ""Paris""} /. data


{7, 2}



By the way you can write importCity like this:
importCity[cityName_String] :=
  With[{raw = Import[cityName ~~ "".csv""]},
    dataRaw[cityName] = raw;
    data[cityName]    = Differences @ raw;
    dataMax[cityName] = Max @ raw;
  ]

"
cdf format - CDF and MediaWiki,"
I am the author of the comp.soft-sys.math.mathematica message linked by Szabolcs, wherein I briefly mentioned a CDF extension for MediaWiki I have developed. In the few days since I sent that message, I have improved the extension so that meets MediaWiki's best practice guidelines for extensions, and added new features: it can show CDF files uploaded to a wiki in wiki pages using a simple syntax, it can optionally show CDF files from other servers, and you can configure it to show a 'download' link beneath each CDF so that users may view the file offline if they want.
Full documentation for the extension, including installation instructions and examples, is given on the extension's page on mediawiki.org at http://www.mediawiki.org/wiki/Extension:WolframCDF but a brief summary of the page follows.
[edit]Note that this extension will only work with MediaWiki 1.17 or later. Earlier versions of MediaWiki do not include the Resource Loader system this relies on.[/edit]
To install the extension, download a zip archive of the latest version, unpack it and place the wolfram_cdf directory in your mediawiki extensions directory. Add the following to your wiki's LocalSettings.php file:
require_once(""$IP/extensions/wolfram_cdf/CDF.php"");
You will also need to ensure that file uploads are enabled, and .cdf file extensions are allowed, to do this your LocalSettings.php will need to include code like:
$wgEnableUploads  = true;
$wgUseImageMagick = true;
$wgFileExtensions = array( 'png', 'gif', 'jpg', 'jpeg', 'txt', 'cdf' );
You may also need to either ensure that your webserver serves up .cdf files with the mime type application/x-netcdf or, if that is not possible, you may need to modify your wiki's includes/mime.types to contain
text/plain txt cdf
otherwise uploading CDF files may fail. Once the extension is installed, you can show CDF files in wiki pages by following these steps:

upload your CDF file to the wiki
place a <cdf width=""width in pixels"" height=""height in pixels"">filename</cdf> tag in the page where you want the CDF file to appear.

For example, if you upload a 500x600 pixel CDF file called ""MyDemonstration.cdf"" to the wiki, you can show it in a page using
MyDemonstration.cdf
More configuration options and examples are provided on the MediaWiki.org page linked above.
"
front end - Is it possible to insert an animated image into Mathematica notebook?,"
The credits go to belisarius and the Mathematica help (ref/format/GIF), but I thought the comment would be worth an answer.
Import[""ExampleData/cellularautomaton.gif"", ""Animation""]




"
plotting - subscripts in plot axis labels,"
There is a subtle problem if you use strings as axis labels. Look closely at a plot like this:
Plot[f, {x, -1, 1}, AxesLabel -> {x, ""\!\(\*SubscriptBox[\(f\), \(i\)]\)(x)""}]

You will see that the argument x in the function appears in a different font style than the argument on the horizontal axis. 
To make sure that you get a consistent font style on both axes using the default styling for graphics, you should use the following:
Plot[f, {x, -1, 1}, AxesLabel -> {x, HoldForm[Subscript[f, i][x]]}]

Of course, to enter the Subscript expression in your label, you can still use the keyboard shortcuts that are mentioned by @Szabolcs.
The argument in HoldForm is your vertical label, typed in actual Mathematica syntax with square brackets for the function argument. I didn't surround the horizontal label in HoldForm, but you could do that for safety, in particular if your variable x has been assigned a value somewhere else in the Notebook.
"
list manipulation - Partition a set into subsets of size $k$,"
Try with
partitions[list_, l_] := Join @@
  Table[
    {x, ##} & @@@ partitions[list ~Complement~ x, l],
    {x, Subsets[list, {l}, Binomial[Length[list] - 1, l - 1]]}
  ]

partitions[list_, l_] /; Length[list] === l := {{list}}

The list must have a length multiple of l
"
graphics - Extruding along a path,"
In Mathematica 7 or 8, you can just use Tube.  Please see the docs for many, many examples.
Example:
Show[ParametricPlot3D[{Cos[x], Sin[x], x/5}, {x, 0, 15}] /. 
  Line -> (Tube[#, 0.2] &), PlotRange -> All]


"
plotting - How can I make a 2D line plot with a drop shadow under the line?,"
This solution creates copies of the original curve that use coordinates shifted by Offset to have the shadow behave the same regardless of the scale of the coordinates.  It uses multiple copies of the original, in varying thicknesses, opacities, and offsets.  It also uses JoinForm[""Round""] to avoid sharp corners in the shadow.
offset[p_, o_] := Offset[o, #] & /@ p

offsetPrims[prims_, o_] := 
 prims /. {
    GraphicsComplex[p_, r__] :> GraphicsComplex[offset[p, o], r], 
    Line[p_, r___] :> Line[offset[p, o], r]
    }

shadow[prims_] := 
   With[{bare = DeleteCases[prims, _Hue | _RGBColor, Infinity]}, 
      {Black, JoinForm[""Round""], 
         {AbsoluteThickness[5], Opacity[0.05], offsetPrims[bare, {3, -3}]}, 
         {AbsoluteThickness[4], Opacity[0.1], offsetPrims[bare, {2, -2}]},     
         {AbsoluteThickness[3], Opacity[0.1], offsetPrims[bare, {1, -1}]}}
      ]

DropShadow[g_Graphics] := Graphics[{shadow[First[g]], First[g]}, Options[g]]

DropShadow[
   DateListPlot[
      {FinancialData[""GOOG"", ""Close"", {{2009, 5, 1}, {2010, 4, 30}}], 
       FinancialData[""AAPL"", ""Close"", {{2009, 5, 1}, {2010, 4, 30}}]}, 
      Joined -> True]]




This could be extended to work with points and polygons as well.
"
graphics - Forcing a graph not to resize,"
Assuming that timecoeff is scaled between 0 and 1 you could do something like this (I just made something up for timecoeff and hamiltMol): 
Clear[ighamiltMol, t]; t = 0;
timeCoeff[i_] := (1 + Sin[t + 2.5 i])/2
hamiltMol = NestList[RotateRight, {0, 1, 0, 0, 0, 1}, 5];

ighamiltMol = 
 Dynamic@AdjacencyGraph[hamiltMol,(*hamiltMol is a symmetric sparse/
   adjacency matrix*)
   EdgeShapeFunction -> (Line[#1] &),
   VertexLabels -> Placed[""Name"", Tooltip], 
   GraphStyle -> ""SpringEmbedding"", 
   VertexShapeFunction -> ({{Opacity[0], Disk[#1, #3]},
       Disk[#1, #3 timeCoeff[#2] ]} &),
   VertexSize -> 
    4/3];(*timeCoeff[] looks in a list of complex \
exponentials*)Animator[Dynamic[t], {0, 2 Pi}, .1]
ighamiltMol


This works by using a VertexShapeFunction which consists of two disks on top of each other, namely a transparent one with a fixed radius, and a solid one with a varying radius. The option VertexSize -> 4/3 makes sure that the maximum radius is equal to 2/3 time the mimimum length of all vertices.
"
list manipulation - Elegant operations on matrix rows and columns,"
I like to use Part even when I don't want to modify the original matrix.  This of course requires making a copy but it keeps syntax more consistent.
adding column one to column three:
m = Range@12 ~Partition~ 3;
m // MatrixForm

$\left(
\begin{array}{ccc}
 1 & 2 & 3 \\
 4 & 5 & 6 \\
 7 & 8 & 9 \\
 10 & 11 & 12
\end{array}
\right)$
m2 = m;

m2[[All, 3]] += m2[[All, 1]];

m2 // MatrixForm

$\left(
\begin{array}{ccc}
 1 & 2 & 4 \\
 4 & 5 & 10 \\
 7 & 8 & 16 \\
 10 & 11 & 22
\end{array}
\right)$
With an external vector:
v = {-1, -2, -3, -4};

m2 = m;

m2[[All, 3]] += v;

m2 // MatrixForm

$\left(
\begin{array}{ccc}
 1 & 2 & 2 \\
 4 & 5 & 4 \\
 7 & 8 & 6 \\
 10 & 11 & 8
\end{array}
\right)$
swapping rows and columns:
m2 = m;

m2[[{1, 3}]] = m2[[{3, 1}]];

m2 // MatrixForm

$\left(
\begin{array}{ccc}
 7 & 8 & 9 \\
 4 & 5 & 6 \\
 1 & 2 & 3 \\
 10 & 11 & 12
\end{array}
\right)$
m2 = m;

m2[[All, {1, 3}]] = m2[[All, {3, 1}]];

m2 // MatrixForm

$\left(
\begin{array}{ccc}
 3 & 2 & 1 \\
 6 & 5 & 4 \\
 9 & 8 & 7 \\
 12 & 11 & 10
\end{array}
\right)$

Simultaneous row-and-column operations
Part is capable of working with rows and columns simultaneously(1).
We can operate on (or replace) a contiguous sub-array:
m2 = m;

m2[[3 ;;, 2 ;;]] /= 5;

m2 // MatrixForm

$\left(
\begin{array}{ccc}
 1 & 2 & 3 \\
 4 & 5 & 6 \\
 7 & \frac{8}{5} & \frac{9}{5} \\
 10 & \frac{11}{5} & \frac{12}{5} \\
\end{array}
\right)$
Or a disjoint specification:
m2 = m;

m2[[{1, 2, 4}, {1, 3}]] = 0;

m2 // MatrixForm

$\left(
\begin{array}{ccc}
 0 & 2 & 0 \\
 0 & 5 & 0 \\
 7 & 8 & 9 \\
 0 & 11 & 0 \\
\end{array}
\right)$
Or construct a new array from constituent parts in arbitrary order:
mx = BoxMatrix[2] - 1;

mx[[{1, 2, 5, 4}, {4, 5, 1}]] = m;

mx // MatrixForm

$\left(
\begin{array}{ccccc}
 3 & 0 & 0 & 1 & 2 \\
 6 & 0 & 0 & 4 & 5 \\
 0 & 0 & 0 & 0 & 0 \\
 12 & 0 & 0 & 10 & 11 \\
 9 & 0 & 0 & 7 & 8 \\
\end{array}
\right)$
"
From a list to a list of rules,"
Another way:
Thread[var -> #] & /@ values

"
performance tuning - Split a string at specific positions,"
Here is a faster version of István's function:
split[s_String] :=
  StringReplace[s, {
    StartOfString ~~ l : LetterCharacter .. :> l,
    l : LetterCharacter .. ~~ EndOfString   :> l,
    l : LetterCharacter .. :>
          StringInsert[l, "" "", 1 + Quotient[StringLength@l, 2] ],
    d : Repeated[DigitCharacter, {2, ∞}] :>
          StringJoin @ Riffle[Characters@d, "" ""]
  }] // StringSplit

Timings:
str = StringJoin @@ (RandomInteger[{0, 1}, {500000}] /. {0 -> ""0"", 1 -> ""x""});

First@AbsoluteTiming[istvan = splitIstvan@str;]
First@AbsoluteTiming[mrwizard = split@str;]
istvan === mrwizard


0.7710441

0.4260243

True


"
"Copying an image from the clipboard, modifying it and returning it to the clipboard","
Here are two functions that'll do what you need.
putClipboardImage[img_Image] := Module[{nb},
  nb = CreateDocument[{}, Visible -> False, WindowSelected -> False];
  NotebookWrite[nb, 
   Cell[BoxData@ToBoxes@Image[img, Magnification -> 1]]];
  SelectionMove[nb, All, CellContents];
  FrontEndTokenExecute[nb, ""CopySpecial"", ""MGF""];
  NotebookClose[nb]
  ]

getClipboardImage[] := Module[{tag},
  Catch[NotebookGet@ClipboardNotebook[] /. 
    r_RasterBox :> 
     Block[{}, 
      Throw[Image[First[r], ""Byte"", ColorSpace -> ""RGB""], tag] /; 
       True];
   $Failed, tag]
  ]

Warning: if the image is very small, this method will pad it with some wide pixels.  It is copying the cell contents, not the image itself.  If the image is small than the cell height, it'll get padded.
Copying
The reason the image can't be pasted to every program when using CopyToClipboard is that it is placed onto the clipboard as a metafile (as well as a Mathematica expression), but not as a bitmap.
My function works by writing the image into a new hidden notebook, then invoking the Edit -> Copy As -> Bitmap command programmatically, to ensure that the image is placed on the clipboard as a bitmap.  This works on Windows, but on OS X it's probably necessary to change MGF to something else, as the same command is not available (try PDF).  On Linux this functionality is simply not available.
Pasting
Pasting works by accessing the special object ClipboardNotebook[] and reading its contents.  The unusual looking ReplaceAll - Throw - Catch construct is just a performance optimization to avoid unpacking the array representing the image data.
I used the same techniques in the image uploader palette.
"
functions - How to test if optional argument has been given?,"
Why not use something like
f[first_, arg___] := {arg} === {""ArgValue""};

For general tests, you can compare {arg} to {}, to determine whether or not the arg is empty.
"
"front end - How to prevent the welcome screen from showing up after I close my last notebook? (Ubuntu 11.10, MMA 8.0.4.0)","
The screen won't show when you use File | Quit, or you can use the shortcut Ctrl+Q.
I actually wrote the Wolfram support about this issue, the response said that that window opening is the desired behavior and it's thought to be somewhat of a substitute of not having the ""main bar"" the Windows version has. In that sense, it is not intended that closing all notebooks also shuts down Mathematica (plus kernel). When I told him that it's a bug unless you can disable it, I was told he'll bring the idea up for development at some point. Oh well.
"
manipulate - How to use button to evaluate a cell,"
The first button you don't have to create ;-) It's called the ""Enter"" button and it's already on your keyboard. Press it with the insertion cursor in the following block of code:
d = Manipulate[Plot[Sin[k x], {x, 0, 2 \[Pi]}], {k, 1, 10}];
e = True;

Dynamic[If[e, d, """"]]


The second button is generated below. Pressing it toggles the Manipulate between an on and off state.
Button[""Manipulate On/Off"", e = Not[e]]


"
export - How to do http POST in Mathematica?,"
In a post about automated image uploading Arnoud Buzing describes an undocumented and unsupported POST method. It looks like this:
 xml = Import[url, ""XML"", ""RequestMethod"" -> ""POST"", 
              ""RequestParameters"" -> {""key"" -> key, ""image"" -> image}];

Note: at the time of this answer I was using V8. Since the arrival of URLFetch in V9 I believe URLFetch is the preferred method.
"
list manipulation - Why does MatrixForm affect calculations?,"
MatrixForm is a wrapper that pretty-prints your matrices. When you do the following:
cov = {{0.02, -0.01}, {-0.01, 0.04}} // MatrixForm

you're assigning the prettified matrix to cov (i.e., wrapped inside a MatrixForm). This is not accepted as an input by most functions (perhaps all) that take matrix arguments. What you should be doing to actually assign the raw matrix to cov, yet get a pretty print in the output, is the following:
(cov = {{0.02, -0.01}, {-0.01, 0.04}}) // MatrixForm

You can also read more about why this happens due to the different precedences here in Leonid's book.

You can also avoid having to use MatrixForm every time by setting the default display for matrix outputs to be typeset accordingly. For this, you set the $PrePrint variable in your init.m file as:
$PrePrint = Replace[# , mat_?MatrixQ :> MatrixForm[mat]] &

You can also find this in Szabolcs's mathematica tricks. To reset the value of $PrePrint, simply unset it with $PrePrint=.
"
graphics - How to draw a gene regulatory state space diagram in Mathematica,"
This could be useful to get started:
Graphics[
 GraphicsComplex[
  Tuples[{0, 1}, {2}], {Thick, Blue, Arrowheads[.1],
   Arrow[{{2, 1}, {3, 1}, {4, 2}, {4, 3}}, .1]}],
 Axes -> True, AxesOrigin -> -{0.5, 0.5}, 
 AxesStyle -> Arrowheads[.05], GridLines -> {{.5, 1.5}, {.5, 1.5}}, 
 PlotRange -> {{-.5, 1.5}, {-.5, 1.5}}, Ticks -> {{0, 1}, {0, 1}}, 
 AxesLabel -> {""b"", ""c""}
 ]


"
syntax - Error when using rule as a list index,"
Using Trace,
Trace[x = Range[10]; { i, x[[i]] } /. i -> 5]

we will see that the error comes from Mathematica trying to evaluate
{1,2,3,4,5,6,7,8,9,10}[[i]]

As you pointed out, the error message is harmless in this case.  If you want Mathematica to substitute first, you can use Hold and ReleaseHold:
x = Range[10];
ReleaseHold[Hold[{i, x[[i]]}] /. i -> 5]

which prevents the evaluation of {i, x[[i]]} until the Hold is released.  The output is the same, but now without the error message:

{5,5}

"
front end - Is there a way to have a Tooltip for non-editable raster graphics produced by MakeBoxes?,"
My colleague John Fultz suggested the following answer.
f /: MakeBoxes[dat : f[args_], fmt_] := 
 TagBox[ToBoxes[Rasterize@RandomImage[1, {100, 100}]], 
  InterpretTemplate[f[args] &], Editable -> False, Selectable -> True,
   SelectWithContents -> True, Tooltip -> ""tooltip""]

After a bit of exploring I realized that I should have checked the Options for TagBox all along.
Options[TagBox]

==> {AutoDelete -> False, BaseStyle -> {}, 
 DefaultBaseStyle -> {}, DefaultTooltipStyle -> ""TooltipLabel"", 
 DeleteWithContents -> True, DeletionWarning -> False, 
 Editable -> Automatic, SelectWithContents -> False, 
 Selectable -> Automatic, StripWrapperBoxes -> False, 
 SyntaxForm -> Automatic, TagBoxNote -> None, Tooltip -> None, 
 TooltipDelay -> 0., TooltipStyle -> {}}

Hopefully someone else finds this useful.
"
list manipulation - Extracting values from nested rules in JSON data,"
It is possible to get rid of all but one ReplaceAll. First, you need to remember that ReplaceAll tests each Rule in order, so to deal with the missing ""badge_counts"" condition, you can simply add that to the list, as follows
{""display_name"", ""creation_date"", ""reputation"", ""reputation_change_week"",
 ""is_employee"", ""last_access_date"", ""user_type"", 
 ""badge_counts""} /. Flatten[{ record, 
   ""badge_counts"" -> {""bronze"" -> 0, ""silver"" -> 0, ""gold"" -> 0} }]

where record is one user record. Since, ""badge_counts"" -> {""bronze"" -> 0, ""silver"" -> 0, ""gold"" -> 0} is listed after the one in the user info, it will only be used if there is no ""badge_counts"" in the user info.  To eliminate the ""badge rules"", I would remove them using ReplaceRepeated (//.) and one more replacement rule and a final Flatten:
{""display_name"", ""creation_date"", ""reputation"", ""reputation_change_week"",
 ""is_employee"", ""last_access_date"", ""user_type"", 
 ""badge_counts""} //. Flatten[{ record, 
   ""badge_counts"" -> {""bronze"" -> 0, ""silver"" -> 0, ""gold"" -> 0},
   Rule[_, a_]:> a}] // Flatten

which returns for your info

{""Verbeia"", 1326833982, 3571, 605, False, 1331949804, ""registered"", 35, 0, 11}

Edit: Originally, I used a slightly different approach instead of Rule[_, a_]:> a. I am reproducing it here, for the curious:
{""display_name"", ""creation_date"", ""reputation"", ""reputation_change_week"",
 ""is_employee"", ""last_access_date"", ""user_type"", 
 ""badge_counts""} /. Flatten[{ record, 
   ""badge_counts"" -> {""bronze"" -> 0, ""silver"" -> 0, ""gold"" -> 0}}] // 
Block[{Rule=#2&}, Flatten[#]]&

which relies on the property of Block to temporarily override the behavior of Rule.
Edit 2: Here's one more alternative which should reduce it to a single pass, unlike ReplaceRepeated. This method, also, eliminates the need for the final Flatten
Clear[killRules]
killRules[a : {_Rule ..}] := Sequence @@ a[[All, 2]]

{""display_name"", ""creation_date"", ""reputation"", ""reputation_change_week"",
 ""is_employee"", ""last_access_date"", ""user_type"", 
 killRules[""badge_counts""]} /. Flatten[{ record, 
   ""badge_counts"" -> {""bronze"" -> 0, ""silver"" -> 0, ""gold"" -> 0}}]

"
Operate on several lists to create one list,"
The general way to do this is using MapThread.  Using your norm example,
MapThread[Norm[{##}]&, {listX, listY, listZ}]

This particular example has easier solutions though:
Sqrt[ listX^2 + listY^2 + listZ^2 ]

"
cdf format - Can CDF file embedded in a web page receive external parameters?,"
You cannot import data to a web embedded CDF:
http://www.wolfram.com/player-pro/how-player-pro-compares.html
...that is to say in principle you can't. However if you read this thread:
Deploying Mathematica Content Online
you will note that @Jens demonstrated that it was possible to import data from a URL. However after investigating this I was told by Wolfram that this was a bug that will be closed in future builds so you cannot rely on this.
"
Mathematica: finding min/max in list,"
Well, you could extract the y values and then calculate their minimum.
rand = RandomInteger[{0, 9}, {10, 3}]


{{6, 5, 2}, {3, 8, 3}, {0, 4, 0}, {3, 7, 5}, {4, 2, 7}, {6, 4, 5}, {3, 3, 3}, {7, 9, 7}, {4, 5, 5}, {4, 2, 5}}


Min[ rand[[All, 2]] ] (* 1 = x, 2 = y, 3 = z *)
Max[ rand[[All, 2]] ]


2
9


Another approach is of course sorting the list by user-defined rules and then picking the first/last element. For example, the following sorts the list according to ascending y values, and then extracts the min/max from that.
sorted = Sort[rand, #1[[2]] < #2[[2]] &]
sorted[[1, 2]] (* Minimal y *)
sorted[[-1, 2]] (* Maximal y *)


2
9


Note that this actually sorts the whole list, which is far less effective computationally. Normally, min/max functions don't sort, they just search.
"
front end - Pasting TemplateBox with a Dynamic argument,"
Pause[3]; NotebookWrite[InputNotebook[], 
 TemplateBox[{Dynamic}, ""Print"", 
 DisplayFunction :> OpenerBox[(# &)]]]

Had to make name a valid function name.
"
numerics - Wrong computation with N,"
This will fix the problem:
Partition[
  Table[{n, N[f[n + 1]/Product[f[k], {k, 1, n}], 10]}, {n, 1, 20}],
        2] // Grid

with output:

The fix I added is precision 10 specification to the function N[... , 10]. If you read Documentation for N in section ""More Information"" you find:
""N[expr] gives a machine-precision number, so long as its magnitude is between $MinMachineNumber and $MaxMachineNumber."" 
Evaluating this:
In[1]:= $MaxMachineNumber
Out[1]= 1.79769*10^308

tells us that when your Table reaches n=9 you hit the greater than $MaxMachineNumber case:
In[2]:= N[f[9 + 1]]
Out[2]= 2.463534156527763*10^348 + 0. I

note 348 > 308 exponent. So now you should explicitly specify the precision you want, like I did with N[... , 10] for example.
Also, to clarify the nature of repeating 4.5826..., I played a bit with Mathematica to come up with a ""conjecture"":
$$\frac{2\cos\left(2^n \cos^{-1}\frac52\right)}{\prod_{k=1}^n 2\cos\left(2^{k-1} \cos^{-1}\frac52\right)}=\sqrt{21}\coth\left(2^n \cosh^{-1}\frac52\right)$$
So because Coth saturates quickly at 1 we have our limit for large arguments
In[3]:= N@Sqrt[21]
Out[3]= 4.58258

yet the numbers in your Table should of course decrease very slowly in ""not printed"" after-decimal-point part due to decreasing Coth function. And this is why the 1st number is 4.6:
In[4]:= TrigExpand[Sqrt[21] Coth[2 ArcCosh[5/2]]]
Out[4]= 23/5

"
keyboard - Ctrl+= opens the alpha input instead of below-script,"
The keyboard shortcut for underscripts has now been changed to ctr-4 (ctr-$). So, to enter your Sum[expr, {n, 1, 10}], you should type
escsumesc
ctr-$n=1ctr-%10
ctr-spaceexpr
Another option is to type the overscript ctr-& first and then use the ctr-% shortcut to move to the underscript position.
Not all of the tutorials have been updated (and if you feel like it, you can submit a bug report to WRI about the oversight that you noticed). That said, the main documentation page on Typing Underscripts does use the correct shortcut (as does the Underscript page).
By the way, I also still find myself pressing ctr-= for underscript and getting frustrated. But I don't think that I'd go as far as to claim that the Wolfram|Alpha interface is completely useless...
"
formatting - Delete a style type from stylesheet,"
I probably haven't understood your problem, but since you're not going into Mr.Wizard's question I have to go by what I read. So here it goes.
Here we have a MMA notebook (left) and a style file (right):

Deleting a style from the style file (just selecting the cell bracket and hitting the delete key):

And finally deleting the last style, we're back at the default style:

"
differential equations - How can you compute Itō Integrals with Mathematica?,"
While I cannot answer your question I would like to point at Computational Financial Mathematics using MATHEMATICA®: Optimal Trading in Stocks and Options, which should answer it.
From the index:

"
programming - Using a list of tuples in a pure function,"
It is good practice to check the precedence of code that is not behaving as you expect.

One of the easiest ways to do this is to use Ctrl+. to expand the selection outward from the cursor while respecting Mathematica precedence.
Converting the expression to StandardForm (Ctrl+Shift+N) will often reveal something about the way Mathematica is parsing your code.
Explicitly parenthesize the code using group, supplied below.
Wrapping the code with HoldForm[FullForm[ . . . ]] (or appending // FullForm // HoldForm)  is a robust but harder to read way to check exactly what Mathematica makes of your code.
In this case syntax highlighting should also tell you that something may be wrong, but the highlighting is not entirely reliable.  (It may show errors on some correct code.)
As a last resort if other methods fail e.g. because your code has syntax errors you can use UndocumentedTestFEParserPacket to see how the Front End is parsing it.  Example:

Infix form of PutAppend ( >>> ) does not work with variable


In the image below I have converted to StandardForm and also used Ctrl+. to expand the selection.  You can see that Mathematica is parsing your Function as (0. &) and that the Map operation is being done before the Set operation.

A function to explicitly parenthesize code:
SetAttributes[group, HoldFirst]

group[expr_] := 
  Replace[
    Unevaluated[expr], 
    x : _[___] :>
      RawBoxes @ RowBox[{""("", ToBoxes @ Unevaluated @ x, "")""}],
    {0, -1}
  ];

Applied to your case:
group[
  value[#[[1]], #[[2]]] = 0. & /@ tuples
]


((value[((#1)[[1]]), ((#1)[[2]])]) = ((0. &) /@ tuples))



This may be easier to read than the FullForm as it tends to expand code less.
The output of group is valid input which may be used as-is or modified.

"
differential equations - What method does NDSolve use for solving PDEs?,"
Update: The answer below is for Mathematica 9 or earlier.  Since version 10, Finite Element Methods are included:

https://reference.wolfram.com/language/FEMDocumentation/tutorial/FiniteElementOverview.html


The methods NDSolve uses are documented in detail here:

Advanced Numerical Differential Equation Solving in Mathematica

This section says that PDEs are solved using the ""method of lines"", and explains which kinds of problems this method can deal with.  There's also a detailed example of how the method works.

The numerical method of lines is a technique for solving partial
  differential equations by discretizing in all but one dimension, and
  then integrating the semi-discrete problem as a system of ODEs or
  DAEs.
...
It is necessary that the PDE problem be well posed as an initial value
  (Cauchy) problem in at least one dimension, since the ODE and DAE
  integrators used are initial value problem solvers. This rules out
  purely elliptic equations such as Laplace's equation, but leaves a
  large class of evolution equations that can be solved quite
  efficiently.

"
numerics - Funny behaviour when plotting a polynomial of high degree and large coefficients,"
If you Rationalize your real numbers you will be able to use Mathematica's arbitrary precision engine:
poly2 = Rationalize[poly[z], 0];

Plot[poly2, {z, 0, 1}, WorkingPrecision -> 50]



Arbitrary and machine precision
Mathematica has two kinds of numeric calculations: machine precision, and arbitrary precision.  Machine precision is fast but is limited to 53 binary (≈16 decimal) digits(1)(2) and may lose precision during a calculation.  Mathematica also does not track the precision of a result.
Numbers entered as 1.234 or 1234` are taken to be machine precision.
Arbitrary precision is slower, but Mathematica will track the precision of calculations, often using more calculations as necessary to preserve precision, and print the precision of the result.
Exact values such as 1234 and 1/2 can be used in arbitrary precision calculations.  Numbers can also be entered with e.g. 1.234`20 specifying 20 digits of precision, and these will automatically use arbitrary precision if all other values are either exact or arbitrary.
Precision can be checked with the function Precision:
Precision /@ {1.234, 1234`, 1.234`20, 7}


{MachinePrecision, MachinePrecision, 20., ∞ }


Precision can only be preserved if all values in a calculation have at least that precision.  Also, arbitrary precision arithmetic may be used with numbers having a precision less than MachinePrecision -- Mathematica will show the true precision of the result.
Precision[1.234 + 7]

Precision[1.234`20 + 1.234`12]


MachinePrecision

12.301


Precision can be set with SetPrecision.  It is probably better to use this rather than Rationalize to put numbers into a form that the arbitrary precision engine will use, because the latter will be manufacturing false precision.
Applying this to your problem:
poly3 = SetPrecision[poly[z], 15];

Plot[Evaluate[poly3], {z, 0, 1}, WorkingPrecision -> 50]


During evaluation of In[91]:= Plot::precw: The precision of the
  argument function <<>> is less than WorkingPrecision (50.`). >>

This is an important warning because it lets you know that your results may not be valid.
See this tutorial for more information about precision.  Take time to understand the difference between Mathematica's meanings of Accuracy and Precision.

Recommended reading, a more recent answer from Szabolcs regarding arbitrary precision:

Very different results from evaluating same expression with different precisions


Interval
Michael's answer shows the folly of simply doing a Rationalize as I did at the start of this answer.  Since questions like this come up often it would be good to have a general solution that is easily applied.  I propose this rule using his formula:
machineToInterval = 
  c_Real?MachineNumberQ :> 
    Interval[ {1 - 2^-54, 1 + 2^-54} SetPrecision[c, ∞] ];

This converts any machine numbers into explicit Interval form.
To extract an ordered pair of values from a numeric Interval we merely need First.
poly3 = poly[z] /. machineToInterval;

Plot[{First @ poly3, poly[z]}, {z, 0, 1}
 , WorkingPrecision -> 50
 , PlotStyle -> {{Thick, Red}, ColorData[97][1]}
]


"
plotting - RegionPlot3D contour problem,"
Solution using Show needs to rearrange the order of ranges in ContourPlot3D, e.g. : 
Show[RegionPlot3D[(s - 3 q*s + q > 0 && p == 0) ||
                     (s - 3 q*s + q <= 0 && p == 1), 
                  {q, 0, 1}, {s, 0, 1}, {p, 0, 1}, AxesLabel -> Automatic], 
     ContourPlot3D[s - 3 q*s + q == 0, {q, 0, 1}, {s, 0, 1}, {p, 0, 1}]]


Edit
Here is another solution without Show, using only Plot3D and HeavisideTheta function :
Plot3D[ HeavisideTheta[-s + 3 q*s - q], {q, 0, 1}, {s, 0, 1}, 
        Exclusions -> None, PlotPoints -> 100, PerformanceGoal -> ""Quality"", 
        ColorFunction -> Function[{x, y, z}, RGBColor[x, y, 1]], 
        MeshFunctions -> {#1 &, #2 &, #3 &}, BoxRatios -> {1, 1, 2/3}]


"
performance tuning - Efficient conditional division,"
To stay with your example:
n = 12; p = 4;
If[
   #2 == 0, n= #1;
   Print[""A division took place!""]
   ] & @@ QuotientRemainder[n, p]


A division took place!

"
manipulate - What changes in Dynamic have occurred from Mathematica 7 to Mathematica 8 that might induce incompatibilities?,"
The following does something similar to OP's parametric manipulate function. It works without issue in version 8.0.4:
    animFunc[Dynamic[freq1_], Dynamic[freq2_]] := Manipulate[
    ParametricPlot[{a1 Sin[freq1 (x + p1)], 
    a2 Cos[freq2 (x + p2)]}, {x, 0, 20 Pi}, PlotRange -> 1, 
    PerformanceGoal -> ""Quality""],
    {{a1, 1}, 0, 1, Animator, AnimationRunning -> False}, {p1, 0, 2 Pi,
    Animator, AnimationRunning -> False}, {{a2, 1}, 0, 1, Animator, 
    AnimationRunning -> False}, {p2, 0, 2 Pi, Animator, 
    AnimationRunning -> False}, ControlPlacement -> Top];

Usage example:
    Column[{Slider[Dynamic[y1], {1, 4, .1}], 
    Slider[Dynamic[y2], {1, 4, .1}], animFunc[Dynamic@y1, Dynamic@y2]}]

Screenshots with two different settings:

"
"output formatting - Constructing a list that includes a leading zero (01,02,03 ... 55, 56, etc.)","
I always use IntegerString for this (I also number my files in a similar way):
In[1]:= IntegerString[#, 10, 2] & /@ Range[87]

Out[1]= {""01"", ""02"", ""03"", ""04"", ""05"", ""06"", ""07"", ""08"", ""09"", ""10"", \
""11"", ""12"", ""13"", ""14"", ""15"", ""16"", ""17"", ""18"", ""19"", ""20"", ""21"", \
""22"", ""23"", ""24"", ""25"", ""26"", ""27"", ""28"", ""29"", ""30"", ""31"", ""32"", \
""33"", ""34"", ""35"", ""36"", ""37"", ""38"", ""39"", ""40"", ""41"", ""42"", ""43"", \
""44"", ""45"", ""46"", ""47"", ""48"", ""49"", ""50"", ""51"", ""52"", ""53"", ""54"", \
""55"", ""56"", ""57"", ""58"", ""59"", ""60"", ""61"", ""62"", ""63"", ""64"", ""65"", \
""66"", ""67"", ""68"", ""69"", ""70"", ""71"", ""72"", ""73"", ""74"", ""75"", ""76"", \
""77"", ""78"", ""79"", ""80"", ""81"", ""82"", ""83"", ""84"", ""85"", ""86"", ""87""}

I think this is the most convenient solution, as it's built-in and doesn't require any additional effort to get it working.
"
formatting - CDF and personalized style,"
I encountered no problems here. My system: Mathematica 8.0.4 WIN7. My workflow:
1) File > New > Notebook
2) Format > Edit Stylesheet... I applied new styles to Title, Subtitle and Section.
3) Enter your content in Mathematica notebook.
4) File > Deploy > Standalone... This will produce a CDF file with inherited styles.
Here is the snapshot of CDF file I created opened in Wolfram CDF Player - as you can see all styles are preserved:

"
Using patterns in pure functions,"
You could write something like this:
# /. x_Integer :> x (x - 1) & /@ {1, 2, 3}


{0, 2, 6}

"
extract values from replacement list,"
I also think that what you are already using is the best way, but here is another one to toss into the mix:
Solve[x + y == 3 && x - y == 6, {x, y}][[1]] /. Rule -> (#2 &)


{9/2, -(3/2)}


"
plotting - Ad hoc graphics primitives-like objects,"
The result of Plot3D and related functions is something of the form Graphics3D[primitives, options], so to extract the graphics primitives you can simply take the first part of the plot. These can then be manipulated similar to Sphere[] in your example, e.g.
plot = Plot3D[Exp[-(x^2 + y^2)], {x, -2, 2}, {y, -2, 2}][[1]];

GraphicsRow[
 Table[Graphics3D[
   Rotate[Scale[{GrayLevel[.7], plot}, {1, 1.5, 1}, {0, 0, 0}], 
    i Degree, {0, 0, 1}], PlotRange -> {{-2, 2}, {-2, 2}, {-2, 2}}, 
   AspectRatio -> 1, Background -> Black, Boxed -> False, 
   ViewPoint -> Front, SphericalRegion -> True, 
   Lighting -> {{""Directional"", White, 
      ImageScaled[{0, 0, 1}]}}], {i, {0, 45, 90}}]]


"
plotting - Saner alternative to ContourPlot fill,"
I actually like your own solution as a way to generalize the RegionPlot approach, and the answer by @tkott! 
Edit with improved version of RegionPlot trick
Since @tkott's solution was still rough around the edges, I hacked together a version of it that should be able to emulate all the features of ContourPlot - i.e., be usable as a drop-in replacement with the same syntax and options. Here it is:
contourRegionPlot[f_, rx_, ry_, opts : OptionsPattern[]] := 
 Module[{cont, contourOptions, frameOptions, colList, levelList, lab, 
   gr, pOpt, allLines, contourstyle, regionPlotOptions, 
   contourStyleList},
  contourstyle = 
   ContourStyle /. {opts} /. 
     None -> Opacity[0] /. {ContourStyle -> Automatic};
  contourOptions = 
   Join[FilterRules[{opts}, 
     FilterRules[Options[ContourPlot], 
      Except[{Prolog, Epilog, Background, ContourShading, 
        ContourLabels, ContourStyle, RegionFunction}]]], {Background -> None, 
     ContourShading -> True, ContourLabels -> Automatic, 
     ContourStyle -> contourstyle}];
  regionPlotOptions = 
   Join[FilterRules[{opts}, 
     FilterRules[Options[RegionPlot], 
      Except[{Prolog, Epilog, Background,RegionFunction}]]], {Background -> None, 
     PlotStyle -> None}];
  cont = Normal@
    ContourPlot[f, rx, ry, Evaluate@Apply[Sequence, contourOptions]];
  colList = 
   Reverse@Cases[
     cont, {EdgeForm[___], ___, 
       r_?(MemberQ[{RGBColor, Hue, CMYKColor, GrayLevel}, 
           Head[#]] &), ___} :> r, Infinity];
  {contourStyleList, levelList} = 
   Transpose@
    Cases[cont, Tooltip[{gr_, __}, lab_] -> {gr, lab}, Infinity];
  frameOptions = FilterRules[{opts}, Options[Graphics]];
  allLines = 
   Flatten@Prepend[
     Table[RegionPlot[Evaluate[f < levelList[[i]]], rx, ry, 
       Evaluate@Apply[Sequence, regionPlotOptions]], {i, 
       Length[levelList]}], 
     RegionPlot[f > levelList[[-1]], rx, ry, 
      Evaluate@Apply[Sequence, regionPlotOptions]]];
  pOpt = allLines[[1, 2]];
  Show[Graphics[
    MapThread[{EdgeForm[#1], FaceForm@Directive[Opacity[1], #2], 
       FilledCurve[
        List /@ Cases[Normal[#3], _Line, Infinity]]} &, {Append[
       contourStyleList, Opacity[0]], colList, allLines}], pOpt], 
   frameOptions]]

Edit 3
I streamlined some inefficient code, and made the ContourStyle option work. The function  is clearly slower than my rasterized approach. But it comes close to the old version-5 behavior. 
Edit 4
In the above code, one can now also use Epilog, and it is allowed to specify ContourStyle as a list with separate directives for each contour.
That's probably all I'll do with this method, since there are sufficiently many alternatives that could be used if the above doesn't do what you want. I personally still prefer the continuous gradients of DensityPlot and contourDensityPlot (see below). Meanwhile there is also @Szabolcs' answer, which is seen in his example to accept the RegionFunction argument. Instead of implementing this option, I chose to ignore it in the above solution (it does work in the contourDensityPlot solution below).  
Here is another example:
contourRegionPlot[Sin[x^2 + y^2]/(x^2 + y^2), {x, -2, 2}, {y, -2, 2}, 
 ContourStyle -> Black, ColorFunction -> Hue]


If you leave out the styling, you'll get the version-8 default styles.
Alternative image-based approach
I don't know if my solution (based on rasterization, not your proposal) is saner, but it offers some additional possibilities. In case you haven't already tried it, you may want to look at my answer on stackOverflow. The post links to a page whose parent page has several different functions that all use rasterized images for the shading. In this case, the relevant one would be rasterContourPlot. Since it uses images, one can apply opacity or potentially other image effects to the output.
But as I said, your approach of stacking different image levels seems very sane to me. 
Edit
Among the rasterized solutions I list above, the first one I did was the one listed below. My rationale for it was: if I am going to try and fix the shading problem for ContourPlot, why not add a feature that I was looking for anyway: 
While contour lines are good, I also like to have the color fill to have a smooth gradient representing the function more faithfully. With the uniform ContourShading of ContourPlot, it seems to me that you're sometimes losing too much information about the function. Of course if I just want smooth color gradients, I could use DensityPlot instead. But wanted both, gradients and contours. That's originally why I decided it was time to write my own replacement for ContourPlot, listed here:
contourDensityPlot[f_, rx_, ry_, 
  opts : OptionsPattern[]] :=
 (* Created by Jens U.Nöckel for Mathematica 8,revised 12/2011*)
 Module[{img, cont, p, plotRangeRule, densityOptions, contourOptions, 
   frameOptions, rangeCoords}, 
  densityOptions = 
   Join[FilterRules[{opts}, 
     FilterRules[Options[DensityPlot], 
      Except[{Prolog, Epilog, FrameTicks, PlotLabel, ImagePadding, 
        GridLines, Mesh, AspectRatio, PlotRangePadding, Frame, 
        Axes}]]], {PlotRangePadding -> None, ImagePadding -> None, 
     Frame -> None, Axes -> None}];
  p = DensityPlot[f, rx, ry, Evaluate@Apply[Sequence, densityOptions]];
  plotRangeRule = FilterRules[Quiet@AbsoluteOptions[p], PlotRange];
  contourOptions = 
   Join[FilterRules[{opts}, 
     FilterRules[Options[ContourPlot], 
      Except[{Prolog, Epilog, FrameTicks, Background, ContourShading, 
        Frame, Axes}]]], {Frame -> None, Axes -> None, 
     ContourShading -> False}];
  (* //The density plot img and contour plot cont are created here:*)
  img = Rasterize[p];
  cont = If[
    MemberQ[{0, 
      None}, (Contours /. FilterRules[{opts}, Contours])], {}, 
    ContourPlot[f, rx, ry, 
     Evaluate@Apply[Sequence, contourOptions]]];
  (* //Before showing the plots,
  set the PlotRange for the frame which will be drawn separately:*)
  frameOptions = 
   Join[FilterRules[{opts}, 
     FilterRules[Options[Graphics], 
      Except[{PlotRangeClipping, PlotRange}]]], {plotRangeRule, 
     Frame -> True, PlotRangeClipping -> True}];
  rangeCoords = Transpose[PlotRange /. plotRangeRule];
  (* //To align the image img with the contour plot,enclose img in a//
  bounding box rectangle of the same dimensions as cont,
  //and then combine with cont using Show:*)
  Show[Graphics[{Inset[
      Show[SetAlphaChannel[img, 
        ""ShadingOpacity"" /. {opts} /. {""ShadingOpacity"" -> 1}], 
       AspectRatio -> Full], rangeCoords[[1]], {0, 0}, 
      rangeCoords[[2]] - rangeCoords[[1]]]}, 
    PlotRangePadding -> None], cont, 
   Evaluate@Apply[Sequence, frameOptions]]]

With your example, it produces the following output. To get this result, using the rasterized image of the DensityPlot was the only ""sane"" alternative.
contourDensityPlot[Cos[x] + Cos[y], {x, 0, 4 Pi}, {y, 0, 4 Pi}]


I should add a note about the options: you can feed this function with the options for ContourPlot and DensityPlot.  You can completely suppress the ContourPlot output by giving the option Contours -> None.
I also added an option ""ShadingOpacity"" that can be used to make the shaded background transparent. The shading is fully opaque for ""ShadingOpacity"" -> 1 and fully transparent for ""ShadingOpacity"" -> 0. This option is useful if you want to combine the plot with a Prolog, or if you have added Gridlines -> Automatic which usually will be hidden behind the density plot shading.
Edit 2
As mentioned in the comment to the question, I also tried polygone (a command-line tool you have to run in Terminal), and got mixed results with EPS exported from Mathematica version 8.
"
charts - Retrieving PlotRange from BarChart,"
Extracting the PlotRange from a BarChart is not as straightforward as it should be. If no PlotRange is specified in creating the chart, then Options will return PlotRange -> All and AbsoluteOptions will return PlotRange -> {{0., 1.}, {0., 1.}
bc = BarChart[{1, 2, 3, 4}];

Options[bc, PlotRange]
(* {PlotRange -> All} *)

AbsoluteOptions[bc, PlotRange]
(* {PlotRange -> {{0., 1.}, {0., 1.}}} *)

The incorrect result from AbsoluteOptions appears to be related to the presence of dynamic objects in the graphics expression (i.e. the bars with their mouseover effects) . I don't know why this causes AbsoluteOptions to go wrong, but a workaround is to replace the dynamic bars with straighforward rectangles, allowing AbsoluteOptions to extract the correct PlotRange. Thus, a replacement for AbsoluteOptions for BarCharts is:
barChartOptions[chart_, opts___] := 
 AbsoluteOptions[chart /. 
  Tooltip[StatusArea[RawBoxes[DynamicBox[{_, RectangleBox[data__]}]], _], _] :> 
    Rectangle[data], opts]

barChartOptions[bc, PlotRange]
(* {PlotRange -> {{0.545455, 4.45455}, {0., 4.}}} *)

"
How to remove repeated permutations?,"
Did I understand correctly?
Subsets[Range[1, 16], {2}]

EDIT: If you want to use Permutations, you could use
DeleteDuplicates[Permutations[Range[16], {2}], Sort[#1] == Sort[#2] &]

which deletes all ""duplicates"", where ""duplicate"" is defined by the equality of the two lists when sorted (ie, {2,3} is ""equal"" to {3,2} for purposes of this comparison).
EDIT: The meaning of #1 and #2 may be demonstrated by this example:
f={#1,#2}&

and then f[a,b] evaluates to {a,b}. That is, you are defining a pure function which takes two arguments, returning a list containing the two arguments, and assigning it to f. This could also be useful.
In the DeleteDuplicates example above, I am using as a test function (see second usage example in the documentation and also this example) that considers two lists equal if they are the same after sorting; thus, {3,4} is equal to {4,3}, since when sorted they both become {3,4}.
See also this.
"
packages - How safe is Encode?,"
The documentation of Encode states:

No function is provided in Mathematica to convert encoded files back
  to their original form.

implying that an average user should not be able to view your proprietary code.
If you look at the example on the Encode doc page you see that Get is used to read back the Encoded Collatz package and Collatz works as intended. If you now type: 
Definition[Collatz]

you get
Collatz[1]:={1}

Collatz[Collatz`Private`n_Integer]:=
    Prepend[Collatz[3 
        Collatz`Private`n+1],Collatz`Private`n]/;OddQ[Collatz`Private`n]&&
           Collatz`Private`n>0

Collatz[Collatz`Private`n_Integer]:=
    Prepend[Collatz[Collatz`Private`n/2],Collatz`Private`n]
      /;EvenQ[Collatz`Private`n]&&Collatz`Private`n>0

So, some or all of your code becomes visible.
Of course, you can use TagSet to prevent this:
Collatz /: Definition[Collatz] := """"

but I'd think there will be ways to get around that and other measures.
So, it doesn't seem that Encode is sufficient to keep your code proprietary. It might be a good way to prevent third parties from viewing your code during transport, though. In a quick search I couldn't find the type of encryption, so there's not much to say about its actual safety. 
If you want to deploy your code in encoded form, your clients might have to use Mathematica Player Pro (or MMA itself) as I don't think the CDF-player reads encoded documents (it doesn't import and export documents at all, see the CDFplayer FAQ). There may be Digital Rights Management in future versions according to the same FAQ:

Can I put copy protection on my CDFs? 
At the moment, we do not have
  Digital Rights Management (DRM) for CDF, but we are working on making
  it available. Contact us for more details when DRM support becomes
  available.


Update:
There was a discussion about DRM in the LinkedIn group Mathematica. Perhaps you could contact the guy who seemed to have a solution?
"
matrix - Obtain approximate Hessian using FindMinimum,"
Unfortunately, this requires a lot more devious trickery than I would have preferred. As noted in the documentation at tutorial/UnconstrainedOptimizationQuasiNewtonMethods, the Hessian is not formed directly in the BFGS method, so we have to recover it from the Cholesky factors. However, all of this is done inside the kernel where we cannot access it using ordinary methods, and the only way I can see to obtain these factors is to hook calls to the BLAS function *TRSV (called as LinearAlgebra`BLAS`TRSV in Mathematica) and extract its arguments directly. Needless to say, this is hardly likely to be particularly robust, but it hopefully it will work well enough for your needs.
Let us define:
approximateHessianList[f_, vars_, start_] :=
  With[{fmarg2 = Thread[{vars, start}]},
   Module[{steps, lowerTriangles, upperTriangles},
    Internal`InheritedBlock[{LinearAlgebra`BLAS`TRSV},
     Unprotect[LinearAlgebra`BLAS`TRSV];
     trsv : LinearAlgebra`BLAS`TRSV[uplo_, trans_, diag_, a_, x_] /; (
       Switch[
        trans,
        ""N"", Sow[LowerTriangularize[a], ""LowerTriangle""],
        ""T"", Sow[UpperTriangularize[a], ""UpperTriangle""]
       ]; True
      ) := trsv;
     Protect[LinearAlgebra`BLAS`TRSV];
     {steps, lowerTriangles, upperTriangles} =
      Reap[
       FindMinimum[
        f, fmarg2,
        Method -> {""QuasiNewton"", ""StepMemory"" -> Infinity},
        StepMonitor :> Sow[vars, ""Step""]
       ], {""Step"", ""LowerTriangle"", ""UpperTriangle""}
      ][[2, {1, 2, 3}, 1]];
     Transpose[{steps, MapThread[Dot, {lowerTriangles, upperTriangles}]}]
    ]
   ]
  ];
SetAttributes[approximateHessianList, HoldAll];

We may now write:
approximateHessianList[Cos[x^2 - 3 y] + Sin[x^2 + y^2], {x, y}, {1, 1}]

which gives a list of steps in the BFGS optimization along with the approximate Hessians evaluated at those points. For the sake of brevity (and because it is obviously the most accurate), let us take only the last of these:

{{1.37638, 1.67868}, {{15.1553, 0.986982}, {0.986982, 20.2017}}}


which we may compare to the exact Hessian evaluated at this point:
D[Cos[x^2 - 3 y] + Sin[x^2 + y^2], {{x, y}, 2}] /. {
  x -> 1.376384972443001`, y -> 1.6786760817546214`
 }


{{15.1555, 0.983708}, {0.983708, 20.2718}}


Clearly, it is not a bad approximation.
Now, some caveats. Since the logic of the code inside the kernel is completely opaque, I am not sure whether this business with the upper and lower triangles is really necessary, since the argument a of LinearAlgebra`BLAS`TRSV appears to be the same for successive calls, firstly with trans == ""N"" and then with trans == ""T"". However, this represents at most an inefficiency. A more serious problem is that I am not sure whether the first Hessian obtained using this method corresponds to the initial point, $(x,y)=(1,1)$ , or the point at the end of the first step, which here is $(x,y)=(0.811216, 1.68144)$ . While this does not really matter if the approximation has converged, it does influence the interpretation of the earlier approximations substantially, so hopefully someone with access to the kernel code will be able to clarify this aspect of FindMinimum`QuasiNewton's behaviour.
"
Quality of random numbrs - Mathmatica Stack Exchang,"
I finally found some time to investigate this. I think it warrants a detailed response. In places I will repeat what others have pointed out, but I wanted something that ties together the various threads as best I can discern them.
I'm not certain what is meant by the Rule 30 RNG having ""an extremely small effective size"". Possibly it refers to taking bits only from the middle column? That is in fact what it does, or at least did the last time I looked at the implementation code. That is relatively less speed efficient than other RNGs but does give pseudorandom sequences of high quality. More on that in a bit.
I see the claim: ""ExtendedCA: What is this? Apparently hasn't been tested."" The documentation states

The cellular automaton used by ""ExtendedCA"" produces an extremely high level of randomness. It is so high that even using every single cell in output will give a stream of bits that passes many randomness tests, in spite of the obvious correlation between one cell and five previous ones.

I will give a bit more detail on this matter. In house testing has shown ExtendedCA passing all Diehard and BigCrush tests. One test has a p-value around .993, with all others in the range .01-.99. Moreover some correlation testing has been done that is outside of the tests in TestU01 (the Crush suite).
The Rule 30 generator is almost as good as this in terms of the Big Crush suite. I want to address specifically the following comment: ""Rule30CA: Low quality (Meier & Staffelbach 1991, Sipper & Tomassini 1996)""
I have not yet managed to locate a copy of that first article. I did find some explanation of it in a more recent paper by Lacharme, Martin, and Sole (see refs below). I gather the issue is strictly of cryptographic usage, where (un)predictability is more important than (pseudo)randomness. They indicate that it may be possible to reconstruct part of the initial configuration given the stream of middle column bits. While this is out of my area, I will concede that this might be problematic for that type of use. That said, let me also remark that the initial configuration part reconstructed is from the left half set of columns. If one has a look at the Rule 30 output from a very specific one bit initial cell, as seen in the ""Structure and properties"" section in Rule 30's Wikipedia article, one will observe considerably more regularity on the left side than the right. This leads me to suspect that knowing the leftmost initial bits will not be of general help in full reconstruction of the middle column. But again, I'm no expert on this.
Pseudorandomness is an entirely different matter. As I mentioned above, Rule 30 actually tests quite well in this regard. So let me take up the matters under discussion in Sipper & Tomassini (1996). It is important to understand what exactly is their claim. They tested using not just the center column, but all columns, of the various RNGs. Used in this way, Rule 30 is indeed quite bad. That's why it does not get used in this way. I note that the authors point out that this is the actual use (first paragraph of section 2). They also state quite clearly (section 4):

The relatively low results obtained by the rule 30 CA may be due to the fact that we considered N random sequences generated in parallel, rather than the single one considered by Wolfram.

The point, I think, was not that they were claiming Rule 30 generator is bad when properly used, but rather that they were able to find ones that operate more efficiently in terms of how many bits can be used per iteration.
As mentioned in another response and comments thereto, they then (section 5) state  (emphasis mine):

It seems safe to say at this point that our co-evolved generators are at least as good as the best available CA randomizers.

Here is the point. They tested against the suite by Knuth which, at the time of that writing, was ""best practice"". The Marsaglia Diehard test suite showed up also in 1996 so it may be no surprise they were not aware of it. The l'Ecuyer Crush tests were not around for several more years. Later analysis, as indicated in the paper by Seredynski, Bouvry, and Zumaya (linked to by a comment to this query, see below for another link), indicates that a related evolved CA-based generator, by Tomassini and Perrenoud (see below for ref), does not fare terribly well on Diehard. While I do not know if this is also the case for the Sipper and Tomassini RNG, I will speculate that the Sipper/Tomassini generator would be no better, and perhaps worse, since (going by dates of publication) it was very likely developed a few years earlier. The upshot is that the Rule 30 and ExtendedCA RNGs are, by the standards of current testing, quite sound. Some of the others that showed up in the earlier literature apparently fall short.
Some other pseudorandom remarks.

(From comments)

[T]he ExtendedCA generator is just a simplified version of CA30 so is likely to suffer from the same problems.""

It may have similar problems but it is not a simplified version of Rule 30. It uses a neighborhood of five noncontiguous cells (this is indicated in the first paragraph describing it from the documention I referenced above).

Reading about the evolution methods used to construct nonuniform CA-based RNGs leads me to think they should not of necessity work well. That is to say, they might, but one has to be lucky. Here is my reasoning. First, as best I can tell, they select based on an entropy condition that will be satisfied even better by a low discrepancy sequence generator. Such sequences have excellent qualities e.g. for quasi-Monte-Carlo integration. But they are quite far from random. Second is that the winners of each ""round"" (in the sense of evolutionary methods) are heavily dependent on what I'll call ""the kindness of neighbors"". So there is no compelling reason to believe that a local rule that seemingly works well will continue to do so if its neighbors change. This is a general problem with evolutionary methods that have such linkage between genes or their equivalent units. Such methods do in practice still often give good results, due to the effect of co-evolution amongst neighbors. But still...

(From comments):

Now remember that Rule 30 was introduced for the purpose of crypto, so this is a reasonable avenue to check.

I cannot myself give an accurate accounting of the historical origins of Rule 30 applications. For what it is worth, here is what Stephen Wolfram writes in his 2002 NKS tome.

""I originally studied rule 30 in the context of basic science, but I soon realized that it could serve as the basis for practical random sequence generation and cryptography, and I analyzed this extensively in 1985. (Most but not all of the results from my original paper are included in this book, together with various new results.) In 1985 and soon thereafter a number of people (notably Richard and Carl Feynman) tried to cryptanalyze rule 30, but without success. From the beginning, computations of spacetime entropies for rule 30 (see page 960) gave indications that for strong cryptography one should not sample all cells in a column, and in 1991 Willi Meier and Othmar Staffelbach described essentially the explicit cryptanalysis approach shown on page 601. Rule 30 has been widely used for random sequence generation, but for a variety of reasons I have not in the past much emphasized its applications in cryptography.""



I hope this is of some use for understanding the qualities of the CA-based RNGs in Mathematica.

Here are some references.

Seredynski, Bouvry, and Zumaya paper ""Cellular automata computations and secret key cryptography"" (Parallel Computing, 2004).

Tomassini and Perrenoud paper ""Cryptography with cellular automata"" (Applied Soft Computing, 2001).

Lacharme, Martin, and Sole paper ""Pseudo-random sequences, Boolean functions and cellular automata"" (Proceedings of Boolean Functions: Cryptography and Applications, BFCA 2008); also here.


"
evaluation - Subtle difference in conditional rules placement,"
This isn't a runtime issue, so you won't find the answer by tracing f[foo] and family.
It's a definition thing. If you look at the downvalues you'll see that in f as well as in h the Unevaluated got stripped off when running the SetDelayed
Let's look at the fullform of your definitions
f:
SetDelayed[
 f[Condition[Pattern[x, Blank[]], 
   SameQ[Head[Unevaluated[x]], Symbol]]],
 Unevaluated[x]]

So, Mathematica sees this code. 
First it evaluates SetDelayed, it is inert.
It checks its attributes: HoldAll, SequenceHold.
Now it strips off the Unevaluated of its arguments... (!!)
Evaluates the expression as a whole, and stores the definition (the Unevaluated is gone already)
g:
SetDelayed[
 g[Pattern[x, Blank[]]],
 Condition[Unevaluated[x], SameQ[Head[Unevaluated[x]], Symbol]]]

Now, in this case, no argument has head Unevaluated so it survives :)
h:
SetDelayed[
 Condition[h[Pattern[x, Blank[]]], 
  SameQ[Head[Unevaluated[x]], Symbol]], Unevaluated[x]]

Same as f, goodbye Unevaluated
"
Impossible to bypass evaluation on returned values?,"
Well, it seems that you just hit the fundamental problem of this approach: any global definition is attached to some symbol. In cases of DownValues, SubValues and perhaps UpValues, this does not harm your approach. But for OwnValues (meaning symbols which have direct values, i.e. variables), it does. You pretty much made this observation yourself. You have to decide which semantics you wish for your function. From what I can tell, you probably do wish to wrap them in some Hold-like wrapper.
However, I would take a different road. I would use Block dynamically, to make a dynamic environment where these symbols are Block-ed, and work in that dynamic environment for whatever code transformations (quoting, etc) you may wish to perform. Yet another approach is to temporarily hide certain symbols with some dummy symbols (assuming that your goal is to make some portions of your code inert and available as data) - I described a very simple version of it here. I actually did write a quoting library based on a combination of these two approaches, for some code-generation purposes, and this worked out quite well for me.
"
list manipulation - Equating matrices (or higher order tensors) element-wise,"
What about flattening first?
Thread[Flatten /@ (A==B)]

"
probability or statistics - Cluster analysis returns questionable results,"
Clustering is  a relatively unstable process. Points which exist near to cluster boundaries may have small Euclidean, or other, distances between them, but be on different sides of the local boundary. So, in and of themselves, point separation distance metrics may be misleading.
If clusters in the data overlap to any degree, a common case, then there is almost certain that some unavoidable mislabelling of cluster membership will occur in the region of overlap.
The exact specifics of how this mislabelling came about will depend on the distance metric used  and the  distribution and dimensionality of the original data.
Projecting the data down into a low dimensional space (1D,2d,3D) using PrincipleComponents[], or other similar dimensional reduction transform ... MDS etc, will allow you to plot the clusters and visualise some elements of their specific configurations. This may, or may not, be useful in deciding if the clustering you have is sensible.
"
How to know if a number is the square of a rational?,"
The only trick I can see is a trivial one: if $x$ is the square of a rational, it is also a rational. That's because of the  $x = (a/b)^2 = a^2/b^2$.
So, I'd write a function testing the rationality, which returns either True, False, or Null (if rationality cannot be established):
isRational[x_] := If[Simplify[x ∈ Rationals], True, False, Null]

which works like this:
In[30]:= isRational /@ {1/3, π, EulerGamma}
Out[30]= {True, False, Null}

And then simply use it by first checking if the number itself is known to be rational:
isSqrRational[x_] := If[isRational[x], isRational[Sqrt[x]], False, isRational[Sqrt[x]]]

which gives:
In[33]:= isSqrRational /@ {1/3, 1/4, π, EulerGamma}
Out[33]= {False, True, False, Null}

"
functions - Cannot evaluate differential in Mathematica,"
$P[y]$ is defined to be $\partial_yF[y]$. If you now call $P[2]$ for example, this is translated to $\partial_2F[2]$, which of course does not make any sense.
One way to get around this behavior is not taking the derivative with respect to y, but with respect to the first argument instead. The following example assigns f[y] to be the derivative of g[y]:
g[y_] := y^2
f[y_] := Derivative[1][g][y]
f[x]


2 x


Instead of Derivative[1][g][y] you could also have used the shorthand notation g'[y]. Read the explicit long version I used as an operator applied to multiple things: Derivative[1] takes a function and calculates its first derivative with respect to the first argument. Derivative[1][g] is that derivative (as a pure function), and Derivative[1][g][y] is that pure function applied to a value y.
The script above has one problem however: Every time you call f[x], it re-calculates the derivative, which can take some time if your function is more complicated and you need a lot of data points. If you use functions instead of patterns (i.e. no :=) you can also get around this problem:
g = #^2 &
f = g'
f[x]


#1^2 &
2 #1 &
2 x


"
Saving in $\LaTX$ - Mathmatica Stack Exchang,"
The way you do this - by saving the whole notebook with un-formatted In/Out cells - will get you a file with non-traditional working Mathematica notation. For example you will get  square brackets for functions instead of round ones and capitalized functions names. If your goal is just to get a nicely formatted formula in $\TeX$ form, you could use this (for your 1st equation):
In[1]:= f = First[y /. DSolve[y'[x] + x y'[x]^2 == 1, y, x]];
        TeXForm[f[x]]

Out[1]//TeXForm=
c_1+\frac{1}{2} \left(-2 \sqrt{4 x+1}-2 \log \left(1-\sqrt{4 x+1}\right)\right)

If you paste the output in the body of your $\TeX$ file between $$ you'll get a nice formula:

If you would like to save the whole document you need to apply some formatting to it, depending on what you exactly need. For example turning an output cell into text cell will result in wrapping the formulas in \( ... \) , which is an equivalent of $...$ in $\LaTeX$.
"
graphs and networks - Simple algorithm to find cycles in edge list,"
Edited to account for @Szabolcs comment
A index-disordered edge list (a bit different from yours):
el = {{3, 2}, {1, 3}, {2, 5}, {5, 8}, {4, 7}, {7, 6}, {6, 4}, {8, 1}}

Let's visualize with labels 
gr = Graph[el, VertexLabels -> ""Name"", PlotRangePadding -> .2]


This will pick up the cycles but reorder them (as @Szabolcs reflects in the comment)
In[1]:= ConnectedComponents[gr]

Out[1]= {{1, 2, 3, 5, 8}, {4, 6, 7}}

We see this ordering is wrong because there is no edge between vertices 1 and 2. This more elaborate line will work:
In[2]:= Map[First, (FindHamiltonianCycle /@ (Subgraph[gr, #] & /@ 
         ConnectedComponents[gr])), {3}]

Out[2]= {{{1, 3, 2, 5, 8}}, {{4, 6, 7}}}

FindEulerianCycle would work too.
I wonder how it scales if you check this on your ~1000 vertex case.
"
front end - Close subgroup of cells and keep them closed,"
Adapting this answer, please try this:
autoFoldOutput[] := (If[$FrontEnd =!= $Failed, 
   SelectionMove[EvaluationNotebook[], All, EvaluationCell];
   FrontEndTokenExecute[""SelectionCloseUnselectedCells""]])

And then in a new cell:
2 + 2
autoFoldOutput[]

"
Can Mathematica do symbolic linear algebra?,"
For the posted example, TensorReduce does the trick:
TensorReduce[
  Transpose[Transpose[A].Transpose[B]], 
  Assumptions -> {A ∈ Matrices[{m, n}], B ∈ Matrices[{k, m}]}
]


B.A


"
plotting - How to save plots in grayscale,"
One way would be to use ColorConvert to convert the RGB or Hue values to gray scale. Here's an example:
Plot[{Sin[x], Cos[x], Exp[-x^2], Sinc[π x]}, {x, 0, π}] /. 
  x : _RGBColor | _Hue | _CMYKColor :> ColorConvert[x, ""Grayscale""]



For 2D plots that accept a ColorFunction, you can simply use GrayLevel to get the plot in grayscale as:
DensityPlot[
  Sin[x ^2 + y^2], {x, 0, 3}, {y, 0, 3},
  ColorFunction -> GrayLevel,
  PlotPoints -> 100
]




Typically, these grayscale plots are useful when submitting to journals that charge exorbitant prices just to print in colour. However, just a note of caution that discerning different shades of gray is not easy. For the most effect, it is recommended (at least in the journals I publish in), that you also change the line type for your different curves (and not more than 4 curves/plot). You should also choose the colours (or colourscale, for 2D surface plots) wisely so that they convert well to grayscale. For example:


"
graphics - Consistent Plot Styles across multiple MMA files and data sets,"
For an example of plot option customization that I am still rather proud of please see:
How to change the default ColorData used in Mathematica's Plot?
For general customization I think you already outlined some good options.  I personally favor the custom function method for maximum control.  Another, perhaps cleaner method that I crudely copy from Leonid works well if you can pool options for all plot types in one list ($myoptions):
Update: changed withOptions to use the ""injector pattern"" so as not to disrupt functions if withOptions is used indiscriminately (withOptions[ 1 + 1 ]). 
$myoptions = {Filling -> {1 -> {{2}, {Red, Purple}}}};

SetAttributes[withOptions, HoldFirst]

withOptions[head_Symbol[body__]] :=
  FilterRules[$myoptions, Options[head]] /. {opts___} :> head[body, opts]

withOptions @ Plot[{Sin @ Log @ x, Cos[3 x]}, {x, 0, Pi}]



Here I posted another method in answer to specifying plot ranges, but the method is very general and can be used for any options or parameters.  It works by creating an UpValue assignment for the symbol given that applies to any head.  This could of course be further restricted to apply to only one head or a list of heads.  One could also include FilterRules as shown in the code above, depending on the effect desired.  For example:
SetAttributes[setOpts, HoldAllComplete]

Quiet[
 setOpts[s_Symbol, pat_: _, spec__?OptionQ] :=
  s /: (h : pat)[pre__, s, post___] :=
   FilterRules[{spec}, Options[h]] /. {opts___} :> h[pre, opts, post],
 Optional::""opdef""
]

Now a single option as used above is assigned to op1:
setOpts[op1, Filling -> {1 -> {{2}, {Red, Purple}}}]

And used in Plot:
 Plot[{Sin @ Log @ x, Cos[3 x]}, {x, 0, Pi}, op1]


Alternatively the options can be restricted to a particular head or head pattern.  Here a different set of options, also named op1, is defined only for ParametricPlot:
setOpts[op1, ParametricPlot, Frame -> True, PlotStyle -> Thick, Axes -> None, 
 MeshShading -> {Red, Blue}, Mesh -> 15]

ParametricPlot[{{2 Cos[t], 2 Sin[t]}, {2 Cos[t], Sin[t]}}, {t, 0, 2 Pi}, op1]


Using op1 in Plot will still produce the result shown earlier.
You could also use Alternatives in the pattern, e.g: Plot | ListPlot | Histogram or more complication patterns with conditions, etc.
"
Make a ragged list rectangular by trimming instead of padding,"
You are looking for Take. To then make the array rectangular, I would do something like this
Take[ragged, All, Min[Length /@ ragged] ]

"
calculus and analysis - Integral not simplifying,"
Mathematica obviously cannot decide the sign of l^2*ArcCos[x/l] - x*Sqrt[l^2 - x^2]. The rest of your code is fine. For example, just replace the first function by 
Function[x, 
 If[x < l, (NN*Pi*α*b^2*(l^2 ArcCos[x/l]))/(a^2*β), 0]] 

(in other words, just get rid of -x*Sqrt[l^2 - x^2]) and everything will work as expected. 
"
functions - Block attributes of Equal,"
you are good! Based on your comments, I crafted this:
Block[{Equal, H = Developer`ToPackedArray},
 SetAttributes[Equal, Listable];
 Equal[x_H, y_H] := 
  Equal[Developer`FromPackedArray[x], Developer`FromPackedArray[x]];
 a == b]

which works in both cases.
Update
Mr.Wizard said "" I expected symbols localized with Block to behave generically."" Although the above works, as mentioned in the comments, there is an observable difference between Equal and other user defined symbols in the rewrite/eval loop in regards to Listable and automatic unpacking of packed arrays. I played with different definitions and couldn't find why this happens.
Clear[f, g, h, z1, z2];
ClearAttributes[{z1, z2}, {Listable}];
f[a_, b_] := Block[{Equal, H = Developer`ToPackedArray},
   SetAttributes[Equal, Listable];
   Equal[x_H, y_H] := 
    Equal[Developer`FromPackedArray[x], 
     Developer`FromPackedArray[x]];
   Print[ a == b  // FullForm];
   a == b];
g[a_, b_] := Block[{Equal, H = Developer`ToPackedArray},
   SetAttributes[Equal, Listable];
   Print[ a == b  // FullForm];
   a == b];
h[a_, b_] := Block[{Equal = z1, H = Developer`ToPackedArray},
    SetAttributes[z1, Listable];
    Print[ a == b  // FullForm];
    a == b] /. z1 -> Equal;
i[a_, b_] := Block[{Equal = z2, H = Developer`ToPackedArray},
    SetAttributes[Equal, Listable];
    Print[ a == b  // FullForm];
    a == b] /. z2 -> Equal;

Then I did
{a , b } = {{1, 2}, {1, 3}};
{c , d} = Developer`ToPackedArray /@ {a, b};

which produces,

In[211]:= f[a, b]
List[Equal[1,1],Equal[2,3]]
Out[211]= {True, False}
In[212]:= f[a, c]
List[Equal[1,1],Equal[2,2]]
Out[212]= {True, True}
In[213]:= g[a, b]
List[Equal[1,1],Equal[2,3]]
Out[213]= {True, False}
In[214]:= g[a, c]
Equal[List[1,2],List[1,2]]
Out[214]= True
In[215]:= h[a, b]
List[z1[1,1],z1[2,3]]
Out[215]= {True, False}
In[216]:= h[a, c]
List[z1[1,1],z1[2,2]]
Out[216]= {True, True}
In[217]:= i[a, b]
z2[List[1,2],List[1,3]]
Out[217]= False
In[218]:= i[a, c]
z2[List[1,2],List[1,2]]
Out[218]= True

So one can see that there is a difference between g[a,c] and h[a,c]: in g Equal does not unpack, whereas in h the user-defined z1 does. I think all the other behaviours can be explained from the evaluation (rewrite) steps as explained in the Mathematica documentation.
Anyway, just wanted to comment finally that although Mr Wizard's is a fair claim. There are a number of areas where other than pure symbolic/rewrite manipulation is occurring, and that simply Block is not probably considering. For example -hope not to trivial for you-, Block[{Equal}, ToExpression[""?Equal""]] still prints the Equal documentation, instead of a reference to an undefined symbol. So, like in this case, maybe Equal (and other built-ins) have special behaviour which Block is not touching.
Sorry, I will leave it as answer, but now probably I should say it is not...
Update 2
Actually, just checked that Block leaves ::usage untouched! So, if you do
f::usage = ""Symbol f"";

then

Information[f]
Symbol f

And if you do Block still you get the same

Block[{f}, Information[f]]
Symbol f

so Block and Information are not working together, even for user-defined symbols! 
Last update
As noticed by some, symbols like Plus have special behaviour too. So this
Block[{Plus}, Print[Trace[Plus[1, 2]]]]; (* 1 *)
Block[{Global`Plus}, Print[Trace[Plus[1, 2]]]]; (* 2 *)
Block[{Global`Plus}, Print[Trace[Global`Plus[1, 2]]]]; (* 3 *)

produces

{1+2,3}
{1+2,3}
{}

which demonstrates that Plus retains the built-in behaviour in 1 and 2, being really overridden only with a syntax like 3, which is not convenient. By the way, 2 generates a warning. 
Bottom, line, to answer Mr.Wizard's request -I believe this answer was suggested in the comments- it seems the only generic way to override a built-in is to provide your own user defined symbol instead. If one wants to redefine, say Plus, IMHO it is not a burden as whatever definition one wants to introduce can be done with the user-defined symbol and still one has the convenience of the syntactic sugar. To wit
Block[{Plus = plus}, plus[0, _] := 0; Print[Trace[0 + 2]]]; 
which produces

{{Plus,plus},plus[0,2],0}

So, I will leave it like this.
"
sound - Random data gnrator - Mathmatica Stack Exchang,"
Edit: this answer is now structured in two sections. The first deals about creating a candidate RNG from audio data. The second demonstrates some testing I performed on this RNG.

Creating the RNG
Okay, I'll got at it another way then. I recorded 10 seconds of ambient noise on my MacBook Pro internal speakers. I was possibly in the worst conditions for this: my quiet flat, at night. The generated wav file was then imported into Mathematica. At least for my own combination of hardware, this doesn't look too good:
data = Import[""test.wav"", ""Data""];
Length[data]
ListPlot[data[[1]]]
Histogram[data[[1]], PlotRange -> {{-0.0004, 0.0004}, Automatic}]

The data array has two components of length 520192 (it's 48 kHz audio, so it's indeed raw data). But, they take only a handful of possible values:

That being said, maybe some randomness can be extracted if the signal oscillate between these values in some random manner. If that's the case, I expect each value will only bring very little entropy to the result, but collectively you can still get something out. And indeed, the Fourier transform is:
ListPlot[Abs@Fourier[data[[1]]]]


which shows some promising behaviour. We take the mantissa, which is still very far from being uniformly distributed:
Histogram[(MantissaExponent[#][[1]] &) /@ Abs@Fourier[data[[1]]]]


and we can further refine by keeping only least-significant bits:
Histogram[(BitAnd[Floor[MantissaExponent[#][[1]]*2^32], 2^8 - 1] &) /@ Abs@Fourier[data[[1]]]]


Each integer in this list is between 0 and 255 (inclusive), so it's a 8-bit integer. They look nicely equidistributed, which of course is the lowest possible criterion for any kind of random generator. They should be further tested for randomness.
Alternatively, we can make it into a RNG that creates floating-point numbers between 0 and 1. The following is my “final state” code:
data = Import[""test.wav"", ""Data""][[1]];
Print[""Raw data length (one channel): "", Length[data]];
randombytes = 
  BitAnd[Floor[MantissaExponent[#][[1]]*2^32], 2^8 - 1] & /@ 
   Abs@Fourier@data;
Print[""Number of random bytes: "", Length[randombytes]];
randomint32s = 
  Table[randombytes[[i]] + randombytes[[i + 1]]*2^8 + 
    randombytes[[i + 2]]*2^16 + randombytes[[i + 3]]*2^24,
   {i, 1, Length[randombytes], 4}];
randomfloats = N[#/2^32] & /@ randomint32s;
n = Length[randomfloats];
Print[""Number of random reals: "", n];


Testing this RNG
I'm not an expert, so I performed so basic randomness tests following the guidelines in John D. Cook’s “Testing a Random Number Generator” chapter in Beautiful Testing. It's not DIEHARD, or DIEHARDER, but it's a start!
The approach I followed is to compare the properties of our RNG to those of streams of Mathematica’s default RNG (with the same size). I thus generate 100 vectors of reference random numbers:
references = Table[Table[RandomReal[], {i, n}], {j, 100}];

Then, I compare their properties. For example, I compare the average of randomfloats to the distribution of averages of same-sized vectors returned by RandomReal. For our RNG to be decent, our average must fit somewhere in the distribution of averages from RandomReal, which I test by calculating the later’s standard deviation:
w = Mean[randomfloats]
t = Mean /@ references; Print[Min@t, "" "", Mean@t, "" "", Max@t, "" "", StandardDeviation@t];
Print[""DeltaMean over deviation: "", (w - Mean@t)/StandardDeviation@t];

which outputs:

0.499767
0.498 0.500117 0.502256 0.00081088
DeltaMean over deviation: -0.432063


so our result is at $-0.43\sigma$, and we can be happy about it! I did the same thing for the min ($-0.25\sigma$), max ($0.22\sigma$), and variance (slightly larger at $1.4\sigma$, but still no cause for concern). I skipped the book's bucket test, because we already established that using histograms.
Then, the Kolmogorov-Smirnov test:
Quiet@KolmogorovSmirnovTest[randomfloats, UniformDistribution[{0, 1}], ""TestConclusion""]


The null hypothesis that the data is distributed according to the UniformDistribution[{0,1}] is not rejected at the 5. percent level based on the Kolmogorov-Smirnov test.

Here I'd be tempted to say: victory!

Obviously, if you've read until here, either you like what I write (and I'd appreciate an upvote) or you are an expert, in which case I welcome comments on my empirical investigation. Thanks!
"
linear algebra - ordering of functional eigenvalues,"
My strong hunch is that when the eigenvalues cannot be treated as numbers, the eigenvalues are always ordered according to ""Sort"". Thus, they are sorted in MMA's ""canonical"" order, some of which is described in this question: https://mathematica.stackexchange.com/a/2730/360. 
For your specific example:
In[48]:= Sort[{Log[x], Log[2 x], Log[3 x]}]

Out[48]= {Log[x], Log[2 x], Log[3 x]}

In[49]:= Sort@Eigenvalues[{{Exp[x], Exp[x]}, {Exp[x], Exp[x/2]}}] == 
 Eigenvalues[{{Exp[x], Exp[x]}, {Exp[x], Exp[x/2]}}]

Out[49]= True

For mixed eigenvalues, the numeric ones are listed first:
In[63]:= m = ({{1000, 0, 1}, {1, Log[3 x], 0}, {0, 0, Log[2 x]}});
Eigenvalues[m]

Out[64]= {1000, Log[2 x], Log[3 x]}

"
calculus and analysis - Checking if first derivative is zero at a given point,"
You have three variables, so the ""first derivative"" is a little ambiguous.  You can take a derivative with respect to one of these and feed the solution in directly, e.g.
D[V[a, h, tau], a] /. {a -> 8.47344, h -> 1.67718, tau -> 12.9438}

(Spoiler: none of them are zero)
When you take the total derivative Dt[V[a, h, t], a, h, tau], it gives you a result in terms of the relationship between the variables, such as Dt[a,h] or Dt[h,tau].  You have to specify what these are from you original problem.  Substituting in numbers directly gives nonsensical expression such as Dt[8.47344, 1.67718].  You can't take the derivative of a number with respect to a number.
You could also ask Mathematica when one of the first derivatives is zero:
Solve[D[V[a, h, tau], a] == 0]

"
How do I treat elements in a list as variables inside a module?,"
You should have included the error messages. There are several problems with this code. First, you can only assign to parts of an expression, if it is stored in some symbol. This is because expressions are immutable in Mathematica. I discuss this here. In your case, you pass the list itself. So, the first step would be to use pass-by-reference semantics (emulated by Hold - attributes) and write
SetAttributes[testscan, HoldAll];
testscan[listin_] := 
  Module[{zz}, 
     Do[
       listin[[1]] = zz; Print[{zz, listin[[1]]}], 
       {zz, 1, 2, 1}
     ]
  ]

and then use it as
lst = {a, 1, 3, 1};
testscan[lst]

which gives the desired outcome, bacause now the input list is stored in a variable which is passed unevaluated (as a reference, more or less). 
It is important to note however, that the a in lst was not modified, but rather replaced by new values, so that now 
?lst

Global`lst
lst={2,1,3,1}

If you really want to modify a, I recommend reading this answer.
"
plotting - Changing the plot variable inside Plot,"
Plot has attribute HoldAll (you can check with Attributes[Plot]), which makes it not recognize the two separate curves and ""sees"" it as one. Use Evaluate to overcome this.
Plot[Evaluate[vec /. x -> y], {y, -2, 2}, PlotStyle -> {Blue, Red}]

"
calculus and analysis - simplifying $\frac{\log x^a}{a} = \log x$,"
In your particular examples, PowerExpand[Log[x^a]/a] evaluates to Log[x], and PowerExpand[1/a*Log[(x + Log[x]*Cos[x])^a]] also works.
EDIT: To be clear, and as commented upon by Andrzej, PowerExpand may give wrong answers. See the documentation, in particular this.
EDIT2: Does something like (1/a*Log[(3*Exp[-1/x]*Sqrt[1 - Exp[1/x]])^a]) //. 
 Log[Times[x_, y_]] -> Log[x] + Log[y] do what you want? (this it pattern-matching, a Andrzej suggested in reply to your comment).
"
plotting - Non-linear inequalities,"
Unless I made a typo (please next time provide the equations also in MMA code) your problem is rather strange.
The a5 is clearly just a point, a4 is false, and a3 reduces to a line. Only a2 and a1 are areas as the following shows:
a1 = b^2 + 9*c^2 - 3*c < 0
a2 = Reduce[{(Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0 && 
           (-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0}]
a3 = Reduce[{(Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0 &&
           (-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12}]
a4 = Reduce[{(-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c <= 0 &&
           (Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12}]
a5 = Reduce[{(Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12 &&
           (-Sqrt[b^2 + 9*c^2 - 3*c] - b + 6*c)/c == 12}] 
bb = {3*c > 2*b - 1 && 3*c > -(2*b) - 1 && 1 > 3*c}

(*
==> b^2 - 3 c + 9 c^2 < 0

==> (0 < c < 1/15 && 
   Sqrt[3 c - 9 c^2] <= b <= 1/4 (1 + 9 c)) || (b == 2/5 && c == 1/15)

==> -(1/4) < b <= 0 && c == 1/9 (-1 - 4 b)

==> False

==> c == 1/15 && b == -(2/5)

==> {3 c > -1 + 2 b && 3 c > -1 - 2 b && 1 > 3 c}
*)

RegionPlot[{a1, a2, a3, a4, a5, bb}, {b, -1, 1}, {c, -1, 1}, PlotPoints -> 100]


"
plotting - Using a function name instead of its definition in AxesLabel,"
What you are looking for can be achieved by wrapping the labels in HoldForm, or if you prefer, HoldForm@InputForm. For example, here is a plot that combines both labeling issues you mentioned:
f = x^2;
Plot[f, {x, -2, 2}, AxesLabel -> {x, HoldForm[InputForm[E = f]]}]

The two issues you mention are indeed separate: 

To get f instead of $x^2$ you should use HoldForm, but that still allows the display of TraditionalForm shorthand forms for built-in symbols such as E (which is Euler's constant but is pretty-printed as $\mathbb e$). 
To prevent the replacement of E by $\mathbb e$, InputForm can be used. 

As you noticed, using strings in labels (though sometimes perfectly fine) has undesirable effects on the font and requires more ""finger-painting"" with styles. The HoldForm approach is easier to use and the code is easier to read when labels get complicated.
See also this related question.
To expand on this topic:
Sometimes you need more complicated labels that require ""two-dimensional"" typesetting, as in $\psi = \frac{1}{2}\int f(x) \mathbb{d}x$, see this image:

Edit: how to get formatting into labels in general
For output like the above, the essential ingredient is that the expression should be wrapped in a FormBox. Strings aren't made for two-dimensional display, but Mathematica has a way of sneaking FormBoxes into strings: see the documentation.
Therefore, you can get a two-dimensional formula into a plot label either using HoldForm or a string. Using HoldForm, I got the formatting in the image by doing the following:

Create the formula in a TraditionalForm environment. This could e.g. be in a Text cell by starting an equation with Ctrl-( and ending with Ctrl-).
Copy this formula from within that math inset. 
Lay out your plot by typing something like Plot[f, {x, -2, 2}, AxesLabel -> {x, HoldForm[    ]}]
In the blank space that I have left inside the HoldForm[    ], paste the copied equation.
You will be asked if you want to wrap the TraditionalForm expression in a FormBox, and the answer is yes.
Provided that the pasted expression obeys Mathematica syntax, you should now be able to evaluate the plot cell and get the output shown above.

Now in some cases you want to label a graph with a two-dimensional formula that doesn't obey Mathematica syntax, and in that case you would replace step 4. above by this:
Plot[f, {x, -2, 2}, AxesLabel -> {x,""""}

Instead of HoldForm, I now left an empty string """" in the label. Now proceed as above with step 4, for example using an equation like
-(\[HBar]^2/(2m))\[PartialD]^2 \[Psi]

entered in a math inset (in a text cell as in step 1). If you tried this with HoldForm, it would give a syntax error because the \[PartialD] is being used in a mathematically acceptable but syntactically incorrect way.
Edit 2: the fastest way
The way I described copying and pasting of TraditionalForm into strings was based on my habits, but it's actually not the fastest. I should adjust my habits to the following: In the code for your plot, type a single string placeholder letter for your label, such as ""y"". Using the mouse, highlight the y in your string and go to the menu item Cell > Convert To > TraditionalForm (or use the keyboard shortcut). This creates the all-important FormBox. Since this box is invisible, you now have to use the arrow keys or mouse to get inside this FormBox, right next to to the placeholder y. From here, you can start typing any arbitrary formula which will then be typeset as TraditionalForm in the plot label.
So in conclusion, HoldForm is a very direct way of getting valid Mathematica expressions into labels without expanding them, and strings should be used in combination with the FormBox wrapper method above to typeset arbitrarily complicated labels.
"
numerical integration - What is NDSolve`FEM`*?,"
Version 8 does not have a built-in finite element method. If you want to use the finite element method, you may want to look at the following packages:

ACEFem
IMTEK Mathematica Supplement (IMS) and here and here 

To the question: NDSolve`FEM` is an internal context to NDSolve that currently does not do anything much. It's only use is as a container in the unstructured interpolation.
Hope this helps.
"
bugs - How to fix broken InterpolatingFunction?,"
This is a bug in version 8 and has been fixed in the development version. For now, you have to export the data and reconstruct the interpolation once you have read in the data. What follows is way to recover your data. You should not use this on a day to day basis. The idea is to recover your data and store the data and then reconstruct the interpolation.
coords = intNew[[3, 1, 1]];
vals = Partition[intNew[[4]], 1];
data = Join[coords, vals, 2];
Interpolation[data, InterpolationOrder -> 1]

Update:
Here is a slightly better fix. For large data the re-computation of the underlying mesh can be expensive. In this case, (and only in this case), you can use the following to avoid the expensive mesh creation.
mesh = intNew[[3, 1]];
vals = intNew[[4]];
iff = NDSolve`FEM`ElementInterpolation[{mesh}, vals]

Hope this helps.
"
front end - Why are some function names red?,"
The red colouring indicates shadowing — i.e., when a symbol originally in a particular context, is exposed to the current context path, thereby clashing with another symbol of the same name in a different context, also on the context path. 
Example of shadowing:
Here is a short example that demonstrates this. Try it out in a fresh kernel (call Quit[] before you try it).
(* Define f in the test` context *)
Begin[""test`""]
    f[x_] := x^2
End[]

(* Define f in the Global` context *)
f[y_] := y^3

So far, all's well and you see the symbols coloured the way you're used to. Now expose test`f by adding it to the context path with:
$ContextPath = Prepend[$ContextPath, ""test`""]

You'll now notice that both the f turned red to indicate that it is being shadowed by a different definition.

For more information on this, you can read about shadowing in the documentation and also this article by David Wagner in the Mathematica journal.
Which definition is used in case of a conflict?
The definition that is used first, in the case of shadowing, is the one belonging to the context that appears first in $ContextPath. This is the same behaviour as in your unix shells, where directories in the $PATH variable are searched in the order they appear.
In the above example, I used Prepend, which would've placed test` first in the list. So the definition of f will be test`f and you can easily test this:
f[x]
Out[1]= x^2

Now quit your kernel and do the same, except now you place the new context at the end. You can see that the definition used is that of Global`f. 
$ContextPath = Append[$ContextPath, ""test`""]
f[x]
Out[2]= x^3

Incidentally, it is also possible to trigger this shadowing warning (red colour) even if there isn't a real conflict. This can occur if the same context appears at different positions in $ContextPath. To test this, in a clean kernel, define test`f as before, and Append and Prepend it to $ContextPath.  
Changing the colour of the warning
To change the colour from red to your favourite, go to Preferences > Appearance > Syntax Coloring > Errors and Warnings and change the colour in the very last option:

To do it programmatically, evaluate:
SetOptions[$FrontEndSession, AutoStyleOptions -> {""SymbolShadowingStyle"" -> 
    {FontColor -> Orange}}]

Replace Orange with the color of your choice and $FrontEndSession with $FrontEnd if you want the change to persist across future sessions (it essentially writes it to the FE's init.m). See this answer for more on the various style tokens and what they control.
"
front end - Why are some functions available without having to load their parent package?,"
If you look at their Contexts, you'll see that all of them are in the System` context and not the GraphUtilities` context.
Context /@ {GraphDistanceMatrix, CharacteristicPolynomial, AdjacencyMatrix}
Out[1]= {""System`"", ""System`"", ""System`""}

Some packages are preloaded when the kernel starts — System` is one of them, whereas GraphUtilities` is not. You can see all packages that are pre-loaded with $Packages
$Packages
Out[2]= {""ResourceLocator`"", ""DocumentationSearch`"", ""GetFEKernelInit`"",
    ""JLink`"", ""PacletManager`"", ""WebServices`"", ""System`"", ""Global`""}

"
plotting - Labeling points of a list in plot,"
BubbleChart with a custom function for the tooltip content:
 labelingfunc[v : {x_, y_, w_}, i_, ___] := 
 Placed[Grid[{{""point "", i}, {""coordinates"", {x, y}}}, Frame -> All, 
 Alignment -> Left], Tooltip];
 BubbleChart[(Append[#, 1] & /@ coord), 
 ChartLabels -> Placed[Style[#, ""Subsection""] & /@ Range[Length@coord], Center],
 BubbleSizes -> {0.1, 0.1}, LabelingFunction -> labelingfunc]


"
symbolic - Extract real part of a complex expression better than Re does,"
Removing the imaginary portion of an expression is done by doing
ComplexExpand[Re[expression]].

Using just Re alone will not work as Re does no evaluation on symbols with unknown complex parts.
Now as stated in the problem and the comments above this particular problem requires a fair amount of assumptions. The simplest way to add local assumptions is to use Assuming. But this will not work, so we must instead make use of Simplify. For example:
Simplify[ComplexExpand[Re[expression]], a > 0]

where a is a symbol used in expression and is a real number greater than zero.
"
symbolic - Validating simplifications analytically,"
You are assuming that
$$
\sqrt{\frac{a}{b}} = \frac{\sqrt{a}}{\sqrt{b}}
$$
This is not generally true.  Take for example $a=1$ and $b=-1$ for which this identity does not hold.
You need to give additional assumptions to Simplify, in this case that $b>0$.
Simplify[Sqrt[a/b] == Sqrt[a]/Sqrt[b], b > 0]

(* ==> True *)

"
variable sized lists and using lists as variables,"
I would start by creating a function that returns a value based on your equation, i.e. the solution of your example $x^2+y^2+z^2=1$:
findSolutions[y_, z_] := Module[{x},
    x /. Solve[x^2 + y^2 + z^2 == 1, x]
]

The output looks like this:
findSolutions[1, 2]


{-2 I, 2 I}


Next, set up the table of $(y,z)$ values you want to feed that function, for example by generating random numbers or by using some formula:
sampleData = Table[{y, z}, {y, -2, 2, 1/2}, {z, -1, 1, 1/3}];
sampleData = Flatten[sampleData, 1]


{{-2, -1}, {-2, -2/3}, {-2, -1/3}, ...}


The second line is necessary since Table creates an additional nested layer for each variable it cycles through, so that the data initiall looks like {{{ ... }}}. The Flatten gets rid of this (here) unnecessary layer.
Alright, let's apply our function to the data,
findSolutions @@@ sampleData


{{-2 I, 2 I}, {-((I Sqrt[31])/3), (I Sqrt[31])/3}, ...}


findSolutions @@@ sampleData applies findSolutions to every sublist of sampleData, the result is a list of all results of the function based on the data provided. You can now do additional stuff with that, for exmple use Union (will sort the list as well) or DeleteDuplicates (won't do that) to get rid of double entries; you may also want to flatten the result, since findSolutions returns tuples of all possible solutions for a given $(y,z)$, etc. For example // Flatten // Union yields

{-1, 0, -I/3, I/3,  ...}


"
graphics - Change the color of a Locator in a Manipulate,"
As far as I know, you can't change the colour of the default locator directly, but you could use the specification for the default locator to create a coloured version of the default locator. These specifications can be found in the file MiscExpressions.tr located in $InstallationDirectory\SystemFiles/FrontEnd/TextResources. It turns out that the locator is specified as 
GraphicsBox[
 InsetBox[GraphicsBox[{col, {AbsoluteThickness[1], 
     Antialiasing -> False, 
     LineBox[{{{0, -10}, {0, -2}}, {{0, 2}, {0, 10}}, {{-10, 0}, {-2, 
         0}}, {{2, 0}, {10, 0}}}], Antialiasing -> True, 
     CircleBox[{-0.5, 0.5}, 5]}, {AbsoluteThickness[3], Opacity[0.3], 
     CircleBox[{-0.5, 0.5}, 3]}}, ImageSize -> 17, 
   PlotRange -> {{-8, 8}, {-8, 8}}], {0, 0}, Center]]

So using this you could create a coloured locator by doing something like
loc[col_] := Rasterize[
  ToExpression@
   GraphicsBox[{col, {AbsoluteThickness[1], Antialiasing -> False, 
      LineBox[{{{0, -10}, {0, -2}}, {{0, 2}, {0, 10}}, {{-10, 0}, {-2,
           0}}, {{2, 0}, {10, 0}}}], Antialiasing -> True, 
      CircleBox[{-0.5, 0.5}, 5]}, {AbsoluteThickness[3], Opacity[0.3],
       CircleBox[{-0.5, 0.5}, 3]}}, ImageSize -> 17, 
    PlotRange -> {{-8, 8}, {-8, 8}}],
  Background -> None]

Graphics[{Disk[], Locator[{0, 0}, loc[Darker[Green]]]}]


"
programming - Handling failed FindRoot calls,"
You can use Check to return an alternate result and use Quiet to avoid the messages that you are expecting anyway.  Here's an example:
Quiet[Table[Check[x /. FindRoot[x^2 - c, {x, 1}],
  ""NaN"", {FindRoot::lstol, FindRoot::jsing}], {c, -5, 5}],
  {FindRoot::lstol, FindRoot::jsing}]

(* Out: 
  {""NaN"", ""NaN"", ""NaN"", ""NaN"", ""NaN"", 7.45058*10^-9, 
   1., 1.41421, 1.73205, 2., 2.23607}
*)

One important note is to make sure that the Check is inside the Quiet, and not the other way around.  If Quiet is inside Check the message will be ""quieted"" before it is seen by Check and so you won't get ""NaN"".
"
Manipulate Evaluation Order Problem,"
I can't help you with why your code doesn't work, but this seems to work. In this solution n is reset to either 1 or 2 when Parity is changed before Print is called. 
Manipulate[Manipulate[
  If[Not[Parity[n]], n = Mod[n + 1, 2, 1]];
  Print[{Parity, n}];
  {Parity, n},
  {n, Select[Range[1, 10, 1], Parity]}], {Parity, {OddQ, EvenQ}}]

"
programming - Path queries for tree-structured data,"
This is not really a full answer, but it may be a start. If you want something like a path specification with wildcards, spans and such, then you are actually very close to general pattern matching, and you might want such functionality anyway, so why not just start out with this? Replace and Replace All just extract components of this structure type, so they aren't ideal for doing the path queries. 
Lets define a test structure:
data = {
  row1 -> {key1 -> 1, key2 -> value2}, 
  row2 -> {key1 -> 2, key2 -> value4}, 
  row2 -> {key1 -> 3, key2 -> value4}
};

Then to take the element identified by the symbolname row1, we do:
 Cases[data, HoldPattern[row1 -> _],1]

To do a wildcard search we do
 Cases[data, HoldPattern[_ -> _],1]

To do a range search, we need to carry out a check on the matches and only take those in range, so we take:
 Cases[data, HoldPattern[_ -> a_] /; (key1 /. a) < 3]

Similarly you can carry out arbitrary checks on the elements of the pattern you are looking for, and do arbitrary depth searches and other nice things. And if you need to manipulate the data structure, you can simply use positions to get the point to edit. 
editAt = First@Position[data, HoldPattern[_ -> a_] /; ((key1 /. a) == 2), 1]
data[[Sequence @@ editAt]] = {key1 -> 22, key2 -> value4}

"
graphics - Composition: how to make a day and night world map?,"
Let me first name your maps correctly (you switched night and day maps):
night= Import[""http://eoimages.gsfc.nasa.gov/images/imagerecords/55000/55167/earth_lights_lrg.jpg""];
day= Import[""http://eoimages.gsfc.nasa.gov/images/imagerecords/57000/57752/land_shallow_topo_2048.tif""];

The images have different sizes:
ImageDimensions[day]

(*
==> {2048, 1024}
*)

ImageDimensions[night]

(*
==> {2400, 1200}
*)

so, I rescale the night image. Artefacts (if any) will probably be less visible there.
night = ImageResize[night, ImageDimensions[day]];

Now, for the calculation of the mask we don't need to use external sources. AstronomicalData will do:
mask =
 Rasterize[
  RegionPlot[
   AstronomicalData[""Sun"", {""Altitude"", {2012, 6, 21}, {lat, long}}] <
     0, {long, -180, 180}, {lat, -90, 90}, Frame -> None, 
   PlotRange -> Full, PlotStyle -> Black, PlotRangePadding -> 0, 
   AspectRatio -> (#2/#1 & @@ ImageDimensions[day])],
  ImageSize -> ImageDimensions[day]
  ]


Then, stealing the ImageCompose idea from Yu-Sung:
pl=ImageCompose[night, SetAlphaChannel[day, mask]]


Borrowing and adapting some code from the Texture doc page:
Show[
 Graphics3D[{White, Tube[{{0, 0, -1.4}, {0, 0, 1.4}}, .04]}],
 SphericalPlot3D[1 , {u, 0, Pi}, {v, 0, 2 Pi}, Mesh -> None, 
  TextureCoordinateFunction -> ({#5, 1 - #4} &), 
  PlotStyle -> Texture[Show[pl, ImageSize -> 1000]], 
  Lighting -> ""Neutral"", Axes -> False, RotationAction -> ""Clip""], 
 Lighting -> ""Neutral"", Boxed -> False, 
 Method -> {""ShrinkWrap"" -> True}
]


"
functions - What is so special about Prime?,"
Actually, I believe the issue reduced to that of implementing PrimePi[]. It is easy to implement Prime[] using PrimePi[] and FindRoot[] — in fact this is done on page 134 of Bressoud and Wagon, ""A Course in Computational Number Theory"". So all you need is to have a fast implementation of PrimePi[].
The first efficient way was found by Legendre in 1808. The modern approach of Lagarias, Miller and Odlyzko (1985)  gives PrimePi[] for $10^{20}$, which is larger than the Mathematica implementation. All this is discussed in detail in the Bressound and Wagon book. Curiously they include a Mathematica package that implements the Lagarias, Miller and Odlyzko method, but it appears that (somewhat surprisingly) it has not been included in the Mathematica kernel.


J. C. Lagarias, V. S. Miller, and A. M. Odlyzko, Computing $\pi(x)$*: The Meissel-Lehmer method*, Math. Comp. 44 (1985), 537–560. MR 86h:11111

"
front end - Avoiding an unresponsive user interface in OS X,"
The main part of this question has been answered at 
How to abort on any message generated?
However, in my mind there remains a very live issue: why should the front end ever crash at all? Its primary job is as a user interface. As such, there is no excuse for it to crash, ever.
By contrast, when I use a terminal program to connect with, say, a Linux console interface, one of my concerns is never that the terminal program itself would crash. Why should it?
Yet the Mathematica front end crashes or hangs several times a day during my work. I use the following sequence of ways to get out of an impending crash:

If one responds quickly, the hangup can usually be stopped with the menu command ""Interrupt Evaluation"". 
If that doesn't work, pressing Cmd+. might halt the computation.
If Cmd+. fails, sometimes it is possible to use the menu command ""Quit Kernel"".
If I can't quit the kernel, sometimes I can quit Mathematica entirely by using the ""Force Quit"" command from the Dock.
If ""Force Quit"" also fails, then I have to go into Activity Monitor and terminate the Mathematica process at the level of the operating system.

Only the last method is certain to work.
This sort of distracting search for the proper panic button is often necessary several times per day when I am working intensively with relatively large objects, such as an image of more than ten megapixels.
I find it very surprising that this glaring problem was not fixed a long time ago.
"
graphics - Height-dependent filling color in 3D Data Plots,"
If nobody comes with a much cleverer solution, this might be a way to achieve what you're looking for. However, first your data have to be reshaped.
newtable = {{1, 2, 1}, {3, 1, 3}, {4, 3, 4}};
BarChart3D[newtable, ChartLayout -> ""Grid"", 
    ViewPoint -> {3.33, -8.26, 5.36}, ColorFunction -> ""DarkRainbow"", 
    Method -> {""Canvas"" -> None}]


With some additional options:
BarChart3D[newtable, ChartLayout -> ""Grid"", ChartElementFunction -> ""Cube"",
    ViewPoint -> {3.33, -8.26, 5.36}, ColorFunction -> ""DarkRainbow"",
    Method -> {""Canvas"" -> None}, BarSpacing -> {None, None}]


"
plotting - Easy Way to Create Trellis Plots in Mathematica,"
Perhaps this is what you are doing, but just in case:
t = Table[{RandomChoice[{""Reg1"", ""Reg2"", ""Reg3""}], 
    RandomReal[{10, 20}], RandomReal[{50, 70}]}, {i, 1, 10}];
sel[x_] := Select[t, #[[1]] == ""Reg"" <> ToString[x] &];
plt[x_] := ListLinePlot[#] &@(sel[x][[All, 2 ;; 3]]);

pltR = Flatten[Options[plt[#], PlotRange] & /@ Range[3] /. 
              HoldPattern[PlotRange -> x_] -> x, 1];
pltRR = {{Min@pltR[[All, 1, 1]],  Max@pltR[[All, 1, 2]]}, 
         {Min@pltR[[All, 2, 1]],  Max@pltR[[All, 2, 2]]}};

GraphicsGrid[{ListLinePlot[#, PlotRange -> pltRR] &@ (sel[#][[All, 2 ;; 3]]) & 
             /@ Range[3]}, Dividers -> All]


"
list manipulation - MapThread on a nested Map,"
I am not exactly sure what you are looking for so, here are two ideas:
MapThread[
 f[#1, #2] &, {Map[Map[(# + 1/Min[#]) &, #] &, #] & /@ list1, list2}]

or
MapThread[
 Function[{x, y}, Map[Map[(# + 1/Min[y]) &, #] &, x]], {list1, list2}]

Hope this helps.
"
Calling a function an unspecified number of times,"
Something like :
sample[ranges_] := Table[Evaluate[ranges[[All, 1]]], Evaluate[Sequence @@ ranges]]

used like :
sample[{{x, 0, 3, 1}, {y, -2, 2, 1}}]

"
graphics - How to make an inkblot?,"
A bit of image processing:
Table[
  Blur[
    Dilation[
     Graphics[
      Table[
        Rotate[
           Disk[RandomReal[{-10, 10}, {2}], {RandomReal[{1, 5}],RandomReal[{1, 5}]}],
           RandomReal[{0, 3.14}]
          ], 
         {40}
       ]
     ], 
     DiskMatrix[20]
   ], 20
  ]// Binarize, 
  {3}, {3}
] // Grid


Lots of parameters to play with...
Now these are bitmaps and if vector graphics are required (the question seems to imply that) we can adapt a bit of Vitaly's code from here:
img = Thinning@EdgeDetect@p;
points = N@Position[ImageData[img], 1];
pts = FindCurvePath[points] /. c_Integer :> points[[c]];
Graphics[{EdgeForm[Directive[Dashed, Thick, Red]],FilledCurve@({Line@#} & /@ pts)}]

 
with p our blob bitmap. (The contour is dashed to better show that we're dealing with vector graphics here).
"
Edge problems in a directed graph,"
Solution based on graphics primitives
You might consider using this approach:
h = Graphics[Line[{{0, 1/2}, {0, -1/2}}]];
Graphics[{
    {Thick, Arrow[{{.1, 0}, {.9, 0}}]},
    {Red, Thick, Arrow[{{.5, 0}, {.5, -.5}, {2, -.5}, {2, -.1}}]},
    Arrowheads[{{Automatic, Automatic, h}}],
    {Red, Thick, Arrow[{{1.1, 0}, {1.9, 0}}]},
    Style[{Text[""X"", {0, 0}], Text[""Y"", {1, 0}], Text[""Z"", {2, 0}]},
    FontFamily -> ""Helvetica"", FontSize -> 20]
}]

that produces this:

For the curved lines you can play with:
Graphics[{Arrow[BezierCurve[{{0, 0}, {1, 1}, {2, -1}}]]}]

Solution based on Graph
This solution is a bit more convoluted than the previous, but with some tweaking it works.
h = Graphics[Line[{{0, 1/2}, {0, -1/2}}]];
vlabel[lbl_] := Graphics[Text[Style[lbl, FontFamily -> ""Helvetica"", FontSize -> 20],
    Background -> White]];
verts = {""X"", ""Y"", ""Z""};
edges = {""X"" -> ""Y"", ""Y"" -> ""Z"", ""X"" -> ""Z""};
vcoords = {{0, 0}, {1, 0}, {2, 0}};
eshapef = {""X"" \[DirectedEdge] ""Y"" ->
    ({Thick, Black, Arrow[{{0.1, 0}, {.9, 0}}]} &),
    ""Y"" \[DirectedEdge] ""Z"" ->
    ({Thick, Red, Arrowheads[{{Automatic, Automatic, h}}],
    Arrow[{{1.1, 0}, {1.9, 0}}]} &), ""X"" \[DirectedEdge] ""Z"" ->
    ({Thick, Red, Arrow[{{0.5, 0}, {0.5, -.5}, {2, -.5}, {2, -.1}}]} &)};
Graph[{""X"", ""Y"", ""Z""}, edges,EdgeShapeFunction -> eshapef,
    VertexCoordinates -> vcoords,
    VertexLabels -> Table[i -> Placed[i, Center, vlabel], {i, verts}]]


"
numerical integration - Publishing results obtained in Mathematica,"
This question is somewhat subjective, but here's my take on it:
The reason the precise methods are mentioned in papers is to make results reproducible.  One has to draw a line when it comes to describing methods.  Will you mention what method you used to add or multiply numbers on a computer?  What if the numbers are huge and you used FFT-accelerated convolution for arithmetic?  It all comes down to how essential the method was in obtaining your results.
If the method is really not essential to your results (solving differential equations on a computer can be considered rather trivial these days), then I don't believe it is necessary to mention the method.  If someone wants to reproduce your results, they can just implement any trivial method, or more likely use some package like Mathematica (or any other) that has it built-in.  If you feel like, you can say ""the PDEs were solved numerically using Mathematica 8"".
If a trivial method won't work (e.g. you have stiff equations), you may need to mention the method.  In this case it's likely that you also need to select a method manually and tune its parameters.  The available method are described in some detail here.  Again, you can just say that you used Mathematica and mention the method it uses for PDEs (the method of lines) and the exact settings you chose (e.g. an implicit Runge Kutta scheme).
If your equations are such that the method is absolutely essential to the results, then you likely have implemented the method yourself, and this question wouldn't come up.
To sum up: There's nothing wrong with saying that you used Mathematica, and there's nothing wrong with not mentioning the exact method for as long as this is not essential to getting the results.  People could reproduce your results using a naive application of MATLAB or SciPy as well.
Example: I've used a Delaunay triangulation in my work.  I didn't mention how I got it, nor do I think it is necessary.  (In fact I don't even know how the triangulation algorithm works.) It is just a detail that would distract.  Similarly, the subject of your research might be the system described using the PDE, and you don't need to know any advanced PDEs solving methods to obtain your results.
"
Formatting a fraction as a mixed number,"
Here is a definition for mixedForm that works for all cases, i.e. proper and improper fractions and integers.
Clear[mixedForm]
mixedForm[Rational[x_, y_]] := 
    If[Abs@x > y, HoldForm[#1 + #2/y], x/y] & @@ (Sign@x QuotientRemainder[Abs@x, y])
mixedForm[x_Integer] := x

Some examples:
mixedForm /@ {2, 4/5, 10/3, -3/4, -5/2}
Out[1]= {2, 4/5, 3 + 1/3, -3/4, -2 - 1/2}

Compare with Eli's, which produces 0s if the number is an integer or a proper fraction
ImproperForm /@ {2, 4/5, 10/3, -3/4, -5/2}
Out[2]= {2 + 0, 0 + 4/5, 3 + 1/3, -1 + 1/4, -3 + 1/2}

"
equation solving - Solve Lagrange multipliers optimization problem,"
The short answer is that this is not a correct formulation of a Lagrange multiplier problem in the first place. In the question, derivatives are being taken with respect to the multipliers $\lambda1$ and $\lambda2$. That's simply wrong. These multipliers are there to enforce the fact that the gradients of the objective function and constraint conditions are linearly dependent. But they aren't themselves variables in the gradient. 
"
How to get string representation (like repr in Python),"
Just use ToString
ToString[""a\nb"", InputForm] // InputForm


""\""a\\nb\""""


Adding // InputForm is not strictly necessary.  It will influence only the printing of the output, not its structure.  By default, Mathematica does not show quotes around strings in the output, and it expands escaped characters (such as \n) to their meaning (an actual newline in this case).  InputForm will change this behaviour and will cause Mathematica to show quotes and escaped characters.
"
complex - presenting a real number as real instead of imaginary,"
That results only holds if you assume that d > c. I.e.
Simplify[(I a)/Sqrt[c - d], Assumptions -> d > c]

"
numerical integration - How to set the NDSolve method to LSODA,"
If you load the package using Needs as shown in the Tutorial and then evaluate $NDSolveProblems you will list a list of names of all the problems included in the package. 
I think I can now also answer the first part of the question. The method has to be called as
NDSolve`LSODA

rather than LSODA (for some reason it is in the NDSolve` context, which suggests that it is not intended for ""ordinary users""). To see its options, just evaluate
?NDSolve`LSODA

The whole issue of these ""hidden contexts"" in Mathematica could be the topic of an interesting discussion ;-)
"
evaluation - Old values are not freed/garbage collected when you re-evaluate an assignment,"
You need to set
$HistoryLength = 0

(or other small value) at the beginning of the session to prevent Out from remembering previous outputs.  One non-obvious thing about Out is that if we do
In[1]:= a=1;

then Out[1] will still be set to 1 despite the semicolon at the end of the input!
There's also the CleanSlate` package which has a ClearInOut function that clears old inputs and outputs.
"
evaluation - How to properly DumpSave & Get Global`s symbols inside packages while not touching Global context?,"
To show how this is possible:

Simply put: I want to use DumpSave & Get the way I use Export &
  Import, but with efficiency and flexibility benefits.

You can simply use Import and Export.  They do support the same format that DumpSave uses, and they give you the same performance.  But they don't save symbol names.
Export[""data.mx"", data, ""MX""]

data = Import[""data.mx""]

MX files are not portable between architectures though, so you may consider using Compressed strings, as described here.  This is several times slower, but it's still quite fast compared to any other alternative and it's portable.  
If you ever need to save InterpolatingFunctions, please be aware of this problem.
"
assignment - Setting parts of a list,"
(a[[#]] = {1, 2, 3}) & /@ Range[4, 6];

You get:
In[1]:= a

Out[1]= {1, 2, 3, {1, 2, 3}, {1, 2, 3}, {1, 2, 3}, 7, 8, 9, 10}

A convenient thing to remember is that if your elements are not sequential it is still easy to set up: 
(a[[#]] = {1, 2, 3}) & /@ {1, 3, 10};

In[2]:= a

Out[2]= {{1, 2, 3}, 2, {1, 2, 3}, 4, 5, 6, 7, 8, 9, {1, 2, 3}}

"
import - Fetching data from HTML source,"
I recommend that you import as an XMLObject, which represents structured XML data in a Mathematica-based format.  
info = Import[
   ""http://area51.stackexchange.com/proposals/4470/martial-arts"", 
   ""XMLObject""];

You can access the parts of xml using Mathematica patterns, like so:
labels = Cases[info, XMLElement[
  ""div"", {""class"" -> ""site-health-label""}, label_] :> 
  First[label], Infinity];
values = Cases[info, XMLElement[
  ""div"", {""class"" -> ""site-health-value""}, value_] :> 
   First[value], Infinity];
Grid[{labels, values}, Dividers -> All]


"
evaluation - Arguments to If[] are not evaluated,"
You can evaluate
?? If

to see that its attributes are
Attributes[If]={HoldRest,Protected}

HoldRest tells you that the first argument always gets evaluated while the rest  (2nd, 3rd, and 4th) are unevaluated. In practice you can't make any assumptions about the rest because it's not possible to tell how a function evaluated held arguments internally.

That said, if you think about it, it's clear that If must evaluate the first argument, so see if it's True or False.  It is also highly desirable not to evaluate the rest of its arguments.  How would you expect the following to work?
If[a > 0,  b += 1]

Of course it must only add 1 to b if a > 0, and not otherwise!  As you can see, it is a must for any code with side effects not to evaluate automatically.  Even if we don't have non-functional constructs, we may have something like
If[a > 0, f[a], f[-a]]

for a function f that would give an error for negative arguments.  Finally, if this function f is expensive to evaluate, an If without HoldRest would evaluate it twice, while using the result from only one evaluation---this is wasteful.
I think this should make it clear why it is highly desirable for If to have HoldRest (and also why it is not necessary for it to have HoldAll)
"
"Morphing Graphics, color and location","
Try a simple way. Typical key frame animation is done by nothing more than n-degree interpolation (and n is usually 1), and they look quite reasonable.
Here is how I would tackle (it is generic version, so individual points have its own colors).

Define ""start"" and ""final"" positions:
startPos = RandomReal[{-2, 2}, {4000, 2}];

normalRDN[μ_, σ_, No_] := RandomVariate[
  NormalDistribution[μ, σ], No];

(* Tuples does the neat trick to create corner points *)
finalPos = Join @@ Table[((normalRDN[#, .5, 1000] & /@ c)\[Transpose]),
   {c, Tuples[{-1, 1}, 2]}];

Define ""start"" and ""final"" colors as a list of triples:
startCol = Table[0.5, {4000}, {3}];

finalCol = Join[Table[{1., .5, .5}, {1000}], Table[{.4, .4, 1.}, {1000}],
   Table[{0., 1., 0.}, {1000}], Table[{1., 1., 0.}, {1000}]];
(* Numericize them to make sure that the end results are all nicely packed. *)

Define ""duration"" functions: a function from time to [0, 1]
locationDuration[t_] := Piecewise[{{0, t < 2},
   {0.5 t - 1, 2 <= t < 4}, {1, True}}]

colorDuration[t_] := Piecewise[{{0, t < 0}, {0.5 t, 0 <= t < 2}, {1, True}}]

They are just piecewise linear functions, but you can find your own (such as CDF--much smooth) or try random perturbation.
Define ""easing"" function: Interpolating from start to end values with duration
easing[t_, f_, sPos_, fPos_] := (1 - f[t]) sPos + f[t] fPos;

Again, it can be more sophisticated, but usually linear is OK.
Put them together: The key here is usage of VextexColors; very effective way to change colors.
Manipulate[
   Graphics[Point[easing[t, locationDuration, startPos, finalPos], 
   VertexColors -> easing[t, colorDuration, startCol, finalCol]], 
   PlotRange -> 2, Background -> Black], {t, -0.5, 4.5, Animator, 
AnimationRepetitions -> 1}]


Here is the result (tiny).

Forget to mention that when you are using VertexColors, it doesn't get antialiased by default unlike other 2D graphics (true for Polygon too). It may result in square points, not circular points. You may want to turn on the hardware AA in Preference->Appearance->Graphics. One way to avoid (if your graphics hardware does not support AA) is to use color directive separately for each color group.
Thanks!
"
wolfram alpha queries - Roughly how many times per day may WolframAlpha[] be used?,"
Perhaps this helps:

The WolframAlpha function is limited to 1,000 API calls per day  for
  professional Premier Service subscribers (500 API calls per  day for
  student and classroom Premier Service subscribers), and  100 API calls
  per day for all other users, unless an API upgrade is  purchased.

"
performance tuning - Parallelization of distinct array write access from subkernels,"
Firstly, I want to point out not only that Fourier works for arbitrary n-dimensional arrays (as already mentioned by whuber), but also that it's already very efficiently parallelized using threading (via the Intel MKL). Therefore, attempts to parallelize it further are futile unless you intend to distribute the workload over a cluster--and then, even using algorithms that require no synchronization, the cost of communication must be considered and carefully minimized. As Amdahl's law makes clear, the performance one may gain through parallelization is very strongly constrained by the remaining serial portion of the workload, and communication is inherently difficult to parallelize within the ""scatter/gather"" paradigm offered by the Parallel` package. It is possible to implement MPI-style message passing on top of MathLink, but even then, Mathematica and MathLink are not ideal for the purpose, and you will definitely need a cluster with a high-performance interconnect such as InfiniBand in order to make this reasonably scalable.
All this being said, there's no reason not to at least try to implement a row-column decomposition to see what can be done with it. Taking your MFFTs to start with, and assuming that the input array will always have quite a high aspect ratio as in your question, we can get much better performance by doing the column-wise transforms ""by hand"" with a tensor dot product rather than calling Fourier once for each column. This is because the overhead of the function call is significant, and for small $N$ there's not that much to be gained from an $O(N M \text{log} N)$ algorithm versus one that works in $O(N^2 M)$ time (although this still implies $\approx$ 3 times as many operations for $N = 4$, so it helps that the dot product is efficient and well parallelized). Let's write:
DFTMatrix[n_] := 1/Sqrt[n] Table[Exp[(2 Pi I (r - 1) (s - 1))/n], {r, 1, n}, {s, 1, n}];

MFFTs2[data_?ArrayQ] /; ArrayDepth[data] > 1 :=
 Block[{local = data, len = Length[data], i},
  Do[local[[i, All]] = Fourier[local[[i, All]]], {i, 1, len}];
  Developer`ToPackedArray@DFTMatrix@N[len].local
 ];

MFFTs2[data_] := Fourier[data]; (* fallthrough for 1-d arrays *)

which is a lot faster (and still works for arrays of arbitrary dimensionality). For an array with $(N, M) = (4, 2^{20})$ , the AbsoluteTiming of MFFTs2 is 0.52 seconds versus 12.16 seconds for MFFTs, and (this surprised me!) MFFTs2 is even faster than Fourier for arrays of certain non-power-of-2 dimensions such as $4 \times (2^{20}+1)$ , where AbsoluteTimings are 0.78 seconds for MFFTs2 and 1.45 seconds for Fourier. Here I've kept your Do construct because it doesn't unpack, unlike the simpler Fourier /@ local, which unpacks down to level 1 (although isn't significantly slower as a result). It's worth remembering, though, that both approaches still copy their input (i.e., the FFT is not performed in-place).
Now, thinking about parallelizing it, the main consideration is avoiding unpacking since there's really no way to avoid the communication cost of sending each of the sub-arrays at level 1 to the subkernels. As a result, performance will always be poor, even on a cluster; parallel FFTs are ordinarily used when the data do not need to be sent in their entirety as they have already been distributed, and it is then desired to form the distributed FFT. In any case, doing the best we can, we need both withModifiedMemberQ from this answer, and to avoid the distribution of the whole of the array when only the parts at level 1 are actually required by each subkernel. Writing that down, we get:
MFFTp2[data_?ArrayQ] /; ArrayDepth[data] > 1 :=
 Block[{local = data, i},
  local = withModifiedMemberQ@ParallelTable[
   Fourier[i], {i, local},
   DistributedContexts -> None
  ];
  Developer`ToPackedArray@DFTMatrix@N@Length[data].local
 ];

MFFTp2[data_] := Fourier[data];

which, for an array of $(N, M) = (4, 2^{21} + 1)$ , gives an AbsoluteTiming of 4.59 seconds (of which 0.81 seconds is spent on communication), versus Fourier's AbsoluteTiming of 3.04 seconds. So, at least communication costs aren't totally overwhelming, and perhaps on a cluster with a fast interconnect it might outperform Fourier for certain (large) inputs. However, performance is still mediocre at best, which conforms to our generally low expectations for this kind of approach.
"
topology - Plotting the open ball for the post office metric space,"
I'll just post because I don't think Eli Lansey’s answer uses the right definition for post office metric. I like the other name of the post office metric better: British rail metric. It assumes that, when going from point A to point B, the fastest path is to go via London (i.e., the origin), unless of course you're already at your destination!
So, we consider a fixed point $\mathbf{p}$, the ball $B_r(\mathbf{p})$ is the set of points $\mathbf{q}$ that satisfy:
$$\|\mathbf{p}\|^2 + \|\mathbf{q}\|^2 < r^2$$
that is, if we have $\mathbf{q}=(x,y)$, the ball $B_r(\mathbf{p})$ is the union of the $\{\mathbf{p}\}$ and all points satisfying:
$$x^2 + y^2 < r^2 - \|\mathbf{p}\|^2$$
The latter is the ball of radius $r' = \sqrt{r^2 - \|\mathbf{p}\|^2}$ around the origin for the Euclidean distance in the plane, which we might note $B_{r'}^{\text{E}}(\mathbf{O})$. To summarize:

if $r < \|\mathbf{p}\|$, $B_r(\mathbf{p}) = \{\mathbf{p}\}$
otherwise, $B_r(\mathbf{p}) = \{\mathbf{p}\} \cup B_{r'}^{\text{E}}(\mathbf{O})$ with $r' = \sqrt{r^2 - \|\mathbf{p}\|^2}$


Okay, this being Mathematica.SE, I figure I could give code to draw the above, in addition to doing the maths. So, this draws the ball (point $\mathbf p$, which is part of the ball, is drawn as a little filled square so it's visible):
ball[p_, r_] := Show[
  RegionPlot[
   x^2 + y^2 + p[[1]]^2 + p[[2]]^2 < r^2, {x, -5, 5}, {y, -5, 5}, 
   PerformanceGoal -> ""Quality""],
  Graphics[{Blue, Point[p]}]
  ]

and this is an animation of a ball of radius 3 as its center $\mathbf p$ moves from $(0,0)$ to $(0,4)$:

"
Conditional Gathering of lists,"
You need Split:
Split[list, Greater]

SplitBy doesn't work here because the specified function is applied to each element separately before doing a normal Split.  What you want is a pair-wise comparison with a custom comparator, which is what Split does.

Looking at this again you may want GreaterEqual to group identical elements in the same list:
Split[{2, 1, 1, 7, 5, 5, 5, 6, 0}, GreaterEqual]


{{2, 1, 1}, {7, 5, 5, 5}, {6, 0}}


For fun I tried to do this operation without Split.  Since I was having fun I used Do rather than Module to localize symbols i and x.
split = Last @ Reap @ Do[If[n > x, i++]; Sow[x = n, i], {i, 1}, {x, 1}, {n, #}] &;

split @ {2, 1, 1, 7, 5, 5, 5, 6, 0}


{{2, 1, 1}, {7, 5, 5, 5}, {6, 0}}


"
evaluation - How do I write a ValueQ function that only returns True if there exists an OwnValue?,"
Leonid and I had a very productive chat with the end result of Leonid asking me to go ahead and post the answer. If others have a better answer to this narrowly phrased question please do not let my submission deter you!
Essentially the problem with these ""safe"" ValueQ questions is one of interpretation. What does it mean when we ask if a symbol has a value? 

Mathematica says a symbol has a value if it has any of the following: OwnValues, UpValues, DownValues, NValues, SubValues or FormatValues. This makes sense in the context of MMA being essentially a glorified pattern matcher.
Folks that come from a non MMA background with prior programming experience will say that a symbol only has a value if it has some OwnValues. This mirrors the behavior of nearly every non MMA programming language in existence. 

In order for MMA to implement #1 above, MMA chooses to do some evaluation in order to determine if any of the Up/Down/N/Sub/Format values actually contain a meaningful value. This is the heart of the problem. If the user expects behavior #2, that can be had with a very simple function that requires no evaluation at all.
SetAttributes[ownValueQ,HoldAll];
ownValueQ[s_Symbol] := ValueQ[s]; 
ownValueQ[_]        := False

The above includes no evaluation as the implementation of ValueQ when handling OwnValues on a symbol is: 
HoldComplete[sym]=!=(HoldComplete[sym]/.OwnValues[sym])

"
import - Importing from Excl - Mathmatica Stack Exchang,"
With syntax errors fixed:
  Import["" appropriate path /Desktop/stproj.xls"", ""xls"", ""Data"", 1]

should import the file.
Regarding population counts you are getting, the = sign at the beginning of an input cell invokes Wolfram Alpha query which allows free-form input (hence you get no syntax error warnings). Interestingly, Wolfram Alpha interprets the query somehow and returns:

If you click the red + button on the top right to get the full results, you see why W|A returns with this result: 

"
"programming - Reading from STDIN, or: how to pipe data into Mathematica","
Standard input
Try using the Input and or InputString commands to read from the standard input. For example a program that does
Print[InputString[]];

when run on the commandline with 
$>  echo ""Hello"" | mathematicaScript
Hello

Of course this also works from the standard Mathematica workbook.
From Invoked program
Use Import with a ""!"" before the shell command. For example:
Import[""!help"", ""string""]

You may use any valid format that the Import function supports.
"
equation solving - Solve[ ] with Method -> Reduce gives a different result than Reduce[ ],"
Solve by default works with generic parameters, even if you use the option Method -> Reduce. To get the special parameter value m = 2 you need to set MaxExtraConditions to All:
Solve[Sqrt[x + Sqrt[x]] - Sqrt[x - Sqrt[x]] == m Sqrt[x/(x + Sqrt[x])], x, Reals, 
    Method -> Reduce, MaxExtraConditions -> All]
Out[1]= {{x -> ConditionalExpression[(4 - 8 m + 8 m^2 - 4 m^3 + m^4)/(4 - 8 m + 4 m^2),
    1 < m <= 2]}}

"
geography - Google Map in Notebooks?,"
All we need to create an interactive Google Map in the notebook is access to the individual tiles - and there is a relatively simple naming scheme for those tiles.  The most basic form of a tile URL looks like: http://mt0.google.com/vt/x=xi&y=yi&z=i, where $0\leq xi,yi < 2^i$. For example, at zoom level z=0, there is one tile representing the whole earth:
http://mt0.google.com/vt/x=0&y=0&z=0

At zoom level 1, there are 4 tiles that cover most of the earth:

With a little understanding of the Mercator projection, it's not hard to translate from lat/lng values to tile indices:
{alng,blng} = First[{a,b} /. Solve[
  {a*(-180)+b==0,a(180)+b==1},{a,b}]];
lngToIndex[lng_, zoom_] := Floor[(alng*lng+blng)2^zoom];
mercator[lat_] = Log[Abs[Sec[lat*Degree]+Tan[lat*Degree]]];
{alat,blat} = First[{a,b} /. Solve[{a*mercator[85.0511287798066]+b==0,
  a*mercator[-85.0511287798066]+b==1},{a,b}]];
latToIndex[lat_, zoom_] := Floor[(alat*mercator[lat]+blat)2^zoom];
indicesToTileURL[x_Integer, y_Integer, zoom_Integer] := 
  ""http://mt0.google.com/vt/x="" <> ToString[x] <> ""&y="" <> 
    ToString[y] <> ""&z="" <> ToString[zoom]

Now, suppose I'd like to compute the URL of a tile in my neighborhood.
{lat0,lng0} = CityData[""Asheville"", ""Coordinates""];
x0=lngToIndex[lng0,10];
y0=latToIndex[lat0,10];
indicesToTileURL[x0,y0,10]

""http://mt0.google.com/vt/x=277&y=403&z=10""

We can put this all together to set up an interactive zoomer.
Manipulate[
  With[{x0=lngToIndex[lng0,zoom],y0=latToIndex[lat0,zoom]},
    Grid[{
      {Import[indicesToTileURL[x0-1,y0-1,zoom]],
       Import[indicesToTileURL[x0,y0-1,zoom]],
       Import[indicesToTileURL[x0+1,y0-1,zoom]]},
       {Import[indicesToTileURL[x0-1,y0,zoom]],
       Import[indicesToTileURL[x0,y0,zoom]],
       Import[indicesToTileURL[x0+1,y0,zoom]]},
      {Import[indicesToTileURL[x0-1,y0+1,zoom]],
       Import[indicesToTileURL[x0,y0+1,zoom]],
       Import[indicesToTileURL[x0+1,y0+1,zoom]]}
    }, Spacings -> {0,0}]
  ],{{zoom,13},Range[2,18]}]


This is really just proof of concept at this point.  There's quite a lot more that could be done.  You could use an EventHandler to allow dragging and panning and add other controls as well.  You'd need some error handling to deal with scrolling out of range.  You could also interface other map servers.
Also, I checked the terms of use of the Google Maps API available here:
http://www.google.com/intl/en_us/help/terms_maps.html 
I don't see anything that violates their terms of use but, then, I'm not a lawyer.
"
plotting - Using the same frame ticks for two different histograms,"
Perhaps:
SetOptions[Histogram, BarOrigin -> Left, 
  Frame -> {{True, None}, {True, None}}, FrameTicks -> Automatic];

data1 = Table[BesselJ[1, x], {x, 0, 500}];
data2 = Table[BesselJ[1, x], {x, 0, 100}];
GraphicsGrid[{{
   histo1 = Histogram[data1],
   histo2 = Histogram[data2],
   Show[
    Histogram[data2, ChartElements -> None], 
    Histogram[data1, {HistogramList[data2][[1]]}]]}}]


Edit
use just 
Show[Histogram[data2, ChartElements -> None], Histogram[data1]]

if you don't want to reuse the same bins:

"
plotting - Formatting legend text font,"
Try using Style in the option values for PlotLegend->{...}. For example:
  Plot[{Sin[x], Cos[x]}, {x, 0, 2 Pi}, 
  PlotLegend -> {Style[""sine"", Red, Bold, 18], ""cosine""},  
  LegendLabel -> None]

gives:

"
plotting - Number format of axes in a plot,"
One can also define a KMB number format using NumberForm and its options as follows:
 g[a_] := Switch[a, ""3"", ""K"", ""6"", ""M"", ""9"", ""B"", ""12"", ""T"", _, """"]; 
 kmbtForm[num_?NumericQ, digits_?IntegerQ] := 
 StringReplace[#, ""."" ~~ x : (""K"" | ""M"" | ""B"" | ""T"") -> x] &@
 ToString@
 NumberForm[N@#1, #2, 
  ExponentFunction -> (If[0 >= #, 0, 3 Quotient[#, 3]] &), 
  NumberFormat -> (StringJoin[#1, g[#3]] &)] & @@ {num, digits}

Usage examples:
  {kmbtForm[#, 3], kmbtForm[#, 4]} & 
   /@ {-1234, 12.34, 12345.67, 123456.7, 1234567., 123456789.123, 1234567891.} // Grid

gives

For plot ticks, using a variation of Faysal's tick function with this formatting function 
 tickfunc[xmin_, xmax_] := 
 Function[tickNumber, {tickNumber, kmbtForm[tickNumber, 3]}] /@ 
 FindDivisions[{xmin, xmax}, 10];

in
 Plot[1000 x^3, {x, -10, 10}, Ticks -> {Automatic, tickfunc}]

gives
 
"
graphics - Adding a circle to an already existing drawing,"
You need a large enough PlotRange, or
circ11 = Show[circ, Graphics[Circle[{0, 0}, 40]], PlotRange -> All]

Edit: are you referring to Heike's code? If so, you could simply replace her plot[t] function 
by something like:
plot[t_] := 
 Show[Graphics[{Circle[{0, 0}, 40], 
    Translate[Rotate[{circ[[1]], Point[{0, 0}]}, om2 t], centre[t]]}],
   If[Abs[t] <= $MachineEpsilon, {}, 
   ParametricPlot[centre[s], {s, 0, t}, PlotStyle -> {Black}]], 
  PlotRange -> {{-2 radius, 2 radius}, {-2 radius, 2 radius}}, 
  Axes -> True]

and the outer circle will be visible and not fixed.
"
string manipulation - Splitting words into specific fragments,"
Here is a hybrid recursive/StringReplaceList method.  It builds a tree representing all possible splits.
Now with a massive speed improvement thanks to Rojo's brilliance.
Updated element list per bobthechemist.
elements =
  Array[ElementData[#, ""Symbol""] &, 118] /.
    {""Uup"" -> ""Mc"", ""Uus"" -> ""Ts"", ""Uuo"" -> ""Og""} //
    ToLowerCase;

f1[""""] = Sequence[];

f1[s_String] := 
  Block[{f1}, 
    StringReplaceList[s, 
      StartOfString ~~ a : elements ~~ b___ ~~ EndOfString :> a ~~ f1@b
  ]]

Testing:
f1 @ ""titanic""


{""ti"" ~~ {""ta"" ~~ {""n"" ~~ {""i"" ~~ {""c""}}, ""ni"" ~~ {""c""}}}}


f1 @ ""archbishop""


{""ar"" ~~ {""c"" ~~ {""h"" ~~ {""b"" ~~ {""i"" ~~ {""s"" ~~ {""h"" ~~ {""o"" ~~ {""p""}}, 
     ""ho"" ~~ {""p""}}}}, ""bi"" ~~ {""s"" ~~ {""h"" ~~ {""o"" ~~ {""p""}}, ""ho"" ~~ {""p""}}}}}}}



Responding to comments below and whuber's post, an extension that generates string lists:
f2[s_String] := { f1[s] } //. x_ ~~ y_ :> Thread[x ~~ ""."" ~~ y] // Flatten

f2 @ ""titanic""

f2 @ ""archbishop""


{""ti.ta.n.i.c"", ""ti.ta.ni.c""}

{""ar.c.h.b.i.s.h.o.p"", ""ar.c.h.b.i.s.ho.p"", ""ar.c.h.bi.s.h.o.p"", ""ar.c.h.bi.s.ho.p""}



Incidentally:
f2 @ ""inconspicuousness""


in.c.o.n.s.p.i.c.u.o.u.s.n.es.s
in.c.o.n.s.p.i.c.u.o.u.s.ne.s.s
in.c.o.n.s.p.i.c.u.o.u.sn.es.s
in.c.o.n.s.p.i.cu.o.u.s.n.es.s
in.c.o.n.s.p.i.cu.o.u.s.ne.s.s
in.c.o.n.s.p.i.cu.o.u.sn.es.s
in.co.n.s.p.i.c.u.o.u.s.n.es.s
in.co.n.s.p.i.c.u.o.u.s.ne.s.s
in.co.n.s.p.i.c.u.o.u.sn.es.s
in.co.n.s.p.i.cu.o.u.s.n.es.s
in.co.n.s.p.i.cu.o.u.s.ne.s.s
in.co.n.s.p.i.cu.o.u.sn.es.s
i.n.c.o.n.s.p.i.c.u.o.u.s.n.es.s
i.n.c.o.n.s.p.i.c.u.o.u.s.ne.s.s
i.n.c.o.n.s.p.i.c.u.o.u.sn.es.s
i.n.c.o.n.s.p.i.cu.o.u.s.n.es.s
i.n.c.o.n.s.p.i.cu.o.u.s.ne.s.s
i.n.c.o.n.s.p.i.cu.o.u.sn.es.s
i.n.co.n.s.p.i.c.u.o.u.s.n.es.s
i.n.co.n.s.p.i.c.u.o.u.s.ne.s.s
i.n.co.n.s.p.i.c.u.o.u.sn.es.s
i.n.co.n.s.p.i.cu.o.u.s.n.es.s
i.n.co.n.s.p.i.cu.o.u.s.ne.s.s
i.n.co.n.s.p.i.cu.o.u.sn.es.s


"
"list manipulation - How to ""ignore"" an element of Map or MapIndexed","
This specific behaviour can be achieved using
If[condition, something, Unevaluated@Sequence[]]& /@ list

The key is Sequence[].  Unevaluated prevents it from disappearing from inside the If.
Alternatively you can use Cases (or many other solutions shown in other answers and comments---some of these solutions may be better suited for the problem but Sequence[] has its place too).
Cases[list, element_ /; condition :> something]

"
Plotting Complex Quantity Functions,"
The way you could use ContourPlot here, assuming your variable f is complex (f == x + I y) :
eqn[x_, y_] := (25 Pi ( x + I y) I)/(1 + 10 Pi ( x + I y) I)

{ContourPlot[Re@eqn[x, y], {x, -1, 1}, {y, -1, 1}, PlotPoints -> 50], 
 ContourPlot[Im@eqn[x, y], {x, -1, 1}, {y, -1, 1}, 
 PlotRange -> {-0.5, 0.5}, PlotPoints -> 50]}


These are respectively real and imaginary parts of the function eqn. 
Let's plot the absolute value of eqn :
Plot3D[ Abs[ eqn[x, y]], {x, -1, 1}, {y, -1, 1}, PlotPoints -> 40]


And we complement with the plot of real and imaginary parts of eqn in the real domain :
eqnR[x_] := (25 Pi x I)/(1 + 10 Pi x I)
Plot[{ Tooltip@Re@eqnR[x], Tooltip@Im@eqnR[x]}, {x, -0.25, 0.25}, 
      PlotStyle -> Thick, PlotRange -> All]


"
programming - How do I generate the upper triangular indices from a list?,"
The solution is straightforward: Subsets, specifically
Subsets[{1,2,3}, {2}]

gives

{{1, 2}, {1, 3}, {2, 3}}


To generate the lower indices, just Reverse them
Reverse /@ Subsets[{1,2,3}, {2}]

which gives

{{2, 1}, {3, 1}, {3, 2}}


"
replacement - Replacing composite variables by a single variable,"
You can't use replacements that way, because Mathematica does not do replacements on expressions the way they appear to you. To see what I mean, take a look at the FullForm of your expression:
x/(y*z) // FullForm
Out[1]= Times[x,Power[y,-1],Power[z,-1]]

Whereas, the replacement that you're using is Times[y, z]. 
In general, it is not a good idea to use approaches that exploit the structure of expressions to do mathematical replacements. You might think you have nailed the replacement down, but it will break for a slightly different equation or terms.
To do this in a fail safe manner, you can use Simplify as:
Simplify[x/(y z), w == y z]
Out[2]= x/w

For more complicated examples, you might have to use Eliminate. From the documentation:
Eliminate[{f == x^5 + y^5, a == x + y, b == x y}, {x, y}]
Out[3] = f == a^5 - 5 a^3 b + 5 a b^2

Also read the tutorial on eliminating variables.
"
symbolic - What is a type in Wolfram Mathematica programming language?,"
The nearest Mathematica has to ""types"" are Heads of expressions that are Atoms. For example:
Through[{AtomQ, Head}[2]]

{True, Integer}

Through[{AtomQ, Head}[2 + I]]

{True, Complex}

Through[{AtomQ, Head}[""cat""]]

{True, String}

and so on...
There are also somewhat different ""types"" in the context of Compile.
"
gpu - Why does CUDAQ (from CUDALink) download data from Wolfram servers?,"
It installs CUDA Resources, as indicated in the manual page. The resources are platform and driver specific and can also be downloaded manually from here.
"
programming - Does every Symbol in Mathematica induce a monad?,"
Mathematica provides a perfect way to define monad by setting UpValues and DownValues of some symbol. Please, find specifications for monads Maybe and State below.

Monad Maybe:
DownValues[Just] = {Just[(a: Just[x_])] :> Just[x]};
UpValues[Just] = 
    {(expr: (op: Except[Just | List | Trace | UpValues | DownValues])[
       a___, Just[b_], c___]) /;  
       !MatchQ[
           Unevaluated[expr],
           HoldPattern[If[__, __, Just[x_]] | If[__, Just[x_], __]]
       ] :> Just[op[a, b, c]]};

Rule from DownValues[Just] stands for monad Maybe multiplication law. That is removing of head duplicates. Rule from UpValues[Just] stands for bind operation of monad Maybe. One need to use special pre-condition for this pattern because Mathematica uses some wrapping code to convert evaluating/reducing expression in standard form by low-level call MakeBoxes. For example, let's see this wrapping code:
Hold[
 If[False, 3,
  With[{OutputSizeLimit`Dump`boxes$ =
     Block[{$RecursionLimit = Typeset`$RecursionLimit},
      MakeBoxes[Just[3], StandardForm]
      ]
    },
   OutputSizeLimit`Dump`loadSizeCountRules[]; 
   If[TrueQ[BoxForm`SizeCount[OutputSizeLimit`Dump`boxes$, 1048576]], 
    OutputSizeLimit`Dump`boxes$,
    OutputSizeLimit`Dump`encapsulateOutput[
     Just[3],
     $Line,
     $SessionID,
     5
     ]
    ]
   ],
  Just[3]
  ]
 ]

That's why rule from UpValues[Just] has special pre-condition for being inside of condition expression. Now one can use symbol Just as a head for computations with exceptions:
UpValues[Nothing] = {_[___, Nothing, ___] :> Nothing};
Just[Just[123]]
(*
 ==> Just[123]
*)

Just[123] + Just[34] - (Just[1223]/Just[12321])*Just[N[Sqrt[123]]]
(*
 ==> Just[155.899]
*)

Thanks to @celtschk for great comments of this point.
Monad State:
return[x_] := State[s \[Function] {x, s}];
bind[m_State, f_] := State[r \[Function] (f[#[[1]]][#[[2]]] & @ Part[m, 1][r])];
runState[s_, State[f_]] := f[s];

For monad State I didn't use UpValues and DownValues just for similarity with Haskell notation. Now, one can define some sequential computation as State value with complex state logics as a monadic computation by using return and bind operations. Please, see an example:
computation =
  Fold[bind, return[1], 
   Join[{a \[Function] s \[Function] {a, a + s}, 
     b \[Function] s \[Function] {b, s + b/(3 s)}, 
     c \[Function] s \[Function] {c, s + (s^2 + c)}},
    Array[x \[Function] a \[Function] s \[Function] {a, s}, 300]
    ]
   ];  

To get more effective computation one can use runState operation:
Fold[#2[#1[[1]]][#1[[2]]] &, runState[23, return[1]], 
    Join[{a \[Function] s \[Function] {a, a + s}, 
          b \[Function] s \[Function] {b, s + b/(3 s)}, 
          c \[Function] s \[Function] {c, s + (s^2 + c)}},
         Array[x \[Function] a \[Function] s \[Function] {a, s}, 3000]
  ]
 ]
 (*
  ==> {1, 3119113/5184}
 *)


Conclusion: 

Ideas of rule-based programming and using Head as type identifier allow user to express any(?) programming concept in Mathematica. For example, as it has just been shown, monads State and Maybe from Haskell;
Using of UpValues and DownValues for assigning rules to symbols and using of generalized operations (such as bind is) allow user to put expressions in different monadic environments.

"
plotting - SIGSEGV error with 3D Plots,"
The Mathematica Knowledge Base has an article on this issue.
It´s caused by an error with open source graphics drivers. The mesa solution works by bypassing your graphics card and so will make things run a bit more slowly.
"
list manipulation - Why can't NumberQ be used as the head of a pattern?,"
The syntax _foo indicates that you're looking for a pattern with the head foo. NumberQ is not a Head, but a test returning a boolean True or False depending on whether the expression is a number or not. So you'd have to use it with PatternTest as _?NumberQ. For your example, the following should work:
Cases[list, _?NumberQ]

If you wanted to stick with DeleteCases, then you'll have to negate the test using either of the three constructs below:
DeleteCases[list, _?(Composition[Not, NumberQ])]
DeleteCases[list, _?(! NumberQ[#] &)]
DeleteCases[list, Except[_?NumberQ]]

Beware that ? has a very high precedence and binds very tightly and hence the parentheses are necessary in the first two constructs. See this question for more info.
"
"numerical integration - NDSolve, Schrödinger equation, and decaying solution","
noeckel’s answer on StackOverflow is spot on. This is not a Mathematica issue, this is a mathematical issue. Namely, Mathematica is giving you the correct solution to the system of differential equation and boundary conditions given. The conditions given (and in particular the derivative imposed at the origin) are incompatible with the expected decay. Bear in mind that, at $r \geq 5$, your wavefunction will have two components of the form $\exp(\alpha r)$ and $\exp(-\alpha r)$. For each set of boundary conditions, you get a different linear combination of these two, and the only conditions that make sense are those for which the diverging term is zero.
"
list manipulation - What is a Mathematica packed array?,"
I will answer a couple of your questions only.
Space efficiency
Packed arrays are significantly more space efficient. Example: Let's create an unpacked array, check its size, then do the same after packing it:
f = Developer`FromPackedArray[RandomReal[{-1, 1}, 10000]];
ByteCount[f]
ByteCount[Developer`ToPackedArray[f]]

(*
320040
80168
*)

Time efficiency
The difference seems to be how they are stored; packed arrays can only contain objects of the same type, so mma does not need to keep track of the type of each element. This can also speed up operations with them. Define
ClearAll[timeIt];
SetAttributes[timeIt, HoldAll]
timeIt[expr_] := Module[{t = Timing[expr;][[1]], tries = 1},
    While[t < 1.,
    tries *= 2;
    t = AbsoluteTiming[Do[expr, {tries}];][[1]];
    ];
    Return[t/tries]]

then
ClearAll[f, fpacked];
f = Developer`FromPackedArray[RandomReal[{-1, 1}, 500000]];
fpacked = Developer`ToPackedArray[RandomReal[{-1, 1}, 500000]];

fpacked.fpacked // timeIt
f.f // timeIt

Sin[fpacked] // timeIt
Sin[f] // timeIt

(*
0.0001610173
0.01167263
0.00487482
0.01420070
*)

Unpacking
To be warned of arrays being unpacked, you can do SetSystemOptions[PackedArrayOptions->UnpackMessage->True] or, in versions after 7, On[""Packing""] (thanks to OleksandrR for pointing this out). The you see that eg Select unpacks: try Select[fpacked, 3] and a message is produced. Also assigning a value of different type to a packed array unpacks it: try fpacked[[2]] = 4 to see this.
This unpacking explains mysterious slowdowns in mma code most of the time for me.
Addressing
It appears that it is twice as slow to address a single element in a packed vs an unpacked array:
ClearAll[f, fpacked];
f = Developer`FromPackedArray[RandomReal[{-1, 1}, 500000]];
fpacked = Developer`ToPackedArray[RandomReal[{-1, 1}, 500000]];

fpacked[[763]] // timeIt
f[[763]] // timeIt
(*
4.249656*10^-7
2.347070*10^-7
*)

AppendTo is not faster:
AppendTo[fpacked, 5.] // timeIt
AppendTo[f, 5.] // timeIt
(*
0.00592841
0.00584807
*)

I don't know if there are other kinds of addressing-like operations that are faster for packed arrays (I doubt it but could be wrong).
Aside
In the Developer` context there are these names involving Packed:
Select[
 Names[""Developer`*""],
 Not@StringFreeQ[#, ___ ~~ ""Packed"" ~~ ___] &
 ]
(*
{""Developer`FromPackedArray"", ""Developer`PackedArrayForm"", 
""Developer`PackedArrayQ"", ""Developer`ToPackedArray""}
*)

Developer`PackedArrayForm does this:
ClearAll[f, fpacked];
f = Developer`FromPackedArray[RandomInteger[{-1, 1}, 5]];
fpacked = Developer`ToPackedArray[RandomInteger[{-1, 1}, 5]];

Developer`PackedArrayForm[f]
Developer`PackedArrayForm[fpacked]
(*
{-1, -1, -1, -1, -1}
""PackedArray""[Integer, <5>]
*)

So, you could set $Post = Developer`PackedArrayForm and then packed arrays would be displayed in a special way. I am not sure if this has any other sideeffects (this has been suggested in this great answer by ruebenko).
"
syntax - NMinimize with defined function call getting error NMinimize::nnum,"
The symbol f is the name of the function, and calling f with the proper argument structure (i.e. 1 argument, like x) replaces it with the function value (the definition on the right hand side). Since f is not called with an argument in your example in NMinimize, it is not replaced by the right hand side, thus a symbol is left which cannot be minimized.
If you define f as a function of y and not x, or even as a pure function:
f = #^4 - 3 #^2 - # &;

it is still not enough, as NMinimize then is replaced as:
NMinimize[f, x] --> NMinimize[#^4 - 3 #^2 - # &, x]

where # and x are not bound, as x now you can see that x does not appear at all in the function. On the other hand, this works:
NMinimize[foo^4 - 3 foo^2 - foo, foo]


{-3.51391, {foo -> 1.30084}}

Also note, that if you define your function in the standard way like this:
f[x_] := x^4 - 3 x^2 - x;

then calling f on its own returns the symbol f itself, as f does not have any OwnValue (only DownValues), therefore NMinimize[f, x] does not make sense:
f


f

{OwnValues[f], DownValues[f]}


{{}, {HoldPattern[f[x_]] :> x^4 - 3 x^2 - x}}

"
graphs and networks - NumberOfSpanningTrees command not working correctly,"
The Combinatorica package is now considered obsolete and not compatible with Mathematica's built-in Graph theory functionality. The function CycleGraph, which you are using, is a built-in function and is not understood by the Combinatorica package. You have to replace CycleGraph[i] simply by Cycle[i], which is the corresponding object in Combinatorica. You can confirm this that by looking at (for example) CycleGraph[5] and ShowGraph[Cycle[5]]:
GraphicsRow[{CycleGraph[5] , ShowGraph[Cycle[5]]}]


Actually, the Combinatorica package still has a lot of functionality that has nothing equivalent in the Kernel (and it is not clear if this will ever change completely). On the other hand it is essentially undocumented (unless you buy the book by Skiena and Pemmaraju) and the quality of Mathematica programming is not great (there are also bugs that never seem to get fixed). 
"
Calling Correct Function for Plotting DiracDelta,"
To create the plot you could replace any occurrence of DiracDelta[a] with something like 10000 UnitStep[1/10000 - a^2]], so for example to plot
f[x_] := DiracDelta[x - 2] + DiracDelta[x + 2]

you could do something like
Plot[Evaluate[f[x] /. DiracDelta[a_] :> 10000 UnitStep[1/10000 - a^2]], 
  {x, -4, 4}, Exclusions -> None, PlotPoints -> 800]


Note that for Mathematica to see the discontinuities you need to increase the number of plot points. The number of points needed will depend on the plot range, so you might have to tweak that. 
"
calculus and analysis - Does $x>0$ imply that $x\in\mathbb{R}$?,"
The most direct way to test this is probably the following:
$Assumptions = x > 0;
Element[x, Reals] // Simplify
(* Out[1]= True *)

$Assumptions = True;
Element[x, Reals] // Simplify
(* Out[4]= x ∈ Reals *)

So $x>0$ seems to imply that $x$ is real.
"
front end - How to replace the style of the inline cell in a StyleSheet,"
Using the Option Inspector:
In the Format menu choose Option Inspector, select Cell Options > New Cell Defaults and edit the value of the option DefaultNewInlineCellStyle. 
In the screenshot below, I changed the value of this option from {} to ""Subsection"" using the drop-down menu.
The first two cells on the left notebook show the inline cell styles before and after changing the value of the option  in the Option Inspector.

Using SetOptions:
To change the for the new inline cells for the active notebook, use
 SetOptions[EvaluationNotebook[], DefaultNewInlineCellStyle -> ""Section""]

Example cell containing an inline cell: 

For the style change to apply to all new inline cells in the current front-end session, use
 SetOptions[$FrontEndSession, DefaultNewInlineCellStyle -> ""Section""]

If you want to have the changes to persist across sessions, use
 SetOptions[$FrontEnd, DefaultNewInlineCellStyle -> ""Section""]

Finally, to reset any of the changes, use
 SetOptions[xxx, DefaultNewInlineCellStyle -> Inherited]

where xxx is EvaluationNotebook[], or $FrontEndSession or $FrontEnd.
Setting your own custom styles:
 SetOptions[EvaluationNotebook[], 
 DefaultNewInlineCellStyle -> {FontFamily -> ""SketchFlowPrint"", FontSize -> 24}]


"
plotting - Using PlotLegends with Show messes up the graphics,"
When Show is used the legends use ShowLegend. Here is a demo:
depth4 = Range[20]^3;
plot = ListLogLogPlot[Sort[depth4], PlotRange -> {{1, 50000},
     {1, 50000}}, Joined -> True, PlotStyle -> {Purple},
   BaseStyle -> {FontSize -> 14}];
line = LogLogPlot[11024 x^(-0.94232), {x, 1, 100000},
   PlotStyle -> {Orange, Dashed, Thick}];
line2 = LogLogPlot[31862 x^(-1.07076), {x, 1, 100000},
   PlotStyle -> {Green, Dotted, Thick}];

Needs[""PlotLegends`""]
ShowLegend[Show[plot, line, line2, ImageSize -> 500],
 {{{Graphics[{Purple, Line[{{0, 0}, {2, 0}}]}], ""   depth4""},
   {Graphics[{Orange, Dashed, Line[{{0, 0}, {2, 0}}]}], ""   line""},
   {Graphics[{Green, Dashed, Line[{{0, 0}, {2, 0}}]}], ""   line2""}},
  LegendPosition -> {0.7, 0.2}, LegendSize -> {0.45, 0.4},
  LegendShadow -> False}]


"
How to set a rule in pattern matching to change a string from one form to another,"
It is not quite clear what you are aiming to do, but perhaps this would work:
StringReplace[""r1abc=CxxC(00)r2xyz"",
 R1__ ~~ ""=C"" ~~ x___ ~~ ""C(00)"" | ""C(0)"" ~~ R2__ :> 
  R1 <> ""C(O)"" <> x <> ""C"" <> R2]


r1abcC(O)xxCr2xyz

"
"output formatting - How one can programmatically transform a text into Gothic, DoubleStruck, or something similar?","
Edit: 
Quoting from Heike´s comment: ""The font families used for Greek, script, gothic, and double struck symbols are respectively ""Mathematica1"", ""Mathematica5"", ""Mathematica6"", and ""Mathematica7"" ""
With this knowledge, just use Styletogether with the FontFamily option:
Style[""Doth this help?"", FontFamily -> ""Mathematica6"", 
      FontSize -> 100]


Now for my first version, which seems like prime obfuscation. The one benefit is that characters that are not in the special fonts do not get replaced. So I´ll leave this for purely educational purposes:
text = ""Hello world!"";

gothic = StringReplace[
   text, {x_?UpperCaseQ :> 
     ToString @ ToExpression[""\\[GothicCapital"" <> x <> ""]""],
          x_?LowerCaseQ :> 
     ToString @ ToExpression[""\\[Gothic"" <> ToUpperCase[x] <> ""]""]}];

Style[gothic, 30]




You can get the right prefixes for this solution by looking at the FullForm of your favorite special character (here: Gothic or GothicCapital).
"
options - Extract values for ViewMatrix from a Graphics3D,"
The documentation is wrong. It should have been fixed, but AbsoluteOptions does not work with ViewMatrix (on all platforms). M- introduced interactive 3D graphics since V6, and after that getting values through AbsoluteOptions (which is an old function) becomes very tricky since the Kernel (who evaluates the option) cannot fully know what is happening on FrontEnd side. To compare, before V6, the Kernel was solely responsible for rendering 3D scene (Postscript!), and of course it could tell every matrix value.
Instead, you can try to use 5 values that can define the matrix using Dynamic:
ViewPoint, ViewAngle, ViewVertical, ViewCenter, and ViewRange.

For instance, the following example takes those 5 values from one graphics, and use it for another:
DynamicModule[
 {point = {1.3, -2.4, 2}, angle = N[35 Degree], vertical = {0, 0, 1}, 
  center = Automatic},
 Grid[{{
    Framed[
     Graphics3D[{
       (* Objects *)
       EdgeForm[], Specularity[White, 20],
       FaceForm[Red], Sphere[{-0.2, -0.1, -0.3}, .2],
       FaceForm[Blue], Cylinder[{{0., 0.3, -.5}, {0., 0.3, 0.}}, .1],
       FaceForm[Green], Cone[{{0.2, 0., -0.5}, {0.2, 0., -0.1}}, .2]
       },
      Boxed -> True, Lighting -> ""Neutral"",
      ImageSize -> 300, RotationAction -> ""Clip"",

      (* View control *)
      ViewPoint -> Dynamic[point],
      ViewAngle -> Dynamic[angle],
      ViewVertical -> Dynamic[vertical],
      ViewCenter -> Dynamic[center]
      ],
     FrameStyle -> LightGray],

    (* The second object *)
    Framed[
     Plot3D[Sin[x y], {x, 0, 3}, {y, 0, 3},
      ImageSize -> 300, Axes -> False,
      (* View control *)
      ViewPoint -> Dynamic[point],
      ViewAngle -> Dynamic[angle],
      ViewVertical -> Dynamic[vertical],
      ViewCenter -> Dynamic[center]
      ],
     FrameStyle -> LightGray]
    }}]
 ]

Examples:
 
and

This free course explains about the values in vary detail (with some cool demos--OK. shameless self-promotion :) ):
Wolfram Training: Visualization: Advanced 3D Graphics
Also, in essence, you can reconstruct the view matrix and projection matrix out of those values, but I need to take a look at an old textbook to make sure that I am not saying something wrong :)
"
programming - Is there a convenient way to copy/paste text-interspersed SE code snippets into Mathematica?,"
Code extractor using the StackExchange API
The following code uses the 2.0 version of the SE API and has also been cleaned up a bit (place it in your kernel's init.m or your custom functions package if you'd like to be able to use it anytime).
The function takes a single string argument, which is the URL obtained from the share link under a question/answer.
Example


importCode[url_String] := With[
  {
   filterCode = StringCases[#, (""<pre><code>"" ~~ (""\n"" ...) ~~ x__ ~~ (""\n"" ...) ~~ ""</code></pre>"") /; 
        StringFreeQ[x, ""<pre><code>"" | ""</code></pre>""] :> x] &, 
   convertEntities = StringReplace[#, {""&gt;"" -> "">"", ""&lt;"" -> ""<"", ""&amp;"" -> ""&"", ""&quot;"" -> ""\""""}] &, 
   makeCodeCell = Scan[CellPrint@Cell[Defer@#, ""Input"", CellTags -> ""Ignore""] &, Flatten@{#}] &,
   postInfo = Import[ToString@StringForm[
        ""http://api.stackexchange.com/2.1/posts/`1`?site=`2`&filter=!9hnGsretg"", #3, #1] & @@ 
        {First@StringCases[#, Shortest[s__] ~~ ""."" ~~ ___ :> s], #2, #3} & @@ 
        StringSplit[StringDrop[url, 7], ""/""][[;; 3]], ""JSON""]
   },
  OptionValue[""items"" /. postInfo, ""body""] // filterCode // convertEntities // makeCodeCell]

NOTE: I don't do any rigorous error checking or check to see if you're entering a valid Stack Exchange URL or if the question/answer is deleted (deleted posts cannot be accessed via the API), etc. So if you get any errors, it might be worthwhile to check if there's something wrong on the site.
Also, SE API limits you to 300 calls/day/IP, if I remember correctly. That's quite a lot of calls for any reasonable person and ideally, you shouldn't cross that. Nevertheless, a possibility of being throttled is something to keep in mind if you also happen to be playing with the API for other purposes such as site statistics, etc.
"
"symbolic - Why does Assuming[x > 0, TrueQ[x > 0]] return False?","
Because the assumption system is not called during the standard evaluation sequence, it is only called when Simplify, FullSimplify, Sum, Integrate etc... are used.
Thus, x>0 remains unevaluated:
Assuming[x > 0, x > 0] 
(*
==> x > 0
*)

and TrueQ then returns False:
Assuming[x > 0, TrueQ[x > 0]]
(*
==> False
*)

If, however, you run Simplify before TrueQ, you get the expected result
Assuming[x > 0, TrueQ[Simplify[x > 0]]]    
(*
==> True
*)


As an aside, there is some ""hidden"" functionality in the Assumptions` context that lets you perform various checks and calculations within the assumption system. Run ?Assumptions`* to see what's available. You code, in particular, could be written as
Assuming[x > 0, Assumptions`APositive[x - 0]]
(*
==> True
*)

"
How to set row height in Grid?,"
The Pane construct is quite flexible. I cannot imagine not using it with table for fluid sizes control and features. Here are your data:
data={{""000000000\n111111111\n222222222"",""000000000""},{""000000000"",""000000000""}}

This will fix the cell size and cut off the content if it won't fit:
Grid[Map[Pane[#, ImageSize -> {80, 30}] &, data, {2}], Frame -> All]


This will fix the cell size and shrink the content if it won't fit
Grid[Map[Pane[#, ImageSize -> {80, 30}, ImageSizeAction -> 
""ShrinkToFit""] &, data, {2}], Frame -> All]


Use Scrollbars to view the content that did not fit
data2 = 200! {{1, 1}, {1, 1}};
Grid[Map[Pane[#, ImageSize -> {200, 100}, Scrollbars -> 
{False, True}] &, data2, {2}], Frame -> All]


Forbid line-breaks to use horizontal scrolling only for small row height (updated after @Yu-Sung comment):
data2 = 200! {{1, 1}, {1, 1}};
Grid[Map[Pane[#, ImageSize -> {150, 30}, Scrollbars -> {True, False}] &, 
data2, {2}], Frame -> All, BaseStyle -> {LineBreakWithin -> False}]


"
"import - How to load thumbnail, not image?","

In Mathematica 8, few image files are supported natively--meaning, without calling external MathLink executables, which results in much faster speed (order of magnitude) and great efficiency in memory usage. Currently only TIFF and JPEG work that way. PNG was close but it was cut-off. What I am saying is that you will see much speed up in the future for PNG reading/writing.
Now, I hate to say this, but with M8, there is not much thing to do to improve the speed of PNG (unless you are willing to venture and call libpng directly using LibraryLink. Probably out of bound for most users...).
Again, current Import does not support thumbnail read from image files (maybe we should). I am not sure PNG has its own embedded thumbnail (I think it has... sure for JPEG). So it is no go either...
The Windows system uses Thumbs.db to store ""pregenerated"" thumbnails. But again, M- can't utilize these files except in system dialog boxes (like SystemDialogInput[""FileOpen""]). It is in fact quite tricky to handle this DB so I don't think that the support will happen at all.
If you expect your code to access folders frequently, it won't be bad idea to maintain its own thumbnail database using Thumbnail function (which is quite fast). Possibly some hidden folder with miniaturized images for future use, or some specialized DB file (a notebook or DumpSave). But, yes, it is quite involving... I have to say.

Sorry, no good answer.
"
curated data - How to save ChemicalData queries so that they are available immediately on notebook load?,"
You can ""preload"" all the data to your computer so that it doesn't have to look it up each time. An added advantage is that it'll also be available when you're offline. This is covered in this support article on wolfram.com. In your case, you would do:
ChemicalData[All,""Preload""]
RebuildPacletData[]

and you should be all set. Note that it will take a while to download all the data from their servers.
"
FindInstance with a Diophantine equation seems to go on forever,"
It does not seem surprising that a search space 2000 times larger results in a substantially longer computation time.
Here is a much more direct way to find a solution:
Sqrt @ IntegerPartitions[2012^2, {5}, Range[2012]^2, 1]


{{2011, 63, 7, 2, 1}}


"
linear algebra - Entering block matrices for an arbitrary matrix size,"
We can construct this matrix directly as a SparseArray. This allows some classes of numerical matrices to be stored as packed arrays while being combined with symbolic or exact vectors (or vice versa), so there can be storage and run-time efficiency reasons for using a SparseArray, in addition to the obvious benefit of direct construction. On the other hand, the function needed to construct a sparse block matrix is undocumented.
Define:
f[A_?MatrixQ, t_?VectorQ] /; Length[A] == Length[t] := 
 SparseArray`SparseBlockMatrix[{
  {1, 1} -> A, {1, 2} -> Transpose[{t}], {2, 2} -> {{1}}
 }, Dimensions[A] + 1];

Now:
f[IdentityMatrix[5], Array[a, 5]]

gives (as a sparse array; if you want exactly this output you must first use Normal):

"
plotting - How to add a vertical line to a plot,"
An easy way to add a vertical line is by using Epilog.
Here is an example:
f[x_] := (x^2 z)/((x^2 - y^2)^2 + 4 q^2 x^2) /. {y -> π/15, z -> 1, q -> π/600}
Quiet[maxy = FindMaxValue[f[x], x]*1.1]
lineStyle = {Thick, Red, Dashed};
line1 = Line[{{π/15 + 1/50, 0}, {π/15 + 1/50, maxy}}];
line2 = Line[{{π/15 - 1/50, 0}, {π/15 - 1/50, maxy}}];
Plot[{f[x], f[π/15], f[π/15]/Sqrt[2]}, {x, π/15 - 1/20, π/15 + 1/20},
    PlotStyle -> {Automatic, Directive[lineStyle], Directive[lineStyle]},
    Epilog -> {Directive[lineStyle], line1, line2}]


Caveat
While adding lines as Epilog (or Prolog) objects works most cases, the method can easily fail when automated, for example by automatically finding the minimum and maximum of the dataset. See the following examples where the red vertical line is missing at $x=5$:
data1 = Table[0, {10}];
data2 = {1., 1., 1.1*^18, 1., 6., 1.2, 1., 1., 1., 148341.};

Row@{
  ListPlot[data1, Epilog -> {Red, Line@{{5, Min@data1}, {5, Max@data1}}}],
  ListPlot[data2, Epilog -> {Red, Line@{{5, Min@data2}, {5, Max@data2}}}]
  }


In the left case, Min and Max of data turned out to be the same, thus the vertical line has no height. For the second case, Mathematica fails to draw the line due to automatically selected PlotRange (selecting PlotRange -> All helps). Furthermore, if the plot is part of a dynamical setup, and the vertical plot range is manipulated, the line endpoints must be updated accordingly, requiring extra attention.
Solution
Though all of these cases can be handled of course, a more convenient and easier option would be to use GridLines:
Plot[{f[x]}, {x, π/15 - 1/20, π/15 + 1/20},
    GridLines -> {{π/15 + 1/50, π/15 - 1/50}, {f[π/15], f[π/15]/Sqrt[2]}}, PlotRange -> All]


And for the extreme datasets:
Row@{
  ListPlot[data1, GridLines -> {{{5, Red}}, None}],
  ListPlot[data2, GridLines -> {{{5, Red}}, None}]
  }


"
plotting - Interactively extract points from a plot (ListPlot or SmoothDensityHistogram),"
This is basically the same as what b.gatessucks is doing. The main addition is that I've put all the locators in one list. To add vertices to the polygon you just click somewhere on the graph. I've also added a reset button and a button that prints the indices of the points inside the polygon which makes it easier to copy.
points = RandomSample[
   Transpose[{Flatten[{RandomReal[{0, 5}, 20], RandomReal[{4, 4.5}, 10]}], 
     Flatten[{RandomReal[1, 20], RandomReal[{1.5, 2}, 10]}]}], 30];

winding[poly_, pt_] := Round[(Total @ Mod[(# - RotateRight[#]) &@
  (ArcTan @@ (pt - #) & /@ poly), 2 Pi, -Pi]/2/Pi)]

DynamicModule[{pl, pos},
 pl = SmoothDensityHistogram[points, ColorFunction -> ""TemperatureMap""];
 Manipulate[
  pos = Pick[Range[Length[points]], Unitize[winding[poly, #] & /@ points], 1];
  Show[pl, 
   Epilog -> {{Darker[Green], PointSize[Medium], Point[points[[pos]]]},
     {Black, Point[Complement[points, points[[pos]]]]},
     {EdgeForm[{Red, Dashed}], FaceForm[], Polygon[poly]}}],

  {{poly, {}}, Locator, LocatorAutoCreate -> All},
  Row[{Button[""Copy Points"", Print[pos]], Button[""Reset"", poly = {}; pos = {}]}]]]


"
calculus and analysis - Bug in Integrate for Mathematica,"
I think it is indeed a bug specific to version 8 of Mathematica. 
The same integrals in version 7 give the correct result. 
Compare this issue with this answer. 
In the both cases one works with assumptions which make Integrate behaving improperly.
Edit 1
It seems that definite integrals are calculated correctly and if we subtract the limits of integration in the way that the boolean formula is slightly neutralized, then the result is correct, e.g. :
Integrate[ regFunc[x, y]*((4 x + 3 y) (3 x + 2 y))^4, {x, -10, 10}, {y, -10, 10}] // N

Integrate[ regFunc[x, y]*(12 x^2 + 17 x*y + 6 y^2)^4, {x, -10, 10}, {y, -10, 10}] // N


7836.43
7836.43


RegionPlot[ {-5 < 4 x + 3 y && 4 x + 3 y < 5 && -2 < 3 x + 2 y && 3 x + 2 y < 2, 
             -10 < x < 10 && -10 < y < 10 },
            {x, -25, 25}, {y, -25, 25}, PlotPoints -> 150, MaxRecursion -> 4]


It should be emphasized that Integrate doesn't work either when we use insted of Boole for example UnitStep :
regFuncUS[x_, y_] := UnitStep[ 5 + 4 x + 3 y, 5 - 4 x - 3 y, 2 + 3 x + 2 y, 2 - 3 x - 2 y]

Edit 2
In Mathematica 9 this bug has been fixed :
Integrate[ regFunc[x,y] (( 4 x + 3 y )( 3 x + 2 y ))^4,{x, -100, 100},{y, -100, 100}] //N
Integrate[ regFunc[x,y] ( 12x^2 + 17 x y + 6 y^2 )^4,{x, -100, 100},{y, -100, 100}] //N


16000.
16000.


"
Manipulate not working inside DialogInput,"
Try
DialogInput[{Manipulate[Dynamic[x], {{x, 2}, {1, 2, 3}}, 
   LocalizeVariables -> False], Button[""OK"", DialogReturn[x]]}]

I'm not sure why Dynamic is required.
LocalizeVariables -> False allows the value of x to be returned (outside of the scope of the Manipulate.  LocalizedVariables was shown to be necessary for a Manipulate embedded in DialogInput. See here.
"
keyboard - Emacs key bind on Mathematica Linux,"
I was never able to find a completely satisfying solution, but the following is what I use. The shortcuts for the Mathematica GUI are defined in [MathematicaDir]/SystemFiles/FrontEnd/TextResources/X/KeyEventTranslations.tr. You can also add your own shortcuts there, as long as the functionality you require already exists. (Actually you can also write your own functions and assign shortcuts there.) Of course the shortcuts need to be unique to work correctly, including the ones assigned to menu items, which normally have a Alt-... binding under Linux. These can be edited in the MenuSetup.tr file in the same directory. So you always have to make sure that there is no overlap between these two files. Just as an example, these are the custom shortcuts I defined:
(* My emacs shortcuts *)
Item[KeyEvent[""I"", Modifiers -> {Command}], ""ScrollPageUp""],
Item[KeyEvent[""K"", Modifiers -> {Command}], ""ScrollPageDown""],
Item[KeyEvent[""d"", Modifiers -> {Command}], ""DeleteNext""],
Item[KeyEvent[""D"", Modifiers -> {Command}], ""DeleteNextWord""],
Item[KeyEvent[""i"", Modifiers -> {Command}], ""MovePreviousLine""],
Item[KeyEvent[""k"", Modifiers -> {Command}], ""MoveNextLine""],
Item[KeyEvent[""j"", Modifiers -> {Command}], ""MovePrevious""],
Item[KeyEvent[""l"", Modifiers -> {Command}], ""MoveNext""],
Item[KeyEvent[""o"", Modifiers -> {Command}], ""MoveNextWord""],
Item[KeyEvent[""u"", Modifiers -> {Command}], ""MovePreviousWord""],
Item[KeyEvent[""L"", Modifiers -> {Command}], ""MoveLineEnd""],
Item[KeyEvent[""J"", Modifiers -> {Command}], ""MoveLineBeginning""],
Item[KeyEvent[""O"", Modifiers -> {Command}], ""MoveNextCell""],
Item[KeyEvent[""U"", Modifiers -> {Command}], ""MovePreviousCell""]

"
character encoding - Unicode-aware string functions?,"
See if this helps:
Needs[""JLink`""];
ClearAll[toUpperCase];
toUpperCase[s_String] :=
    JavaBlock[JavaNew[""java.lang.String"", s]@toUpperCase[]];

"
calculus and analysis - Trying to prove that $x\sin(\frac{\pi}{x})\ge\pi \cos(\frac{\pi}{x})$ for $x\ge 1$,"
The proof of the original statement that $f(x)\equiv x\sin\frac{\pi}{x}$ is a monotonically increasing function of $x$ for $x>1$ can be done as follows: 
First, we show that the second derivative $f''(x)$ of the function is negative:
Simplify[D[x Sin[π/x], x, x] < 0, Assumptions -> x > 1]


True

This means that the first derivative $f'(x)$ is a monotonically decreasing function of $x$ for $x>1$. 
Now we show that the derivative of the function approaches zero as $x\to\infty$:
Limit[D[x Sin[π/x], x], x -> ∞]


0

Since the derivative has been shown to be decreasing and to have a limit of zero for $x\to\infty$, it follows that $f'(x) > 0$ for $x>1$. This proves the desired statement about $f(x)$.
Edit
To take the other route proposed in the edited version of the question, you could do the following:
Resolve[ForAll[{x}, x > 1 && Tan[π/x] >= π/x, f'[x] >= 0], Reals]


True

Edit 2
In the Resolve statement above, ForAll has three arguments: the variable {x}, a condition, and the statement to be proved. In words, this says the following: for all $x$ that satisfy the condition $x>1$ and $\tan(\pi/x)\ge \pi/x$, it holds that $f'(x)\ge0$. Of course, the condition can actually be simplified because the tangent inequality as stated here only holds for $x>2$. 
To make the condition fully consistent with the desired interval $x>1$, we simply have to replace $x$ by $2 x$ in the tangent inequality. This leaves the inequality unaffected but extends its range of validity to $x>1$. Therefore, we get the following statement that can be fed to Mathematica:
Resolve[ForAll[x, x > 1 && Tan[π/(2 x)] >= π/x/2, f'[x] >= 0], Reals]


True

"
index - Sequentially numbering a nested list,"
I am pretty sure that it is not the best solution but how about this?
numbering[x_] := Block[{n = 0}, Replace[x, y_ :> {++n, y}, {-1}]]

Some example outputs:
In[1]:= numbering[{a, b, {c, d}, e, {f, {g, h}}}]

Out[1]= {{1, a}, {2, b}, {{3, c}, {4, d}}, {5, e}, {{6, f}, {{7, g}, {8, h}}}}

In[2]:= numbering[Nest[{#, #} &, x, 3]]

Out[2]= {{{{1, x}, {2, x}}, {{3, x}, {4, x}}}, {{{5, x},
    {6, x}}, {{7, x}, {8, x}}}}

About the level spec {-1} (per reference):

Level -1 consists of numbers, symbols, and other objects that do not have subparts.

Sounds exactly like what you want.
"
gui construction - Adjusting placement of control objects in a row within a panel,"
You want to use Grid.
Code
Panel[
 Grid[
  {
    (* The 1st row *)
    {
      Row[{""Board size: "", InputField[Dynamic[max], Number, FieldSize -> 3]}], 
      Button[""Clear Board"", ImageSize -> All]
    },
    (* The 2nd row *)
    {
      Graphics[Circle[], ImageSize -> 300], SpanFromLeft
    }
  }, Alignment -> {{Left, Right}, Baseline}]
]

Result



Few things

SpanFromLeft is used so that the first column of the second row would occupy the second column too.
Grid[{
  {""A"", ""B""},
  {""C"", SpanFromLeft}
 }, Frame -> All, BaseStyle -> {FontSize -> 36}]




Button's default ImageSize is Full, which makes it stretched so that it would fill all cell. So I changed it to All which makes its width just enough for the text.

Button[..., ImageSize->Full] (or the default)



Button[..., ImageSize->All]


Alignment can be specified in {horizontal, vertical} order. Within each, you can specify them for each row / column by giving a list (in this case, Left for the first column, Right for the second column).

Grid has a very rich syntax. The reference is always a good source.
"
Mathmatica Prcision - Mathmatica Stack Exchang,"
NIntegrate[f[x], {x, 0, 2*Pi}, WorkingPrecision -> 15, PrecisionGoal -> 10]


 7.95492652101285


"
performance tuning - Loop optimization,"
Your best bet is to remove the procedural programming Do, While and Append Statements, building lists with Append is not quick. Then embrace a functional programming approach on which Mathematica thrives. Making use of constructs like Transpose, Part, Nest, Map, Table and Fold. These are generally much faster and lead to eventually to less buggy code.
If machine precision numbers are enough you can look at using Compile.
There are many approaches, but you could try something along these lines:-
There is no need to initialise Particle in Mathematica.
You can eliminate the Do loop and  its 80,000 thousand calls to RandomVariate
by just two calls.
dimensions=2; numParticles=20000;
XYs = 
Transpose[{RandomVariate[NormalDistribution[0, Sqrt[EmitX]], {numParticles,dimensions}],
    RandomVariate[NormalDistribution[0, Sqrt[EmitY]], {numParticles,dimensions}]}];

This gives you a list of pairs of Xs and Ys of length numParticles.
You could then write a set of functions to compute coordS, coordsX, coordsY, say C[], cX[], cY[].
Then combine Table and NestWhile.
The basic form for NestWhile is 
NestWhile[function, initial state, terminating condition]

The terminating condition is checked, 'function' is is applied to 'initial state' producing a result.
The result is held in a variable known as #. # may have several components. These components are accessed by the part notation, #[[1]], #[[2]] and so on.
The terminating condition is then checked and if true, result is then given to function to evaluate.
This produces a new result ... and so on. It's basically recursion.
The trick is to make the 'initial condition' have the same structure as the result of applying 'function'. Function may actually be a compound list of results gained by using several functions. And sometimes you need to 'pad' an element of the list, as it can be used to hold the parameters for the nest.
In your case perhaps something to compute the {coordX, coordY, coordS, XY }.
The shape of the code would look something like this
res =   
Table[
 NestWhile[{C[],cX[#[[1,1],#[[3,2]]],Cy[#[[2]]]}&,
 {p[[1]],p[[2]],{PhiS + Pi, BucketHeightP}},
 Abs[#[[3,1]]] >= (PhiS + Pi) ||  Abs[#[[3,2]]] >= d[#[[3,1]]] &], 
{p,XYs}]

Assuming PhiS  BucketHeightP do not change between iterations.
This is just a roughed out solution and probably skips over some details and could definitely be improved but should help you towards a faster implementation and give you a flavour of the functional approach.
I hope you can see that the form of the solution is essentially a Table command with a NestWhileand 3 auxiliary functions. You could even insert the initial creation of the variable XYs into Table command, but that would have just reduced comprehension in this case.
This is typical of what functional programming brings to the party. Very concise programs with a high level of abstraction. 
One way of looking at it is that you start with your initial data and then apply some functional transforms to arrive at your final data. This avoids a lot of the bugs introduced by procedural programs that have lots of state information held in global variables. State information that often gets inadvertently corrupted.
Apologies, but this isn't debugged code, but a template solution - so there might be a few niggles to iron out before it flies.
Further performance tuning tips can be found at:
tuning
"
documentation - Listing the functions defined in a package,"
Possibly this way:  
<< PrimalityProving`

?PrimalityProving`*

or alternatively (see the copy&paste issue in the comments)
?""PrimalityProving`*""




See also the help under ref/Information, subsection ""Generalizations & Extensions"". In some cases you have to provide a string argument:
Information[""*Values""]




"
reference request - Strategies for simplifying complicated expressions,"
I don't know why you would expect Mathematica to understand that this is a real expression when you have I, (-1)^(1/4) and (-1)^(3/4) at various places in the expression.
(-1)^(1/4) // N
(* Out[1]= 0.707107 + 0.707107 I *)

(-1)^(3/4) // N
(* Out[2]= -0.707107 + 0.707107 I *)

In this particular instance, the denominator is pretty obviously real.
Simplify[Sign@Denominator[finalnew], 
  Assumptions -> {ka > 0, kd > 0, L > 0, ω > 0, d > 0}]

(*
Out[3]= Sign[(ka^4 ω^2 + d^2 (kd^2 + ω^2)^2 - 4 d ka^2 ω (kd^2 - kd ω + ω^2)) 
    Cos[ Sqrt[2] L Sqrt[ω/d]] - (ka^4 ω^2 + d^2 (kd^2 + ω^2)^2 + 4 d ka^2 ω (kd^2 + kd ω + ω^2)) 
    Cosh[Sqrt[2] L Sqrt[ω/d]] - 2 Sqrt[2] ka ((d^(3/2) (kd - ω) ω^(5/2) - 
        kd^2 (d ω)^(3/2) + kd^3 Sqrt[d^3 ω] - ka^2 kd Sqrt[d ω^3] + ka^2 Sqrt[d ω^5]) 
    Sin[Sqrt[2] L Sqrt[ω/d]] + (kd^2 (d ω)^(3/2) + kd^3 Sqrt[d^3 ω] + ka^2 kd Sqrt[d ω^3] + 
        ka^2 Sqrt[d ω^5] + d^(3/2) ω^(5/2) (kd + ω)) 
    Sinh[ Sqrt[2] L Sqrt[ω/d]])
]
*)

Simplify[Im@Denominator[finalnew], Assumptions -> {ka > 0, kd > 0, L > 0, ω > 0, d > 0, u > 0}]
(* Out[4]= 0 *)

So concentrate on refining the numerator. The equivalent
Simplify[Im@Numerator[finalnew], 
 Assumptions -> {ka > 0, kd > 0, L > 0, ω > 0, d > 0, u > 0}]

does not simplify to zero. For example:
Expand@Im@Numerator[finalnew] /. {ka -> 1, kd -> 1, L -> 1, ω -> 1, d -> 1, u -> 1}

(*
Out[5]= 6 Im[(-24 - 168 I) Cos[(-1)^(1/4)] - (24 - 168 I) Cosh[(-1)^(1/4)] - 
    (78 - 102 I) (-1)^(1/4) Sin[(-1)^(1/4)] + (42 + 24 I) (-1)^(3/4) Sin[(-1)^(1/4)] +
    (108 + 144 I) (-1)^(1/4) Sinh[(-1)^(1/4)] + 6 (-1)^(3/4) Sinh[(-1)^(3/4)]]
*)

You can confirm the numerator is also real for specific values of the parameters:
FullSimplify@ Im[Numerator[finalnew] /. {ka -> 1, kd -> 1, L -> 1, ω -> 1,  d -> 1, u -> 1}] 
(* result is zero *)

But this takes an inordinate amount of time and the result is a long complex expression.
FullSimplify[Im[Numerator[finalnew]], Assumptions -> {ka > 0, kd > 0, L > 0, ω > 0, d > 0, u > 0}]

As for general strategies, FullSimplify with as many variables in the Assumptions option is a good bet in most cases, as is separately simplifying numerators and denominators. I don't know if there are best-practice strategies, though. I would expect it would depend on the kind of expression, for example, whether it is a polynomial or contains trigonometric expressions.
"
formatting - How to edit the text coming together with the numeration of pages in pdf produced out of a notebook?,"
You can do that in the “Headers and footers” dialog:

or right in the notebook with PageHeaders.
"
graphics - How to reduce the memory necessary for the image?,"
Try to use something like the following depending on the rasterization resolution you are seeking.
Export[""fig1A.pdf"", fig1A, ""AllowRasterization"" -> True,
ImageSize -> 350, ImageResolution -> 600]

This issue was previously discussed here and I am referring to the solution by Heike. Searching the site before posting a new question is the right thing to do. 
"
programming - Modifying a List in a function in place,"
You basically need a pass-by-reference semantics, which in Mathematica can be emulated with Hold-attributes. Add a HoldFirst attribute to your function:
SetAttributes[func,HoldFirst]

and you should be fine. Without it, list evaluates to its value before the assignment is attempted, and since expressions in Mathematica are immutable, you get an error.
To address your question in comments, the one-liner you asked for can be this:
func = Function[{list,column}, 
         list[[All, column]] = Map[#*2 &, list[[All, column]]],
         HoldFirst
       ]

Note however that, since this is a pure function, you can not do argument checks as elegantly as you can with patterns, and you can not overload your functions on different arguments as elegantly.
Note also that, while yet another way to do this is to keep your function as it is but rather wrap the first argument in Unevaluated in every function call, I would strongly advise against that. The reason is that it makes the function itself not self-contained, because it has to assume that the user will always remember to use Unevaluated (which it shouldn't), and there is no way to test whether or not the user actually did use it. 
"
plotting - How do I get rid of the overlap of gridlines and tick mark labels?,"
Setting PlotRangePadding to zero is probably the easiest option, but as an alternative you could draw the grid lines by hand using ProLog:
ticks = {Range[0, 2 Pi, Pi/6], Range[0, 1.5, .125]};
Plot[1/Root[-3 - 8 #1 Tan[a/2] - 
     3 Tan[a/2]^2 + #1^4 (1 + Tan[a/2]^2) + #1^2 (-9 + 
        3 Tan[a/2]^2) &, 2], {a, 0, 2 Pi}, AxesOrigin -> {0, 0},
 Ticks -> ticks,
 Prolog -> 
  Style[{Gray, Dashed, 
    Line[{{#, 0}, {#, 1.4}}] & /@ Rest[ticks[[1]]], 
    Line[{{0, #}, {2 Pi + .2, #}}] & /@ Rest[ticks[[2]]]}, 
   Antialiasing -> False]]


"
syntax - Convert operator to string,"
This seems to work
convert[str_] := Module[{stream, output},
  stream = StringToStream[""\""\\["" <> ToString[str] <> ""]\""""];
  output = Read[stream];
  Close[stream];
  output]

convert /@ {Equilibrium, LongRightArrow, LeftVector, Equal} // InputForm


Edit
You could also do something like this:
convert[str_] := ToExpression[""\""\\["" <> ToString[str] <> ""]\""""]

convert /@ {Equilibrium, LongRightArrow, LeftVector, Equal} // InputForm

"
syntax - Setting the DifferenceOrder Option,"
This is not an answer, but it is really too long for a comment.
I don't know if IDA is the same as BDF, I would have to look closer. However, as you wish to have explicit control over the order of the method and that is not available, it is likely that you can extract what order it does use out of the InterpolationFunction returned.
If you set InterpolationOrder -> All on NDSolve, it's supposed to use the underlying method's order as the interpolation order. Experimenting with 
Interpolation[..., InterpolationOrder -> ...]

reveals you may be able to extract the order of interpolation used. For instance, 
Interpolation[..., InterpolationOrder -> 2][[2]]

gives something like 

{4, 7, 0, {11}, {3}, 0, 0, 0, 0, Automatic}


The fifth term, {3} in this case, is always one more than the order. Using that technique on
sol = NDSolve[ {y''[t] + y'[t] + y[t] == 0, y'[0] == y[0] == 1}, 
               y, 
               {t, 0, 2 \[Pi]}, 
               Method -> {""BDF""}, 
               InterpolationOrder -> All
      ]

via sol[[1, 1, 2, 2]] gives

{4, 17, 5, {119}, {4}, {InterpolatingFunction[{{0., 6.28319}}, ""<>""]}, 
   0, 0, 0, Automatic}


which implies that it uses a 3$^\text{rd}$ order method.

Edit:
As I intimated, the above method seems workable, but if the format of InterpolatingFunction changes, it will fail. However, there is a package specifically designed to extract this type of information from an InterpolatingFunction: DifferentialEquations`InterpolatingFunctionAnatomy`.  Using sol from above,
Needs[""DifferentialEquations`InterpolatingFunctionAnatomy`""];
InterpolatingFunctionInterpolationOrder @ sol[[1, 1, 2]]


{3}


which confirms what the other method came up with.
Edit 2:
In addition to the package, above, some opaque objects like SparseArray and InterpolatingFunction can have their properties queried. Thanks to Oleksandr, for InterpolatingFunction these are {""Domain"", ""Coordinates"", ""DerivativeOrder"", ""InterpolationOrder"", ""Grid"", ""ValuesOnGrid""}. So, then you can determine the order used, via
sol[[1, 1, 2]][""InterpolationOrder""]

"
parallelization - Export to file from ParallelDo loop,"
Although I'd generally suggest using ParallelTable instead, I can imagine a scenario where you would like to use ParallelDo with a function that is really lengthy and could potentially hang or crash. Then you would want to save the results of each successful parallel computation to avoid losing it in case of a  crash.
But to do that, it's safest to create a separate file for each result, because we don't usually have control over the order and timing with which ParallelDo produces results. 
Since the loop can always be parameterized by integer indices, we can use these indices to label the individual result files, too. Then these files can later be combined into a single file when all the results have been written out:
ParallelDo[
 Export[""out-"" <> 
   ToString@NumberForm[i, 2, NumberPadding -> {""0"", "" ""}] <> ""-"" <> 
   ToString@NumberForm[j, 2, NumberPadding -> {""0"", "" ""}], 
  ToString[Row[{i, "","", j, "","", integral1[i, j]}]] <> ""\n"", 
  ""Text""], {i, 10}, {j, 1, 10}]

Here, I used NumberForm with 2 digits and leading 0 as padding, to produce file names in which the integers i and j appear with constant length. You would have to change the 2 to something larger if the integers range over more digits. 
I've inserted a ToString before the integral1 function because I don't know what that function is. 
When the loop is done, you'll have files ranging from out-001-001 to out-010-010. Under Unix, these can be combined easily by issuing the command cat out* > results which creates a file called results where you have everything in the desired format.
"
options - What does MaxStepFraction do?,"
The documentation is fairly clear on this:

MaxStepFraction is an option to functions like NDSolve that specifies the maximum fraction of the total range to cover in a single step.

In simpler terms, you can think of MaxStepFraction as the inverse of the number of intervals in the total range, whereas MaxStepSize is the length of an interval. The following graphic should make the difference clear:

So in other words, setting MaxStepFraction = 1/10 and setting MaxStepSize = L/10 will give you the same result. The documentation linked above also has an example that demonstrates this:
"
formatting - NIntegrate is resetting my variables and not giving me a result?,"
Some of the symbols you're using depend on the VectorAnalysis package.  So, be sure to execute the following from a fresh kernel.
Needs[""VectorAnalysis`""]

Also, be sure to define your hSol function for only numeric values.
hSol[x_?NumericQ,y_?NumericQ,t_?NumericQ] := ...

"
graphics - Using Texture to color countries according to their timezones,"
The main problem here is that you need to include a VertexTextureCoordinates (VTC) in the Polygon for a texture to be applied. However, the rest of the problem is not as simple as it seems. Here's the output of my approach. Below it, I discuss texturing several polygons belonging to the same country, according to their timezone. You can also skip that and jump straight to the code block.

Handling textures for several polygons
CountryData[country, ""Polygon""] will give you a list of polygons that depict the main boundaries, but is not necessarily contiguous. This differs from country to country — for example, Alaska is not included for the USA, but Tasmania is for Australia. Since they're sorted by area (at least, that's how it seems to me), you could simply pick the first to get the largest land mass, but it looks weird in cases such as New Zealand, Canada, Indonesia, etc.
However, the polygons returned are in the form Polygon[{poly1, poly2, ...}] and you cannot provide VTC for all of them at once. So you'll need to split the polygons and supply the VTC for each. If we naïvely follow the documentation and try something like the following (zoneTexture is defined later, but is not necessary to understand), you get:
With[{country = ""Australia""},
    p = CountryData[country, ""FullPolygon""];
    c = CountryData[country, ""FullCoordinates""];
    z = zoneTexture@CountryData[country, ""TimeZones""];
];

Graphics[{EdgeForm[Black], Texture[z], (Polygon[p[[1, #]], 
    VertexTextureCoordinates -> Transpose[Rescale /@ Transpose[c[[#]]]]] & /@ Range[Length[c]])
}]


Doesn't seem so bad, except when you look closely, you'll notice that Tasmania also has the same texture as the mainland — i.e., not coloured per its time zone. Now this can be easily fixed. You just need to get the extents of the country's boundaries and rescale the VTC to range from 0 to 1 within those extents.
Code
The following code will generate the image above. Note that I use the image available in ColorData using the ""Image"" option, and index it directly to obtain the texture. This avoids having to convert it to an Image, which can slow it down. Texture rasterizes objects anyway, so nothing is lost here. I also resize it so that it covers some cases where you observe white gaps.
Begin[""ZoneMap`""];
    image = ImageResize[ColorData[""Rainbow"", ""Image""], 1000];
    zoneTexture[zones_] := If[Length[zones] == 1, #, ImageRotate[#]] &[
        ImageTake[image, All, Clip[Floor[1000 {#1 + 12, #2 + 12}/24], {1, 1000}]] & @@ 
        Through[{Min, Max}[zones]]
    ];

    CountryGraphics[country_] := Module[{
        coordinates = CountryData[country, ""Coordinates""],
        polygons = CountryData[country, ""Polygon""],
        zones = CountryData[country, ""TimeZones""],
        minmaxlat, minmaxlong},

        {minmaxlat, minmaxlong} = {Min@#, Max@#} & /@ Transpose[coordinates~Flatten~1];
        Graphics[{EdgeForm[Black], Texture[zoneTexture[zones]],
            (Polygon[polygons[[1, #]], VertexTextureCoordinates -> 
            Transpose[{Rescale[#1], Rescale[#2, minmaxlong]} & @@
            Transpose[coordinates[[#]]]]] & /@ Range[Length[coordinates]])
        }]
   ];
End[];

ZoneMap`CountryGraphics /@ CountryData[""Countries""] // Show

Now this works fairly well and you should be able to replace zoneTexture with whatever you'd like.
Extending to ""FullPolygon"" for the countries
This can also be extended to cover the full boundaries of a country, i.e., including unincorporated territories by choosing ""FullPolygon and ""FullCoordinates"" in the respective calls. However, it fails for 2 countries (to my knowledge): USA and Russia. The reason it fails is because there is no equivalent ""FullTimeZones"" that will return the full extent of the time zones. Hence, the rescaling stretches the time zone map for the primary regions all the way across the entire extent. For example, in the case of USA, Guam, which is near Australia, forces the texture to stretch from there onwards. It is worse in the case of Russia, because the far east tip of the mainland lies in the Western hemisphere, resulting in:

One would also expect a similar scaling problem for the UK, but Britain still has the same colour since there is only one time zone. In this case, the territories are also coloured as GMT, but they're tiny anyway. Since there are only two cases that stand out visually, they can be handled individually, which is left to the reader.
"
Transpos unvn lists - Mathmatica Stack Exchang,"
Yes, but it is not trivial to comprehend. You would have to use the second argument of Flatten to implement a generalized transpose of uneven lists. For example:
(* Uneven list *)
list = Range ~Array~ 5
Out[1]= {{1}, {1, 2}, {1, 2, 3}, {1, 2, 3, 4}, {1, 2, 3, 4, 5}}

(* Transpose the list *)
list ~Flatten~ {2}
Out[2]= {{1, 1, 1, 1, 1}, {2, 2, 2, 2}, {3, 3, 3}, {4, 4}, {5}}

For more information on how the second argument of Flatten works and what it can do, see this answer by Leonid.
"
plotting - How to make a 3D globe?,"
This answer was originally posted in 2012 and based on version 8 of Mathematica.  Since then, a number of changes have made it possible to generate the globe in much less code. Specifically:

CountryData[_,""SchematicPolygon""] now returns polygons of sufficient resolution to make a nice globe. Thus, we don't need to apply polyline simplification to FullPolygons.
Triangulation is now built in.

Thus, we can now generate the globe as follows:
countryComplex[country_] := Module[
  {boundaryPts, mesh, g, triPts, tris, pts3D, linePts, lines, linePts3D},
  boundaryPts = Map[Reverse, 
        CountryData[country, ""SchematicCoordinates""], 
    {2}];
  mesh = TriangulateMesh[Polygon[boundaryPts]];
  g = Show[mesh];
  {triPts, tris} = {g[[1, 1]], g[[1, 2, 2, 1, 1, 1]]};
  pts3D = Map[
        Normalize[First[
            GeoPositionXYZ[GeoPosition[Reverse[#]]]
        ]] &, triPts];
  g = Show[RegionBoundary[mesh]];
  {linePts, lines} = {g[[1, 1]], g[[1, 2, 2, 1, 1, 1]]};
  linePts3D = Map[
        Normalize[First[
            GeoPositionXYZ[GeoPosition[Reverse[#]]]
        ]] &, linePts];
  {GraphicsComplex[pts3D, 
        {EdgeForm[], ColorData[""DarkTerrain""][Random[]], Polygon[tris]}, 
        VertexNormals -> pts3D],
   GraphicsComplex[linePts3D, {Thick, Line[lines]}]}
];

SeedRandom[1];
complexes = countryComplex /@ Prepend[CountryData[All], ""Antarctica""];
pic = Graphics3D[{{ColorData[""Aquamarine""][3], 
  Sphere[{0, 0, 0}, 0.99]}, complexes}, 
  Lighting -> ""Neutral"", Boxed -> False]



Orginal 2012 Answer
I'm posting this as a second answer, as it's really a completely different approach.  It's also been substantially expanded as of April 25, 2012.  While this still doesn't specifically address the question of adding a region, it does plot the countries separately.  Of course, each country could be viewed as a region in itself.
Our objective is to make a good, genuine 3D globe.  We prefer not to use a texturized parametric plot, for then we we'll have distortion at the poles and no access to the graphics primitives making the image.  
It's quite easy to project data given as (lat,lng) pairs onto a sphere using GeoPosition and related functions (or even just the standard parametrization of a sphere).  However, the SchematicPolygon returned by CountryData are of insufficient resolution to generate a truly nice image while the FullPolygons are so detailed that the resulting 3D object is clunky to interact with.  Furthermore, non-convex 3D polygons tend to render poorly in Mathematica with the fill leaking out.
Our solution is two-fold.  First, we simplify the FullPolygons to a manageable but still detailed level.  Second, we triangulate the resulting polygons before projecting onto the sphere.  Note that we use a third party program called triangle for the triangulation.  Once installed, however, the procedure can be carried out entirely within Mathematica using the Run command.
Polyline simplification
Here are the Schematic and Full Polygons returned by CountryData for Britain, known for it's complicated coastline.  Note that the FullPolygon consists of nearly 4000 total points, while the SchematicPolygon has only 26.
pts[0] = Map[Reverse, 
  CountryData[""UnitedKingdom"", ""SchematicCoordinates""], {2}];
pts[1] = Map[Reverse, 
  CountryData[""UnitedKingdom"", ""FullCoordinates""], {2}];
Total /@ Map[Length, {pts[0], pts[1]}, {2}]

{26, 3924}
In order to plot a nice image that is easy to interact with, we've really got to reduce the number of points in the FullPolygon.  A standard algorithm for reducing points while maintaining the integrity of the line is the Douglas-Peucker algorithm.  Here is an implementation in Mathematica:
dist[q : {x_, y_}, {p1 : {x1_, y1_}, p2 : {x2_, y2_}}] := With[
   {u = (q - p1).(p2 - p1)/(p2 - p1).(p2 - p1)},
   Which[
    u <= 0, Norm[q - p1],
    u >= 1, Norm[q - p2],
    True, Norm[q - (p1 + u (p2 - p1))]
    ]
   ];
testSeg[seg[points_List], tol_] := Module[{dists, max, pos},
    dists = dist[#, {points[[1]], points[[-1]]}] & /@ 
      points[[Range[2, Length[points] - 1]]];
    max = Max[dists];
    If[max > tol,
     pos = Position[dists, max][[1, 1]] + 1;
     {seg[points[[Range[1, pos]]]], 
      seg[points[[Range[pos, Length[points]]]]]},
     seg[points, done]]] /; Length[points] > 2;
testSeg[seg[points_List], tol_] := seg[points, done];
testSeg[seg[points_List, done], tol_] := seg[points, done];
dpSimp[points_, tol_] := 
  Append[First /@ First /@ Flatten[{seg[points]} //. 
       s_seg :> testSeg[s, tol]], Last[points]];

Let's illustrate with the coast of Britain.  The second parameter is a tolerance; a smaller tolerance yields a better approximation but uses more points.  The implementation doesn't like the first and last points to be the same, hence we use Most.  Finally, we can toss out parts that yield just two points after simplification, since they will be very small.
pts[2] = Select[dpSimp[Most[#],0.1]& /@ pts[1], Length[#]>2&];
Total[Length /@ pts[2]]

341
The result has only 341 total points.  Let's look at the mainland.
Row[Table[Labeled[Graphics[{EdgeForm[Black],White,
  Polygon[First[pts[i]]]}, ImageSize -> 200],
  Length[First[pts[i]]]],{i,0,2}]]


Our simplified polygon uses only 158 points for mainland Britain to yield an approximation that should look good on a globe.
Triangulation
Triangulation is an extremely important topic in computational geometry and still a topic in current research.  Our topic here illustrates it's importance in computer graphics; it is also very important in the numerical solution of PDEs.  It is surprisingly hard to do well in full generality.  (Consider, for example, that our simplified polygons are not guaranteed to be simple, i.e. they may and probably do self-intersect.)  Unfortunately, Mathematica doesn't have a built in triangulation procedure as of V8.  Rather than start from scratch, I've written a little interface to the freely available program called triangle:
http://www.cs.cmu.edu/~quake/triangle.html
Installing triangle on a unix based system, like Mac OS X, was easy enough for me - though, it does require some facility with C compilation.  I don't know about Windows.  Once you've got it set up to run from the command line, we can access it easily enough through Mathematica's Run command by reading and writing triangle files.  Let's illustrate with the boundary of Britain again.
Triangle represents polygons using poly files.  The following code writes a sequence of points to a stream in poly file format.
toPolyFile[strm_, pts : {{_, _} ..}] := Module[{},
   WriteString[strm, ToString[Length[pts]] <> "" 2 0 0\n""];
   MapIndexed[
    WriteString[strm, 
      ToString[First[#2]] <> "" "" <>
       ToString[First[#]] <> "" "" <>
        ToString[Last[#]] <> ""\n""] &, pts];
   WriteString[strm, ToString[Length[pts]] <> "" 0\n""];
   Do[WriteString[strm, 
     ToString[i] <> "" "" <> ToString[Mod[i - 1, Length[pts], 1]] <> 
      "" "" <> ToString[i] <> ""\n""],
    {i, 1, Length[pts]}];
   WriteString[strm, ""0""]
   ];

For example, we can write poly files for the british coast approximations as follows.
Do[
  strm = OpenWrite[""BritishCoast""<>ToString[i]<>"".poly""];
  toPolyFile[strm,First[pts[i]]];
  Close[strm],
{i,0,2}]

We'll triangulate using the following command.
$triangleCmd = ""/Users/mmcclure/Documents/triangle/triangle -pq "";

Here's the actual triangulation step.
Do[
  Run[$triangleCmd<>""BritishCoast""<>ToString[i]<>"".poly""],
{i,0,2}]

This produces new poly files as well as node and ele files.  These can be read back in and translated to GraphicsComplexs.
triangleFilesToComplex[fileName_String, itNumber_:1] := 
  Module[{pts, triangles, edges, data},
   data = Import[fileName <> ""."" <> ToString[itNumber] <> "".node"",  ""Table""];
   pts = #[[{2, 3}]] & /@ data[[2 ;; -2]];
   data = Import[fileName <> ""."" <> ToString[itNumber] <> "".ele"", ""Table""];
   triangles = Rest /@ data[[2 ;; -2]];
   data = Import[fileName <> ""."" <> ToString[itNumber] <> "".poly"", ""Table""];
   edges = #[[{2, 3}]] & /@ data[[3 ;; -3]];
   GraphicsComplex[pts, {
     {White, EdgeForm[{Black,Thin}], Polygon[triangles]},
     {Thick, Black, Line[edges]}}]]

Here's the result.
GraphicsRow[Table[
  Graphics[triangleFilesToComplex[""BritishCoast""<>ToString[i]]],
{i,0,2}], ImageSize -> 600]


The Globe
OK, let's put this all together to generate the globe.  The procedure will generate a huge number of files, so let's set up a directory in which to store them.  (Unix specific)
SetDirectory[NotebookDirectory[]];
If[FileNames[""CountryPolys""] === {},
  Run[""mkdir CountryPolys""],
  Run[""rm CountryPolys/*.poly CountryPolys/*.node CountryPolys/*.ele""]
];

The next command is analogous to the toPolyFile command above, but accepts a country name as a string, generates poly files for all the large enough sub-parts, and triangulates them.
$triangleCmd = ""/Users/mmcclure/Documents/triangle/triangle -pq "";
triangulateCountryPoly[country_String] := 
  Module[{multiPoly, strm, fileName, len, fp},
   fp = CountryData[country, ""FullCoordinates""];
   multiPoly = Select[dpSimp[Most[#], 0.2] & /@ fp, Length[#] > 2 &];
   len = Length[multiPoly];
   Do[
    fileName = ""CountryPolys/"" <> country <> ToString[i] <> "".poly"";
    strm = OpenWrite[fileName];
    toPolyFile[strm, multiPoly[[i]]];
    Close[strm];
    Run[$triangleCmd <> fileName], 
    {i, 1, len}];
   ];

Next, we need a command to read in a triangulated country (consisting of potentially many polygons) and store the result in a GraphicsComplex.
toComplex3D[country_String] := 
  Module[{len, pts, pts3D, ptCnts, triangles, edges, data},
   Catch[
    len = 
     Length[FileNames[
       ""CountryPolys/"" <> country ~~ NumberString ~~ "".1.poly""]];
    pts = Table[
      data = 
       Check[Import[
         ""CountryPolys/"" <> country <> ToString[i] <> "".1.node"", 
         ""Table""], Throw[country]];
      #[[{2, 3}]] & /@ data[[2 ;; -2]], {i, 1, len}];
    ptCnts = Prepend[Accumulate[Length /@ pts], 0];
    pts = Flatten[pts, 1];
    triangles = Flatten[Table[
       data = 
        Check[Import[
          ""CountryPolys/"" <> country <> ToString[i] <> "".1.ele"", 
          ""Table""], Throw[country]];
       ptCnts[[i]] + Rest /@ data[[2 ;; -2]], {i, 1, len}], 1];
    edges = Flatten[Table[
       data = 
        Check[Import[
          ""CountryPolys/"" <> country <> ToString[i] <> "".1.poly"", 
          ""Table""], Throw[country]];
       ptCnts[[i]] + (#[[{2, 3}]] & /@ data[[3 ;; -3]]), {i, 1, len}],
       1];
    pts3D = 
     Map[Normalize[First[GeoPositionXYZ[GeoPosition[Reverse[#]]]]] &, 
      pts];
    GraphicsComplex[pts3D,
     {{EdgeForm[], ColorData[""DarkTerrain""][Random[]], 
       Polygon[triangles]},
      {Line[edges]}}, VertexNormals -> pts3D]
    ]
];

OK, let's do it.
countries = Prepend[CountryData[All], ""Antarctica""];
triangulateCountryPoly /@ countries; // AbsoluteTiming

{77.350341, Null}
SeedRandom[1];
complexes = toComplex3D /@ countries; // AbsoluteTiming

{94.657840, Null}
globe = Graphics3D[{
  {ColorData[""Aquamarine""][3], Sphere[{0, 0, 0}, 0.99]}, complexes},
  Lighting -> ""Neutral"", Boxed -> False]


"
syntax - Orthonormalization of non-hermitian matrix eigenvectors,"
The way I am interpreting this question, it has nothing to do with the vectors in question being eigenvectors of any particular matrix. If this interpretation is wrong, the question needs to be clarified. 
The next point is that orthogonality requires an actual scalar product, and for a complex vector space this rules out the Dot product because Dot[{I,0},{I,0}] == -1 which is obviously not positive.
Therefore, the only way that it could make sense to speak of orthogonalization with respect to the Dot product for complex vectors is that you might wish for some reason to apply the orthogonalization algorithm (e.g., Gram-Schmidt) to a set of vectors with complex entries. 
Doing this is completely legitimate, but it will not lead to vectors that are orthogonal with respect to the Dot product because the Dot product is not a scalar product. It just doesn't make sense to use the term ""orthogonality"" in this case.
Here is a function that performs the algorithm as described:
orthoDotize[vecs_] := Module[{s, a, e, ortho},
  s = Array[a, Dimensions[vecs]];
  ortho = Orthogonalize[s];
  ortho /. Thread[Flatten[s] -> Flatten[vecs]]
  ]

This function has the property that its output satisfies the expected Euclidean orthogonality relations when the vectors in the list vecs are real. If they are not real, then the dot product after ""pseudo-orthogonalization"" can have imaginary parts:
mat = {{0. + 1.002 I, -1}, {-1, -I}};
evecs = N[Eigenvectors[mat]];
ovecs = orthoDotize[evecs]


{{0.722734 + 0. I, -2.69948*10^-16 + 0.691127 I}, {3.67452*10^-15 + 
     0.691127 I, 0.722734 - 3.56028*10^-15 I}}

Chop[ovecs[[1]].ovecs[[2]]]


0. + 0.999001 I

Edit: a possible cause of confusion
However, as I mentioned in my comment to the question (March 28), it could also be that there is a mathematical misunderstanding of a different kind here: equating orthogonality with biorthogonality. 
As explained on this MathWorld page, we can define left and right eigenvectors of the matrix mat, which in this case are transposes of each other because mat is symmetric. To get these (generally different) sets of eigenvectors, you can do 
eR = Eigenvectors[mat];
eL = Transpose[Eigenvectors[Transpose[mat]]];

The last line follows from 
$\begin{eqnarray*}\vec{x}_{L}^{\top}M & = & \lambda \vec{x}_{L}^{\top}\\\Leftrightarrow\,\,\,M^{\top}\vec{x}_{L} & = & \lambda \vec{x}_{L}\end{eqnarray*}$
Then the following holds:
eL.eR // Chop


$\begin{pmatrix}0.0446879 & 0\\0 & 0.0446879\end{pmatrix}$

The appearance of the diagonal matrix here means that the rows of the matrix eL (the left eigenvectors) are orthogonal to the columns of eR (the right eigenvectors) in the sense of the matrix product. This is automatically true, and there is no need to do any further orthogonalization. 
Edit 2
In case it needs further clarification: for any symmetric matrix mat we have that Transpose[eR] == eL. This implies that Transpose[eR].eR is diagonal (see above) and therefore eR[[1]].eR[[2]] == 0. That's why there is no need for any further orthogonalization in the example given in the question. 
Edit 3
If mat is not symmetric, then its (right) eigenvectors are not orthogonal in the dot multiplication sense. Forming any kind of linear combination of those eigenvectors with the intention of orthogonalizing them will lead to new vectors which in general are no longer eigenvectors (unless the vectors in question share the same eigenvalue). So the orthogonalization idea is either trivial (for symmetric matrices) or violates the eigenvector property (for general non-symmetric matrices with non-degenerate spectrum).
"
programming - Abort not aborting,"
This question has been asked before on stack overflow. However we will summerize some of the answers given there on our new Mathematica site.
Wrap In Compound Expression
One suggestion by Michael Pilat, given there was to wrap your lines in CompoundExpression, e.g.
(
   Print@Range[5];
   Abort[];
   Print@Range[5];
)


During evaluation of In[39]:= {1,2,3,4,5}
$Aborted


If you mind the formatting of parenthesis, you could explicitly use the FullForm of CompoundExpression like this:
CompoundExpression[
   Print@Range[5],
   Abort[],
   Print@Range[5],
]

Use of $PreRead
Suggested by Alexey Popkov:
In[1]:= $new$PreRead = False;
AbortAllPendingInputs := 
  AbortProtect[If[! $new$PreRead, $new$PreRead = True;
    $TimeOfAbort = SessionTime[];
    last$PreRead = ToString[Definition[$PreRead], InputForm];
    ClearAll[$PreRead];
    $PreRead := If[TrueQ[SessionTime[] - $TimeOfAbort < 1], """",
       $new$PreRead = False;
       ClearAll[$PreRead];
       If[last$PreRead === ""Null"", #, 
        ToExpression[last$PreRead]; $PreRead@#]
       ] &;]];

In[3]:= f := CheckAbort[Pause[10], AbortAllPendingInputs; Abort[]]

In[4]:= While[True, f]
While[True, f]
While[True, f]


Out[4]= $Aborted

Note that this solution will need to be modified if you use $PreRead for anything else.
Use of CellEvaluationFunction
CellEvaluationFunction gets the BoxData expression, before it is even split. Just assigning something like CellEvaluationFunction:>ToExpression seems to do the trick.
You can set it as an Input cell style, or as a notebook option, or front end session option, or however you like
SetOptions[$FrontEndSession, CellEvaluationFunction :> ToExpression]

However, you lose the multiple outputs in those new lines when you don't use ;. This can probably be solved but I don't know very well how CellEvalutionFunction works, and how can it receive a box structure, default to Identity but expect to return an expression. Edit should you come up with any improvements
"
list manipulation - Issues with a Counter that is tallying term appearances,"
If I am following your code, I think the problem is that you are collecting expressions such as bigramHash[""ottawa"", ""citizen""] which will evaluate differently depending on the DownValue associated with bigramHash.  Therefore, these expression will evaluate to whatever the final DownValue of bigramHash[""ottawa"", ""citizen""] is, if present.
Here is a simplified example of the problem:
filelist = {
   {{""a"", 1}, {""b"", 2}},
   {{""cat"", 5}, {""dog"", 3}},
   {{""a"", 4}, {""b"", 6}}
 };

Reap[Do[
   Clear[bigramHash];
   (bigramHash[#] = #2) & @@@ file;
   count = bigramHash[""a""];
   Print[count];
   Sow[count],
   {file, filelist}
]][[2, 1]]


During evaluation of In[26]:= 1

During evaluation of In[26]:= bigramHash[a]

During evaluation of In[26]:= 4

{1, 4, 4}


One simple fix is to define a default DownValue e.g. bigramHash[___] = 0:
Reap[Do[
   Clear[bigramHash];
   bigramHash[___] = 0;
   (bigramHash[#] = #2) & @@@ file;
   count = bigramHash[""a""];
   Print[count];
   Sow[count],
   {file, filelist}
]][[2, 1]]


During evaluation of In[36]:= 1

During evaluation of In[36]:= 0

During evaluation of In[36]:= 4

{1, 0, 4}


"
"plotting - When using GraphPlot with an adjacency matrix, how can I make Mathematica draw exactly one self loop for any non-zero weight?","
A simple hack of a way to obtain the behaviour that you want is to negate the adjacency matrix. Now, don't ask me what that means or represents, but it works!

Modifying the example from the accepted answer in the question that CHM shared to include multiple self loops:

You can see that the second one displays the behaviour you want. 
"
graphics - Can 2D and 3D plots be combined so that the 2D plot is the bottom surface of the 3D plot boundary?,"
The following is probably what you want.
Make3d[plot_, height_, opacity_] := 
  Module[{newplot},
    newplot = First@Graphics[plot]; 
    newplot = N@newplot /. {x_?AtomQ, y_?AtomQ} :> {x, y, height};
    newplot /. GraphicsComplex[xx__] :> {Opacity[opacity], GraphicsComplex[xx]}
  ]

Show[{Graphics3D[Make3d[twoDptsPlot, -1, .75]], threeDPtsPlot,surfacePlot}, Axes -> True]

which gives

This function can takes any 2D plot and place it on a 3D box with a specified height. I got this trick in the web few years back but now cant remember the reference. Hope this helps you.
"
import - How to extract sample values from an imported WAV file?,"
You want this:
data = Import[""test.wav"", ""Data""]

This imports the raw data of sample values. For example, on a test file of approximately 10 seconds, stereo at 48000 Hz, data is an array of size 2 × 520192 (from which I can deduce that my recording was actually 10.84 seconds). 
See the documentation for WAV format import/export, as well as this answer on a related question for some more details.

Going at it differently, if you already have imported your file as a Sound object (as in your example), you can still recover the sample data. Inside your Sound object is a SampledSoundList:
In[25]:= Head@First@B
Out[25]= SampledSoundList

This in turn contains the raw data:
In[26]:= Length@B[[1, 1]]
Out[26]= 2

In[27]:= Table[Length@B[[1, 1, i]], {i, 1, 2}]
Out[27]= {520192, 520192}

"
parallelization - Are built-in Mathematica functions already parallelized?,"
Natively multi-threaded functions
A lot of functions are internally multi-threaded (image processing, numerical functions, etc.). For instance:
In[1]:= a = Image[RandomInteger[{0, 255}, {10000, 10000}], ""Byte""];

In[2]:= SystemOptions[""ParallelOptions""]

Out[2]= {""ParallelOptions"" -> {""AbortPause"" -> 2., ""BusyWait"" -> 0.01,
    ""MathLinkTimeout"" -> 15., ""ParallelThreadNumber"" -> 4, 
   ""RecoveryMode"" -> ""ReQueue"", ""RelaunchFailedKernels"" -> False}}

In[3]:= ImageResize[a, {3723, 3231}, 
   Resampling -> ""Lanczos""]; // AbsoluteTiming

Out[3]= {1.2428834, Null}

In[4]:= SetSystemOptions[
 ""ParallelOptions"" -> {""ParallelThreadNumber"" -> 1}]

Out[4]= ""ParallelOptions"" -> {""AbortPause"" -> 2., ""BusyWait"" -> 0.01, 
  ""MathLinkTimeout"" -> 15., ""ParallelThreadNumber"" -> 1, 
  ""RecoveryMode"" -> ""ReQueue"", ""RelaunchFailedKernels"" -> False}

In[5]:= ImageResize[a, {3723, 3231}, 
   Resampling -> ""Lanczos""]; // AbsoluteTiming

Out[5]= {2.7461943, Null}

Functions calling optimized libraries
Mathematica surely gets benefit from multi-threaded libraries (such as MKL) too:
In[1]:= a = RandomReal[{1, 2}, {5000, 5000}];

In[2]:= b = RandomReal[1, {5000}];

In[3]:= SystemOptions[""MKLThreads""]

Out[3]= {""MKLThreads"" -> 4}

In[4]:= LinearSolve[a, b]; // AbsoluteTiming

Out[4]= {4.9585104, Null}

In[5]:= SetSystemOptions[""MKLThreads"" -> 1]

Out[5]= ""MKLThreads"" -> 1

In[6]:= LinearSolve[a, b]; // AbsoluteTiming

Out[6]= {8.5545926, Null}

Although, the same function may not get multi-threaded depending on the type of input.
Compiled function
CompiledFunctions and any other functions that automatically use Compile can be multi-threaded too, using Parallelization option to Compile.
Caution

Measuring timing with AbsoluteTiming for multi-threaded functions could be inaccurate sometimes.
The performance gain is usually not direct proportion to the number of threads. It depends on a lot of different factors.
Increasing number of threads (by using SetSystemOptions ) more than what your CPU support (either physical or logical cores) is not a good idea.

"
graphics - How do I draw a DensityPlot in polar coordinates?,"
Use the two-argument form ArcTan[x, y] instead of ArcTan[y/x]:

ArcTan[x,y] gives the arc tangent of y/x, taking into account which quadrant the point $(x,y)$ is in. 

It just works:

"
graphics - Memory Leak in Frontend,"
This is a simpler example that shows the behavior (in Win-x86-64, M8.0.4):    
Do[Rasterize[Graphics[Table[RGBColor @@ RandomReal[1, {3}], {1000}]]], {1000}]

Apparently, the memory gets allocated for each RGBColor with unique value, but is never freed. The same goes to other color directives.
"
graphics3d - Facegrids at ticks,"
This can be found on the 'More Information' section of the FaceGrid doc page though it may not be very easy to grasp. Here's an example:
Plot3D[Sin[R bn/10], {R, 2, 100}, {bn, 1, 5}, 
 AxesStyle -> Thickness[0.005], 
 Ticks -> {{2, 10, 20, 30, 50, 100}, {1, 2, 3, 4, 5}, {0.5, 1.0, 1.5, 2.0, 2.5}},
 Boxed -> False, 
 Mesh -> {{0, 2, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100}, 
          {1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5}}, 
 PerformanceGoal -> ""Quality"", 
 FaceGrids -> 
   {{{0, -1, 0}, {{2, 10, 20, 30, 50, 100}, {0.5, 1.0, 1.5, 2.0, 2.5}}}, 
    {{1,  0, 0}, {{1, 2, 3, 4, 5}, {0.5, 1.0, 1.5, 2.0, 2.5}}}, 
    {{0, 0,  1}, {{2, 10, 20, 30, 50, 100}, {1, 2, 3, 4, 5}}}
   }
]


Basically what Facegrid specifies here is which faces to draw and what lines to draw
in each face. For each face, we need one list. An identification of the grid we are talking about is the first element of each face grid specification. This specification can be thought of the unit vector pointing straight to the grid you want to indicate, so {1,0,0} would be the $+x$ face grid, and {0,-1,0} would be the $-y$ grid.  The next element of the grid specification list is a specification of the grid lines, a list with tick values for each of the remaining coordinates. So, if the $+x$ grid is being specified this list contains a specification for the $y$ and $z$ ticks.
"
numerical integration - Controlling the time step in NDSolve?,"
To get a fixed step size with the BDF method you can lower the AccuracyGoal and PrecisionGoal to increase the adaptive step sizes and then use MaxStepSize to limit the step size to any value you want.
Get an example stiff system from the documentation:
Needs[""DifferentialEquations`NDSolveProblems`""];
Needs[""DifferentialEquations`NDSolveUtilities`""];
system = GetNDSolveProblem[""VanderPol""];

Solve with the BDF method:
sols = NDSolve[system, {T, 0, 10}, Method -> ""BDF""];
Plot[Evaluate[sols[[1, All, 2]]], {T, 0, 10.}, Frame -> True]


Plot the step sizes:
StepDataPlot[sols] /. AbsolutePointSize[_] -> PointSize[Small]


Solve again with low precision and accuracy goals and small MaxStepSize:
sols = NDSolve[system, {T, 0, 10}, Method -> ""BDF"", 
  PrecisionGoal -> 0, AccuracyGoal -> 0, MaxStepSize -> 1. 10^-5
];
Plot[Evaluate[sols[[1, All, 2]]], {T, 0, 10.}, Frame -> True]


Now we have a fixed step size:
StepDataPlot[sols] /. AbsolutePointSize[_] -> PointSize[Small]


We can increase the step size, but the result starts to diverge from the true solution:
sols2 = NDSolve[system, {T, 0, 10}, Method -> ""BDF"", 
   PrecisionGoal -> 0, AccuracyGoal -> 0, MaxStepSize -> 1. 10^-4
];
Plot[Evaluate[Flatten[{sols, sols2}][[All, 2]]], {T, 0, 10.}, Frame -> True]


We still have a fixed step size, though:
StepDataPlot[sols2] /. AbsolutePointSize[_] -> PointSize[Small]


"
kernel - Does Mathematica on Mac OS use virtualization for certain functions?,"
Yes, the Mathematica application on Mac OS contains a few external binaries, which are mostly used for importing and exporting. These files have suffix .exe:
$ find ""/Applications/Mathematica 8.app"" -name '*.exe'|wc -l
49
But even though .exe is a prefix common for Windows executables, it doesn’t mean that it can’t be used for other things. In fact, Mac OS (like Linux and other Unixes) doesn’t care much how files are named, and while it is typically to name binary files on these systems without suffix at all, a .exe suffix doesn’t hurt. Moreover, you can actually check that these files are Mac OS binary:
$ file ""/Applications/Mathematica 8.app/SystemFiles/Converters/Binaries/MacOSX-x86-64/GIF.exe""
/Applications/Mathematica 8.app/SystemFiles/Converters/Binaries/MacOSX-x86-64/GIF.exe: Mach-O 64-bit executable x86_64

the key point being this last part of the string: Mach-O 64-bit executable x86_64. There is thus no need to assume that Mathematica uses virtualization on Mac OS (and I'd be very surprised, to say the least, if it did).
"
"conditional - How to avoid returning a Null if there is no ""else"" condition in an If construct","
It depends what you consider nothing, but you could try something like this
If[a, b, Unevaluated[Sequence[]]]

for example 
3 + If[False, 1, Unevaluated[Sequence[]]]

returns 3. Wrapping an argument of a function in Unevaluated is effectively the same as temporarily setting the attribute Hold for that argument meaning that the argument isn't evaluated until after it's inserted in the definition of that function.
By the way, in your definition of QuickSort you're calling Cases[x, j_ /; j < pivot] six times. It's probably more efficient to assign Cases[x, j_ /; j < pivot] to a dummy variable and use that instead.
"
cdf format - CDF plug-in and animation controls,"
I don't think you are supposed to be able to use an input field. The Create a Computable Document HowTo says:

All interactive content must be generated with the Manipulate command
  and may only use mouse-driven elements, such as Slider, Locator,
  Checkbox, PopupMenu, etc.

Couldn't you build numerical selectors like below?
DynamicModule[{h = 0, s = 0, t = 0},
 Manipulate[
  Grid[
   {
    {Button[""+"", h++; If[h > 9, h = 0]], 
     Button[""+"", t++; If[t > 9, t = 0]], 
     Button[""+"", s++; If[s > 9, s = 0]]}, 
    {h, t, s}, 
    {Button[""-"", h--; If[h < 0, h = 9]], 
     Button[""-"", t--; If[t < 0, t = 9]], 
     Button[""-"", s--; If[s < 0, s = 9]]}
    }
   ]
  ]
 ]


"
What are the differences between the “Home Edition” and the regular Mathematica?,"
From the FAQ:

Q: How is Mathematica Home Edition different from the professional version of Mathematica?
Mathematica Home Edition includes all of the functionality found in the professional version. The difference is that Mathematica Home Edition is only authorized for use on personally owned computers for non-professional and non-academic purposes.

"
testing and verification - How can I run MUnit TestSuites outside WorkBench?,"
Have a look at this post. There is a short explanation how to do it. I use this quite often and it works very well for me.
"
programming - Repeatedly randomly redrawing part of a random sample that matches a certain criterion,"
This is wasteful but, if I understand the problem correctly, it does the trick with minimal code using ReplaceRepeated.
n = 10000;
limitValue = 0.5;
RandomReal[{0, 1}, n] //. x_ /; x < limitValue :> x + RandomReal[{0, 1}]

I was actually surprised at the speed of it.
Edit:
Per request in the comments. To keep track of the number of additions we can modify things slightly with Reap and Sow.
n = 10000;
limitValue = 0.5;
{res, count} = 
  Reap[Transpose[{RandomReal[{0, 1}, n], Range[n]}] //. {x_, i_} /; 
      x < limitValue :> (Sow[i]; {x + RandomReal[{0, 1}], i})];

Now res[[All,1]] contains the values you want and Tally[count[[1]]] contains a list of pairs {i,k} where i is the index and k is the number of additions.
"
manipulate - How to generate a real-time stream of data?,"
You could use RunScheduledTask or its relatives for this. For example, to append a random integer to catch once every two seconds you could do something like 
catch = {};
task = RunScheduledTask[AppendTo[catch, RandomInteger[10]], 2];

You could also use CreateScheduledTask which is similar to RunScheduledTask except that the task won't be started automatically after it's been created. You'll have to use StartScheduledTask to start it manually.
To start and stop the scheduled task you can use StartScheduledTask[task] and StopScheduledTask[task], respectively, and RemoveScheduledTask[task] will remove the scheduled task once you're done with it.
Additional information about these functions is available in the Documentation Center.
"
graphics - Filling a polygon with a pattern of insets,"
Finally, with version 12.1 come  the directives HatchFilling and PatternFilling which make the task much easier:
Graphics[{HatchFilling[""Diagonal""], EdgeForm[Black], 
    Polygon[{{0, 0}, {1, 0}, {1, 1}, {0.5, 1.5}, {0, 1}}]}]


img = ExampleData[{""TestImage"", ""Mandrill""}];

Graphics[{PatternFilling[img, ImageScaled[1.5]], EdgeForm[Black], 
    Polygon[{{0, 0}, {1, 0}, {1, 1}, {0.5, 1.5}, {0, 1}}] }]


Graphics[{PatternFilling[#], EdgeForm[Black], 
   Polygon[{{0, 0}, {1, 0}, {1, 1}, {0.5, 1.5}, {0, 1}}] }, ImageSize -> 100] & /@ 
  {""Checkerboard"", ""Chevron"", ""ChevronLine"", ""Circle"", ""Diamond"", ""DiamondBox"", 
   ""DiamondPlate"", ""DiamondPoint"", ""Grain"", ""Grid"", ""GridPoint"", 
   ""Halftone"", ""HalftoneGrid"", ""Herringbone"", ""Hexagon"", 
   ""Octagon"", ""Plaid"", ""Weave"", ""XGrid"", ""XGridPoint""}  // Multicolumn[#, 5] &


"
How to mark an imag? - Mathmatica Stack Exchang,"
This is a simple way:
Show[
    Plot[Sin[x], {x, 0, 2 \[Pi]}],
    Graphics[{PointSize[Large], Red, Point[{3 \[Pi]/2, -1}],
    Black, Text[""Minimum"", {3 \[Pi]/2, -.8}]}]]


Edit
If you have an image created with Colorize you can apply the same method. In the example below img is the image you obtain by taking the first example given in the Help under Colorize.
Show[
   img,
   Graphics[{PointSize[Large], Red, Point[{20, 100}],
   White, Text[""California"", {30, 90}]}]]


"
plotting - ListLogLinearPlot logarithmic axis tickmarks,"
You can create some custom ticks that work the way you want. There might be a better way than Superscript, but I couldn't work out how to get ScientificForm or NumberForm to just show the exponent rather than 1 x 10^4 etc.
myTicks = Table[{10^i, Superscript[10, i]}, {i, -20, 15}]

Notice I've changed the way the a variable enters into the Manipulate, as it will give you more chance to explore some of the lower-exponent values.
Manipulate[
 ListLogLinearPlot[{Table[{10^a s[T], T}, {T, 0, 1000}], 
   Table[{10^a t[T], T}, {T, 0, 1000}]}, GridLines -> None, 
  Ticks -> {myTicks, Automatic}, PlotStyle -> {Thickness[0.005]}, 
  Joined -> True, PlotRange -> Automatic], {a, -8, 8}]


"
numerics - Annoying display truncation of numerical results,"
Maybe this :
NumberForm[#, 10] &@ {123.189094`, 123.189263`}


{123.189094, 123.189263 }


?
Edit
Consider also this utility of NumberForm[ x, {m, k}] giving m real digits of x with  k digits to the right of the decimal point, e.g. 
NumberForm[#, {10, 7}] &@ { 197.9898987322333, 201.73205080756887 }


{ 197.9898987, 201.7320508 }


"
"cdf format - How to embed ""Share content"" button into a CDF?","
For short textual content, you can always use SystemOpen on a crafted URL. For example, the code below works in CDF and allows you to embed content in a tweet (sorry, I don't know the facebook API, so I went with this instead!):
hexEncode[s_String] := 
  StringJoin@Riffle[IntegerString[ToCharacterCode[s, ""UTF-8""], 16, 2], ""%"", {1, -2, 2}];
sendTweet[text_, expr_] := 
  SystemOpen[""http://twitter.com/home?status="" <> hexEncode@ToString@expr];
Button[""Share"", sendTweet[""Check this out! "", data]]

"
plotting - How to change the axes' origin and direction?,"
1: Reversing the image in a 2D plot (ArrayPlot or MatrixPlot)
Simply use DataReversed -> True. This has the effect of flipping the image along the horizontal axis. For example:
func[x_, y_] := Sinc[y ^2 + x^3];
data = Table[func[x,y], {x, -π, π, 0.1}, {y, -π, π, 0.1}];
ArrayPlot[data, DataReversed -> #] & /@ {True, False} // GraphicsRow


2: Changing the origin in a 1D plot (ListPlot or Plot)
Use AxesOrigin -> {x, y} to change the origin to where ever you like. For example:
Plot[Sin[x], {x, 0, 2 Pi}, AxesOrigin -> {0.5, 0.5}]


3: Changing the direction of the y-axis (or x-axis) in a 1D plot
Flipping the y-axis in a 1D plot is a bit more involved and is a very common approach in displaying depth plots. You can implement this in Mathematica by negating your input to ListPlot and assigning custom ticks with a function. Here's an example:
x = Sin /@ Range[0, 2 π, 0.1];
ListPlot[-x, Ticks -> {Automatic, Function[{xmin, xmax}, 
    Table[{i, -i, {0.02, 0}}, {i, N@FindDivisions[{xmin, xmax}, 10]}]]}]


"
evaluation - Changes in Handling of Real Zeros,"
Only precise zero coefficients are eliminated.  Use Chop:
3. in + 4. in - 7. in + 5. lb // Chop


5. lb



Leonid admonished me for posting a method overloading Times.  I didn't honestly expect anyone to use that and I think I made that pretty clear in the original post.  
Nevertheless, here is a safer method that only affects uses of specified units:
units = {in, lb};

(# /: 0. # := 0 #) & /@ units;

3. in + 4. in - 7. in + 5. lb


5. lb


"
Function Interpolation with Automatic / Algorithmic Values Mesh,"
As far as I know, there is no built-in function to do this. However, what you can do is a heavy abuse of Part to extract the points from a Plot object:
g = Plot[Sin[x], {x, 0, 2 Pi}]




The InputForm, i.e. how Mathematica sees this picture internally, looks like like this:

Graphics[{{{}, {}, {Hue[0.67, 0.6, 0.6], Line[{{1.2*^-7, 1.2*^-7}, [long list of points]} ... (options etc)


You can now extract these points by using Part, i.e. [[ ]]:
points = g[[1, 1, 3, 2, 1]]


{{0., 0.}, {0.01, 0.01}, {0.02, 0.02}, {0.03, 0.03}, {0.06, 0.06}, ...


This can now be used for a ListPlot to visualize the points extracted:
ListPlot[points]




The density of points and the recursion can be set usual when plotting, i.e. PlotPoints and MaxRecursion.
Remarks:

I've rounded the values above heavily so it doesn't blow up the answer. Usually the numbers are much more precise.
Bear in mind that this does extractions from Plot that are not supposed to be done. For this reason, you should be especially careful setting plotting parameters and things like these, as I could imagine that some of them may change the structure of the Graphics object you're extracting the data from.

"
graphics - Autorotating 3D plots,"
Note that ViewPoint is given in specially scaled coordinates which depend on amongst things the size of the bounding box. To get better control over the positioning of the camera you could use ViewVector instead, which is given in terms of the coordinates of the plot. You could for example do something like this:
rotateMeHarder1[g_, vertical_, viewpoint0_, center_List: {0, 0, 0}, 
  nframes_Integer: 15, opts : OptionsPattern[]] := Module[{grlist},
  grlist = 
   Table[Show[g, ViewVertical -> vertical, 
     ViewVector -> {RotationMatrix[2 Pi/nframes i, 
          vertical].(viewpoint0 - center) + center, center},
     SphericalRegion -> True, opts], {i, 0, nframes - 1}]]

where g is the Graphics3D object, vertical is the vertical axis, viewpoint0 is the starting position of the camera, center is the center of the graph, nframes is the number of frames, and opts are additional options of the graph. 
Usage
To create an animation of the plot p in the original question rotating around the axis anchored at {10, 0, 0} and direction {0, 1, 0}, and initial camera position {30, 30, 30} you could do something like
p = SphericalPlot3D[10 + 5*Re@ SphericalHarmonicY[3, -3, θ, ϕ], 
  θ, ϕ, Boxed -> False, Axes -> True, 
  AxesOrigin -> {0, 0, 0}, AxesStyle -> {{Thick, Red}, {Thick, Green}, {Thick, Blue}}, 
  Ticks -> None, PlotStyle -> Opacity[0.7]];

grlist = rotateMeHarder1[p, {0, 1, 0}, {30, 30, 30}, {10, 0, 0}, 20, 
  ViewAngle -> 50 Degree]

ListAnimate[grlist]

Note that I'm using ViewAngle to adjust the size of the graphics relative to the viewing area. By increasing the ViewAngle you effectively zoom out and vice versa. Another option to change the relative size of the graphics would be to change the distance of the initial camera position to the axes of rotation. 
You can use Export to create an animated .gif or other type of movie, e.g.
Export[""movie.gif"", grlist];


This solution requires some manual tuning especially in choosing the initial view vector and the view angle. You could for example use Manipulate to experiment with values for these parameters. 
"
streams - How do I re-direct FilePrint's output?,"
I can only give a partial answer. Your problem arises because FilePrint doesn't use $Output (stdout). It uses the stderr stream, so you can't capture what it writes by using Block and assigning to $Output. Unfortunately, I don't think any system variable is bound to stderr. Perhaps I'm wrong. In that case, I hope a more knowable person will be able to complete this answer.
In case anyone is interested, here is how I discovered that FilePrint was using stderr.
text = ""fee fi fo fum"";
output = With[{str = OpenWrite[]},
  Block[{$Output = str},
    Print[text]];
  Close[str]];
FilePrint[Print[Streams[]]; output]

{OutputStream[stdout,1],OutputStream[stderr,2]}

""fee fi fo fum""

"
plotting - Color linear interpolation of ParametricPlot3D,"
There are a few things wrong with your code. First of all, the ranges for the parameters are in the wrong format. They should be of the form {u, umin, umax} etc. If you want to control the step size you could use PlotPoints and MaxRecursion.
Secondly, as celtschk pointed out, the arguments in a pure function should be combined in a list. If you check the documentation of ColorFunction, you'll see that for ParametricPlot3D, the arguments provided to the ColorFunction are in this case the three spacial coordinates $x, y, z$ and the two parameters $u, v$ in that order. Therefore you could define your ColorFunction for example as
Function[{x, y, z, u, v}, Blend[{Red, Green, Blue}, {(x/5)^2, (y/2)^2, (z/2)^2}]

You would also need to set ColorFunctionScaling -> False. With these settings, the ellipsoid then becomes something like
ParametricPlot3D[{5 Cos[u] Cos[v], 2 Cos[v] Sin[u], 2 Sin[v]}, {u, 0, 
  2 Pi}, {v, -Pi/2, Pi/2}, Axes -> False, Boxed -> False, Mesh -> None,
 PlotPoints -> 40,
 ColorFunctionScaling -> False, 
 ColorFunction -> Function[{x, y, z, u, v}, Blend[{Red, Green, Blue}, 
   {(x/5)^2, (y/2)^2, (z/2)^2}]]]


"
dynamic - Way to find color at a point in a Graphics?,"
This method uses Intersection to test the colours, which should be faster than looping through the list of sample points.
I.e. with sample image, a:
a = Graphics[{Yellow, Rectangle[{0, 0}, {300, 185}], 
    Inset[Graphics[{Blue, Rectangle[{0, 0}, {20, 10}]}],
     {100, 140}, {0, 0}, {20, 10}]},
   PlotRange -> {{0, 300}, {0, 185}}, ImageSize -> 300];

samplepoints = {{101, 141}, {117, 141}, {117, 148}};
testcolours = {{255, 255, 0}, {255, 255, 255}, {0, 0, 0}};

b = Rasterize[a];
pointcolors = Part[b, 1, 1, #2, #1] & @@@ samplepoints;
valid = Intersection[testcolours, pointcolors] == {}


True

The test does not find yellow, white or black at coordinates (101, 141), (117, 141) or (117, 148) and so sets valid True.
Note
I opted not to use ImageValue as I found its results unpredictable, e.g.
newsamplepoints = {{1, 1}, {101, 141}, {117, 141}, {117, 148}, {300, 185}};

b = Rasterize[a];
pointcolors = Part[b, 1, 1, #2, #1] & @@@ newsamplepoints;
Graphics[{RGBColor @@ #, Disk[]}, ImageSize -> 20] & /@ pointcolors


pointcolors = ImageValue[a, newsamplepoints];
Graphics[{RGBColor @@ #, Disk[]}, ImageSize -> 20] & /@ pointcolors


There are only colours yellow and blue in the sample graphic.
The rasterizing method does seem to be a little slower though.  You could use either.
moresamplepoints = 
  Transpose[RandomInteger[{1, #}, 10000] & /@ {300, 185}];

Timing[(b = Rasterize[a];
  pointcolors = 
   Part[b, 1, 1, #2, #1] & @@@ moresamplepoints;)]


{0.078, Null}

Timing[pointcolors = ImageValue[a, moresamplepoints];]


{0.031, Null}

"
computational geometry - How to determine the convex hull of some text?,"
An alternative approach that does not require the ComputationalGeometry package: You can use a combination of ClusteringComponents and ComponentMeasurements as follows:
Define
  chVertices[txtimg_] := 
  Insert[#, First@#, -1] &@
  ComponentMeasurements[ClusteringComponents[Binarize@txtimg, 2], 
  ""ConvexVertices""][[2, 2]]

Example data:
  textimg1 = Image[Graphics[
  Text[Style[""'., ab cgixyz,..."", Green, FontFamily -> ""Times"", FontSize -> 72]]], 
  ImageSize -> {600, 100}];
  textimg2 = Image[Graphics[{EdgeForm[], Brown, 
  ImportString[ExportString[
  Style["".t e q s t,"", Italic, FontFamily -> ""Times"", FontSize -> 36], 
  ""PDF""], ""PDF"", ""TextMode"" -> ""Outlines""][[1, 1]]}], ImageSize -> {600, 100}];
  textimg3 = Image[Graphics[
  Text[Style[""Get Convex Hull points."", Orange, 56]]], 
  ImageSize -> {600, 100}];

Input pictures:

Results:  
 Row[Show[#, Graphics@{Red, Thick, Line[chVertices[#]]}] & 
 /@ {textimg1, textimg2, textimg3}]


"
recursively solve equation and saving the values,"
You get
  {0.0351204, 0.06995, 0.104221, 0.137709, 0.170237, 0.201687, 0.231988, 0.26111, 0.289058, 0.315857, 0.34155, 0.366188, 0.389828, 0.412529, 0.434347}

using any of the methods below:
   Last /@ sols

or
   sols[[All,2]]

or
  sols /. (a_ == b_) -> b

All give a list of solutions with T== removed.
Update: an alternative approach to get a list of solutions for T is to Map Reduce[...] on the list t:
  solutionlist = Map[Reduce[f == #, T, Reals][[2]] &, t] 

"
"list manipulation - Handling vector comparisons in ""Piecewise"" function","
I'm not in front of a computer now, but I think you should be able to set your function to Listable and use it as-is:
SetAttributes[myfunc, Listable]

"
calculus and analysis - Notation of partial derivative,"
For a start, f[x,y]^(0,1) isn't the same as f^(0,1)[x,y].
But the real reason is that these expressions are very different in meaning, as revealed by their FullForm:
D[f[x, y], y] // FullForm


Derivative[0,1][f][x,y]


versus (and I had to use a simple symbolic expression as the exponent to show what was going on:
f[x,y]^z//FullForm


Power[f[x,y],z]


Similarly, Derivative doesn't correspond to Superscript. They are syntactically different despite the visual similarities.
Stick with D[f[x,y],y] and so on. If you need the vector derivative, you can use the syntax:
 D[f,{{x1,x2,x3...}}]

as described in the documentation.
"
Can this code be written in a more functional style,"
Two more ways:
   parti1[a_, p_] := SortBy[a, {Sign[# - p] &, # == # &}]

or
   parti2[a_, p_] := Join[Select[a, # < p &], {p}, Select[a, # >= p &]]

With
  a = {3, 5, 6, 7, 2, 1, 2}; (* and *) p =3

both give
  {2, 1, 2, 3, 5, 6, 7}

Update: While the two methods above and Heike's two methods give exactly the same results, unfortunately, it turns out that Parti is a tougher nut than it seemed at first glance and none of these functions replicate Parti except for very special inputs. Here is why:
These functions, in effect, partition a list into lower and upper contour sets of the element p preserving the original ordering of the elements in each subset. With Parti, on the other hand, the orginial ordering is preserved only for the lower contour set, and the ordering of the elements in the upper contour set is not preserved. That is, when an element in the lower contour set moves it moves to the right of his previous left sibling and stays there, while an element on the upper contour set can move many times during the operation of Parti depending on the pattern of elements on its right. 
For example, for the input list {3, 2, 5, 6, 2, 1} all four functions agree with Parti, i.e.,
 Parti[{3, 2, 5, 6, 2, 1}, 3]==parti1[[{3, 2, 5, 6, 2, 1}, 3]=={2, 2, 1, 3, 5, 6}

Yet, with a slight change in the list to {3, 2, 5, 2, 6, 1}, we get
  Parti[{3, 2, 5, 2, 6, 1}, 3] (* => {2, 2, 1, 3, 6, 5} *)

while parti1 and its siblings give
  parti1[{3, 2, 5, 2, 6, 1}, 3] (* => {2, 2, 1, 3, 5, 6} *)

Another example: for the input list {3, 2, 5, 6, 7, 8, 9, 2, 1}
   Parti[{3, 2, 5, 6, 7, 8, 9, 2, 1},5]   (* =>  {3, 2, 2, 1, 5, 8, 9, 6, 7}, but *)
   parti1[{3, 2, 5, 6, 7, 8, 9, 2, 1},5]  (* =>  {3, 2, 2, 1, 5, 6, 7, 8, 9}      *)

Thus, the elements of the upper contour set always move to the right but their final positions relative to each other cannot be determined in a simple manner without using finer pattern information.
So ... it seems that the parties are interesting, at best, as a first step towards an answer to OP's question, and, quite possibly, as just answers seeking an interesting question.
A new attempt: Try ReplaceRepeated and pattern matching:
  partiReplace[a_List, p_] := 
  With[{leftlist = Alternatives[Sequence @@ Select[a, # < p &]], 
  rightlist =  Alternatives[ Sequence @@ Select[a, # >= p &]]}, 
  (Drop[a, Flatten[Position[a, p]]] 
  //. {Shortest[beg___], i : rightlist, 
  Shortest[rgtn : rightlist ...], 
  j : leftlist, k : leftlist ..., end___} 
  -> {beg, j, rgtn, i, k, end}) 
  // Insert[#, p, 1 + Length@(leftlist)] &]

Tests: For the examples considered above, partiReplace gives the same result as Parti. 
For a limited set of test data
  testdata = RandomReal[{0, 10}, {100, 21}];

we get
   Parti[Most@#, Last@#] == partiReplace[Most@#, Last@#] & @@ testdata 
   (* => True  *)

"
calculus and analysis - How to evaluate the $0/0$ type limit in Mathematica?,"
Edit 
The answer is ""ambiguous"" because you have two parameters, $\alpha$ and $k$, and in this case the limit depends on the value of $\alpha$. What you can try is the following: 
f[k_, α_] := ((k + 2) (α^2 - Sqrt[α^4 + k]) + k)/(α^2 - Sqrt[α^4 + k] + 2 k)
Simplify[Limit[f[k, α^(1/4)], k -> 0] /. α -> α^4, α ∈ Reals]


$\frac{2 \left(\alpha ^2-1\right)}{4 \alpha ^2-1}$

What I did is to remove all powers of $\alpha$ from under the square roots, so that the $k\to 0$ limit makes them look like $\sqrt{k+\alpha}\to \sqrt{\alpha}$ which manifestly cancels with the already present $\sqrt{\alpha}$ terms. At the end, I replace $\alpha$ by $\alpha^4$ to return to the original definition.
What follows below are the steps that led me to finally settle on the above approach. The upshot is that we have to avoid handing Mathematica expressions such as $\sqrt{\alpha^4}-\alpha^2 = 0$ because it doesn't simplify them at an early enough stage in the evaluation, even when the domain is real.
Initial answer
First assume simply that $\alpha$ is real:
Assuming[α ∈ Reals, Limit[f[k, α], k -> 0]]


2

Now say explicitly that $\alpha>0$:
Assuming[α > 0, Limit[f[k, α], k -> 0]]


$\frac{2 \left(\alpha ^2-1\right)}{4 \alpha ^2-1}$

The behavior can be illustrated with a contour plot of f[k, α] around {0,0}:
ContourPlot[f[k, α], {k, 0, .1}, {α, -.3, .3}, FrameLabel -> {""k"", ""α""},
    PlotRange -> {1, 5}, ContourLabels -> True]


In the plane of $k, \alpha$, Mathematica acts as if it preferred to choose the ""easiest"" approach to the $k=0$ axis by taking $\alpha = 0$ in the first case. But what it should have done is to return the more general result, or a ConditionalExpression (not necessary in this particular case because the general result goes smoothly to 2 for $\alpha\to0$). 
The first result is a bug, I would say: Since $\alpha$ is a constant while the limit is taken, setting it to zero when it's allowed to be any real number is just too restrictive. This preliminary conclusion that it's a bug is strengthened  below where I try to understand why it may be happening, and whether the function f[k, α] can be made to look less pathological before doing the limit.
Work-around
From the comments in the other answers, it is clear that Mathematica doesn't use the assumption of real variables at a sufficiently early stage in the calculation. You can even see that without taking any limit:
f[0, α]


2

The reason for this result is that it can't see the simplification $\sqrt{\alpha^4}-\alpha^2 = 0$ which is always true for real $\alpha$. It knows this fact, but isn't using it. To check this, we can do
Refine[0 == (Sqrt[α^4] - α^2), α ∈ Reals]


True

If this guess about the bug is right, then it's basically a problem of the order of two non-commuting limits. In addition to doing $k\to0$, the assumption of real $\alpha$ amounts to taking the limit $\Im(\alpha)\to 0$ (zero imaginary part). If you do the latter limit last, it gives $2$, but we are interested in the opposite order of limits.
To avoid this problem, one can eliminate the variable $k$ in terms of a new variable that gets rid of the square root:
First transform to variables $x=\sqrt{k}$ and $y=\alpha^2$ to end up with at most squares:
Clear[g];
g[x, y] = Simplify[f[x^2, Sqrt[y]]]


$\frac{\left(x^2+2\right)\left(y-\sqrt{x^2+y^2}\right)+x^2}{-\sqrt{x^2+y^2}+2x^2+y}$

Next, define a third new variable $z\equiv y-\sqrt{x^2+y^2}$  that incorporates the unwanted square root, 
newg = g/.First@Solve[Eliminate[{g == g[x, y], z == -Sqrt[x^2 + y^2] + y}, x],g]


$\frac{2 y z+2 y-z^2-z-2}{4 y-2 z-1}$

Finally, observe that the limit $k\to0$ is the same as the limit $z\to0$ provided that we make the assumption $\lim_{x\to 0}(y-\sqrt{x^2+y^2})=0$ (which is true because $y\ge0$). Therefore, we can take the desired limit by setting
newg /. z -> 0


$\frac{2 y-2}{4 y-1}$

This is the correct limit if we reinstate $y=\alpha^2$. Note that I didn't have to use Limit at all because the function is well-behaved in this simplified form.
"
editing - Is it possible to colorize brackets in the notebook editor to see matches more easily?,"

If there's no way to colorize bracket nesting, is there a keyboard
  shortcut for ""Check Balance"" like shift-% in VIM for C-code?

Yes, right from the help file:

Check Balance     Shift+Ctrl+B

"
evaluation - Module variable scoping in Scheduled Tasks?,"
You hit a rather subtle behavior, related to the garbage-collection and the Temporary attribute, and the semantics of Module regarding returning expressions. The thing is, to achieve your goal, you need the Module-generated variable (function)'s definition(s) to be exported outside Module (to be persistent). But, since you return not the symbol itself, but its r.h.s. (which is a chunk of code with delayed evaluation, either Function or ScheduledTaskObject in this case), the definitions of runNextTask are destroyed because it has a Temporary attribute, despite the fact that code containing this variable has been exported outside Module. 
To illustrate my point, here are two work-arounds which both will lead to your desired effect:

Instead of assigning runNextTask to Unique[], insert a line ClearAll[runNextTask] right after the Module declarations. This will remove the Temporary attribute and the definition of runNextTask will persist.
Wrap your final call in Hold (so, return Hold[runNextTask[]]), and then use ReleaseHold outside Module.

This is your code for this option:
res = 
 Module[{state = 0, runNextTask},
   runNextTask[] :=
     StartScheduledTask@
       CreateScheduledTask[
         state = state + 1;
         If[state < 4,
           (Print[state]; runNextTask[])
         ],
         {0.10}];
   Hold@runNextTask[]]

ReleaseHold[res]

In this case, the definition also persists. 
Note that this problem is not seen in examples where all evaluation happens at the time when Module is left: the following code will execute promptly
Module[{f, n = 0},
  f[] := (n++; If[n < 10, Print[""*""]; f[]]);
  f[]]

even though all definitions for f are destroyed at the end - because the execution here is immediate (the same evaluation process, so that f still has all definitions during this evaluation), while delayed and asynchronous code induces a separate evauation process.
"
calculus and analysis - Derivative of real functions including Re and Im,"
The functions Re and Im (just as Conjugate) don't satisfy the Cauchy-Riemann differential equations and are therefore not analytic. That means their derivative is not uniquely defined in the complex plane. That's the reason why Re' and Im' can't be simplified. 
Therefore, we have to be more specific about how we want the limit to be done that corresponds to the desired derivative. The cleanest way of doing that is this simple replacement for the derivative:
Limit[(Gamma[I (x + ε)] - Gamma[I x])/ε, ε -> 0]


$i \Gamma (i x) \psi ^{(0)}(i x)$

Now I'll try to apply this to the real part instead:
Assuming[Element[x, Reals], Limit[(Re[Gamma[I (x + ε)]] - Re[Gamma[I x]])/ε, ε -> 0]]


$-\Im(\psi ^{(0)}(i x)) \Re(\Gamma (i x))-\Im(\Gamma (i x))
   \Re(\psi ^{(0)}(i x))$

So we don't get any of the pesky Re' here. For those who don't like the $\LaTeX$ format, here is the real output:
-Im[PolyGamma[0, I x]] Re[Gamma[I x]] - Im[Gamma[I x]] Re[PolyGamma[0, I x]]

Edit: generalization
Motivated by the discussion of Heike's answer, I wrote a definition of a directional derivative in an arbitrary direction in the complex plane. I did this to show that such a definition can be made without in any way modifying SystemOptions (see in particular ""More Information"").
dirDeriv[f_, var_, angle_: 0] := Module[{g, x},
  g = f /. var -> x;
  Assuming[x ∈ Reals,
   D[g, x] /. (h_'[p_] :> h'[p]/D[p, x]) /. (h_'[p_] :> 
       Limit[(h[p /. x -> x + ε Exp[I angle]] - 
            h[p])/ε/Exp[I angle], ε -> 0]) /. 
    x -> var
   ]
  ]

The first argument is the function to be differentiated, the second argument is the name of the independent variable, which will be treated as a real number. The third (optional) argument is the phase angle of the line in the complex plane along which the limit for the derivative is taken. By default this angle is zero corresponding to the real axis (the result depends on the angle only if the first argument is non-analytic).
Here is how to apply this function as a replacement for the standard derivative:
dirDeriv[Re[Gamma[I x]], x]


$-\Im(\psi ^{(0)}(i x)) \Re(\Gamma (i x))-\Im(\Gamma (i x))
   \Re(\psi ^{(0)}(i x))$

A simpler example is
dirDeriv[Re[Exp[I x^2]], x]


$-2 x \sin \left(x^2\right)$

The function works by doing the standard derivative and then looking for any occurrences of Re', Im' and others (in fact, anything looking like h_'[p_]). These patterns are then replaced by first undoing the chain rule that Mathematica automatically applies (that's the division by D[p, x]), and then calculating the directional derivative  as a limit analogous to the example above.
With this function one can easily explore the direction dependence of the derivative for non-analytic functions. For example,
Table[dirDeriv[Re[x], x, angle], {angle, 0, Pi, Pi/4}]


{1, 1/2 - I/2, 0, 1/2 + I/2, 1}

Edit 2: numerical functions
The above discussion concerns symbolic directional derivatives of possibly non-analytic functions. The situation is in some ways much simpler if the goal is to do  numerical differentiation, i.e., calculate the derivative of a function f[x] which is numeric when the argument x is numeric. 
For that case, one can go straight to the numerical approach by doing this:
Needs[""NumericalCalculus`""];
ND[Re[Gamma[I x]], x, 1]

With the numerical derivative ND, you can for example make plots directly. Here is a comparison of the symbolic result with the numerical one:
Plot[{
  -Im[PolyGamma[0, I x0]] Re[Gamma[I x0]] - 
   Im[Gamma[I x0]] Re[PolyGamma[0, I x0]], 
   ND[Re[Gamma[I x]], x, x0]},
  {x0, 0, 5}, PlotStyle -> {Thin, Dotted}]


"
pattern matching - Split a Unicode string maintaining uppercase characters,"
You can do the lower case conversion as a condition on the pattern, and thereby retain the original:
StringCases[""TtattÁatT"", c__ /; MemberQ[List@@alt, ToLowerCase[c]]]


{""Tt"", ""a"", ""tt"", ""Á"", ""a"", ""tT""}

"
evaluation - Difficulty catching thrown errors in asynchronous tasks,"
Why this does not work
The problem here seems to be that Catch can only catch exceptions thrown by some code down the same evaluation stack, corresponding to the same evaluation process. However, the asynchronous mechanism you use (based on CreateScheduledTask etc) induced a different evaluation at a specified time, with another evaluation stack, and at a later time. So, at any given iteration, your Catch is watching for the stack number n, while your exception, if thrown, will be in a stack number n+1 - in other words, your Catch is always one evaluation too early.
In order to catch your exceptions, you'd have to place Catch inside CreateScheduledTask (so that it watches the correct evaluation stack), which would largely destroy the purpose. Therefore, I'd suggest to communicate the state and status of your system (error or not) via flags, which are set inside your code in CreateScheduledTask, and checked in your function, rather than using exceptions. You can, of course, still use exceptions to short-circuit the failure inside the code in CreateScheduledTask, but not as a communication mechanism between that code and the function which creates it (but see also below).
Time travel and lazy evaluation, or how to make it work
However, using exceptions in the fashion you want is not impossible, thanks to the lazy evaluation, available in Mathematica. If you insist on minimal modification for your code, then here is how: make your function runNextTask accept some arbitrary code as a parameter, and hold it, evaluating only inside body. Then:
Module[{state = 0, runNextTask, catchResult,
    defaultCatchResult =  Unique[]},
    (*the following device removes the ""Temporary"" 
      attributes from ""runNextTask"" and ""catchResult.""*)
    ClearAll[runNextTask, catchResult];
    SetAttributes[runNextTask, HoldAll];
    runNextTask =
     Function[
        code,
        catchResult =
          Catch[
             code;
             If[state < 4,
              (*the following invocation techniques make 
                the body here asynchronous.*)
                 StartScheduledTask@
                   CreateScheduledTask[
                     state = state + 1;
                     runNextTask[If[state < 2, Print[state], Throw[state]]],
                     (*This is the amount of time with which to separate 
                      asynchronous invocations.*)
                     {0.10}
                   ]
             ]; (* If *)
             defaultCatchResult
          ]; (* Catch *)
          If[catchResult =!= defaultCatchResult, Print[""ERROR""]],
          HoldAll
     ]; (* Function *)
     runNextTask[Null]]

Note that the function is now HoldAll, as well as the runNextTask (the latter isn't really necessary though). By using this construct, I basically pass the code from the ""future"" to the ""past"" (from the stack-matching perspective. Of course, it is really the other way around), making it evaluate in a different evaluation stack, now the same as that where Catch is - and now it works.
"
parallelization - Setting $RecursionLimit across all parallel kernels,"
As sebhofer pointed out, my previous solution didn't work — a fact that I missed because I wrote it without an mma to test. The users who voted for it also must've missed it, because on the surface it looks like a straightshot answer, but no. So, here's Jackson's solution that works — Use ParallelEvaluate as:
ParallelEvaluate[$RecursionLimit = 10^6]


Here's my previous solution that doesn't work, but I'm leaving it here so that others will not try something similar.
Block[{$RecursionLimit = Infinity},
    SetSharedVariable[$RecursionLimit]
    (* your parallel code *)
]

Using Block allows you to temporarily modify $RecursionLimit so that the global value is unaffected andSetSharedVariable declares that the variable's value is synchronized across all kernels.
"
faq - Can I simplify an expression into form which uses my own definitions?,"
Daniel Lichtblau and Andrzej Koslowski posted a solution in mathgroup, which I adjusted marginally. (I like to use german identifiers, because they will never clash with Mma builtins). That's the code:    
SetAttributes[termErsetzung,Listable];
termErsetzung[expr_, rep_, vars_] := 
Module[{num = Numerator[expr], den = Denominator[expr],
        hed = Head[expr], base, expon},
  If[PolynomialQ[num, vars] && PolynomialQ[den, vars] && ! NumberQ[den], 
    termErsetzung[num, rep, vars]/termErsetzung[den, rep, vars], (*else*)
    If[hed === Power && Length[expr] === 2,        
       base  = termErsetzung[expr[[1]], rep, vars];
       expon = termErsetzung[expr[[2]], rep, vars];
       PolynomialReduce[base^expon, rep, vars][[2]],        (*else*)
      If[Head[Evaluate[hed]] === Symbol && 
        MemberQ[Attributes[Evaluate[hed]], NumericFunction], 
        Map[termErsetzung[#, rep, vars] &, expr],    (*else*)
       PolynomialReduce[expr, rep, vars][[2]] ]]]
];

TermErsetzung[rep_Equal,vars_][expr_]:=
  termErsetzung[expr,Evaluate[Subtract@@rep],vars]//Union;

Usage is like this:
a*b/(a + a*Cos[a/b]) // TermErsetzung[k b == a, b]


a/(k (1 + Cos[k]))

The first parameter is the ""replacement equation"", the second the variable (or list of variables) to be eliminated:
a*b/(a + a*Cos[a/b]) // TermErsetzung[k b == a, {a, b}] 


{b/(1 + Cos[k]), a/(k (1 + Cos[k]))}

"
graphics - How can I extract data points from a black and white image?,"
UPDATE: Added a few workarounds for bugs / features introduced in Mathematica v10 or later.

Main issue involved LocatorPane whose Appearance option no longer correctly handles more than one Graphics object [CASE:4984027]. This bug was introduced somewhere after v11.3 and is present in v.13.1.  Additional issues concerned the scaling of the graphics used in the various panels, which was incorrect. Perhaps a different default was introduced somewhere after v9 where the code worked as intended.


Original text
Here the contours of a method to do this half-automatic selection you are looking for. It is heavily based on an example on the ImageCorrelate doc page of Waldo fame. First, you interactively select an example of the plot marker you want to look for:
img = Import[""http://i.stack.imgur.com/hhPr9.png""];

pt = {ImageDimensions[img]/4, ImageDimensions[img]/2};
LocatorPane[
 Dynamic[pt],
 Dynamic[
  Show[
   img,
   Graphics[
    {
     EdgeForm[Black], FaceForm[], Rectangle @@ pt
     }
    ]
   ]
  ], Appearance -> Graphics[{Red, AbsolutePointSize[5], Point[{0, 0}]}]
 ]


Then you use Mathematica v8's image processing tools to find similar structures:
res =
  ComponentMeasurements[
   MorphologicalComponents[
    ColorNegate[
     Binarize[
      ImageCorrelate[
       img,
       ImageTrim[img, pt],
       NormalizedSquaredEuclideanDistance
       ], 0.18
      ]
     ]
    ], {""Centroid"", ""Area""}, #2 > 1 & (*use only the larger hits*)
   ];

The coordinates are now in res. I'll show them below. Many are correct, sometimes you get some spurious hits and misses. It depends on the Binarize threshold value and the ""Area"" size chosen in ComponentMeasurements third argument.
Show[img, Graphics[{Green, Circle[#, 5] & /@ res[[All, 2, 1]]}]]



EDIT: Here a more complete application. It is not robust as it is (no error handling at all), but nevertheless already quite useful.
The function getMarkers is called with an image as argument and the name of a variable in which the final markers are returned:

You get the app with tabs that represent processing stages:

In the first tab you define the axes by dragging the colored dots to the locations on the x and y axis with the highest known value and to the origin of the plot. Here, you also enter the values for the bottom left and top right corners of the rectangle that they define:

In the next tab you then indicate the marker you want to have detected:

The detection results are presented in the next tab and you can drag a slider to increase or decrease the number of results:



You can manually adjust the detected markers in the next tab. Markers can be dragged, removed (alt-click an existing marker) and added (alt-click on an empty spot). Actually, this is so easy to do that I would be tempted to say that I could do without the marker-detection  phase.
The end result can be seen in the Results tab. If something is wrong you can go back to an earlier tab:
.
The data plotted in the Results tab is also copied in the variable passed to the function, test in this example.
test

(*
==> {{400.5159959, 0.007353847123}, {450.3095975, 
  0.005511544915}, {499.8452012, 0.004129136525}, {550.9287926, 
  0.002664992936}, {600.4643963, 0.001702431875}, {653.869969, 
  0.000764540446}, {685.6037152, 0.0002398789942}, {764.7123323, 
  0.0002481309886}, {801.7027864, 0.0001989932135}}
*)

The code:
findMarkers[img_, pt_, thres_, minArea_] :=
  ComponentMeasurements[
    MorphologicalComponents[
     ColorNegate[
      Binarize[
       ImageCorrelate[img, ImageTrim[img, pt],
        NormalizedSquaredEuclideanDistance
        ], thres]
      ]
     ],
    {""Centroid"", ""Area""},
    #2 > minArea &
    ][[All, 2, 1]];

SetAttributes[getMarkers, HoldRest];
getMarkers[img_, resMarkers_] :=
 DynamicModule[
  {
   pt = {ImageDimensions[img]/4, ImageDimensions[img]/2},
   axisDefinePane, defineMarkerPane, findMarkerPane, editMarkersPane, 
   finalResultPane, xAxisBegin, xAxisEnd, yAxisBegin, yAxisEnd, 
   myMarkers, myTransform, 
   xoy = {{1/2, 1/8} ImageDimensions[img], {1/8, 1/8} ImageDimensions[
       img], {1/8, 1/2} ImageDimensions[img]}},
  axisDefinePane =
   Grid[
    {
     {
      LocatorPane[
       Dynamic[xoy],
       Dynamic[
        Show[
         img,
         Graphics[{Line[xoy]}],
         ImageSize -> ImageDimensions[img]
         ]
        ],
       Appearance ->
        {
         Graphics[{AbsolutePointSize[5], Red, Point[{0, 0}]}],
         Graphics[{AbsolutePointSize[5], Green, Point[{0, 0}]}],
         Graphics[{AbsolutePointSize[5], Blue, Point[{0, 0}]}]
         }
       ]
      },
     {Row[{""x(1): "", 
        InputField[Dynamic[xAxisBegin], Number, FieldSize -> Tiny], 
        "" x(2): "", 
        InputField[Dynamic[xAxisEnd], Number, 
         FieldSize -> Tiny]}]}, {Row[{""y(1): "", 
        InputField[Dynamic[yAxisBegin], Number, FieldSize -> Tiny], 
        "" y(2): "", 
        InputField[Dynamic[yAxisEnd], Number, 
         FieldSize -> Tiny]}]}}];
  
  defineMarkerPane =
   LocatorPane[
    Dynamic[pt],
    Dynamic[
     Show[
      img,
      Graphics[{EdgeForm[Black], FaceForm[], Rectangle @@ pt}],
      ImageSize -> ImageDimensions[img]
      ]
     ],
    Appearance -> Style[""\[FilledSmallCircle]"", Red]
    ];
  
  findMarkerPane =
   Manipulate[
    Show[
     img,
     Graphics[{Red, 
       Circle[#, 5] & /@ (myMarkers = findMarkers[img, pt, t, 1.05])}],
     ImageSize -> ImageDimensions[img]
     ],
    {{t, 0.2, ""Threshold""}, 0, 1},
    TrackedSymbols -> {t},
    ControlPlacement -> Bottom
    ];
  
  editMarkersPane =
   LocatorPane[
    Dynamic[myMarkers],
    img,
    Appearance -> 
     Graphics[{Red, Circle[{0, 0}, 1]}, ImageSize -> 10],
    LocatorAutoCreate -> True
    ];
  
  finalResultPane =
   Dynamic[
    myTransform = 
     FindGeometricTransform[{{xAxisEnd, yAxisBegin}, {xAxisBegin, 
          yAxisBegin}, {xAxisBegin, yAxisEnd}}, xoy][[2]] // Quiet;
    ListLinePlot[resMarkers = myTransform /@ Sort[myMarkers], 
     Frame -> True, Mesh -> All, ImageSize -> ImageDimensions[img]],
    TrackedSymbols -> {myMarkers, xoy, xAxisEnd, yAxisBegin, 
      xAxisBegin, yAxisBegin, xAxisBegin, yAxisEnd}
    ];
  
  TabView[
   {
    ""Define axes"" -> axisDefinePane,
    ""Define marker"" -> defineMarkerPane,
    ""Find Markers"" -> findMarkerPane,
    ""Edit Markers"" -> editMarkersPane,
    ""Results"" -> finalResultPane
    }
   ]
  ]

"
import - Importing a large Excel file,"
From a very pragmatic point of view, it might be easier to use an external tool such as xlsx2csv (Python script, but other alternatives exist). Then simply import the comma-separated values:
ImportString[StringJoin
  @Riffle[ReadList[OpenRead[""!./xlsx2csv.py test.xlsx""], ""String""], ""\n""], ""CSV""];

On a 21 MB XLSX file on my Mac Book Pro, the above takes 115 seconds. xlsx2csv accounts for 95 of those, and 20 seconds for the Mathematica import. It can be made even faster with a temporary file (and then directly importing instead of using string operations), reducing the timing of the Mathematica part down to 10 seconds.
"
front end - Finding a Specific Line in a Package,"
There is a certain impedance mismatch between lines of code and Mathematica expressions, because Mathematica code is written more or less directly in the parse trees, and the syntax (which encourages nested expressions) was not particularly designed to make lines a  really good concept here. That said, this would be a problem in any language, to various extents, because, while you know what you meant in the code and what the error is, the parser may interpret things differently (this is the difference between syntax and semantics). For example, your particular error which you mentioned in the question will be interpreted as a bracket not closed at the end of file, not where you think it really happens (because the parser thinks that the rest of the code is within an opening bracket of Protect). 
In any case, the following function will (hopefully) at least tell you what parser thinks, in terms of line numbers:
ClearAll[getErrorLine];
getErrorLine[filename_String] :=
 Module[{code, lengths},
    code = Import[filename, ""Text""];
    lengths = StringLength /@ StringSplit[code, ""\n""] + 1;
    With[{sl = SyntaxLength[code]},
      LengthWhile[Accumulate[lengths], # < sl &]
    ]
 ]

For a test package like this (all new lines intact):
BeginPackage[""SyntaxTest`""]

f::usage;

Begin[""`Private`""]

g[x_]:= x^2;

f[x_]:=Sin[g[x]

End[]

EndPackage[]

it gives
getErrorLine[""C:\\Temp\\SyntaxTest.m""]


13

which is, at the end of the package. And this is correct, since you can not assign a well-defined semantics to a syntactically broken code, so you can only ask what parser thinks.
"
Getting Integrate to perform numerical integration,"
Use NIntegrate to perform numerical integration (simply replace Integrate with NIntegrate in the definition of R21). On my laptop, it spits out the numerical value of the result in 0.3 s (and the result is 9.46643, by the way).
"
syntax - Integrating with multiple indicator functions,"
A better construct for your indicator function would be using Piecewise. So you'd define an indicator function $I_{(a,b]}$ as:
indicator[a_, b_][x_] := Piecewise[{{1, a < x <= b}, {0, True}}]

However, there are other issues in your code that could be improved. 

First, avoid using capital letters for your variables/functions. This is because Mathematica uses that notation for its own functions and invariably, you'll (at some point) be bitten by it.
Define your functions by appropriately scoping the variable. For example you defined Js = 6 s (1 - s). However, if s had a pre-existing value (you never know... sometimes it could be in a different notebook but shared context), then you're assigning to Js the result based on that value of s.
Use Set (=) instead of SetDelayed (:=) when you use D. Otherwise, you'll end up calculating the derivative at each integration point. See this answer for an example of why this matters.

My suggested rewrite of the definitions part of your problem would be something like this:
j[s_] := 6 s (1 - s);      (*weight function*)
j1[s_] = D[j[s], s] ;      (*first derivative of Js*)
j2[s_] = D[j[s], {s, 2}];  (*second derivative of Js*)
f[s_] := 1/(1 + Exp[-(s)]) (*Fs*)
finv[s_] := -Log[-1 + 1/s] (*F inverse*)
finv1[s_] = D[finv[s], s]; (*derivative of F inverse*)

You can try working with this and the indicator function above to see if it makes any difference or if you're getting the answer you expect.
"
numerics - Numerical underflow for a scaled error function,"
If you have an analytic formula for f[x_] := Erfc[x]*Exp[x^2] not using Erfc[x] you could do what you expect.  However it is somewhat problematic to do in this form because Erfc[x] <  $MinNumber for x == 27300.
$MinNumber


1.887662394852454*10^-323228468


N[Erfc[27280.], 20]


5.680044213569341*10^-323201264


Edit
A very good approximation of your function f[x] for values x > 27280 you can get making use of these bounds ( see e.g. Erfc on Mathworld) :

which hold for x > 0.
Here we find values of the lower and upper bounds with  relative errors for various x:
T = Table[ 
          N[#, 15]& @ {2 /(Sqrt[Pi] (x + Sqrt[2 + x^2])), 
                       2 /(Sqrt[Pi] ( x + Sqrt[x^2 + 4/Pi])), 
                       1 - ( x + Sqrt[x^2 + 4/Pi])/(x + Sqrt[2 + x^2]),
          {x, 30000 Table[10^k, {k, 0, 5}]}];

Grid[ Array[ InputField[ Dynamic[T[[#1, #2]]], FieldSize -> 13] &, {6, 3}]]


Therefore we propose this definition of the function f (namely the arithetic mean of its bounds for x > 27280 )  :
f[x_]/; x >= 0 := Piecewise[ { { Erfc[x]*Exp[x^2],                      x < 27280 },

                               { 1 /( Sqrt[Pi] ( x + Sqrt[2 + x^2])) 
                               + 1 /( Sqrt[Pi] ( x + Sqrt[x^2 + 4/Pi])), x >= 27280}}
                           ]
f[x_] /; x < 0 := 2 - f[-x]

I.e. we use the original definition of the function f for 0 < x < 27280, the approximation for x > 27280 and for x < 0 we use the known symmetry of the Erfc function, which is relevant when we'd like to calculate f[x] for  x < - 27280. 
Now we can safely use this new definition for a much larger domain :
{f[300], f[300.], f[30000.], f[-30000.]}


{E^90000 Erfc[300], 0.0018806214974, 0.0000188063, 1.99998}


and now we can make plots of f around of the gluing point ( x = 27280.)
GraphicsRow[{ Plot[ f[x], {x, 2000, 55000}, 
                      Epilog -> {PointSize[0.02], Red, Point[{27280., f[27280.]}]}, 
                      PlotStyle -> Thick, AxesOrigin -> {0, 0}], 
              Plot[ f[x], {x, 27270, 27290}, 
                      Epilog -> {PointSize[0.02], Red, Point[{27280., f[27280.]}]}, 
                      PlotStyle -> Thick]}]


"
How to apply or map a list of functions to a list of data?,"
Here's how you can do it in a simple way:
functionMap[funcs_List, data_] := Module[{fn = RotateRight[funcs]}, 
    First[(fn = RotateLeft[fn])][#] & /@ data]

Use it as:
functionMap[{f1, f2, f3}, Range[20]]
(* {f1[1], f2[2], f3[3], f1[4], f2[5], f3[6], f1[7], f2[8], f3[9], f1[10],
    f2[11], f3[12], f1[13], f2[14], f3[15], f1[16], f2[17], f3[18], f1[19], f2[20]} *)

"
Delayed evaluation of assignment,"
I think this does what you want, it is like a Block that accepts the local variables given as rules. Using Block instead of With should solve the problem that some of your parameters are ""hidden in complicated functions"":
ClearAll@blockrules

SetAttributes[blockrules, HoldAll]

blockrules[rules_, expr_] := Block @@ Join[
   Hold @@ {rules} /. Rule -> Set,
   Hold[expr]
   ]

use it like e.g.:
blockrules[ass1, NDSolve[diffEq, {x}, {t, 0, 1}]]

While I think this should solve the problem you were describing, you probably should think about rearranging your code so that it does not use global symbols hidden deeply in complicated functions as parameters but rather make those parameters explicit arguments to those functions. You are asking for all kind of hard to detect errors with those ""hidden"" parameters...
"
front end - How to visualize/edit a big matrix as a table?,"
Based on the approach of F'x this is a version aimed rather at large arrays. It should perform reasonably well independent of the array size and lets one edit the given variable directly. Performance suffers only from the maximal number of rows and columns to be shown, which can be controlled with the second argument. I did choose to use the ""usual"" syntax for controllers with a Dynamic wrapper, which basically just serves as a Hold in the function definition pattern. With the Interpretation-wrapper it will evaluate to just the array it shows. There are a lot of possible improvements, so everyone is welcome to make such improvements. Here is the code:
editMatrix[Dynamic[m_], maxfields_: {10, 10}] := 
  With[{maxrows = Min[maxfields[[1]], Length[m]], 
    maxcols = 
     If[(Depth[m] - 1) == 2, Min[maxfields[[2]], Length[m[[1]]]], 1]},
    Interpretation[
    Panel[DynamicModule[{rowoffset = 0, coloffset = 0}, 
      Grid[{{If[Length@m > maxrows, 
          VerticalSlider[
           Dynamic[rowoffset], {Length[m] - maxrows, 0, 1}]], 
         Grid[Table[
           With[{x = i, y = j}, 
            Switch[{i, j}, {0, 0}, Spacer[0], {0, _}, 
             Dynamic[y + coloffset], {_, 0}, 
             Dynamic[x + rowoffset], _, 
             If[(Depth[m] - 1) == 2, 
              InputField[Dynamic[m[[x + rowoffset, y + coloffset]
   ]
             ], 
               FieldSize -> 5], 
              InputField[Dynamic[m[[x + rowoffset]]], FieldSize -> 5]
   ]
      ]
            ],
         {i, 0, maxrows}, {j, 0, maxcols}]]}, {Spacer[0], 
         If[Length@First@m > maxcols, 
          Slider[Dynamic[coloffset], {0, Length[m[[1]]] - maxcols, 
            1}]
    ]}}]
      ]
    ],
    m]
];

You can test it with, e.g.:
a = RandomReal[1, {1000, 300}];

editMatrix[Dynamic[a], {10, 6}]


This will confirm that a will actually be changed when editing the corresponding InputField:
Dynamic[a[[1, 1]]]

"
Plotting contours of a function for different values of a parameter,"
Use Table to generate the values for different t:
ContourPlot[Evaluate@Table[(x - t)^2 + (y - t^2)^2 == t^2, 
    {t, -20, 20, 1}], {x, -110, 110}, {y, -110, 110}]


"
How do I calculate the probability of reaching mean residual life,"
This topic is a bit unfamiliar to me but here's my take. I believe you can simplify your life a bit by looking at an alternative definition of mrl.
Using the definition for continuous distributions...
Expectation[x - t \[Conditioned] x > t, x \[Distributed] dist] ==
Expectation[x - t, x \[Distributed] TruncatedDistribution[{t, Infinity}, dist]] ==
Expectation[x, x \[Distributed] TruncatedDistribution[{t, Infinity}, dist]] - t

giving us...
 mrl[t_] = Mean[TruncatedDistribution[{t, Infinity}, dist]] - t

This gives an easy way to obtain another measure which, according to Klein and Moeschberger (a book I highly recommend), is preferable for skewed distributions. This is the median residual life:
mdrl[t_] =  Median[TruncatedDistribution[{t, Infinity}, dist]] - t

For fun, lets compare them for dist = LogNormalDistribution[1.75, .65].
Plot[{mrl[t], mdrl[t]}, {t, 0, 40}, PlotStyle -> {Red, Blue}]


Now the probability that someone survives mrl (or mdrl) units beyond time t given they have survived to time t is relatively easy to compute in that we can state it exactly as we say it.
pMRL[t_] := NProbability[x > t + mrl[t] \[Conditioned] x > t, x \[Distributed] dist]
pMDRL[t_] := NProbability[x > t + mdrl[t] \[Conditioned] x > t, x \[Distributed] dist]

Not surprisingly, the plot for pMDRL is not very exciting compared to pMRL.
Plot[{pMRL[t], pMDRL[t]}, {t, 0, 10}, PlotStyle -> {Red, Blue}]


"
plotting - Fixing quirky typesetting in plot labels,"
To fix the superscript placement and the italic m, you can use the options ScriptBaselineShifts and SingleLetterItalics in Style. For example
Plot[1 - Exp[-x], {x, 0, 3}, AxesLabel -> {""thickness (μm)"",
  Style[Row[{""power density "", Style[""("",Larger], ""W/m^2"", Style["")"", Larger]}],
    ScriptBaselineShifts -> {0, .5},
    SingleLetterItalics -> False, ""TraditionalForm""]}]


There are some other options in Style that might help. For example if you want a smaller font for the superscript, you can use the option ScriptSizeMultipliers.
"
graphics - Rotate doesn't work with BarChart and BoxWhiskerChart,"
You left off the angle to rotate through:
Rotate[BarChart[RandomReal[1, {4, 5}], ChartLayout -> ""Percentile""], 90 Degree]


Rotate[BarChart[RandomReal[1, {4, 5}], ChartLayout -> ""Percentile""], 45 Degree]


Strange that it didn't throw an error, though.
"
"numerics - Finding real roots of negative numbers (for example, $\sqrt[3]{-8}$)","
Mathematica 9 introduces two new functions, CubeRoot and Surd, that give real-valued roots:
In[1]:= CubeRoot[-8]
Out[1]= -2

In[2]:= Surd[-32, 5]
Out[2]= -2

You can use these to plot real roots:
Plot[CubeRoot[x], {x, -3, 3}]


Note that these functions are undefined for complex numbers:
In[5]:= CubeRoot[1 + I]

CubeRoot::preal: The parameter 1+I should be real valued. >>

Out[5]= Surd[1 + I, 3]

and the typeset form has a small ""tail"" at the end of the overbar to visually distinguish them from the usual roots:

"
import - Stream CSV or TSV files,"
Here is a function which may help:
Clear[readRows];
readRows[stream_, n_] :=
   With[{str = ReadList[stream, ""String"", n]},
      ImportString[StringJoin[Riffle[str, ""\n""]], ""Table""] /; str =!= {}];
readRows[__] := $Failed;

I tested on your file and it works all right (it may make sense to read rows in batches, this is much faster):
n=0;
str = OpenRead[""C:\\Temp\\EUR_USD_Week1.csv""];
While[readRows[str, 1000] =!= $Failed, n++];
Close[str];
n

(*  82   *)

By the way, speaking of practicality of Import - I agree, but do read this answer - it is based on the same idea as above code, and makes importing whole files quite practical IMO. In particular, using the readTable function from there, I get your file read in its entirety under 3 seconds on my machine:
In[64]:= readTable[""C:\\Temp\\EUR_USD_Week1.csv"",2000]//Short//AbsoluteTiming
Out[64]= {2.4775391,{{lTid,cDealable,CurrencyPair,RateDateTime,RateBid,RateAsk},
  <<81172>>,{1385715072,D\[Ellipsis] SD,2011-01-07,\[Ellipsis] }}}

with a very decent memory usage:
MaxMemoryUsed[]

(* 71652808 *)

meaning 50 Mb of net usage (when you subtract the startup memory usage) - for this particular example. You can tweak the second parameter to trade run-time for memory efficiency. See the linked post for more details.
"
How can one nested list be used to find the positions of those values in another nested list?,"
How about mapping Position like so
Position[listb, #] & /@ lista
(*{{{3}}, {{4}}, {{5}}, {{6}}, {{7}}, {{8}}, {{9}}, {{1}}, {{2}}}*)

which gives the position of each sublist of lista in listb?
To get only the first instance, use
Position[listb, #, 1, 1] & /@ lista

(the last argument of Position specifies how many positions found to return; the penultimate argument specifies the level at which to search).
"
graphics - Plotting Error Bars on a Log Scale,"
I always use the package ErrorBarLogPlots. From the website:

ErrorBarLogPlots.m is a package which adds log-scale plotting functions similar to the standard ErrorListPlot provided in Mathematica 6. The added functions are ErrorListLogPlot, ErrorListLogLinearPlot, and ErrorListLogLogPlot.""

"
export - Exporting and reimporting a list of lists changes the dimensions,"
What is happening is that your data is imported as strings:
dummy = Table[{k, 2*k}, {k, 1, 3}, {m, 1, 3}]
Dimensions[dummy]
Export[""~/Desktop/dummy.dat"", dummy]; dummyImport = 
 Import[""~/Desktop/dummy.dat""]
Dimensions[dummyImport] 
Map[Head, dummy, {-1}]
Map[Head, dummyImport, {-1}]


One way to fix it is to force the save to occur in some particular format:
dummy = Table[{k, 2*k}, {k, 1, 3}, {m, 1, 3}]
Dimensions[dummy]
Export[""~/Desktop/dummy.dat"", dummy, ""MAT""]; dummyImport = 
 Import[""~/Desktop/dummy.dat"", ""MAT""]
Dimensions[dummyImport] 

Map[Head, dummy, {-1}]
Map[Head, dummyImport, {-1}]


Alternatively, DumpSave, which uses an OS-dependent format, may be used to save and reload parts of the environment
DumpSave[""~/Desktop/dummy.mx"", dummy];
ClearAll[dummy];
dummy
Import[""~/Desktop/dummy.mx""]
dummy

"
performance tuning - Getting lengths of sublists that sum to more than one,"
Very good question / problem. Generally, this problem seems to belong to the class of problems where Compile is the best choice if maximum efficiency is looked for, since it is, by its nature, not a good fit for the Mathematica paradigm of working with lots of data at once. However, your last solution can be, in a somewhat modified form, brought to the same performance level while only partly compiled:
Clear[split, thresholdSemiCompiled];
split = Compile[{{nums, _Real, 1}}, 
   FoldList[If[# > 1, 0, #] &[#1 + #2] &, 0.0, nums], 
   CompilationTarget -> ""C""];

thresholdSemiCompiled[l_List] := 
   Flatten@Differences[SparseArray[Unitize[split[l]] - 1][""NonzeroPositions""]]

It turns out that Clip was a major bottleneck in the compiled split, and once I replaced it with If, it became an order of magnitude faster. This one is on par with your fastest fully compiled solution, in terms of performance.
Edit (by Oleksandr R., at Leonid's request)
In version 8, provided that an integer argument is used rather than a pattern, Position can be compiled down into a call to a new kernel/VM function ""Position"". This allows the above to be implemented in purely compiled code and avoids the need to use SparseArray in an undocumented and perhaps unintuitive way to get the positions of the zeros without unpacking the input array:
thresholdCompiled = Compile[{{nums, _Real, 1}},
  Flatten@Differences@Position[
    Unitize@FoldList[If[# > 1, 0, #] &[#1 + #2] &, 0.0, nums],
    0
  ], CompilationTarget -> ""C""
 ];

The performance gained by doing this is, perhaps surprisingly, relatively minor: this version returns timings of about 7/8ths those of the semi-compiled approach, irrespective of compilation to MVM bytecode or to C, probably due to the ability to locate zeros directly rather than having to subtract 1 from the array and find nonzero elements, and by avoiding the need to return a large intermediate array. (Unitize, Differences, Position, and Flatten are all compilable, but in version 8 they are compiled into simple function calls, so the only situation in which we would expect a performance gain through compilation is when, as here, it allows a larger problem to be dealt with entirely in compiled code.)
"
Using several anonymous functions mixed together,"
You can always use Function to create anonymous functions:
Function[{a},a^2]

is equivalent to
#^2&

and can be used as such, but it is unambiguous.
It can be used as:
Function[{a},a^2][2]

(* ==> 4  *)

"
"programming - Cases[data,Colon[key,_]] vs. Cases[data,key:_] toward XPath, XQuery","
I'd like to discuss two points:
Cases, destructuring and escaping in patterns
There indeed can be a problem when using Cases to destructure expressions involving rules, because Cases has an extended syntax which uses rules, and interprets them differently. For example:
dataR = {row1 -> {key1 -> value1, key2 -> value2}, 
    row2 -> {key1 -> value3, key2 -> value4}}

Here is a naive attempt that will fail:
Cases[dataR, row1 -> _]

(* {} *)

This will work:
Cases[dataR, p : (row1 -> _)]

(* {row1 -> {key1 -> value1, key2 -> value2}} *)

The reason is that the colon (which is a short-cut for Pattern) serves as an escaping mechanism in this case. The ""politically correct"" way to perform escaping in patterns is however to use Verbatim:
Cases[dataR, Verbatim[Rule][row1, _]]

(* {row1 -> {key1 -> value1, key2 -> value2}} *)

In some cases, particularly when you only need to collect some parts of the expression involving rules, this may be unnecessary since the escaping will be naturally achieved by the destructuring rule. Example:
Cases[dataR, (row1 -> x_) :> x]

(* {{key1 -> value1, key2 -> value2}} *)

Better ways to destructure trees
You can use the fact that your tree is made of rules, to destructure it better. There were a few questions here about it, particularly this and this. Let me just show you a simple construct here:
ClearAll[destructure];
destructure[tree_, keys__List] :=
   Fold[If[#2 === All, Flatten[#1[[All, 2]]], #2 /. #1] &, tree, keys]

This uses the fact that each branch is itself a set of rules. Some examples of use:
destructure[dataR,{row1,key1}]

(* value1 *)

destructure[dataR,{row1,All}]

(* {value1,value2} *)

destructure[dataR,{All,All}]

(* {value1,value2,value3,value4} *)

"
programming - Mathematica implementation of Earth Movers Distance?,"
In Mathematica 9, it is already implemented under ImageDistance.
See Similarity Graph of Images Using Earth Mover Distance.
"
export - My donut has holes in it!,"
Answer
Apparently, the mesh lines generate points which are too close to the triangle vertices, and VRML is not being able to handle them correctly.
To prove the theory, try the example without meshes:
p = ParametricPlot3D[{(2 + Cos[v]) Sin[u], (2 + Cos[v]) Cos[u], 
   Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, PlotStyle -> Red, Mesh -> None];

Export[""test.x3d"", p];

It should look OK using FreeWRL:

So the possible solution is to isolate meshes from the surface, i.e. generate them separately and let them be two different graphics complex so that they wouldn't share any points.
We already know how to generate the surface without mesh. To generate only meshes, this would do it (plotting with PlotStyle->None):
p2 = ParametricPlot3D[{(2 + Cos[v]) Sin[u], (2 + Cos[v]) Cos[u], 
   Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, PlotStyle -> None]

The result is:



Now, combine those two using Show and export.
Export[""test.x3d"", Show[p, p2]];

The result is perfect:

Now, you got your wholly donut back. Enjoy!
Note: I am using Windows version of FreeWRL so the result may be different on other platform. In that case, it may as well a bug in FreeWRL, not Mathematica's problem.
Bonus
OK. I shouldn't advocate the use of undocumented features. But if you really want more solid looking meshes, not shamble lines (many format/renderer is not so great at pure line drawing, more so with 3D printing...), this syntax may help you: MeshStyle->Tube[thickness] (thickness in user coordinate scale).
For instance:
p2 = ParametricPlot3D[{(2 + Cos[v]) Sin[u], (2 + Cos[v]) Cos[u], 
   Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, PlotStyle -> None, MeshStyle -> Tube[.02]]

will create:



Disclaimer There is no guarantee that the syntax will work on the future version of Mathematica. So if you value compatibility, you should not use this. But the resulting 3D graphics will be always valid since it is using our Tube primitive. Tube is supported for export formats. For instance, if you export it to x3d:
Export[""test.x3d"", Show[p, p2]];

(It may take quite a while, since Mathematica is converting tubes into polygons for compatibility during exports), the result will be:

Again, it is not a permanent solution but if you really need better mesh lines for export or 3d printing, it will give you a temporary relief.
"
syntax - Accept Infinity as an Integer argument,"
You can do this by using Alternatives to have the pattern accept either an integer or Infinity as an argument, like so:
Pillsy`Foo[x : (_Integer | Infinity)] :=
 Module[{limit = Min[x, 10], i = 1},
  While[i <= limit, ++i];
  i - 1]

It helps that Mathematica functions like Min and Max usually do the right thing with Infinity as an argument.
"
plotting - Printing exported PDF graphics fails (version 8),"
You might also have luck if you specify the ImageSize
Export[filename, plot, ""PDF"", ImageSize -> 8*72]

I have also been able to print files when using the Print As Image option (under Advanced from the Print menu of Adobe). 
"
time series - Stationarity tests,"
The three best-known tests for stationarity (or rather, unit roots) in time series econometrics are:

Dickey-Fuller including Augmented Dickey-Fuller
Phillips-Perron
KPSS

There are also Bayesian tests of unit roots, as implemented in this conference presentation. If you have access to JSTOR or another way of getting at old journals, this article might be of interest.
As far as I'm aware, nobody has created a pre-digested package for unit root testing in Mathematica. The notebook I wrote - about a decade ago - only includes the KPSS test, and I can give no warranties about whether I did it right. It was written for version 3 and would need considerable updating to work with version 8, as it has dependencies on several packages that have been made obsolete when the functionality was rolled into the main kernel.
"
How to create a list of pre-defined functions?,"
What you want is best accomplished in two steps. First, you want to construct your list of PDFs as a list of pure functions, like so:
peaks = Table[
  With[{factor = factors[[i]]},
   Composition[factor*# &, 
    PDF@CauchyDistribution[pos[[i]], gamma1]]],
  {i, Length@factors}]

Conveniently, PDF, when applied to a distribution as its only argument, returns a pure function; I use Composition to multiply the result returned by that function by factor[[i]]. The With statement is there to insert factors[[i]] into Function despite its non-standard evaluation; you could also use Evaluate. Now that you have a list of functions, you can index into them to apply them one at a a time:
In[69]:= peaks[[1]][0.1]
Out[69]= 0.376381

You can also use Through to apply all the functions in a list to a single argument:
In[70]:= Through[peaks[0.1]]
Out[70]= {0.376381, 0.0953388}

"
Export long filename truncated,"
The problem is not with Mathematica, but with the quicktime plugin/codec. The reason you see this error is that earlier versions of OSX (version 9 and below) had an upper limit of 31 characters for the filename (27, if you include the extension). Today's systems allow up to 255 characters, but the plugin still forces the filename to be backwards compatible. It is not related to a temporary file not being renamed.
StringLength[""Lorem-ipsum-dolor-s#123C8BE.mov""]
Out[1]= 31

Final Cut Pro's manual tells you about this (but leaves the choice of truncating to the user):

Although current file systems such as HFS+ (used by Mac OS X) allow you to create filenames with a 255-character limit, you may want to limit your filename length if you intend to transfer your files to other operating systems. Earlier versions of the Mac OS allow only 31-character filenames, and if you want to include a file extension (such as .fcp, .mov, or .aif), you need to shorten your Mac OS 9-compatible filenames to 27 characters.

Couple of other examples where people have been bitten by this behavior. AFAIK, the workaround is to rename the file after exporting.
"
syntax - Why can't D[] be used in place here?,"
Plot has attribute HoldAll which means in this case that D[Sin[x], x] isn't evaluated until after x is replaced with some number, so you end up with something like D[Sin[-6.28], -6.28] etc. which causes the errors since you can't take a derivative with respect to a number. 
One way to get around this is to use Evaluate to evaluate the derivative before the numbers are plugged in, i.e. to do something like
Plot[Evaluate[{Sin[x], D[Sin[x], x]}], {x, -2 Pi, 2 Pi}]


"
"graphs and networks - Is UndirectedEdge[a,b] the same edge as UndirectedEdge[b,a]?","
This is not inconsistent at all. You're using MemberQ, which only looks at the structural form and UndirectedEdge[1, 4] and UndirectedEdge[4, 1] are not the same, even though you know they mean the same thing. To check if an edge is in a graph, use EdgeQ
EdgeQ[g, 1 \[UndirectedEdge] 4]
EdgeQ[g, 4 \[UndirectedEdge] 1]
(* True, True *)


I think it's probably just an oversight on WRI's part to not include the Orderless attribute and such oversights are not uncommon. I can't think of a reason why it shouldn't be Orderless. One can always add this to the definition as follows:
Unprotect[UndirectedEdge];
SetAttributes[UndirectedEdge, Orderless];
Protect[UndirectedEdge];

Now using MemberQ as in the question will yield True in both cases. However, I would not recommend doing this, because I think it is worth it to understand the structural and semantic differences between the two and one should always use the one appropriate for the task (and in this case, also has a more meaningful name). 
"
formatting - Managing formatted usage messages in Wolfram Workbench,"
This problem exists because WB encourages you to edit the .m file directly. If you created and edited an .nb (package) file -which automatically creates and updates a .m file - this  problem (and others) would not exist. Indeed, if you work with the .nb (package) file you have all the cell organizational/styling facilities available.  So when I recently moved to WB, I wanted WB for creating documentation, Munit testing, ect...TOGETHER WITH front end .nb editing capabilities. Is this possible? Fortunately yes. Here is how (very detailed for beginners):
If you have a xyz.m file, create next to it (ie. in the SAME folder, which is inside the WB workspaces folder) a package file xyz.nb (you create this file in MMA or even in WB, I think). WB will- by default - load MMA front end whenever you want to edit this .nb file.  You put in this .nb file all the code you may already have written in the .m file. You may leave the code in Code cells, but (much) preferably you put it in Input-Initialization cells. Then you save the .nb file. This will automatically erase and update your old .m file (so back it up - BEFOREHAND - the first time, just in case). Now you have a .nb file next to a synchronized .m file. Next time you want to edit your code, double-click the .nb file in WB. This will automatically load MMA front end and update the .m file when saving the .nb file. If you want to debug, just use the .m file in WB, but remember that any changes you make should in the end be made to the .nb, if you want to keep them.
So we can have the best of WB and MMA together.
Advantages of .nb (package) editing: 

nicely hierarchically formatted .nb package file
nicely formatted usage messages
syntax highlighting
possibility to add text cells for comments, explanation, ect

HTH
"
formatting - Usage displays properly only after second call,"
I think I have found a solution to this issue, which has been a problem since at least Mathematica version 6 and continues through at least version 11.0. The problem occurs when a user-defined usage message has complex formatting, for example, subscripts, entered using 2D input.     
Suppose we have a function with usage message defined as

which also can be input as 
f::usage = ""\!\(\*SubscriptBox[\(test\), \(1\)]\)\n\!\(\*SubscriptBox[\(test\), \(2\)]\)""

If we evaluate ?f once, we get 

which is incorrectly formatted, but if we evaluate it again in the same input cell, without deleting the output cell, we get the correct version:

To see what's going on, we can run Trace[Information[f]], but that produces an enormous output, most of which has nothing to do with formatting the output string. To look for mentions of the usage string itself, we can use
Trace[Information[f], x_String /; !StringFreeQ[x, ""test""], TraceBackward -> True] 


This fingers the function System`Dump`fixmessagestring as a possible culprit. The function definition can be found with
InputForm@Definition[System`Dump`fixmessagestring]

which returns
System`Dump`fixmessagestring[System`Dump`s_] :=
  StringJoin[
    ""\"""",
    StringReplace[System`Dump`s, {""\n"" -> ""\\n"", ""\\"" -> ""\\\\"", ""\"""" -> ""\\\""""}], 
    ""\""""
  ]

This function converts some special characters in the string to explict form, as is done in InputForm. However, there are many kinds of formatting that this function doesn't address, which may be part of the problem. We can redefine this function to do a more thorough job by evaluating 
System`Dump`fixmessagestring[System`Dump`s_] := ToString@InputForm@System`Dump`s

and now ?f returns the correct result every time. It's still not clear to me why the original version would cause a problem on the first evaluation, but not on the second, but, regardless, it seems that we have a fix.
A concern might be if this has an effect on built-in usage messages, but in my testing, the built-in messages display identically.
The redefinition could be done inside the user-defined package, making the fix invisible.
Also, with the command On[System`Dump`fixmessagestring], we can have Mathematica send us a trace message whenever System`Dump`fixmessagestring is called. That will let us see if the function is ever called anywhere outside of Information[], where the redefinition might have other consequences. So far it seems that the function is just confined to Information[] and ?.
Since there seems to be a one-line fix to this problem, it would be nice if it were eventually fixed in Mathematica itself.
"
How to set the return type of a compiled function? (Compile::noinfo warning),"
I think Leonid’s comment is spot on. You could work around the issue with a completely different approach:
MakeInPeriodicCell = Compile[{{x, _Real}, {cellwidth, _Real}},
   If[x < -(cellwidth/2.), x + cellwidth, 
    If[x > cellwidth/2., x - cellwidth, x]]
   ];

"
scoping - How to use local variables with indices in a Mathematica Block environment?,"
The problem is that the definition which makes Subscript[a,i] evaluate to 6 is stored in the DownValues of Subscript. The down values of Subscript don't care about the blocking of a and will still exist when Block exits. You can check that by evaluating DownValues[Subscript]. You could use TagSet (shortcut: /:) to store that value in the UpValues of the localized a, which would behave as you expect (i.e. the rule in UpValues of a is removed when Block exits):
ClearAll[f, a, Subscript]
Subscript[f, i_][x_] := Block[{a},
  a /: Subscript[a, i] = 3 x;
  Subscript[a, 1]
]

on the other hand I wouldn't actually recommend to use such subscripted variables, what you have seen is probably only one of several unexpected things that could happen.
Side Note:It probably should be mentioned that the definition for Subscript[f,i_][x_] is also not associated with f but with Subscript, which can be checked by evaluating SubValues[Subscript]. Unfortunately this can not be changed by using TagSet for f, since Mathematica here will complain about f being too deep in the left hand side expression. One possibility to change that is to reformulate the function definition to e.g.:
f /: Subscript[f, i_] = Function[x,
  Block[{a},
   a /: Subscript[a, i] = 3 x;
   Subscript[a, 1]
   ]
  ]

which will behave the same as the original in most practical cases but of course is not exactly the same thing. You can use UpValues[f] to check that this rule is now really associated with f.
"
syntax - Extracting equations from Piecewise expressions,"
Here is a way to separate your equation into different subparts. It uses Reap and Sow to tag parts of the expression as either ""equation"" or ""conditions"" or ""constants"".
f = Which[FreeQ[#, x], Sow[#, ""constants""],
        MemberQ[{Equal, Unequal, Greater, GreaterEqual, Less, LessEqual, And, Or}, Head[#]], 
        Sow[#, ""conditions""],True, Sow[#, ""equation""]] &;

Last@Reap[Scan[f, List @@ PDF[LogNormalDistribution[1.75, 0.65], x] // Flatten], 
    {""equation"", ""conditions"", ""constants""}] ~Flatten~ 1

(* Out[1]= {{(0.613757 E^(-1.18343 (-1.75 + Log[x])^2))/x}, {x > 0}, {0}} *)

So now you have your equations in the first sublist, conditions in the second and constants in the third. If you need only the first, you need to Reap only that. This should work with your second example too.
Note that you'll have to be careful to ensure that x above does not have any value — using formal symbols is better.
"
compile - Expression evaluation inside of FindRoot inside a Compiled Function,"
I think you're going after it the wrong way. FindRoot is not compilable, and it's expected to be the most CPU-expensive part of your loop, so the possible benefits of compilation seem scarce.
To quote this most excellent answer by halirutan:

To summarize: Usually you don't need any list of supported functions, because the rule of thumb is, that compile will not work with already optimized, complicated Mathematica-methods. This includes NIntegrate, FindRoot or NMinimize. Nevertheless, Compile can easily be used to make those function-calls really fast. What you have to do is to compile your target function, because the most time with stuff like NIntegrate is spent, evaluating the integrand. The same is true for FindRoot, NMinimize and many more methods.

(emphasis mine).
"
graphics - Animating a Voronoi Diagram,"
The first step is to rasterize the points, so let's just start there as an example:
n = 512;
g = Image[Map[Boole[# > 0.001] &, RandomReal[{0, 1}, {n, n}], {2}]]

The trick is to exploit the distance image.  Almost all the work is done here (and it's fast):
i = DistanceTransform[g] // ImageAdjust // ImageData;

We need a little more precomputation of the final boundaries.  Rasterizing a vector-based Voronoi tessellation would be faster, but here's a quick and dirty solution:
mask = Image[WatershedComponents[Image[i]]]

Now the animation is instantaneous: it's done simply by thresholding the distances.  (Colorize it if you like.)  Have fun!
Manipulate[
 ImageMultiply[
  Image[MorphologicalComponents[Image[Map[1 - Min[c, #] &, i, {2}]], 1 - c]], mask],
 {c, 0, 1}
 ]


"
cdf format - Understanding CDF,"
Actually this is just meant as a side note to your own answer, but it became too long for a comment. As you can guess I'm interested in this myself and have done some testing, most of what I mentioned is from that experience. It has been reported that there would be differences in what the player would allow depending on whether Mathematica is installed or not. I don't believe that this is true, at least not by design, but as of now this is one of the things I have not explicitly checked..
I think some of the confusion about what can be done in a CDF format comes from the fact that one has to make a distinction between:

CDF as a format
restrictions of the Wolfram Player Pro (called Mathematica Player Pro for vs. 6 and 7)
restrictions of the free CDF-Player
restrictions of the browser plugin (full window mode)
restrictions of the browser plugin (embedded cdf in html)
restrictions of the pre version 8 Mathematica Reader
restrictions of the demonstration site

and of course it doesn't help that some of the WRI documentation seems to not be very precise concerning these distinctions. The most relevant statement on restrictions seems to be this, from here

Can I use any Mathematica functionality that I want?
Yes. Almost all of Mathematica's computational functions can be incorporated into CDFs. However, in files saved straight out of Mathematica 8 for the free CDF Player, some functionality is not available: non-numeric input fields, dialog windows, and data import and export (except from Wolfram-curated data sources, e.g. ChemicalData, CountryData, and WordData). Please contact us about activating higher-level application content in CDFs.

To me it looks like the CDF format itself does not imply any restrictions, meaning that when you open a CDF document with a full version of Mathematica, it just behaves like a normal notebook (NB) file. The main difference seems to be a signature that is added to the CDF but not the NB files. I guess it is this signature that will be checked by the various players to see which restrictions are to be used when e.g. showing the dynamic content. While saving with Mathematica will create a signature that will only let the free CDF player use some functionality, it seems possible (but only by WRI) to create signatures that will allow the free CDF-Player to allow more or all (?) functionality. It is most probably this possibility that they are calling ""activate higher-level application content in CDFs"" or ""CDFs with enhanced functionality"". You would need to contact WRI to make use of that possibility, of course. This is a very different approach from using the Wolfram Player Pro, which already could show and play dynamic content within normal notebook files in earlier versions and of course can do so with CDF files as well. Unlike the CDF-Player, the Wolfram Player Pro will even allow shift-return-evaluations and import and export external files, including loading packages, which must be Encoded, though.
I think you got the restrictions mostly sorted right by now in your own answer, except for some details:
Complex Functions
I think the restriction that only a very limited set of functions is allowed in dynamic content of a CDF document is only enforced for the CDF browser plugin, but the standalone free CDF Player will run dynamic content that makes use of almost every function. The CDF will then be shown with a warning header about potentially dangerous content but after explicitly enabling dynamics there the dynamic content will work alright. Unlike mentioned elsewhere I also don't think that the way how you create the CDF document will make a difference concerning these restrictions. It is the use of the CDF browser plugin for showing that document that makes a difference. If you deploy to be embedded in html the formatting of the CDF document will be slightly changed to something more condensed. But when opening the CDF document created that way with the standalone CDF Player, it behaves mostly like one that is deployed as ""Standalone"" or saved directly as CDF (except for the mentioned formatting).
Edit: I just learned that there is another distinction, since the browser plugin will behave differently when it is embedded in html or running in a ""full screen"" mode which will fill the full browser window. The difference is that in the latter it can show the docked cell to let the user allow ""dynamic content for potential dangerous code"" while it can't do so in the embedded mode. If the user allows dynamic content then some of the restrictions of the browser-plugin are released, but I think there will still be some more than with the standalone player. There is a workaround which allows for that docked cell to appear even in when the cdf is embedded in html, which was obviously uncovered here, but that might have problems with resizing (and probably other) and is not officially supported, so could even go away with future versions. In any case, the difference seems again not be within the CDF document but in by which program and how it is shown.
Manipulate
From all test I have done there seems to be no need to use a Manipulate, despite the fact that this is mentioned in the WRI docs. It is just the most comfortable way to get the initialization of your dynamic content right, especially if the dynamic content depends on nontrivial functionality (that is many functions/symbols). Using the SaveDefinitions option is much more convenient than putting all the function definitions in the Initialization option of a DynamicModule or Dynamic by hand, and it is only available for Manipulate, not e.g. DynamicModule. Nevertheless, the following will make your first example work well in the (standalone) free CDF-Player, with no Manipulate involved at all:
DynamicModule[{x = 0},
 Panel[Column@{InputField[Dynamic@x, Number], Dynamic@func@x}],
 Initialization :> (func[x_] := 100*x)
]

For most practical considerations I think you can think of SaveDefinitions as an option that will create a correct Initialization option for you by inspecting the code, trying to determine dependencies and save all definitions that the code depends to that Initialization option. This can go wrong, and whether it works or not most probably doesn't have anything to do with what the CDF document or any of the ways to show such a document would allow to be run.
Needs
For the Needs restriction I think the point is that it's not possible to read external files in the free CDF-Player from CDF-documents created from a normal Mathematica, and thus it's not possible to load an external package file in the free CDF-Player from such a CDF-document. I don't have seen any restrictions concerning anything related to the name spaces (Contexts) so I think as long as you manage to get the initialization right (so that all dynamic content will work correctly) the symbols used can live in any namespace you want. It's just not that easy to achieve this, as has been discussed in e.g. this post (which I think you know about), and in some cases the SaveDefinition option probably isn't getting things right, too.
I think it's worth repeating here that you will need to enclose all code (""function definitions"") and all data that is used by the dynamic content in the CDF document for it to work in the free CDF Player or the browser plugin. Only when shown in Wolfram Player Pro or Mathematica, code and data could come in separate files as well.
Edit: I just learned that Import will actually work for nonlocal url's, so it should be possible to load data from a public webserver with the CDF-Player and even the browser plugin, but probably not for every format that Mathematica supports. But it's definitely not supposed to be possible to load data from a local filesystem, neither in the standalone version nor the browser plugin.
Nontrivial Example
During my tests I was trying to get as far as I could in deploying an application in the free CDF player. The following is what I managed to do, some of it is still worth improving and the whole example is just a proof of concept, but I think it shows that one can do a lot more in the free CDF player than is obvious at first sight.
CurrentValue[EvaluationNotebook[], TaggingRules] = {
   ""Context"" -> ""cdfapp`"",
   ""Code"" -> Compress[""
       BeginPackage[\""cdfapp`\""];
       run::usage=\""run[]\"";
       clear::usage=\""clear[]\"";
       Begin[\""`Private`\""];
       run[]:=With[{cntxt=CurrentValue[ButtonNotebook[],{TaggingRules,\""Context\""}]},
        Set@@Join[
         ToExpression[cntxt<>\""content\"",InputForm,Hold],
        Hold[Manipulate[Plot[x^n,{x,0,1},PlotRange->{0,1}],
        {n,1,100},AppearanceElements->None]]
        ]
       ];
       clear[]:=With[{cntxt=CurrentValue[ButtonNotebook[],{TaggingRules,\""Context\""}]},
        Unset@@ToExpression[cntxt<>\""content\"",InputForm,Hold]
       ];
       End[];
       EndPackage[];
       ""
     ]
   };

SetOptions[EvaluationNotebook[], DockedCells -> {
   Cell[BoxData[ToBoxes[
      Row[{
        Button[""Run"",
         ToExpression[
          Uncompress[
           CurrentValue[ButtonNotebook[], {TaggingRules, ""Code""}]]]; 
         Symbol[""run""][], Method -> ""Queued""
         ],
        Button[""Clear"",
         ToExpression[
          Uncompress[
           CurrentValue[ButtonNotebook[], {TaggingRules, ""Code""}]]]; 
         Symbol[""clear""][], Method -> ""Queued""
         ],
        Spacer[30],
        Button[""Quit"", FrontEnd`FrontEndToken[""EvaluatorQuit""], 
         Evaluator -> None],
        Spacer[30],
        Button[""Show Packed Code"", 
         CreateDialog[
          CurrentValue[ButtonNotebook[], {TaggingRules, ""Code""}],
          WindowSize -> {500, 500}], Method -> ""Queued""],
        Button[""Show Clear Code"", 
         CreateDialog[
          Uncompress@
           CurrentValue[ButtonNotebook[], {TaggingRules, ""Code""}],
          WindowSize -> {500, 500}], Method -> ""Queued""]
        }]
      ]], ""DockedCell""]
   }];

Dynamic[Replace[cdfapp`content, s_Symbol :> """"], 
 TrackedSymbols :> {cdfapp`content}]

To run this do the following: create a new CDF document in Mathematica, copy the above code to it and evaluate. It should add a docked cell to the document and an empty output cell. Delete everything except for the empty output cell and save it. Then open it with the free CDF player and try the buttons in the docked cells.
Disclaimer
As I said, much is just deduced from my experiments, some I learned from the CDF-Workshop and the documentation. Anyway I'm glad to hear about any corrections or improvements to these statements.
"
import - Importing HDF5 with compound data,"
I have created h5dumpImport, an open source Mathematica Package that provides a platform independent way to import HDF5 (.h5) file's datasets with compound datatypes while hiding much of the HDF5 implementation from the user.  The package with documentation, examples, and unit test is located here.
Currently, the h5dumpImport package does not directly import the HDF5 (.h5) file format. The h5dumpImport package imports an ASCII dump of a dataset generated by the h5dump command line tool.
Source code and pre-built binary distributions of the HDF5 Software which includes the h5dump command line tool can be found at the The HDF Group's website.
Basic Example
Needs[""h5dumpImport`""]
datasets = Import[""testData.h5"", {""Datasets""}];
dumpFile = h5dump[""/usr/bin/h5dump"", ""testData.h5"", datasets[[1]]];
dumpImport = h5dumpImportNew[h5dumpImport[], dumpFile];
dumpImport.h5dumpImportData[All]
dumpImport.h5dumpImportClose[];


Results:
{{1, 11, 111, 1111, 11111, 111111, 1111111, 1.1, 11.11, ""one""},
 {2, 22, 222, 2222, 22222, 222222, 2222222, 2.2, 22.22, ""two""},
 {3, 33, 333, 3333, 33333, 333333, 3333333, 3.3, 33.33, ""three""}}

Detailed installation instructions, usage information, and documentation, examples, and unit tests can be found here.
"
output formatting - ArcTan expressed as a radian fraction?,"
Short answer: no, ArcTan[2] is not fraction of $\pi$. But this is more of a mathematics question than pertaining to Mathematica.
If you want to “check” that the result is not expressable as a fraction of $\pi$, you can check for the continued fraction reprentation of $\arctan(2)/\pi$, and see that it does not seem to converge:
Table[FromContinuedFraction@ContinuedFraction[ArcTan[2]/\[Pi], n], {n, 20}]


"
bugs - Dialog crashes Mathematica,"
Updated: It seems like this bug has been ironed out in version 9. as it does not cause a crash anymore.

Instead of comments, let's gather here the information we have:

Crash happens on Mathematica 8.0.0.0 through 8.0.4, seemingly on all OS (reported confirmed on: WinXP/32, Mac OS 64-bit, Ubuntu 64bit, Win7/32).
Mathematica 7 doesn't crash, at least on Mac OS.
MM Support provided R Hall a new Mac OS binary that fixes the crash on 8.0.4.

"
probability or statistics - Histograms with pre-counted data,"
Histogram doesn't have any built-in support for weighted data, although it's an interesting idea, and most of the binning algorithms should be amenable to working with it.

That being said, here's a WeightedHistogram function, with some feedback from Andy Ross.  It accepts 

weighted values (in the same format as RandomChoice and EmpiricalDistribution)
binning specifications
Histogram options.  

It doesn't support the height functions, since they'd have to be manually implemented.  (This isn't hard, just a bit tedious since there are several of them.)
The implementation creates a representative sample of the data to compute the bins from.  This is combined with the list of actual values to make sure we cover the extremes, which might have low weights and otherwise not show up in the sample.
Options[WeightedHistogram] = 
   Append[Options[Histogram], ""SampleSize"" -> 1000];

WeightedHistogram[weights_ -> values_, o : OptionsPattern[]] :=
   WeightedHistogram[weights -> values, Automatic, o]

WeightedHistogram[weights_ -> values_, bins_, o : OptionsPattern[]] :=
   Block[{sample, newbins, valuelists, partitions},
      sample = Join[
         RandomChoice[weights -> values, OptionValue[""SampleSize""]],
         values];
      newbins = First[HistogramList[sample, bins]];
      partitions = Partition[newbins, 2, 1];
      valuelists = 
         Total[Pick[weights, Thread[# <= values < #2]]] & @@@ partitions;
      Histogram[values, {newbins}, valuelists &, 
         FilterRules[Flatten[{o}], Options[Histogram]]]
      ]

Now let's try it out with some data that is easily weighted:
data = RandomVariate[PoissonDistribution[30], 10^5];
{values, weights} = Transpose[Tally[data]];

Here's the Histogram applied to the original data:
Histogram[data]


Here's the weighted data, in vanilla and rainbow flavors:
Row[{
   WeightedHistogram[weights -> values], 
   WeightedHistogram[weights -> values, {1}, ChartStyle -> ""Rainbow""]
   }]


"
How do I use the result of Solve in a function definition?,"
You're doing a replacement to get the solution, not evaluating a function in the Z /. part, so it can really be any variable. You'll end up with a recursion with a definition like Z[x_]:= f[Z[x]...]. So try something like:
Z[amax_] := Max[z /. Solve[FullSimplify[PowerF[amax], z ∈ Reals] == P0, z]]

If you want the variable that you're solving for to look similar to your function variable, then use formal symbols. It would look something like this:

As always, the standard warning to not use capital letters as function names and variables applies here.
"
programming - GeoDirection and GeoDistance Memory Leaks: How to Recover the Memory?,"
Wolfram Research has prepared a patch that eliminates this memory leak.  I sent a problem demo notebook to support at WRI, and WRI responded with updated versions for two GeoFunctions.mx files.  Replacing the installed GeoFunctions.mx files with these updated patch versions eliminates the memory loss.  
I asked WRI if I could upload this patch for others to use, and WRI requested that anyone desiring the patch files contact WRI support directly. They will then provide the patch files and the directions for their use. 
Thank you for taking the time to investigate this problem and suggest possible solutions.  I admire your contributions to this forum.
"
export - Saving high-quality graphics through commands,"
Control image size as Graph option:
g = CompleteGraph[100, ImageSize -> 2000];
Export[""mysuperawesomegraph.png"", g]

Also if you already have graphics produced, you can use Show to programmatically resize it:
g = CompleteGraph[100, GraphStyle -> ""LargeNetwork""];
gmag = Show[g, ImageSize -> 2000];
Export[""mysuperawesomegraph.png"", gmag]

In Mathematica there is a difference between Graphics objects and images:
RandomImage[1, {100, 100}]


In[1]:= % // Head
Out[1]= Image

Graphics[Raster[RandomReal[1, {100, 100}]]]


In[2]:= % // Head
Out[2]= Graphics

ImageResize is used for images and may result in the loss of resolution. Changing shown size of Graphics with Show will not result in loss of resolution. 
"
"list manipulation - 3x+1 on arithmetic chains, tree pruning and NestList","
I think you can get the non repeated terminal symbols after round N by using the following (not optimized)
Collatz[Null] = Null;
Collatz[Subscript[m_, d_] /; EvenQ[m] && EvenQ[d]] := 
  Collatz[Subscript[m, d]] = check@Subscript[m/2, d/2];

Collatz[Subscript[m_, d_] /; OddQ[m] && EvenQ[d]] := 
  Collatz[Subscript[m, d]] = check@Subscript[3 m + 1, 3 d];

Collatz[Subscript[m_, d_] /; OddQ[d]] := 
  Collatz[Subscript[m, d]] = 
   Collatz /@ {check@Subscript[m, 2 d], check@Subscript[m + d, 2 d]};

Collatz1[x__] := (p = (DownValues@Collatz /. 
      HoldPattern[_[q_] :> _] :> q)[[2 ;; -4]]; Collatz[x])

check[t_] := If[Cases[p, t, Infinity] == {}, t, Null]

SetAttributes[Collatz, Listable];
SetAttributes[Collatz1, Listable];

NestList[Collatz1, Subscript[1, 1], 12][[-1, 1]]

"
Function as an option to a function,"
Short answer:
You supply a pure function to an option when you want to override the built-in options. In this case, ""Diamond"" and 0.2 resolve to certain functions or are used as values in certain functions internally which is then used for the respective option. The short names are merely a convenient way for you to remember and enter the option.
Longer answer:
It might help to understand what is done internally, so consider this simple example. We construct a function f that takes in a numeric argument x, and an optional value p (with default value 1) and we raise x to power p:
f[x_?NumericQ, opts : OptionsPattern[p -> 1]] := x^OptionValue[p]

f[2]
f[2, p -> 2]
f[2, p -> 3]
(* 2, 4, 8 *)

So far so good. Now let's say you'd like to supply arguments like ""square"" and ""cube"" instead of 2 and 3 and let the function figure out what to do with it. So you do something like:
Clear[f]
f[x_?NumericQ, opts : OptionsPattern[p -> 1]] := Module[{pow},
    pow = OptionValue[p] /. {""square"" -> 2, ""cube"" -> 3};
    x^pow
]

f[2, p -> ""square""]
f[2, p -> ""cube""]
(* 4, 8 *)

You have now built a definition for f that can take simple options for p both as ""square"" or as 2, which gives you additional flexibility.
Extending the idea to a function that accepts functions as option values. I'll define a function g, taking inputs as g[x, p -> func], returning func[x] and also let it take arguments as g[x, p -> ""string""] for some values of ""string""
Clear[g]
g[x_?NumericQ, opts : OptionsPattern[p -> (# &)]] := Module[{func},
    func = OptionValue[p] /. {""square"" -> (#^2 &), ""cube"" -> (#^3 &)};
    func[x]
]

g[2, p -> ""square""]
g[2, p -> ""cube""]
(* 4, 8 *)

Suppose you get bored of the vanilla pre-defined options and want to fancy it up, you can do that by supplying your own pure function as an option to p. For example:
Plot[g[x, p -> (Sin[Exp[#]] &)], {x, 0, π}]


By now, you can begin to see how this is useful. If you had a complicated function that needed to be input as an option or is used repeatedly, you'd want to make things simple for the end user (most likely yourself) and so you pre-define it and provide a short form that is easy to remember and conveys the intent without ambiguity. Any time this needs to be overridden (possibly for a one time use case), you can supply your own function.
Also read this answer for why you need to wrap your custom pure functions in parentheses when supplying as an option value.
"
"fitting - FindFit returns Infinity::indet error when data contains {0,0}","
Well, FindFit works by calculating a Jacobian of your expression, which is a matrix of derivatives with respect to all variables. Analytically, because $b$ is a real variable (and not an integer), you have $q^b = \exp(b \log q)$, so you see how that might become difficult when $q$ becomes zero.
However, the documentation for FindFit describes exactly your problem, and a possible solution. (I found it by looking for ""FindFit Jacobian"" in the documentation, so it's possible to find from your original error message.)

Specify the model gradient to avoid problems with a removable singularity: […] Gradient -> ""FiniteDifference""

This works for you too:
In:=  FindFit[data, a*q^b, {a, b}, q, Gradient -> ""FiniteDifference""]
Out=  {a -> 2., b -> 2.}

"
mathematical optimization - Minimizing a function of many coordinates,"
To get arbitrarily many formal variables, you can use Array. But with those variables, your function definition won't work because of the Apply statement. So I modified your definition as follows (I reduced the point number for testing purposes):
pts = Apply[{ArcCos[2 #2 - 1], 2 \[Pi] #1} &, RandomReal[1, {10, 2}], 1];
Clear[energy];
Clear[a];
vars = Array[a, {Length[pts], 2}];
energy[p_] := 
  Module[{cart}, 
   cart = Map[{Sin[#[[1]]]*Cos[#[[2]]], Sin[#[[1]]]*Sin[#[[2]]], 
       Cos[#[[1]]]} &, p];
   Total[Outer[Exp[-Norm[#1 - #2]] &, cart, cart, 1], 2]];
FindMinimum[energy[vars], Transpose[{Flatten@vars, Flatten@pts}]]


{32.2548, {a[1, 1] -> 1.93787, a[1, 2] -> 1.72361, a[2, 1] -> 1.11355,
     a[2, 2] -> 0.893035, a[3, 1] -> 6.21077, a[3, 2] -> 2.1405, 
    a[4, 1] -> 3.06917, a[4, 2] -> 2.14062, a[5, 1] -> 1.06997, 
    a[5, 2] -> 2.50937, a[6, 1] -> 4.21367, a[6, 2] -> 1.69561, 
    a[7, 1] -> 5.07748, a[7, 2] -> 2.48594, a[8, 1] -> 4.31041, 
    a[8, 2] -> 0.111206, a[9, 1] -> 4.25016, a[9, 2] -> 3.31368, 
    a[10, 1] -> 5.11923, a[10, 2] -> 0.955784}}

The form of the array passed to energy matches the $N\times2$ dimension list that is expected by the line creating the cart variable. In the FindMinimum statement the dummy variables and initial conditions are specified as a single list of pairs by using Flatten on both. 
There is the usual wrinkle that the minimization may need to be tweaked for precision, but that's a different issue.
Finally, to get the minimizing point list, you have to do 
vars/.Last[%]

Edit
Depending on the function to be optimized, it's sometimes faster to avoid the use of derivatives by specifying the initial conditions for FindMinimum in the form of three numbers:
FindMinimum[energy[vars], 
Transpose[{Flatten@vars, Flatten@pts, Flatten@pts - .1, Flatten@pts + .1}]]

Edit 2
I did get a significant speed-up with this for your example, but the performance depends on the random starting points (and on the choice of bracket width) so I can't say anything definitive. That seems like a topic for a different question.
Edit 3
Though I didn't look at the speed issue in detail, forcing FindMinimum to work with numerical derivatives may be the worst option here. That will happen if you define your function energy only for numerical arguments, as in 
energy[p : {{_?NumericQ, _?NumericQ} ..}] := 

followed by either your own or my initial definition above. So although that's a common advice people give in these applications, it is not going to be the fastest approach here.
Edit 4
I just had another idea on how to improve the speed of my solution: the use of Norm might make it harder to estimate the Hessian for this function. And indeed, when I got rid of Norm there was a significant speed gain (note that the initial solution above is already faster than the _?NumericQ approach even when the latter is compiled while mine is not). I think this is worth adding here because Norm seems like a natural thing to use in pair potentials, even if the energy expression becomes more complicated than the one in this question.
So here is the new version, with Norm replaced by Sqrt[(#1 - #2).(#1 - #2)]. Observe that I have now put back the original particle number of 100 because on my laptop this takes less than 8 seconds to evaluate!
pts = Apply[{ArcCos[2 #2 - 1], 2 \[Pi] #1} &, RandomReal[1, {100, 2}], 1];
Clear[energy];
Clear[a];
vars = Array[a, {Length[pts], 2}];
energy[p_] := 
  Module[{cart}, 
   cart = Map[{Sin[#[[1]]]*Cos[#[[2]]], Sin[#[[1]]]*Sin[#[[2]]], 
       Cos[#[[1]]]} &, p];
   Total[Outer[Exp[-Sqrt[(#1 - #2).(#1 - #2)]] &, cart, cart, 1], 2]];
FindMinimum[energy[vars], Transpose[{Flatten@vars, Flatten@pts}]]

Oh, and one more thing I changed (unrelated to the question), is to switch your definitions of polar and azimuthal angles in pts.
"
How to thrad a list - Mathmatica Stack Exchang,"
If your lists are long, there are faster approaches using high-level functions and structural operations. Here are two alternatives.
First we try Outer and Flatten:
data = {{a1, a2}, {b1, b2}, {c1, c2}, {d1, d2}};
Flatten[Outer[List, List@First[data], Rest[data], 1], {{2}, {1, 4}}]


{{{a1, b1}, {a2, b2}}, {{a1, c1}, {a2, c2}}, {{a1, d1}, {a2, d2}}}


And now Distribute and Transpose:
Transpose[Distribute[{List@First[data], Rest[data]}, List], {1, 3, 2}]


{{{a1, b1}, {a2, b2}}, {{a1, c1}, {a2, c2}}, {{a1, d1}, {a2, d2}}}


Evidently, they give the correct result. Now for a Timing comparison:
data = RandomReal[{0, 1}, {10^6, 2}];

The timings, in rank order, are:

kptnw's Table/Transpose method: 0.297 seconds
Outer/Flatten: 0.812 seconds
Distribute/Transpose: 0.891 seconds
rcollyer's Thread/Map approach: 2.907 seconds
R.M's Transpose/FoldList method: 3.844 seconds
paradox2's solution with Riffle and Partition: 7.407 seconds

The Outer/Flatten and Distribute/Transpose approaches are quite fast, but clearly Table is much better-optimized than Distribute, since while these two methods are conceptually similar, kptnw's solution using the former is by far the fastest and most memory-efficient. The other solutions, not using structural operations, are considerably slower, which is not unexpected.
"
Combining heads of lists so that you can create a nested list from two sublists,"
You can do
Transpose@{ Range@20000 - 1, yourList }

Or more generally if yourList is of varying length
Transpose@{ Range@First@Dimensions@yourList - 1, yourList }

Extracting a part of the list, say from index i to index j can be done with Partor Take
newList = Transpose@{ yourList, Range@First@Dimensions@yourList };
newList[[i;;j]]
(* or *)
Take[newList,{i,j}]

"
graphics - Computing and plotting a spectrogram in Mathematica,"
Get a sample sound:
snd = ExampleData[{""Sound"", ""SopranoSaxophone""}];

This gives us a Sound data structure with a SampledSoundList as first element. Extracting the data from it:
sndData = snd[[1, 1]];
sndSampleRate = snd[[1, 2]];

Plotting the data:
ListPlot[sndData, DataRange -> {0, Length[sndData]/sndSampleRate }, 
 ImageSize -> 600, Frame -> True, 
 FrameLabel -> {""Time (s)"", ""Amplitude"", """", """"}, 
 BaseStyle -> {FontFamily -> ""Arial"", FontWeight -> Bold, 14}]


Find the lowest amplitude level (used as reference for dB calculations):
min = Min[Abs[Fourier[sndData]]];

A spectrogram is made by making a DFT of partitions of the sample. The partitions usually have some overlap.
partSize = 2500;
offset = 250;
spectroGramData = 
  Take[20*Log10[Abs[Fourier[#]]/min], {2, partSize/2 // Floor}] & /@ 
   Partition[sndData, partSize, offset];

Note that I skip the first element of the DFT. This is the mean level. I also show only half of the frequency data. Because of the finite sampling only half of the returned coefficient list contains useful frequency information (up to the Nyquist frequency).
MatrixPlot[
  Reverse[spectroGramData\[Transpose]], 
  ColorFunction -> ""Rainbow"", 
  DataRange -> 
    Round[
     {{0, Length[sndData]/sndSampleRate }, 
     {sndSampleRate/partSize, sndSampleRate/2 }}, 
     0.1
    ], 
  AspectRatio -> 1/2,  ImageSize -> 800, 
  Frame -> True, FrameLabel -> {""Frequency (Hz)"", ""Time (s)"", """", """"}, 
  BaseStyle -> {FontFamily -> ""Arial"", FontWeight -> Bold, 12}
]


A 3D spectrogram (note the different offset value):
partSize = 2500;
offset = 2500;
spectroGramData = 
  Take[20*Log10[Abs[Fourier[#]]/min], {2, partSize/2 // Floor}] & /@ 
   Partition[sndData, partSize, offset];

ListPlot3D[spectroGramData\[Transpose], ColorFunction -> ""Rainbow"", 
 DataRange -> 
  Round[{{0, Length[sndData]/sndSampleRate }, {sndSampleRate/partSize,
      sndSampleRate/2}}, 0.1], ImageSize -> 800, 
 BaseStyle -> {FontFamily -> ""Arial"", FontWeight -> Bold, 12}]


"
Map and Apply a function on a nested list,"
You can define a function as :
myF[alist_, f_] := Map[{#[[1]], f[#[[2]]]} &, alist]

myF[{{1, 2}, {4, 2}, {6, 4}}, Log]

(* {{1, Log[2]}, {4, Log[2]}, {6, Log[4]}} *)

Or you can generalize to :
myF2[alist_, f_] := Map[{f[[1]][#[[1]]], f[[2]][#[[2]]]} &, alist]

myF2[alist, {# &, Log}]
myF2[alist, {Sin, Log}]

(* {{1, Log[2]}, {4, Log[2]}, {6, Log[4]}} *)
(* {{Sin[1], Log[2]}, {Sin[4], Log[2]}, {Sin[6], Log[4]}} *)

"
plotting - Creating legends for plots with multiple lines?,"
In case you want more flexibility, it's also possible to design your own legends, for example along the lines of this MathGroup post. For your example, the process would start with the function legendMaker. 
Instead of repeating the same definition as in the above post, I've overhauled legendMaker in response to image_doctor's answer, to separate out the handling of options better.
I've tried to make the spacings and widths of the legends more customizable, and also separated the automatic extraction of the line and marker styles into a separate function extractStyles so that it's easier to modify if needed later.
Here I'm listing all the functions in one code block to make them easier to copy. Below, I'll go through the usage examples for these functions in the order they were written: i.e., from the low-level legendMaker to the high-level deployLegend.
legendMaker allows individual line styles and plot markers to have the value None. This makes it easier to specify custom legends, in particular when combining a line plot without markers, and a list plot without lines. This is motivated by a related answer here, so I posted an example there.
Edit July 14, 2013
A year has passed since the last update to this code, because Mathematica version 9 introduced the new command  PlotLegends which in many cases should make this answer obsolete. However, I tried to keep this answer compatible with versions 8 and 9. This is why this update is necessary, since some functionality was broken in recent Mathematica versions. 
The major changes were in the function extractStyles which tries to guess what lines and markers are being used in a given plot. This relies on the internal structure of the plots, and is therefore fragile. I tried to make it more robust.
I also added usage messages and made sure that autoLegend (the simplest legending function in this answer) accepts the full range of options of legendMaker (the more lower-level legend drawing function). All the examples below are unchanged, except that I added more information at the end.
Options[legendMaker] = 
  Join[FilterRules[Options[Framed], 
    Except[{ImageSize, FrameStyle, Background, RoundingRadius, 
      ImageMargins}]], {FrameStyle -> None, 
    Background -> Directive[Opacity[.7], LightGray], 
    RoundingRadius -> 10, ImageMargins -> 0, PlotStyle -> Automatic, 
    PlotMarkers -> None, ""LegendLineWidth"" -> 35, 
    ""LegendLineAspectRatio"" -> .3, ""LegendMarkerSize"" -> 8, 
    ""LegendGridOptions"" -> {Alignment -> Left, Spacings -> {.4, .1}}}];


legendMaker::usage = 
  ""Create a Graphics object with legends given by the list passed as \
the first argument. The options specify any non-deafult line styles \
(using PlotStyle -> {...}) or plot markers (using PlotMarkers -> \
{...}). For more options, inspect Options[legendMaker]"";

legendMaker[textLabels_, opts : OptionsPattern[]] := 
  Module[{f, lineDirectives, markerSymbols, n = Length[textLabels], 
    x}, lineDirectives = ((PlotStyle /. {opts}) /. 
       PlotStyle | Automatic :> Map[ColorData[1], Range[n]]) /. 
     None -> {None};
   markerSymbols = 
    Replace[((PlotMarkers /. {opts}) /. 
         Automatic :> (Drop[
              Normal[ListPlot[Transpose[{Range[3]}], 
                  PlotMarkers -> Automatic][[1, 2]]][[1]], -1] /. 
             Inset[x_, i__] :> x)[[All, -1]]) /. {Graphics[gr__], 
         sc_} :> Graphics[gr, 
         ImageSize -> (""LegendMarkerSize"" /. {opts} /. 
             Options[legendMaker, 
              ""LegendMarkerSize""] /. {""LegendMarkerSize"" -> 8})], 
      PlotMarkers | None :> 
       Map[Style["""", Opacity[0]] &, textLabels]] /. 
     None | {} -> Style["""", Opacity[0]];
   lineDirectives = PadRight[lineDirectives, n, lineDirectives];
   markerSymbols = PadRight[markerSymbols, n, markerSymbols];
   f = Grid[
     MapThread[{Graphics[{#1 /. None -> {}, 
          If[#1 === {None} || (PlotStyle /. {opts}) === None, {}, 
           Line[{{-.1, 0}, {.1, 0}}]], 
          Inset[#2, {0, 0}, Background -> None]}, 
         AspectRatio -> (""LegendLineAspectRatio"" /. {opts} /. 
             Options[legendMaker, 
              ""LegendLineAspectRatio""] /. {""LegendLineAspectRatio"" -> \
.2}), ImageSize -> (""LegendLineWidth"" /. {opts} /. 
             Options[legendMaker, 
              ""LegendLineWidth""] /. {""LegendLineWidth"" -> 35}), 
         ImagePadding -> {{1, 1}, {0, 0}}], 
        Text[#3, FormatType -> TraditionalForm]} &, {lineDirectives, 
       markerSymbols, textLabels}], 
     Sequence@
      Evaluate[(""LegendGridOptions"" /. {opts} /. 
          Options[legendMaker, 
           ""LegendGridOptions""] /. {""LegendGridOptions"" -> {Alignment \
-> Left, Spacings -> {.4, .1}}})]];
   Framed[f, 
    FilterRules[{Sequence[opts, Options[legendMaker]]}, 
     FilterRules[Options[Framed], Except[ImageSize]]]]];

extractStyles::usage = ""returns a tuple {\""all line style \
directives\"", \""all plot markers\""} found in the plot, in the order \
they are drawn. The two sublists need not have the same length if \
some lines don't use markers ""; 
extractStyles[plot_] := 
 Module[{lines, markers, points, 
   extract = First[Normal[plot]]},(*In a plot,
  the list of lines contains no insets,so I use this to find it:*)
  lines = 
   Select[Cases[Normal[plot], {___, _Line, ___}, Infinity], 
    FreeQ[#1, Inset] &];
  points = 
   Select[Cases[Normal[plot], {___, _Point, ___}, Infinity], 
    FreeQ[#1, Inset] &];
  (*Most plot markers are inside Inset,
  except for Point in list plots:*)
  markers = Select[extract, ! FreeQ[#1, Inset] &];
  (*The function returns a list of lists:*){(*The first return value \
is the list of line plot styles:*)
   Replace[Cases[
     lines, {c__, Line[__], ___} :> 
      Flatten[Directive @@ Cases[{c}, Except[_Line]]], 
     Infinity], {} -> None],
   (*Second return value:marker symbols*)
   Replace[Join[
     Cases[markers//. Except[List][i_Inset, __] :> i, 
       {c__, Inset[s_, pos_, d___], e___} :> If[
        (*markers ""s"" can be strings or graphics*)

        Head[s] === Graphics,
        (*Append scale factor in case it's needed later;
        default 0.01*)
        {s,
         Last[{.01, d}] /. Scaled[f_] :> First[f]
         },
        If[
         (*For strings,
         add line color if no color specified via text styles:*)
             FreeQ[ s, _?ColorQ], Style[s, c], s]
        ],
      Infinity
      ],
     (*
     Filter out Pointsize-legends don't need it:*)

     Cases[points, {c___, 
        Point[pt__], ___} :> {Graphics[{c, Point[{0, 0}]}] /. 
         PointSize[_] :> PointSize[1], .01}, Infinity]
     ], {} -> None]}]

autoLegend::usage = 
  ""Simplified legending for the plot passed as first argument, with \
legends given as second argument. Use the option Alignment -> \
{horizontal, vertical} to place the legend in the PlotRegion in \
scaled coordinates. For other options, see Options[legendMaker] which \
are used by autoLegend."";
Options[autoLegend] = 
  Join[{Alignment -> {Right, Top}, Background -> White, 
    AspectRatio -> Automatic}, 
   FilterRules[Options[legendMaker], 
    Except[Alignment | Background | AspectRatio]]];
autoLegend[plot_Graphics, labels_, opts : OptionsPattern[]] := 
 Module[{lines, markers, align = OptionValue[Alignment]},
  {lines, markers} = extractStyles[plot];
  Graphics[{
    Inset[plot, {-1, -1},
     {Left, Bottom},
     Scaled[1]
     ],
    Inset[
     legendMaker[labels, PlotStyle -> lines, PlotMarkers -> markers, 
      Sequence @@ 
       FilterRules[{opts}, 
        FilterRules[Options[legendMaker], Except[Alignment]]]],
     align,
     Map[If[NumericQ[#], Center, #] &, align]
     ]
    },
   PlotRange -> {{-1, 1}, {-1, 1}}, 
   AspectRatio -> (OptionValue[AspectRatio] /. 
       Automatic :> (AspectRatio /. Options[plot, AspectRatio]) /. 
      Automatic :> (AspectRatio /. 
         AbsoluteOptions[plot, AspectRatio]))]]

Notes for legendMaker:
The horizontal width of the line segment in the legend can be changed with the option ""LegendLineWidth"", and its aspect ratio is set by ""LegendLineAspectRatio"". The size of the markers in the legend is set by ""LegendMarkerSize"" (all these options have reasonable default values), and they can also be passed to the higher-level functions below.
The only required argument for this version of legendMaker is a list of labels. Everything else is optional. I.e., the function automatically determines what to do about the matching line colors and plot marker symbols (if any). 
Plot markers can be defined as String or Graphics objects. To control the line colors, you can specify the option PlotStyle: with PlotStyle -> Automatic, the default plot styles are used. If you have instead prepared the plot with a different list of plot styles, you can enter that here. The option PlotStyle -> None is also allowed. This should be used when labeling a ListPlot that has no connecting lines between the points.
With the setting PlotMarkers -> Automatic, the legend will also display marker symbols according to the default choices that I extract from a temporary ListPlot that is then discarded. The default setting for legendMaker is PlotMarkers -> None.
To make the plots look nice, you can add other options for the legend appearance, e.g.:
opts = Sequence[Background -> LightOrange, RoundingRadius -> 10];

Here I allow all options that Frame can handle, except for ImageSize. 
Now we prepare a plot:
data = {{1, 2}, {3, 4}, {5, 4}};
points = Table[{#1, Log[b, #2]} & @@@ data, {b, 2, 10, 2}];
plot = ListLinePlot[points];

The list labels creates the text that you were asking for:
labels = Table[Row[{Subscript[""Log"", b], x}], {b, 2, 10, 2}]


$\left\{\text{Log}_2x,\text{Log}_4x,\text{Log}_6x,\text{Log}_8x,\text{Log}_{10}x\right\}$

The legend is now displayed as an overlay over the original plot:
newPlot = 
 Overlay[{plot, legendMaker[labels, opts]}, Alignment -> {Right, Top}]


The Overlay that is created here can still be exported and copied even though it's not a graphics box. A good way to copy it to an external editor is to highlight the plot and select Copy As... PDF from the Edit menu (that's at least where it is on Mac OS X).
A different application of legendMaker can be found in this post. That's also a good example for the difference in appearance to the standard Legends package, which many people consider sub-par (it's slow, old-fashioned and even crashes sometimes).
Notes for autoLegend
In response to the comment by Ajasja, I added another layer of automation that makes use of the function legendMaker defined above, but attempts to deduce the colors and marker symbols from the provided plot in a fully automatic way. 
As an example, I took
p = ListPlot[Evaluate[Table[RandomInteger[3 i, 10] + 2 i, {i, 3}]], 
  PlotMarkers -> Automatic, Joined -> True]

and added labels by calling
autoLegend[p, {""Small"", ""Big"", ""Bigger""}, 
 Background -> Directive[LightOrange, Opacity[.5]], 
 Alignment -> {Right, Top}]


The function autoLegend takes the same options as legendMaker, plus the Alignment option which follows the conventions for Overlay.
Here is an example wit graphical markers:
p = ListPlot[Evaluate[Table[RandomInteger[3 i, 10] + 2 i, {i, 3}]], 
  PlotMarkers -> {{Graphics@{Red, Disk[]}, .05}, {Graphics@{Blue, 
       Rectangle[]}, .05}}, Joined -> True];
autoLegend[p, {""Small"", ""Big"", ""Bigger""}, Alignment -> {-.8, .8}]


autoLegend is still limited in the sense that its automatic extraction doesn't yet work with GraphicsGrid or GraphicsRow (but I'll add that at some point). But at least it seems to behave reasonably when you give it several plots at once, e.g. as in this example:
plot1 = Show[Plot[{Sin[x], Sinh[x]}, {x, -Pi, Pi}], 
  ListPlot[Join[{#, Sin[#]} & /@ Range[-Pi, Pi, .5], {#, Sinh[#]} & /@
      Range[-Pi, Pi, .5]]]];
autoLegend[plot1, {""Sin"", ""Sinh""}]


Edit July 5, 2012
By creating the plot legend as an overlay, one gains flexibility because the legend created with legendMaker doesn't have to be ""inside"" any particular graphics object; it can for example overlap two plots (see also my MathGroup post). 
However, overlays aren't so convenient in other respects. Importantly, the graphics editing tools that come with Mathematica can't be used directly to fine-tune the plot and/or legend when it's in an overlay. In an Overlay, I can't make both the plot and legend selectable (and editable) at the same time. 
That's why I changed autoLegend such that it uses Insets instead of Overlay. The positioning just requires a little more code because Inset needs   different coordinate systems to determine its placement and size. To the user, the placement happens in pretty much the same way that the Alignment works in Overlay: you can either use named positions such as Alignment -> {Left, Bottom} or numerical scale factors such as Alignment -> {0.5, 0}. In the latter case, the numbers range from -1 to 1 in the horizontal and vertical direction, with {0, 0} being the center of the plot.
With this method, the plot is fully editable, as shown in the movie below. The movie uses a differently named function deployLegend, but from now on we can define deployLegend = autoLegend
deployLegend[p, {""Label 1"", ""Label 2"", ""Label 3""}]


This is a screen capture of how the legend is now available as part of the graphics object. First, I make a color change in one of the labels to show that the legend preserves formatting. Then I double-click on the Graphics and start editing. I select the legend, making sure I don't have parts of the plot selected. Then I drag the legend around and rotate it. 
These manipulations leverage the built-in editing tools, so I didn't see any reason to use Locators to make the legend movable, as was done with individual labels in this post.
The positioning of the legend is not restricted to the inside of the plot. To make a legend appear off to the side, you just have to Show the plot with a setting for PlotRegion that leaves space wherever you need the legend to go.
Here is an example:
param = ParametricPlot[{{3 Cos[Pi t], 
     Sin[2 Pi t]}, {1 + Cos[Pi t], 
     Sin[2 Pi t + Pi/3]}}, {t, 0, 2}];

autoLegend[param, {""Curve 1"", ""Curve 2""}]


So to move the legend out of the picture, you might do this:
autoLegend[
 Show[param, PlotRegion -> {{0, .7}, {0, 1}}], {""Curve 1"", ""Curve 2""},
  Alignment -> {Right, Center}]


The legend placement is relative to the enclosing image dimensions, as you can see - not relative to the plot range of the ParametricPlot. The plot region may not be the only thing you want to change, though. autoLegend tries to determine the total aspect ratio automatically, but we see that there is a bit too much white space at the top now. For that reason, I also added the option AspectRatio so we can set a manual value:
paramWithLegend = autoLegend[
 Show[param, PlotRegion -> {{0, .7}, {0, 1}}], {""Curve 1"", ""Curve 2""},
  Alignment -> {Right, Center}, AspectRatio -> .25]

This produces the same picture as above but with less white space on top. 
If you want to change the relative size of the legend and/or plot, I'd suggest playing around with ImageSize and Magnify, as in this example:
Magnify[Show[paramWithLegend, ImageSize -> 300], 2]

For some code in autoLegend, I should credit the answer to the question ""ShowLegend values"" where I made a similar legend for color bars in contour plots.
If autoLegend doesn't cut it,  use legendMaker
Limitations of the automatic style recognition in autoLegend may occur if you combine different types of plot with Show, as in the following example from the comments:
myplots = 
  Show[Plot[Sin[x], {x, 0, 2 Pi}, PlotRange -> All, 
    PlotStyle -> {Red, Thick}], 
   ListPlot[
    Table[{x, Sin[x] + RandomReal[{-0.1, 0.1}]}, {x, 0, 2 Pi, 0.1}], 
    PlotRange -> All, PlotMarkers -> Automatic, Joined -> True]];

myStyles = extractStyles[myplots]


{{Directive[Hue[0.67,0.6,0.6],RGBColor[1,0,0],Thickness[Large]],Directive[Hue[0.67,0.6,0.6]]},{\[FilledCircle]}}

Overlay[{myplots,
  legendMaker[{""Sin(x)-theory"", ""Sin(x)-data""},
   PlotStyle -> myStyles[[1]],
   PlotMarkers -> Prepend[
     myStyles[[2]], """"]]}, Alignment -> {Right, Top}]


Here, the problem is that we have two lines with distinct styles, but not the same number of distinct plot markers (just \[FilledCircle]). To get one line with and one line without marker, I call legendMaker with a two-element list for PlotMarkers, one of which is an empty string """".
"
"list manipulation - Part extraction vs functions like First, Last?","
You cannot make assignments to First, Last, Rest, or Most the way you can with Part.  Therefore, there is greater consistency in using Part for all operations.  See this answer for an example of and argument for this consistency.
Also, you must change functions if you need to update your code to index a different element or change an element to a Span.  By using Part from the beginning you have the greatest flexibility without changing functions.  This can make comparing different code revisions easier.  It can also make a user defined function more flexible, e.g.: f[x_, part__ : 1] := foo @ x[[part]]
Less importantly x[[1]] is more terse than First@x, especially in the FrontEnd using 〚 〛, and I am a fan of terse coding.
"
kernel - Unsaved notebook is crashing: is there any way I can save the state of the MathKernel before I kill it?,"
If there is such a thing, I want to know it for windows and linux based OS'es also.
Battling with the same problem I have found 2 partial solutions:

ctrl+s before hitting shift+enter (I think it's command+s for Mac's)
if you ignored #1 then you might still be able to screenshot the code and reenter it

I have tried TextRecognize to restore the text from the image, but it's still a bit off.

Edit:
If your UI is not locked, you can 

Quit the kernel, Evaluation -> quit kernel -> local (or add a shortcut for it) 
Interrupt evaluation

on notebook interfaces: alt + , or Cmd + Option + .
on text-based interfaces: ctrl + C


"
plotting - Plot legend inside a Show,"
Use ShowLegend when you need to use the package's functionality with Show. Here's an example:
eqns = {Sin[3 Tanh[#]], Sin[Erf[#]]} &;
colors = {Blue, Red};
legends = TraditionalForm /@ eqns[x];

plot1 = Plot[Evaluate@eqns[x], {x, 0, π}, PlotStyle -> colors, 
    Filling -> {1 -> {{2}, LightGreen}}];
plot2 = ListPlot[Select[RandomReal[{0, Pi}, {1000, 2}], 
    IntervalMemberQ[Interval[Sort[eqns[First@#]]], Last@#] &], PlotStyle -> Darker@Green];

ShowLegend[Show[plot1, plot2], {{Graphics[{#1, Thick, Line[{{0, 0}, {1, 0}}]}], #2} & @@@ 
   Transpose[{colors, legends}], LegendPosition -> {-0.65, -0.5}, 
   LegendSpacing -> 0, LegendShadow -> None, LegendSize -> 0.6}]


"
calculus and analysis - Integration with vector coefficients,"
It helps to do a little analysis to simplify the problem.  This expression is integrating over a line through $\mathbf{b}$ in the direction of $\mathbf{a}$.  By choosing a suitable coordinate system you can arrange for $\mathbf{a} = (x,0,0)$ where, to assure a unit Jacobian, $x = \|\mathbf{a}\|$ (and you can even make $\mathbf{b} = (0,b,0)$ if you like, but let's just stop here and generically take $\mathbf{b} = (a,b,c)$).  Brute force now succeeds:
ClearAll[x, a, b, c];
Integrate[{x, 0, 0} μ / Norm[{x, 0, 0} μ - {a, b, c}]^3, 
  {μ, -Infinity, Infinity}, 
  Assumptions -> Im[a] == 0 && Im[b] == 0 && Im[c] == 0 && Im[x] == 0 && a b c != 0]

The output, after 5 seconds, is
{ConditionalExpression[(2 a Abs[x])/((b^2 + c^2) x^2), x != 0], 0, 0}

Change back to the original coordinates to obtain the general answer.
The key is to specify the assumptions implicit in the question: namely, that these are real vectors and that the line does not pass through the origin (where the integral diverges).
"
What is an efficient way of selecting multiple colors via Manipulate?,"
With this one you just click the circle to be color-edited. No need to pick an index number first.
DynamicModule[{x = 1},
 Manipulate[c[[x]] = color;
  Grid[
   Table[
    Setter[Dynamic[x, (color = c[[#1]]; x = #1) &], i*4 + j, 
     Graphics[{FaceForm[c[[i*4 + j]]], Disk[]}, ImageSize -> 40]
     ], {i, 0, 2}, {j, 4}
    ]
   ], {color, Red},
  Initialization :> {c = ConstantArray[Black, 12]}]
 ]


Note that I used Dynamic's alternative syntax form, where you determine what should happen if the argument needs to be updated. In this case I use it to set the starting color of the color selector to be the current color of the circle being clicked. Otherwise the color of the circle would be set by the current setting of the color setter. This may be or may not be how you want the control to behave. Just change it to Dynamic[x] if you want to have the other behavior.
"
plotting - Aligning plot axes in a graphics object,"
This is a common (and very big) annoyance when creating graphics with subfigures.  The most general (but somewhat tedious) solution is setting an explicit ImagePadding:
GraphicsColumn[
 {Show[a, ImagePadding -> {{40, 10}, {Automatic, Automatic}}], 
  Show[b, ImagePadding -> {{40, 10}, {Automatic, Automatic}}]}]


This is tedious because you need to come up with values manually.  There are hacks to retrieve the ImagePadding that is used by the Automatic setting.  I asked a question about this before.  Using Heike's solution from there, we can try to automate the process:
padding[g_Graphics] := 
 With[{im = Image[Show[g, LabelStyle -> White, Background -> White]]},
   BorderDimensions[im]]

ip = 1 + Max /@ Transpose[{First@padding[a], First@padding[b]}]

GraphicsColumn[
 Show[#, ImagePadding -> {ip, {Automatic, Automatic}}] & /@ {a, b}]

The padding detection that's based on rasterizing might be off by a pixel, so I added 1 for safety.
Warning: the automatic padding depends on the image size!  The tick marks or labels might ""hang out"" a bit.  You might need to use padding@Show[a, ImageSize -> 100] to get something that'll work for smaller sizes too.
I have used this method myself several times, and while it's a bit tedious at times, it works well (much better than figuring out the image padding manually).
"
How to Map a subset of list elements to a function?,"
You might first partition your list and then use Map as usual :
f[#[[1]], #[[2]]] & /@ Partition[{1,2,3,4}, 2, 1]

(* {f[1, 2], f[2, 3], f[3, 4]} *)

"
plotting - GridLines in LogPlot or LogLogPlot,"
After some fiddling around I came up with this function:
Clear[gitter]
gitter[xspec_, yspec_, logPlot_: False] :=

  Module[{min, max, d, xlines, ylines, i},
   xlines = ylines = None;
   Switch[xspec,
    Automatic, xlines = Automatic,
    {_?NumericQ, _?NumericQ, _?NumericQ},
    {min, max, d} = xspec;
    xlines = Range[min, max, d],
    {_?NumericQ, _?NumericQ, _List},
    {min, max, d} = xspec;
    If[logPlot == False,
     xlines = (Log10[#] &) /@ Flatten[Table[10^i*d, {i, min, max}]],
     xlines = Flatten@Table[10^i d, {i, min, max}]]
    ];
   Switch[yspec,
    Automatic, ylines = Automatic,
    {_?NumericQ, _?NumericQ, _?NumericQ},
    {min, max, d} = yspec;
    ylines = Range[min, max, d],
    {_?NumericQ, _?NumericQ, _List},
    {min, max, d} = yspec;
    If[logPlot == False,
     ylines = (Log10[#] &) /@ Flatten[Table[10^i*d, {i, min, max}]],
     ylines = Flatten@Table[10^i d, {i, min, max}]]];
   {xlines, ylines}];

It handles three cases:
(1) Linear scale: The parameters have the form {min, max, step}
(2) logarithmic scale in a normal Plot: The parameters have the form {min, max, istOfValues}
(3) LogPlot or LogLogPlot: as in (2) but the optional Parameter LogPlot has to be set to True.  
Examples: 
grid = gitter[{-1, 1, {1, 2, 5, 7}}, {-5, 5, {1, 2, 5, 7}}, True];
lp = LogLogPlot[2 x^5/3, {x, 0.1, 10}, GridLines -> grid, 
  PlotRangePadding -> 0, AspectRatio -> 1, 
  Ticks -> {Automatic, Table[10.^i, {i, -5, 5}]}]

gives:
 
and
yticks = Tickmarken[0, 5, {1}, {2, 3, 5, 7}];
gitter = Gitter[{-2, 10, 1}, {0, 5, {1, 2, 3, 5, 7}}];
plot = Plot[Log10[2 E^x], {x, -2, 10}, Ticks -> {Automatic, yticks}, 
  GridLines -> gitter]

gives:

Tickmarken is a function, I use to make Ticks.
"
numerical integration - Solving an ODE numerically,"
If you are willing to settle for $y(5) = 0$ instead of $y(\infty) = 0$, the commands to solve it are
sol = First@NDSolve[
  {-2 x y'[x] == 47.21` (-3.9582` + 10.586` x - 8.0588` x^2 + 3.048` x^3 - 
         0.6087` x^4 + 0.0614` x^5 - 0.0025` x^6)^2 Erfc[x] + y''[x], 
   y[0.6] == 0, y[5] == 0}, 
   y, {x, 0.6, 5}]


Plot[y[x] /. sol // Evaluate, {x, 0.6, 5}]


Increasing the upper bound from 5 to a larger number won't change much, so I believe using $y(5) = 0$ might be a good enough approximation.
There are completely analogous examples in the NDSolve documentation.  Please check them.
"
How to specify the InputField as a String in Manipulate,"
I thought this was undocumented, but actually it just seems to be obscure. The documentation for ControlType mentions, under the ""More Information"" section,

Arbitrary controls can be set up in Manipulate by giving control specifications of the form {u, func}.

So,
Manipulate[InputForm[col], {col, ""AB"", InputField[#, String] &}]

gives (with a different string entered for demonstrative purposes):

"
evaluation - Force function to make assumptions about its input variables in Mathematica,"
The following just works:
Assuming[x > 0, Simplify[Sqrt[x^2]]]

(*
==> x
*)

Your code:
n[x_/; x > 0 && Element[x,Reals]]:=x^(1/2);
n[x_]:=Assuming[x > 0 && Element[x,Reals],FullSimplify[x^(1/2)]];

doesn't work because the x that is passed  after a call of n[x^2] isn't x but x^2. So you're assuming x^2>0 or Element[x^2,Reals].
"
"programming - Finding a ""not-shortest"" path between two vertices","
You can try giving your edges random weights so that FindShortestPath is forced to take a different path. Here are some different possible paths —
Table[HighlightGraph[lab = Graph[edges, EdgeWeight -> RandomInteger[1000, Length[edges]]], 
    PathGraph[s = FindShortestPath[lab, 1, 125]], VertexLabels -> ""Name"",
    ImagePadding -> 10, GraphHighlightStyle -> ""Thick"", ImageSize -> 600], {6}
] ~Partition~ 3 // Grid


"
graphics - Using one table for multiple arguments,"
Adding an additional (optional) parameter for increment, define
 datalistPlot[a_Integer, b_Integer, c_Integer, d_Integer, e_Integer: 1] := 
 Module[{left = Mean@RandomInteger[{a, b}, c]},{
 Transpose@
 Table[{left=(n - 1) left/n + RandomInteger[{a, b}]/n, n left/(n - 1)}, {n, c, d, e}], 
 {c, d}, 
 (a + b)/2
 }] 
 // ListLinePlot[#[[1]], 
 GridLines -> {None, {{#[[3]], Directive[Red, Thick]}}}, 
 DataRange -> #[[2]], PlotRange -> {Automatic, #[[3]] + {-1, 1}}] &

and use as
datalistPlot[list[0, 10, 10, 500, 10]

to get

"
functions - Mapping and Interpolation,"
Your question isn't very clear, but I think you need the Rescale function, especially its 3 argument form:
Rescale[#, {1, 100}, {7, 20}] & /@ Range[1, 100, 5] // N
(* Out[1]= {7., 7.65657, 8.31313, 8.9697, 9.62626, 10.2828, 10.9394, 11.596, 12.2525, 12.9091, 
    13.5657, 14.2222, 14.8788, 15.5354, 16.1919, 16.8485, 17.5051, 18.1616, 18.8182, 19.4747}
 *)

"
plotting - CustomTicks and small ranges,"
As soon as I posted, I realized I could check whether there were any options for LinTicks that might be useful:
Options@LinTicks // TableForm

Scanning that list, I saw:
TickLabelFunction -> Automatic

On a hunch, I added 
TickLabelFunction -> TraditionalForm

To the ticks definition from the question, and things worked:

"
keyboard - Custom setting of HOME and END keys on mac,"
The file KeyEventTranslations.tr which can be found in the directory $InstallationDirectory/SystemFiles/FrontEnd/TextResources/Macintosh couples key events to actions in Mathematica. The two lines that define the behaviour of Home and End are
Item[KeyEvent[""Home""], ""ScrollNotebookStart""],
Item[KeyEvent[""End""], ""ScrollNotebookEnd""],

To change the behaviour of these two keys you could replace ""ScrollNotebookStart"" and ""ScrollNotebookEnd"" to ""MoveLineBeginning"" and ""MoveLineEnd"", respectively. 
To be on the safe side, you could copy the file to the directory $UserBaseDirectory/SystemFiles/FrontEnd/TextResources/Macintosh first and edit that file instead of the original in $InstallationDirectory. 
"
Import DCD (CHARMM/NAMD binary trajectory) file,"
I ported most of the matlab package to Mathematica. Here is the result
(*Some utility functions*)
SetAttributes[MapShowIt, {HoldAll, Listable}];
MapShowIt[code__] := MapShowIt[{code}];
MapShowIt[code_] := With[{y = code}, Defer[code = y]]

ClearAll[Puts]
SetAttributes[Puts, HoldAll];
Options[Puts] = {DisplayFunction -> Shallow};
$VerbosePrint = False;
Puts[msg_, data_, opt : OptionsPattern[]] := 
  If[$VerbosePrint, Print[msg, OptionValue[DisplayFunction][data]]];
Puts[msg_List] := If[$VerbosePrint, Print[MapShowIt[msg]]];
Puts[msg_] := If[$VerbosePrint, Print[msg]];
(*warning this is still unsafe ... it should be done as \
answered  herehttp://mathematica.stackexchange.com/a/4189/745*)

Unprotect[Dot];
SetAttributes[Dot, HoldRest];
Dot[h_, key_Symbol | key_String] := 
  System`Utilities`HashTableGet[h, ToString[Unevaluated[key]]];
Dot /: Set[Dot[h_, key_Symbol | key_String], value_] := (
   Quiet[
      System`Utilities`HashTableRemove[h, ToString[Unevaluated[key]]]
    , System`Utilities`HashTableRemove::norem];
   System`Utilities`HashTableAdd[h, ToString[Unevaluated[key]], 
    value]);
Protect[Dot];
On[Assert];

ClearAll[readDCDHeader];
Options[readDCDHeader] = {""Verbose"" -> False};
readDCDHeader::nonintframes = 
  ""Number of frames calculated from files size (`1`) is not an \
integer!"";
readDCDHeader::diffframes = 
  ""Header claims `1` frames, but there are `2` frames!"";
readDCDHeader[fileName_, opts : OptionsPattern[]] :=
  Module[{str, magicnum, h, i, newsize, newsize1, numlines, fint}, 
   Block[{$VerbosePrint = OptionValue[""Verbose""]},
      h = System`Utilities`HashTable[];

      str = OpenRead[fileName, BinaryFormat -> True];


      fint = BinaryRead[str, ""Integer32""];
      (*if we don't read an 84 then try to reverse the endianes
      If[fint=!=84,(*then*)
        Close[str];
       str= OpenRead[fileName,BinaryFormat -> True,
    ByteOrdering->-$ByteOrdering];]*)
      Assert[fint == 84, ""First integer must be 84""];
      h.stream = str;
      magicnum = BinaryReadList[str, ""Character8"", 4];

      Assert[magicnum == {""C"", ""O"", ""R"", ""D""}, ""CORD not present""];

      h.nset = BinaryRead[str, ""Integer32""];
      h.istart = BinaryRead[str, ""Integer32""];
      h.nsavc = BinaryRead[str, ""Integer32""];

      (*read free indexes*)
      SetStreamPosition[str, 40];
      h.numfree = BinaryRead[str, ""Integer32""];

      Puts[{h.nset, h.istart, h.nsavc, h.numfree}];

      (*find out if is charmm DCD*)
      SetStreamPosition[str, 84];
      i = BinaryRead[str, ""Integer32""];
      If[i == 0, (*then*)
         h.charmm = False;
       ,(*else*)
       h.charmm = True;

       (* check for extra block*)
       SetStreamPosition[str, 48];
       i = BinaryRead[str, ""Integer32""];
       h.charmm$extrablock = (i == 1);

                     SetStreamPosition[str, 52];
                      i = BinaryRead[str, ""Integer32""];
       h.charmm$4dims = (i == 1);
       ];

      Puts[{h.charmm, h.charmm$extrablock, h.charmm$4dims}];

      (*read the timestep*)  
      SetStreamPosition[str, 44];
      If[h.charmm, (*then*)
       h.DELTA = BinaryRead[str, ""Real32""];
       ,(*else*)
       h.DELTA = BinaryRead[str, ""Real64""];];
      h.step = h.DELTA;

      (*get the title*)
      SetStreamPosition[str, 92];
      newsize = BinaryRead[str, ""Integer32""];
      numlines = BinaryRead[str, ""Integer32""];
      (*TODO check for curoupted Ntitle values*)
      h.title = 
     StringJoin@BinaryReadList[str, ""Character8"", numlines*80];
      newsize1 = BinaryRead[str, ""Integer32""];
      Assert[newsize == newsize1];
      Puts[h.title];
      i = BinaryRead[str, ""Integer32""]; 
    Assert[i == 4, ""4 must be read before num of atoms""];
      h.numatoms = BinaryRead[str, ""Integer32""];
      h.N = h.numatoms;
      i = BinaryRead[str, ""Integer32""]; 
    Assert[i == 4, ""4 must be read after num of atoms""];
      Puts[{h.DELTA, h.N}];

      (*love this comment from the original matdcd package*)
      (*stuff with freeindexes.  Just smile and nod.*)
      If[ h.numfree =!= 0, (*then*)
          i = BinaryRead[str, ""Integer32""];  (* should be N-
     NAMNF*4*)

     h.freeindexes = BinaryReadList[str, ""Integer32"", h.N - h.numfree];
          i = BinaryRead[str, ""Integer32""];  (* should be N-
     NAMNF*4*)
       ];

    h.headerend = StreamPosition[str];  
    (*calculate one frame size in bytes*)
    h.framesize = 3*(h.numatoms*4 + 2*4(*for the blocksize*))
        + If[h.charmm$extrablock, 12*4 + 2*4, 0]
        + If[h.charmm$4dims, +h.numatoms*4 + 4*2, 0];

    h.numframes = (FileByteCount[fileName] - h.headerend)/h.framesize;
    (* Warn if noninteger frame number and if the actuaal frames \
differ from h.nset*)
    If[Head[h.numframes] =!= Integer,(*then*)
       Message[readDCDHeader::nonintframes, h.numframes]];
    If[Head[h.numframes] != h.nset,(*then*)
       Message[readDCDHeader::diffframes, h.nset, h.numframes]];

    Return[h];
    ]];


ClearAll[readDCDStep];
Options[readDCDStep] = {""Verbose"" -> False,

   ""Atoms"" -> All(*or a one based list of atoms to take*)};
readDCDStep[h_System`Utilities`HashTable, opts : OptionsPattern[]] :=


  Module[{x, y, z, str, blocksize, ind}, 
   Block[{$VerbosePrint = OptionValue[""Verbose""]},
      ind = OptionValue[""Atoms""];
      Assert[h.numfree == 0, 
     ""Fixed atoms anad free indices are not supported""];
      str = h.stream;

      If[h.charmm && h.charmm$extrablock, (*then*)
       (*unit cell info*) 
         blocksize = BinaryRead[str, ""Integer32""];
         Puts[
      ""Skipping unit info cords. (blocksize: "" <> 
       ToString[blocksize] <> "")""];
         Skip[str, ""Byte"", blocksize];

         Assert[blocksize == BinaryRead[str, ""Integer32""], 
      ""Wrong blocksize in extra block ""];
       ];
     (* Get x coordinates *)
      blocksize = BinaryRead[str, ""Integer32""];
      Puts[
     ""Getting x cords. (blocksize: "" <> ToString[blocksize] <> "")""];
      x = BinaryReadList[str, ""Real32"", blocksize/4]; 
      If[Head[ind] == List, x = Part[x, ind]];
      Puts[""x:\n"", x];
      Assert[blocksize == BinaryRead[str, ""Integer32""], 
     ""Wrong blocksize in x coords""];

      (* Get y coordinates *)
      blocksize = BinaryRead[str, ""Integer32""];
      Puts[
     ""Getting y cords. (blocksize: "" <> ToString[blocksize] <> "")""];
      y = BinaryReadList[str, ""Real32"", blocksize/4];
      If[Head[ind] == List, y = Part[y, ind]];
      Puts[""y:\n"", y];
      Assert[blocksize == BinaryRead[str, ""Integer32""], 
     ""Wrong blocksize in y coords""];

      (* Get z coordinates *)
      Puts[
     ""Getting z cords. (blocksize: "" <> ToString[blocksize] <> "")""];
      blocksize = BinaryRead[str, ""Integer32""];
      z = BinaryReadList[str, ""Real32"", blocksize/4];
      If[Head[ind] == List, z = Part[z, ind]];
      Puts[""z:\n"", z];
      Assert[blocksize == BinaryRead[str, ""Integer32""], 
     ""Wrong blocksize in z coords""];

      (*skip 4th dimension if it exists*)
      If[h.charmm && h.charmm$4dims,(*then*)
         Puts[""Skipping w cords.""];   
         blocksize = BinaryRead[str, ""Integer32""];
                       Skip[str, ""Byte"", blocksize];

     Assert[blocksize == BinaryRead[str, ""Integer32""], 
      ""Wrong blocksize in 4th dim""];
       ];
    Assert[Length[x] == Length[y] == Length[z], 
     ""Wrong size of x or y or z""];  
    Return[Developer`ToPackedArray[Transpose@{x, y, z}]];
    ]];

ClearAll[CloseDCD];
CloseDCD[h_System`Utilities`HashTable] := Close[h.stream];

ClearAll[ImportDCD];
Options[ImportDCD] = Evaluate[Options[readDCDStep]];
ImportDCD[fileName_, options : OptionsPattern[]] :=
  Module[{h, data, ropts, opts}, 
   Block[{$VerbosePrint = OptionValue[""Verbose""]},
      opts = 
     DeleteDuplicates[{options}~Join~Options[ImportDCD], 
      ToString[First[#1]] == ToString[First[#2]] &];
      Puts[opts];  
      h = readDCDHeader[fileName, Verbose -> OptionValue[""Verbose""]];

      ropts = Evaluate[FilterRules[opts, Options[readDCDStep]]];
      data = (readDCDStep[h, ropts])
                  & /@ Range[h.numframes];
      CloseDCD[h];

      Return[data]
    ]];

Some example usage:

Read the header
h = readDCDHeader[""wat.dcd"", Verbose -> True];
CloseDCD[h];
Read one step
h = readDCDHeader[""wat.dcd"", Verbose -> True];
data = readDCDStep[h, Verbose -> True];
Short[data]
CloseDCD[h];
Import the whole trajectory
data = ImportDCD[""wat.dcd"", Verbose -> False];
Dimensions[data]
(*and for fun plot it:*)
Manipulate[
 pdata = Sphere[#] & /@ data[[i]];
 Graphics3D[pdata]
 , {i, 1, Length[data], 1}]


Its also possible to specify a list of one based indexes of which atoms to load using the ""Atoms"" option. 
I really should put this on github and convert it into a package...
"
functions - Plotting a simple relationship with Plot[] results in empty graph,"
It's important to realize that when setting something up of the type:
f[x_]:=x

That you are setting a replacement rule, not creating a function. See Functions vs. patterns for a further discussion of this. 
In the current situation, what you wrote has the following effect. First, you define:
plotFunction[b_, c_] := Plot[a, {d, 0, 10}];

when you call
plotFunction[2, 3]

MMA does something like the following. ""Oooh, I found a pattern that matches plotFunction[b_, c_], I need to replace it, and then evaluate it!"" Replacing it makes the right hand side look like:
Plot[a, {d, 0, 10}]

Since there wasn't anything for b and c to replace, the above is what MMA will now evaluate. Evaluating the expression, it says ""Ooooh, oooh, I know how to deal with a!"", so it replaces it:
Plot[(b + c)/d, {d, 0, 10}]

Then it tries to actually call the replacement-rule (""built-in-function"") Plot which fails, since b and c are not numbers, as you saw. However, if you define:
a[b_,c_,d_]=(b + c)/d    
plotFunction[b_, c_] := Plot[a[b, c, d], {d, 0, 10}];

And call:
plotFunction[2, 3]

MMA first replaces plotFunction with:
Plot[a[2, 3, d], {d, 0, 10}]

Then evaluates that, at which point it sees that there is another pattern it knows how to deal with (a[b_,c_,d_]=(b + c)/d) and replaces that:
Plot[(2 + 3)/d, {d, 0, 10}]

And only then plots it, which results in the correct plot.
For dealing with these types of replacement problems, I strongly suggest the use of WReach's traceView functions. For Plots, this doesn't always help, but can be instructive.
"
How to programmatically create a Manipulate in another Manipulate?,"
EDIT to make the sliders work, in response to comments:
Here's one possible solution, wrapping your inner Manipulate in With statement that defines both the thing that you want to manipulate, and the Sequence of controls, like so:
Manipulate[
 With[{
   value    = Column[Table[x[i], {i, 1, n}]],
   controls = Sequence @@ Table[{{x[i], 0.5}, 0, 1}, {i, 1, n}]},
  Manipulate[
   value,
   controls]],
 {n, Range[6]}]

Both value and controls need to be defined in the same place because Manipulate, like some other constructs (including Module, Function and RuleDelayed) does some sort of symbol renaming for expressions inside of it, and you need the x in value to be the same x in controls.
This gives you a setup that looks like this: 

If you try it out in a notebook, you will have n sliders in the inner Manipulate.
"
plotting - Align Array Plots - Mathmatica Stack Exchang,"
In this particular instance, you can align the two array plots within a row by specifying each ImageSize to have the form {Automatic, h}, for some common h, and also making PlotRangePadding and ImagePadding both be none, like so:
Row[{
  ArrayPlot[List /@ lista, ImageSize -> {Automatic, 250}, 
   Frame -> False,
   PlotRangePadding -> None, ImagePadding -> None],
  ArrayPlot[Transpose@listb, AspectRatio -> 1/GoldenRatio,
   ImagePadding -> None, PlotRangePadding -> None,
   ImageSize -> {Automatic, 250}, Frame -> None]}
]

This yields:

"
Front-end glitch when interacting with dynamic content,"
Upgrading to a newer computer solved the problem. Perhaps it was RAM- or grpahics-card-related, we'll never know.
"
Add lists with unequal lengths together to create a matrix,"
I don't have a free kernel to try your question on, so here's a smaller generalized approach that I could construct in my head. In the end, I'll mention how you can adapt it to yours.
First, consider a non-rectangular list similar to yours:
list = {{{1, a}, {2, b}}, 
        {{3, a}, {2, c}, {4, f}}, 
        {{3, b}, {6, f}, {4, c}, {5, e}}};

The output expected here is a 3x6 matrix with each column corresponding to the unique elements and each row having the corresponding element or zero. Obtaining the unique elements and constructing a larger matrix, as the following, we get:
With[{un = Union@Flatten@list[[All, All, 1]]},
    (un /. Rule@@@#&)/@list /. _Integer -> 0
]

(* Out[1] = {{a, b, 0, 0, 0, 0}, 
             {0, c, a, f, 0, 0}, 
             {0, 0, b, c, e, f}} 
*)

which, I believe, is what you want. If you want the first row to be the list of unique elements, simply join un with the rest as:
With[{un = Union@Flatten@list[[All, All, 1]]},
    {un} ~Join~ ((un /. Rule@@@#&)/@list /. _Integer -> 0)
]

(* Out[2]= {{1, 2, 3, 4, 5, 6}, 
            {a, b, 0, 0, 0, 0}, 
            {0, c, a, f, 0, 0}, 
            {0, 0, b, c, e, f}} 
*)

Now the only change that's required for this to work on your data is to use _SQLDateTime instead of _Integer in the With construct above.
"
"functional style - Composite graphics with Row, Column, data aggregation and layout control","
This is more an idea than an answer.
That kind of graphical output seems ideal for multi cell output. This way, if the output is very long, Mathematica handles the page breaks for you (in case you need to print or generate a PDF report).
Try this:
CellPrint /@ Table[Graphics[{Gray, Rectangle[{0, 0}, {10, 1}]}], {10}]


"
Printing a Dynamic variable inside Dynamic,"
Short answer
For me a Print from within a Dynamic goes to the Messages notebook. Have you checked that with a very simple case? If I evaluate this:
Column[{Slider[Dynamic[x]],Dynamic[Print[x];x]}]
and play with the slider, the Messages notebook will be opened and the x-values are printed to it. If that is not also happening for you, you should provide more detailed information (version, operating system, any special settings?)
Debugging and Organization of User Interface code
Honestly, I think there are some misunderstandings in your code fragment about how to use Dynamic, so I think your real problem is that you don't know how to efficiently organize and debug your user interface code. It doesn't become clear from neither your example nor your description what the complications with your code actually are, so I can just give some general advice. 
First of all I would consider it essential to separate any programming logic from the user interface functionality. I would absolutely discourage to use code within a Dynamic to update variables (or even do parts of your calculation) as a side effect, as e.g. Dynamic[{n, xVariable = mQ[n]}] does. I don't think that Dynamic was ever meant to be used like that.
If you want to create a 3D-plot from the values of many sliders, then write a function which accepts all those values as arguments and calculates the 3D-plot. Keep this function completely free from any user interface code, that is any Dynamic whatsoever. This function can be debugged and tested in the usual way (using Print, Trace or the debugger). When it produces the plot you want, only in the end write a user interface that makes use of that function. From what you described even a simple Manipulate would do, e.g.:
complicatedPlot3D[a_, b_, c_] := 
 Plot3D[x^a + y^b - x*y^c, {x, -1, 1}, {y, -1, 1}]
Manipulate[
 complicatedPlot3D[a, b, c], {a, 1, 5}, {b, 2, 5}, {c, 5, 6}]
If you find a Manipulate will not provide enough flexibility, I think you should try to learn as much as possible from the tutorials on the topic before you try to build something more complicated on your own. I would consider Introduction to Dynamic a must read and Advanced Dynamic Functionality to also be helpful (reading them in the documenation center and actually executing the examples is to be recommended). 
Additional Remarks on Example Code
There are some details in the example code that -- at least without a larger picture -- do not seem to make much sense to me:

It seems useless to wrap a Dynamic around everything. Doing so will actually not do anything because all appearances of the values that are changed are in nested Dynamics. If there would be such expressions which were not nested, it would redefine the functions mQ and mV and recreate the sliders on every change of n or t, but neither of these does in any way depend on those variables. In that latter case the sliders would also start to behave strangely.
Neither the second argument Automatic nor the ContinuousAction->False option to the nested Dynamic do seem to achieve anything.
As it is written, it uses the product of lists to arrange it's various parts. The product is probably just a typo and the whole construct looks more like an accident altogether. There are special functions which allow to control the arrangement of the various parts of a gui, like Grid, Column or Row.
Your question about Print and the placement of ; make me believe that you are not fully aware of the difference between the return value that any expression will give on evaluation and the side effect of writing to a notebook that Print achieves and how all that is linked to the dynamic functionality.

Basically I think the answer of @CHM already gives you something that will work, but I think it might make sense to go one step further and remove all things that seem strange. Here is a version that would do what your example does:
mQ[n_] := 
  75.63510582933174 - 35.87130621205199 n + 86.18343750838301 n^2 - 
   55.324190072519976 n^3;
mV[t_] := -29.619999999999976 + 5.499999999999998 t + 
   18.333333333333325 t^2;

Grid[{
  {Slider[Dynamic[n, (n = #; xVariable = mQ[n]) &]], 
   Dynamic[{n, xVariable}]}, {Slider[
    Dynamic[t, (t = #; yVariable = mV[t]) &]], 
   Dynamic[{t, yVariable}]},
  {Dynamic[xVariable + 2 - yVariable], SpanFromLeft}
  }]

These are the changes: function definitions are made outside of the user interface code, I removed any arguments and options that are not necessary and arranged all parts of the user interface in a Grid. Also I do now set xVariable and yVariable in the functions given as second argument to the Dynamic in the sliders. All other Dynamic are now only showing current values and have no side effects. The overall Dynamic did go away altogether, since it only will make a difference in the initialization of the code, which I will address in the following paragraph.
This code has now two drawbacks, one of that you probably tried (and partially did) solve with that overall Dynamic: 1) the function definitions will not automatically be defined when the resulting gui is shown with a new Kernel and 2) all variables are global. This both can be solved by making proper use of DynamicModule, which would look like this:
DynamicModule[{n = 0, t = 0, xVariable, yVariable},
 xVariable = mQ[n];
 yVariable = mV[t];
 Grid[{{
    Slider[Dynamic[n, (n = #; xVariable = mQ[n]) &]],
    Dynamic[Row[{
       ""n="", NumberForm[n, {5, 3}],
       "", x="", NumberForm[xVariable, {5, 3}]
       }]]
    }, {
    Slider[Dynamic[t, (t = #; yVariable = mV[t]) &]],
    Dynamic[Row[{
       ""t="", NumberForm[t, {5, 3}],
       "", y="", NumberForm[yVariable, {5, 3}]
       }]]
    }, {
    Panel[Dynamic[NumberForm[xVariable + 2 - yVariable, {5, 3}]]],
    SpanFromLeft
    }
   }],
 Initialization :> (
   mQ[n_] := 
    75.63510582933174 - 35.87130621205199 n + 86.18343750838301 n^2 - 
     55.324190072519976 n^3;
   mV[t_] := -29.619999999999976 + 5.499999999999998 t + 
     18.333333333333325 t^2;
   )
 ]

You will find more information about the details of these constructs in the mentioned tutorials. Note that I have also added some means to make the behaviour of the user interface somewhat more appealing.
"
"programming - When should I, and when should I not, set the HoldAll attribute on a function I define?","
The way Mathematica works is that when it encounters a function with arguments it will try to evaluate the arguments first before proceeding to evaluate the function. This behavior can be modified by specifying the various HoldAll, HoldFirst, HoldRest, etc. attributes for a given function.
So in your example f[x+1] will be immediately replaced by f[6] internally.
To answer your question: You need HoldAll or one of it's siblings if you construct functions that need to know the actual parameters with which the function was called. For example, I sometimes need to make file names using ToString on variables that the function is called with regardless of whether those variables evaluate to something.
In general HoldAllis not necessary if you just do arithemtic functions or other simple data manipulating functions. Once you start getting more into the swing of functional programming style of MMA you'll soon realize when and where you need arguments to stay unevaluated.
In the cases you mentioned it becomes obvious why you would want to specify HoldAll. In, e.g., the ""checking evaluation"" case you want the code argument to only be evaluated once you are inside the Block, not immediately when Mathematica encounters the function that specifies the Block.
The case in the syntax highlighting question is similar; the list of vars you supply should be passed as is to the Block, or the function will not work if the vars evaluate to something that does not make sense within the Block (numerical values in this case):

"
graphs and networks - Finding all shortest paths between two vertices,"
Directed Shortest Paths
Here's a friendly amendment to Heike's solution that shows the distance remaining to the finish vertex (in white).  The starting vertex is green. Edges are directed to show the appropriate direction toward the finish.  According to the documentation on GraphDistance, ""For a weighted graph, the distance is the minimum of the sum of weights along any path between s and t."" So it should automatically work with weighted graphs.
First, here's Heike's routine, which does most of the heavy lifting, with a simple tweak to produce directed edges:
paths[gr_, {i_, j_}] := 
  Module[{sub, dist, indices, dd, nbrs}, dist = GraphDistance[gr, i, j];
  indices = {};
  dd = dist;
  Reap[Nest[Function[{vv}, dd -= 1;
  nbrs = VertexList[NeighborhoodGraph[gr, #]] & /@ vv;
  nbrs = Pick[#, GraphDistance[gr, #, j] & /@ #, dd] & /@ nbrs;
  Sow /@ Flatten[Thread /@ Thread[vv \[DirectedEdge] nbrs]];
  Union[Flatten[nbrs]]], {i}, dist]][[2, 1]]]

The following produces the directional routes. Numbers refer to GraphDistance from the current vertex to the finish vertex.
gr = RandomGraph[{30, 40}];
ends = {1, 30};
sub = paths[gr, ends];
e = EdgeList[gr] /. {x_ \[UndirectedEdge] y_ /; 
 GraphDistance[gr, x, 30] < GraphDistance[gr, y, 30] :> y \[DirectedEdge] x, 
   x_ \[UndirectedEdge] y_ /; 
 GraphDistance[gr, y, 30] <= GraphDistance[gr, x, 30] :>  x \[DirectedEdge] y}
gr1 = Graph[e, ImagePadding -> 15];

HighlightGraph[gr1, {Graph[sub], Style[1, Green], Style[30, White]}, 
 VertexLabels ->  Table[i -> Style[GraphDistance[gr1, i, 30], 16], {i, 
    Union[Level[sub, {-1}]]}], 
    VertexSize -> {1 -> Large, 30 -> Large}, 
    GraphHighlightStyle -> ""Thick"", ImagePadding -> 15]



Below is a variant that  displays (a) the vertex indices (small font size) and the distance from the finish vertex on the EdgeLabel (large font).
HighlightGraph[gr1, {Graph[sub], Style[1, Green], Style[30, White]}, 
   VertexLabels -> (v = Union[Level[sub, {-1}]]) /. {i_Integer :> (i -> i)},
   EdgeLabels -> sub /. {x_ \[DirectedEdge] y_ :> (x \[DirectedEdge] y) -> 
   Style[ GraphDistance[gr, x, 30], 14, Background -> White]},
   VertexSize -> {1 -> Large, 30 -> Large}, 
   GraphHighlightStyle -> ""Thick"", ImagePadding -> 15, ImageSize -> 600]


"
front end - Is it possible to Print expressions in reverse order?,"
This is admittedly messy, but something along these lines might work:
insertBelowEvaluationCell[expr_] := 
  (SelectionMove[EvaluationNotebook[], After, EvaluationCell]; 
   NotebookWrite[EvaluationNotebook[], Cell[BoxData@ToBoxes[expr], ""Print""]])

This function moves the insertion point just below the evaluation cell before inserting the text or expression to be printed.
Let's test it:
insertBelowEvaluationCell /@ Range[10]

Problems:

This messes with the insertion point in the notebook which can be modified interactively as well.  Perhaps it's better to write the output into a separate notebook instead.  
It does not work in command line mode (without a front end).
It's slow (noticeably slower than Print).

"
function construction - Picking random items out of a list only once,"
How about making a closure?  A closure is a function with an internal state.
makeDrippingBucket[list_] := 
 Module[{bucket = list}, 
  If[bucket === {}, {}, 
    With[{item = RandomChoice[bucket]}, 
     bucket = DeleteCases[bucket, item]; {item}]] &]

Then use this to make a ""bucket"", like this:
bucket = makeDrippingBucket[{1,2,3,4,5}]

This object has an internal state that changes every time you call it.  Every time you call bucket[], it will give you a new number, until it gets empty.
bucket[]

(* ==> {3} *)


EDIT
The same thing, using @Eli's solution of pre-randomizing the list:
makeDrippingBucket[list_] := 
 Module[{bucket = RandomSample[list]}, 
  If[bucket === {}, {}, 
    With[{item = Last[bucket]}, bucket = Most[bucket]; {item}]] &]

"
complex - Why doesn't FullSimplify drop the Re function from an expression known to be real?,"
The problem is due to Mathematica thinking that the version with the Re[] is actually simpler. This is because the default complexity function is more or less LeafCount[], and 
In[332]:= ArcTan[-Re[x+z],y]//FullForm
Out[332]//FullForm= ArcTan[Times[-1,Re[Plus[x,z]]],y]

whereas
In[334]:= ArcTan[-x-z,y]//FullForm
Out[334]//FullForm= ArcTan[Plus[Times[-1,x],Times[-1,z]],y]

Here is a function that counts leaves without penalizing negation:
In[382]:= f3[e_]:=(LeafCount[e]-2Count[e,Times[-1,_],{0,Infinity}])
{LeafCount[x],LeafCount[-x],f3[x],f3[-x]}
Out[383]= {1,3,1,1}

If you tell mathematica to simplify using this complexity function then you get the expected result:
FullSimplify[ArcTan[-Re[x+z],y],(x|y|z)\[Element]Reals,ComplexityFunction->f3]


Out[375]= ArcTan[-x-z,y]

"
Torn edge paper effect for images,"
A bit lengthy, but here's my attempt. The parameters in torn are the base image img and an array describing which edges should be torn. This array is of the form {{left, right}, {bottom, top}}, where a 0 corresponds to a straight edge and any non-zero value to a torn edge, so {{0, 0}, {1, 0}} would correspond to an image where only the bottom edge is torn. 
Options[torn] = {""amplitude"" -> .04, ""frequency"" -> 50, ""offset"" -> {10, 10}, 
   ""opacity"" -> .7, ""gaussianBlur"" -> 4};

torn[img_, {{l_, r_}, {b_, t_}}, OptionsPattern[]] := 
 Module[{ratio, left, right, bottom, top, poly, img1, shadow, amp, dx, offset},
  ratio = #2/#1 & @@ ImageDimensions[img];
  amp = OptionValue[""amplitude""] {Min[1/ratio, 1], Min[ratio, 1]};
  dx = 1/(OptionValue[""frequency""] {Min[1/ratio, 1], Min[ratio, 1]});
  offset = Abs[{##}] UnitStep[{#1 {-1, 1}, #2 {1, -1}}] & @@ OptionValue[""offset""];

  left = If[l == 0, {{0, 1}, {0, 0}}, 
   Table[{RandomReal[{0, 1} amp[[2]]], i}, {i, 1 - amp[[2]], dx[[2]], -dx[[2]]}]];
  right = If[r == 0, {{1, 0}, {1, 1}}, 
   Table[{1 + RandomReal[{-1, 0} amp[[2]]], i}, {i, dx[[2]], 1 - amp[[2]], dx[[2]]}]];
  bottom = If[b == 0, {{0, 0}, {1, 0}}, 
   Table[{i, RandomReal[{0, 1} amp[[1]]]}, {i, dx[[1]], 1 - amp[[1]], dx[[1]]}]];
  top = If[t == 0, {{1, 1}, {0, 1}}, 
   Table[{i, 1 + RandomReal[{-1, 0} amp[[1]]]}, {i, 1 - amp[[1]], dx[[1]], -dx[[1]]}]];
  poly = Join[left, bottom, right, top];

  {img1, shadow} = 
    Image@Graphics[#, ImagePadding -> OptionValue[""gaussianBlur""], 
        PlotRangePadding -> None, AspectRatio -> ratio, Background -> None, 
        ImageSize -> ImageDimensions[img] + 2 OptionValue[""gaussianBlur""]] & /@
     {{Texture[img], EdgeForm[Black], Polygon[poly, VertexTextureCoordinates -> poly]}, 
      {Polygon[poly]}};
  img1 = ImagePad[img1, offset, {1, 1, 1, 0}];
  shadow = ImagePad[GaussianFilter[shadow, OptionValue[""gaussianBlur""]],
      Reverse /@ offset, {1, 1, 1, 0}];
  ImageCompose[img1, {shadow, OptionValue[""opacity""]}, Center, Center, {1, 1, -1}]]

There are a number of options which control various image parameters. These are the amplitude of the tears ""amplitude"", the frequency of the jags, ""frequency"", the opacity of the shadow, ""opacity"", and the blurriness of the shadow ""gaussianBlur"". The offset of the shadow towards the lower right corner is controlled by the option ""offset"" which is off the form {right, bottom} where right and bottom are in points. Negative values for right and bottom indicate a shadow pointing towards the left and/or top of the image.
Example
img = ExampleData[{""TestImage"", ""Mandrill""}];
torn[img, {{0, 1}, {1, 0}}, ""offset"" -> {20, 20}, ""gaussianBlur"" -> 10]


Edit
Apparently, under certain circumstances Mathematica doesn't render a transparent background for img1 which results in a white region between the image and the shadow. I managed to reproduce this behaviour in version 8.0.1 for OS X with img = Image@Plot[Sin[x], {x, 0, 2 Pi}], but not in 8.0.4. It seems that setting the ImageSize in Graphics is the culprit. To resolve this issue I replaced {img1, shadow} = Image@Graphics... in torn with
{img1, shadow} = 
  Rasterize[
     Graphics[#, ImagePadding -> OptionValue[""gaussianBlur""], 
      PlotRangePadding -> None, AspectRatio -> ratio, 
      Background -> None], 
     ImageSize -> ImageDimensions[img] + 2 OptionValue[""gaussianBlur""], 
     Background -> None] & /@ 
   {{Texture[img], EdgeForm[Black], Polygon[poly, VertexTextureCoordinates -> poly]}, 
    {Polygon[poly]}};

"
"pattern matching - Why doesn't Cases match all instances of XMLElement, given Infinity levelspec?","
The reason your approach fails is because Cases works slightly differently than what you've intended in the question. Cases does a depth-first scanning and once it finds its first match, it transforms it and starts traversing the tree backwards, looking for other matches. Consider this simple example:
list = {p[1, 2], q, {p[3, 4], p[5, p[6, 7]]}};
Cases[list, p[a_, b_] :> f[a, b], Infinity]
(* Out[1]= {f[1, 2], f[3, 4], f[6, 7], f[5, p[6, 7]]} *)

You can see that all 4 instances of p[_, _] are found by Cases, but the rule replacement is only done to the output before returning — i.e., the tree is not modified in place — so when it walks back up a node, it does not see the replacement to the deeper p[_, _] because the tree was never modified. 
The TreeForm below gives an idea of how the last two matches are handled. The third match is the deepest one, p[6, 7] which returns f[6, 7] and in the second one, the one just above it is matched without modifying the inner p[_, _] (because that's the replacement rule given). 


This is exactly the case in your situation, where one XMLElement has another within it.
One possible solution is to extract them all first with Cases and then use ReplaceRepeated:
Cases[list, _p, Infinity] //. p[a_, b_] :> f[a, b]
(* Out[2]= {f[1, 2], f[3, 4], f[6, 7], f[5, f[6, 7]]} *)

So for the example in the question, it would be:
Cases[Import[""http://www.weather.gov/data/current_obs/KOAK.xml"",""XMLObject""],
XMLElement, _XMLElement, Infinity] //. XMLElement[tag:_, _, value:_] :> (tag -> value)


As Albert Retey rightly points out (also, thanks to him for the helpful suggestions and corrections), what Cases does with a rule replacement is the same as Cases with no rule, followed by ReplaceAll:
Cases[list, _p, Infinity] /. p[a_, b_] :> f[a, b]

whereas ReplaceRepeated is what's needed here.
"
plotting - PieChart with radial coloring/color function,"
Your wedge function is a good starting point, and with a few small modifications can be used as a custom ChartElementFunction for PieChart.
wedge[fun_, {minangle_, maxangle_}, colorrange_, divs_: 25] := 
   First[ParametricPlot[
      {v Cos[u], v Sin[u]}, {u, minangle, maxangle}, {v, 0, 1}, 
      ColorFunction -> (ColorData[{""Rainbow"", colorrange}][fun[#4]] &), 
      ColorFunctionScaling -> False, Mesh -> False, ImagePadding -> All, 
      BoundaryStyle -> Directive[Thick, Black], Frame -> False, 
      Axes -> False, PlotPoints -> divs, PlotRange -> {-1.2, 1.2}, 
      Background -> Transparent]]

The main differences are that 

we're using First to extract the main primitives and directives from the plot
we've added a divs parameter to allow us to get better resolution of the colors
we've removed the text, since we're going to do that differently

(With this approach several of the options (Frame, Axes, etc...) become irrelevant, but I haven't removed them.)
I then split out the colorbar function, mainly to improve the readability of the code.  I didn't pass the options through, so it probably lost a small amount of control.
colorbar[colorFunction_, range_, divs_: 25] := 
   DensityPlot[
      y, {x, 0, .1}, {y, First@range, Last@range}, 
      AspectRatio -> 10, PlotRangePadding -> 0, PlotPoints -> {2, divs}, 
      MaxRecursion -> 0, FrameTicks -> {None, Automatic, None, None}, 
      ColorFunctionScaling -> False, ColorFunction -> colorFunction]

Now we come to the main SectorPlot.
SectorPlot[func_List, label_List, colorrange_: {0, 66.7}, 
   opts:OptionsPattern[]] /; Length[func] == Length[label] := 
   Module[{div, size},
      size = 300;
      Row[{
         PieChart[Table[1 -> f, {f, func}], 
            ChartLabels -> Placed[label, ""RadialCallout"", 
               Style[#, Bold, FontFamily -> ""Times""] &], 
            ChartElementFunction -> (wedge[First[#3], First[#1], colorrange, 50] &), 
            ImageSize -> {Automatic, size}, ImagePadding -> 20], 
         Show[colorbar[ColorData[{""Rainbow"", colorrange}], colorrange], 
            ImageSize -> {Automatic, size}, ImagePadding -> 20]
          }]
       ]

The main things to note here:

we use -> to assign the functions as metadata for the (constant-size) sectors
we use ChartLabels and Placed for the sector labels, which provides easy access to several built-in label locations
when we call wedge as a ChartElementFunction

First[#1] is the angle range for the sector
#3 contains a list of all metadata for a sector, we extract the function with First


Here's the final result:
SectorPlot[
   {(60 Sin[4.3 # + 0.3]) &, 
    (50 Sin[12 # + 0.1]) &, 
    (66 Cos[7.3 # + 0.3]) &, 
    (60 Tan[1.2 #]) &, 
    (60 Cos[23.5 # - 0.1]) &}, 
   {""1"", ""2"", ""3"", ""4"", ""5""}, 
   {0, 70}]


(As a note, really big labels are generally problematic, especially inside Graphics which have a constrained size.)
"
graphics - Computing the bounding boxes for Text objects,"
Here a test text. I use a gray background to show how large the bounding box actually is.
t = Graphics[Text[""Test"", BaseStyle -> {128}, Background -> Gray]]


d = ImageDimensions[ImageCrop[t]];
Graphics[{
  FaceForm[], EdgeForm[Red],
  Text[""Test"", {0, 0}, {-1, -1}, BaseStyle -> {128}],
  Rectangle[{0, 0}, Offset[d, {0, 0}]],
  PointSize[0.05], Point[{0, 0}]
}]


If you want a closer cut for your bounding box, just remove the Background option and ImageCrop again. However, note that offsets in the Text function are with respect to the bounding box Mathematica uses (indicated by the gray box).
t = Graphics[Text[""Test"", BaseStyle -> {128}]];
d = ImageDimensions[ImageCrop[t]];
Graphics[{
  FaceForm[], EdgeForm[Red],
  Text[""Test"", {0, 0}, {-.97, -0.6}, BaseStyle -> {128}],
  Rectangle[{0, 0}, Offset[d, {0, 0}]],
  PointSize[0.05], Point[{0, 0}]
}]


Note the {-.97, -0.6} offset?
"
How use Mathematica fonts with LaTeX,"
The instructions you mention are rather outdated.

Modify wolfram.map to have .pfa instead of .pfb (to reflect the format of the font files) and remove all from Janson Text onwards, as those fonts are not provided.
Copy wolfram.map to
/usr/local/texlive/texmf-local/fonts/map/dvips/wolfram/wolfram.map

Copy all subfolders from texmf/fonts (afm/wolfram …) to the corresponding folders in /usr/local/texlive/texmf-local/fonts.
Copy the directory texmf/tex/latex/wolfram to /usr/local/texlive/texmf-local/tex/latex/wolfram
Copy texmf/doc/wolfram to /usr/local/texlive/texmf-local/doc/latex/wolfram
Run mktexlsr so that TeX Live will know about these files
Run updmap-sys --enable Map=wolfram.map
Enjoy

All steps from 2 to 7 should be done as Administrator (prefix the commands with sudo, typing the Administrator's password when requested)
Note that the 7z archive linked to in the blog article seems to be corrupt, while the .zip file is good.

Update
From TeX Live 2013 onwards, it's better to add the line
Map wolfram.map

to the file
/usr/local/texlive/texmf-local/web2c/updmap.cfg

(also requires Administrator privileges) and subsequently run
updmap-sys

without options. This replaces step 7 above.
"
How to match a sequence of complex patterns?,"
We needn't use Map and Apply as in ziyuang's answer. We can make use of PatternSequence with Repeated (..) or RepeatedNull (...) instead, e.g.
list = {{a1, b1} -> {x1, y1}, {} -> {x3, y3}, {a2, b2} -> {x1, y2}, 
        {} -> {x6, y6}, {} -> {x5, y5}, {} -> {x0, y0}, {a3, b3} -> {x3, y3}, 
        {a4, b4} -> {x4, y4}};

Now we can test various approaches :
{ MatchQ[ #, { PatternSequence[{___} -> {_, _}] ..}]& @ list, 
  MatchQ[ #, {({PatternSequence[]} | {_, _} -> {_, _}) ..}]& @ list,
  MatchQ[ #, {({PatternSequence[___]} -> {_, _}) ..}]& @ list }


{True, True, True}


The advantage of PatternSequence is seen when we'd like to deal with more sophisticated cases of pattern matching.
"
data structures - Short syntax for accessing System`Utilities`HashTableAdd and System`Utilities`HashTableGet,"
If you're willing to use a slightly different syntax to invoke System`Utilities`HashTableAdd, you can create your own wrapper around System`Utilities`HashTable that does most of what you want without modifying any built-in functions. The loss of the convenient hashTable.key = value syntax is unfortunately necessary because you can't use TagSet to set a tag more than one level deep in an expression, but personally I think that the postfix form hashTable.key.set[value] isn't much worse. Edit: by introducing a wrapper symbol specifically for this functionality it is also possible to overload Dot reasonably safely and enable the use of infix form as per the question (see below).
Here's the code:
ClearAll[hashTableWrapper];

(* Create new hash table *)
hashTableWrapper /: new[hashTableWrapper] :=
  hashTableWrapper@System`Utilities`HashTable[];

(* Check existence of a key *)
hashTableWrapper /: Dot[
   hashTableWrapper[h_System`Utilities`HashTable], key_, existsQ[]
  ] := System`Utilities`HashTableContainsQ[h, Unevaluated[key]];

(* Clear key value/delete key *)
hashTableWrapper /: Dot[
   hashTableWrapper[h_System`Utilities`HashTable], key_, clear[]
  ] /; System`Utilities`HashTableContainsQ[h, Unevaluated[key]] :=
  System`Utilities`HashTableRemove[h, Unevaluated[key]];

(* Nonexistent keys can't be cleared, but let's not complain *)
hashTableWrapper /: Dot[
   hashTableWrapper[h_System`Utilities`HashTable], key_, clear[]
  ] = Null;

(* Set key value (clearing first if necessary) *)
ClearAll[set]; SetAttributes[set, SequenceHold];
hashTableWrapper /: Dot[
   w : hashTableWrapper[h_System`Utilities`HashTable], key_, set[val___]
  ] := (
   w.Unevaluated[key].clear[];
   System`Utilities`HashTableAdd[h, Unevaluated[key], Unevaluated[val]];
   val
 );

(* Set delayed key value (again, clearing first if necessary) *)
ClearAll[setDelayed]; SetAttributes[setDelayed, {HoldAll, SequenceHold}];
hashTableWrapper /: Dot[
   w : hashTableWrapper[h_System`Utilities`HashTable], key_, setDelayed[val___]
  ] := (
   w.Unevaluated[key].clear[];
   System`Utilities`HashTableAdd[h, Unevaluated[key], Unevaluated[val]]
 );

(* Get key value *)
hashTableWrapper /: Dot[
   hashTableWrapper[h_System`Utilities`HashTable], key_, optional : get[] : get[]
  ] /; System`Utilities`HashTableContainsQ[h, Unevaluated[key]] :=
  System`Utilities`HashTableGet[h, Unevaluated[key]];

(* Deal with query of nonexistent key *)
hashTableWrapper /: Dot[
   hashTableWrapper[h_System`Utilities`HashTable], key_, optional : get[] : get[]
  ] = $Failed;

As a demonstration, let's say we find ourselves forgetting what 1 + 1 is and want to store it in a hash table. And perhaps we want to store the inverse of this operation as well. (These contrived examples help to demonstrate usage with unevaluated expressions for both the key and the value.)
hash = new[hashTableWrapper];
hash.Unevaluated[1 + 1].set[2];
hash.(2).setDelayed[Print[""the value was evaluated""]; 1 + 1];

As this example shows, the key is evaluated unless otherwise specified using Unevaluated. (The parentheses in hash.(2).set[...] are necessary as otherwise this will be interpreted as a multiplication: 0.2 hash set[...].) Now we can write:
hash.Unevaluated[1 + 1].get[]

or simply (since get[] is an optional argument)
hash.Unevaluated[1 + 1]

and get back 2. Similarly, if we write hash.(2).get[] or hash.(2), ""the value was evaluated"" is printed and the unevaluated value 1 + 1 is evaluated to return 2.
Maybe we think that the second definition isn't very useful since it'll be evaluated every time. So, we redefine it:
hash.(2).set@Unevaluated[1 + 1];

which clears the previous definition automatically. (Printing ""the value was evaluated"" in the process. This is the result of System`Utilities`HashTableRemove's own behaviour which is to return the value associated with the key that was removed, if any.) Now hash.(2) will give, more usefully, Unevaluated[1 + 1].
Finally we come to our senses and decide to get rid of these trivial hash table entries. Again, because this calls System`Utilities`HashTableRemove, the values of the keys to be cleared are returned:
hash.Unevaluated[1 + 1].clear[]


2


and
hash.(2).clear[]


Unevaluated[1 + 1]


System`Utilities`HashTableRemove throws an error if invoked on a nonexistent key, but clearing such in this way simply does nothing, returning Null, as I thought this behaviour was more useful. However, an attempt to read undefined keys still fails:
hash.undefined


$Failed


Incidentally, you can have keys containing Dot without any problems, thanks to Dot's attributes Flat and OneIdentity. This one contains Dot in two different ways:
hash.this.is.a.key.containing.Dot.set[""hello""];
hash.this.is.a.key.containing.Dot


""hello""


Edit: implementing infix syntax for Set
Leonid makes a point very well here regarding overloading Set, which actually applies to any built-in function. When overloading any built-in, one has to ask oneself:

If two people did this at the same time, without being aware of each other, could it result in a conflict?

Obviously, the only acceptable overloads are those for which we can answer, ""No"". In practice this usually means creating an ""environment"" using Internal`InheritedBlock within which different semantics apply, introducing one's own symbols that are not likely to conflict with anyone else's (or even, using Module, ones that are unable in principle to cause a conflict), and writing definitions carefully so that the scope is tightly constrained and no evaluation leaks are introduced. In this spirit, here is my suggestion for how to implement, by means of the code above, the hashTable.key = value syntax (and SetDelayed and Unset at the same time, why not):
ClearAll[withHashTableSetSemantics];
withHashTableSetSemantics[expr_] :=
  Internal`InheritedBlock[{Dot},
   Unprotect[Dot];
   Dot /: Set[Dot[w_, key_], val_] /; Head[w] === hashTableWrapper :=
    w.Unevaluated[key].set[val];
   Dot /: SetDelayed[Dot[w_, key_], val_] /; Head[w] === hashTableWrapper :=
    w.Unevaluated[key].setDelayed[val];
   Dot /: Unset@Dot[w_, key_] /; Head[w] === hashTableWrapper :=
    w.Unevaluated[key].clear[];
   Protect[Dot];
   expr
  ];
SetAttributes[withHashTableSetSemantics, HoldAll];

Be aware, however, that although the semantics are close to those of Set, SetDelayed, and Unset, they aren't exactly the same because of the implementation in terms of the hash table functions themselves. Nor are they exactly the same as for the postfix form: for example, while one can write e.g. hash.(2).set@Unevaluated[1 + 1] to set an unevaluated value, the equivalent in the infix form requires two applications of Unevaluated, i.e. hash.(2) = Unevaluated@Unevaluated[1 + 1] (which is consistent with Set itself).
If, in a session, one wishes for these semantics to apply over a number of evaluations, a good way to propagate the environment is to set $Pre = withHashTableSetSemantics. This way, no global settings are modified, and the environment can be disabled again if it causes problems or when no longer needed by Unseting $Pre.
"
Make EventHandler work for clicks and keys in a Dynamic display,"
Try using NotebookEventActions
displaying = True;

SetOptions[EvaluationNotebook[], 
 NotebookEventActions :> {""UpArrowKeyDown"" :> (If[! displaying, 
      Print[""up press""]]), 
   ""DownArrowKeyDown"" :> (If[! displaying, Print[""down press""]]), 
   ""MouseClicked"" :> (If[displaying, displaying = False])}]

"
syntax - How do you set an Optional parameter with a global variable on a Function defined in a Package,"
You'll have to point to the global variable using its full context path as Global`IndexLoopPlot. Otherwise, the optional variable will be interpreted as YourPackage`IndexLoopPlot. The following example shows how:
Quiet@Remove[a, ""test`*""];
BeginPackage[""test`""];
f[x_: Global`a] := {x}
EndPackage[];


"
equation solving - Find roots of polynomial in field extension $GF(2^n)$?,"
Well, for your example $p(x)=x^8 + x^7 + x^5 + x^3 +1$, the associated extension $GF(2^n)\cong \frac{GF(2)[x]}{\langle p(x) \rangle}$ is a vector space over $GF(2)$ of dimension $8$.  The elements of this field can be written as polynomials $a_0+a_1x+\ldots +a_7x^8$ for $a_i\in GF(2)$.  By quotienting we've insisted that $p(x)=0$, so the multiplication between these elements defined by first multiplying the polynomials as usual (taking addition modulo 2), then reducing by $p(x)$.   For example, $(x^2+x^4+x^6+x^7)x=1$.
A quick and dirty Mathematica mockup to implement this is
modpoly[p_] := Module[{J},
  J = Mod[#, 2] & /@ CoefficientList[p, x];
  Total[Table[J[[i]] x^(i - 1), {i, 1, Length[J]}]]
  ]
multiply[p_, q_] := Module[{K},
  modpoly[
   PolynomialMod[modpoly[Expand[p q]], x^8 + x^7 + x^5 + x^3 + 1]]
  ]

which yields, for example,
multiply[x^2 + x^5 + x^6, x + x^6 + x^7]

> 1 + x + x^2 + x^5

"
manipulate - How To interactively create a Polygon in a Graphic?,"
This isn't exactly what you asked for, but it might do the trick. This solution allows you to create a number of different shapes (circle, polygon, line, Bezier curve, etc.). To add a shape, press the ""New object"" button. You can add points to an existing shape by clicking anywhere in the plane. 
Note that I'm using LocatorAutoCreate -> All instead of True which means that you don't need a modifier key to add points. Deleting locators is the same as with LocatorAutoCreate -> True. 
You can edit an existing object by pressing the ""Edit object"" button and choosing the right object. The ""Print shapes"" button prints a list of the shapes where each shape is represented by a list of coordinates and a string indicating the type.
DynamicModule[{types, fun},
 types = {""Circle"", ""Disk"", ""Polygon"", ""Line"", ""Bezier"", ""Spline""};
 fun[{}, ___] := {};
 fun[{a_}, ___] := {};
 fun[pts_, type_] := Switch[type,
   ""Circle"", Circle[pts[[1]], Norm[pts[[2]] - pts[[1]]]],
   ""Disk"", Disk[pts[[1]], Norm[pts[[2]] - pts[[1]]]],
   ""Polygon"", {EdgeForm[Black], FaceForm[Opacity[.5]], Polygon[pts]},
   ""Line"", Line[pts],
   ""Bezier"", BezierCurve[pts],
   ""Spline"", BSplineCurve[pts]];

 Manipulate[
  ptlst[[object]] = pts;
  typelst[[object]] = type;
  grlst = MapThread[fun, {ptlst, typelst}];
  Graphics[grlst, PlotRange -> {{-3, 3}, {-3, 3}}],

  {{pts, {}}, Locator, LocatorAutoCreate -> All},
  {{ptlst, {{}}}, None},
  {{typelst, {""Line""}}, None},
  {{object, 1}, None},
  {grlst, None},
  {{type, ""Line"", ""Object type""}, types},
  Row[{Button[""New object"",
     If[Length[ptlst[[-1]]] > 0,
      AppendTo[ptlst, {}]; AppendTo[typelst, type];
      object = Length[typelst];
      pts = {}]],
    Dynamic@PopupView[Graphics[#, ImageSize -> 50] & /@ grlst,
      Dynamic[object, (object = #; pts = ptlst[[#]]; type = typelst[[#]]) &],
       Button[""Edit object""]],
    Button[""Print shapes"", Print[Transpose[{ptlst, typelst}]]]}]
  ]]


"
Solving inequalities for positive Integers,"
Reduce allows you to specify the domain of Reals, Complexes, or Integers as the third parameter. But, positivity is not directly specifiable at that point. Instead, it must be added to the expr being reduced as an added condition. A simple form of this condition would be
 And @@ Thread[all > 0]

which is equivalent to 

a > 0 && b > 0 && c > 0 && d > 0 && e > 0


Combining this with the Integers domain gives this form for Reduce:
Reduce[# >= 0 && And @@ Thread[all > 0], all, Integers] &

As a word of caution, this will result in a very, very large output as Reduce uses GeneratedParameters for its unknown integer coefficients. For the second inequality, this results in 34 unknown coefficients.
"
pattern matching - Splitting a list in which figures vary from negative to positive,"
Try 
Split[data, Not[#2>0 && #1<0] &]

Note that Split[list, test] splits list between two elements when test fails. In this case you want to to split the list iff #2>0 && #1<0 &[e1, e2] == True which is equivalent to Not[#2>0 && #1<0]&[e1, e2] == False.
"
visualization - How can I visualize features found in an image?,"
Show can combine Image and Graphics:
a = ExampleData[{""AerialImage"", ""Oakland2""}];
b = Graphics[{Red, Thick, Circle[{400, 400}, 300]}];
Show[a, b]


In this way you can do it in a programmatic way. But you can also do this manually and interactively via right-click menu access to Drawing Tools:


"
export - How to convert a 2D image into a 3D graphics?,"
This maybe helpful if you want to convert image structure into 2D/3D line primitives, MorphologicalGraph does some astonishing things out of the box:
img = Import[
   ""https://upload.wikimedia.org/wikipedia/commons/c/ce/Spinnennetz_\
im_Gegenlicht.jpg""];


g = MorphologicalGraph[img // MorphologicalBinarize, 
   VertexCoordinates -> Automatic, EdgeWeight -> Automatic];

edges = EdgeList[g];

extracting the actual connections can be done like this (although more streamlined solutions would be welcome):
vertices = 
  Thread[Rule[VertexList[g], PropertyValue[g, VertexCoordinates]]];

lines = ((edges /. vertices) /. 
    UndirectedEdge[a_, b_] :> Line[{a, b}]);

Graphics[lines]


or with a 3D touch:
Graphics3D[
 Tube[#] & /@ (lines /. {x_?NumericQ, y_?NumericQ} :> {x, 0, y})]


After that, you can choose your preferred 2D/3D vector format for Export.
"
symbolic - Why does this sum not simplify properly?,"
Before I answer your question, I would like to share some results. Since there was no guarantee that the Christoffel–Darboux formula would be invariant under such a change of variables, I did a simple check:
In[25]:= Sum[(HermiteH[k, -x] HermiteH[k, y])/(2^k k!), {k, 0, 3}]

Out[25]= 1 - 2 x y + 1/8 (-2 + 4 x^2) (-2 + 4 y^2) 
       + 1/48 (12 x - 8 x^3) (-12 y + 8 y^3)

In[26]:= Sum[(HermiteH[k, x] HermiteH[k, y])/(2^k k!), 
             {k, 0,n}] /. {x -> -x, n -> 3}

Out[26]= ((12 - 48 x^2 + 16 x^4) (-12 y + 8 y^3) - (12 x - 
8 x^3) (12 - 48 y^2 + 16 y^4))/(96 (-x - y))

In[34]:= (-1/96)(PolynomialReduce[Numerator@%26, {x + y}, {x, y}])[[1, 1]] 
        == %25 // Expand

Out[34]= True

And, it works at higher values of n, also. Similarly,
In[39]:= Sum[(HermiteH[k, -x] HermiteH[k, y])/(2^k k!), {k, 0, n}];
         (% /. n -> 3) == %25 // Expand

Out[40]= True

This leads me to believe that the answer you're given is absolutely correct, just not in its simplest form.
As to why Mathematica does not recognize the simplification, the answer is simply because it does not know everything, and while such a variable transformation seems easy to us, it is not necessarily straightforward to program. 
Edit: Sum behaves this way because the form 
Sum[(HermiteH[k, x] HermiteH[k, y])/(2^k k!), {k, 0,n}]

is recognized and the substitution can be made immediately. To allow for the more complex simplification that you wish, we need to create a custom rule for it, as follows
Unprotect[Sum]
Sum[(HermiteH[k_, x_] HermiteH[k_, y_])/(2^k_ (k_)!), {k_, 0, n_}] := 
 (2^(-1 - n) (HermiteH[n, y] HermiteH[1 + n, x] 
  - HermiteH[n, x] HermiteH[1 + n, y]))/((x - y) n!)
Protect[Sum]

which when used with 
Sum[(HermiteH[k, -x] HermiteH[k, y])/(2^k k!), {k, 0, n}]

gives the desired result.  
A couple of words of caution, though. This is deliberately overriding the built-in behavior of Sum and may affect its behavior in uncertain ways. So, if you decide to take this route, make the substitutions as specific as possible, so that you do not run into unintended behavior.
"
implementation details - How does Interpolation really work?,"
Interpolation function methods
Interpolation supports two methods:

Hermite interpolation (default, or Method->""Hermite"")
B-spline interpolation (Method->""Spline"")

Hermite method
I really can't find any good reference to Hermite method within Mathematica's documentation. Instead, I recommend you to take a look at this Wikipedia article.
The benefits of Hermite interpolation are:

You can compute them locally at the time of evaluation. No global system solving required. So construction time is shorter, and the resulting InterpolatingFunction is smaller.
Multi-level derivatives can be specified at each point.

One problem is that the resulting function is not continuously differentiable ($C^1$ or higher), even if InterpolationOrder->2 or higher is used. See the following example:

Spline method
To be specific, we are using B-spline interpolation with certain knot configuration--depending on the distribution of sample points. I could not find a good web source to describe the method (the Wikipedia article is not great). Although, you can find a step-by-step description of the method in 1D case within Mathematica's documentation (BSplineCurve documentation, Applications -> Interpolation section). Multi-dimension is simply tensor product version.
The benefits:

InterpolationOrder->d always guarantees a smooth function of $C^{d-1}$ class.

Evaluation/derivative computation is very fast.
You can take BSplineFunction out of the resulting InterpolatingFunction (it's the 4th part), which is compatible with BSplineCurve and BSplineSurface for fast rendering.

The problems (of current implementation in V8):

It is machine precision only--although, it is not hard to implement it manually for arbitrary precision using BSplineBasis.
It does not support derivative specification.
Initially it solves global linear system and store the result. So the resulting function is much larger than Hermite method (this is not implementation problem).

Other functions
Some plot functions such as ListPlot3D have their own methods. Sometimes they call the B-spline method, sometimes they use a method based on distance field (for unorganized points), etc. But probably it is not useful here since they are only supported as a visual measure.
"
programming - Is there a Mathematica/Lisp link?,"
Have a look at SchemeLink.
"
dynamic - How to add several Locators to a Graphic with a mouse click?,"
Here are two possible solutions. In both cases, one click brings locators up, another click will make them disappear.
Solution 1
Using multiple dynamic locators. The Map (or /@) is needed, since Dynamic inside Locator should have evaluated part number for pts.
DynamicModule[{pts = {{0, 0}, {0, 1}, {1, 0}}, locs = {}}, 
 Graphics[{EventHandler[
    Polygon[Dynamic[
      pts]], {""MouseClicked"" :> (locs = 
        If[locs === {}, 
         Locator[Dynamic[pts[[#]]]] & /@ Range[Length[pts]], {}])}], 
   Dynamic[locs]}, PlotRange -> 1, PlotRangePadding -> Scaled[.05]]]

A slightly weird behavior of locators (washed out color when it appears first)... which I don't know why.
Solution 2
Using LocatorPane. Simpler, but Dynamic needs to refresh both locPts and pts when locs is assigned (Dynamic[expr, f] syntax).
DynamicModule[{pts = {{0, 0}, {0, 1}, {1, 0}}, locPts = {}},
 LocatorPane[Dynamic[locPts, (If[locPts =!= {}, pts = locPts = #]) &], 
  Graphics[{EventHandler[
     Polygon[Dynamic[
       pts]], {""MouseClicked"" :> (locPts = If[locPts === {}, pts, {}])}]},
    PlotRange -> 1, PlotRangePadding -> Scaled[.05]]]]

"
gui construction - How to make a dynamic stopwatch?,"
Here's my first stab at a solution based on the idea of a closure. Maybe it has some elements that you can draw on for inspiration.
Function to create a timer function
makeTimer[] := Module[{start = AbsoluteTime[]}, Switch[#,
    ""now"", AbsoluteTime[] - start,
    ""lap"", AbsoluteTime[] - start,
    ""reset"", (start = AbsoluteTime[]; 0)]
   &]

Timers can now be created with timer = makeTimer[] and utilised with actions such as timer[""lap""] to get the current lap time. Timers are quiescent unless asked to do something.
You could extend this to handle a pause function if that's required.
Timer with buttons
Create a timer and some buttons to access it, associate the timer with a dynamic variable time.
Grid[{{Button[""Start"", timer = makeTimer[]; time = 0]}, 
      {Button[""Lap"",   time = timer[""lap""]]}, 
      {Button[""Reset"", time = timer[""reset""]]}, 
      {Button[Dynamic[time]]}}]

Schedule a task to update the timer/clock
Create a scheduled task to run every 2 seconds to update the displayed elapsed time or clock.
RunScheduledTask[time = timer[""now""], 2]

Scheduled tasks can be removed thus:
RemoveScheduledTask[ScheduledTasks[]]

"
Collaboration on Mathematica Work,"
I'm just going to address the second part of your question about licences. Incidentally, I will say that this having been moved to Meta has provided an incentive for me to answer, since it's appropriate here to give personal views and opinions, whereas on Main it's not.
Probably by far the best known licence for open source work is the GNU GPL, and the fact that it's so well-known undoubtedly contributes to its continuing popularity. However, I consider this unfortunate in some ways, because of its (quite deliberate) almost total incompatibility with any other licence and expansive definitions of ""linking"" and ""combined works"".
For example, if one program produces any output (e.g., a file on disk) that another program reads and processes in an automated way, these programs are considered linked for the purposes of the GPL. Obviously, this is highly divergent from the ordinary concept of linking in software engineering (which is precisely the LGPL's reason for being, in that it reflects the typical meaning rather than this broader sense). Furthermore, if these two programs are distributed together in a non-incidental way (which by itself results in them constituting a ""combined work""), if either one of them is licensed under the GPL, then the combined work must be also.
The net effect of these factors is to render the GPL highly inconvenient to use for any project that incorporates, even indirectly, commercial/closed-source (""proprietary"") code; this certainly applies to Mathematica, for which the interpreter, runtime environment, and standard library all form part of a closed-source commercial product that is implicitly required by all Mathematica-language code. In my opinion, the fact that WRI asserts that the language itself is proprietary also calls into question whether the GPL can be applicable to any Mathematica project due to its absolute exclusivity toward other licences. The LGPL doesn't really help us here except if we limit ourselves to distributing LibraryLink programs (in source form only, as the LibraryLink headers aren't GPL-compatible). Mathematica does incorporate some libraries licensed under the LGPL--for example, GMP--but this is of little consequence to us as users seeking to distribute our own code. The legal issues are overall so problematic that personally I would be willing to contribute code to any GPL or LGPL-licensed Mathematica project only in the narrowest of circumstances.
So, having argued that we shouldn't use the GPL or LGPL if we wish to avoid making things unduly difficult for ourselves and other contributors to our projects, what options are still open to us? For this I think the OSSCC's licence list is a very useful resource. Their suggestions are:

If you want a licence with strong copyleft provisions, choose the CDDL
If you want a permissive licence, use the Apache License 2.0

Of these, I would personally prefer the latter, but I think the choice between copyleft and permissive is mainly guided by one's own political views, so legitimate disagreement is possible.
One caveat: the Apache License is long, and this level of legal detail might put some potential contributors (or even users) off. The main difference between the Apache License and the much shorter MIT License or New (2-clause) BSD License is that the former requires contributors to grant a licence to any patent rights they may have in their contributions, so as to avoid patent trolling. Where this is not an issue--for example, in code you've written yourself and just want to distribute to the community--I would probably prefer to use one of the shorter permissive licences as a matter of convenience.
Edit
Sjoerd asks:

What about SE's license?

In my opinion, while generally appropriate for the site, this is also highly problematic as far as software packages are concerned. The Creative Commons Attribution-ShareAlike 3.0 licence is a copyleft licence intended for literary and artistic works, not computer code, and as a result makes the assumptions that:

Licensed works have a single Original Author, and that if adaptations are made then it is practical to credit or not credit each of the contributors in relation to their contributions according to their wishes. For software with multiple contributors who each build on each other's contributions, it can become impossible after a number of revisions have been made to determine who is the legitimate Original Author for each aspect of the project (however ""aspect"" should be defined). This is in fact the central problem of the original (3-clause) BSD License, which prompted the creation of the New BSD License by removing the ""endorsement"" clause.
The qualitative nature of a licensed work is not substantially changed by any adaptations. For example, while it would certainly violate the spirit of the licence, it's somewhat unclear whether it would be technically admissible to take a work licensed under CC-by-SA 3.0 and ""adapt"" it as part of a machine-locked, Encoded commercial package, provided that the latter (now rather meaninglessly) adopted the same licence. As copyleft is of little value for software without availability guarantees for the source code, the appropriateness of this licence is called into question.
The licensed work is purely artistic, not the embodiment of an invention, and therefore patents cannot apply to it. This leaves open the possibility of patent trolling.

Other miscellaneous problems in attempting to interpret the CC-by-SA 3.0 licence in the context of computer code also arise from the fact that the licence is clearly not intended for this purpose. Therefore, my suggestion would be not to use it for software packages, and if you want to use code presented on this site in a package, to contact the author and ask whether they'll grant you a licence under alternative terms more suitable for the purpose. (I added a notice to my profile specifying my licensing terms; perhaps it would be helpful if others did the same.)
"
dynamic - Locking a value when Manipulating variables,"
Well, I have needed before to link variables within a manipulate object, and I always get complicated dynamic things, for your example if you want to add constraints to your variables, you could come up with something like this:
Module[{spaces, boxes, lastboxes, lastspaces, condition, solvebox, 
  solvespace},
 condition[s_, b_] := 4 s + 3 b == 640;
 solvebox[s_] := b /. First[Solve[condition[s, b], b]];
 solvespace[b_] := s /. First[Solve[condition[s, b], s]];
 lastboxes = 100;
 lastspaces = solvespace[lastboxes];
 Manipulate[{spaces, boxes}, 
  Control[{{boxes, lastboxes, ""Boxes""}, 0, 640}], 
  Control[{{spaces, lastspaces, ""Spaces""}, 0, 640}], 
  Dynamic[If[! condition[spaces, boxes], 
    If[lastboxes === boxes, 
      With[{newbox = solvebox[spaces]}, 
       If[newbox < 0, spaces = solvespace[boxes], lastboxes = boxes; 
        boxes = solvebox[spaces]]], 
      With[{newspaces = solvespace[boxes]}, 
       If[newspaces < 0, boxes = lastboxes, lastboxes = boxes; 
        spaces = newspaces]]];]; """"], ControlPlacement -> Left, 
  Deployed -> True]
 ]

That Dynamic after Control objects comes pretty good to do that stuff, but does your code become bigger.
"
import - How to test if file exists and stop,"
You might consider using Messages instead of Print.  You should also consider using TrueQ if either root or filename might not be a string.
file::nodir = ""Directory `1` does not exist."";
file::nofile = ""File `1` does not exist."";

If[! TrueQ @ DirectoryQ @ root, Message[file::nodir, root]; Abort[]];
If[! TrueQ @ FileExistsQ @ filename, Message[file::nofile, filename]; Abort[]];

"
How to extract edgeweights from a graph,"
You can still use WeightedAdjacencyMatrix and massage the output to a nicer form —
g = Graph[{1 <-> 2, 2 <-> 3, 3 <-> 1}, EdgeWeight -> {2, 3, 4}];
Replace[Most@ArrayRules@UpperTriangularize@WeightedAdjacencyMatrix[g], 
    {x_, y_} :> UndirectedEdge[x, y], {2}]


"
Export animation of a Manipulate autorun sequence?,"
UPDATE: I recently wrote a related post:
Showcasing Manipulate[…] via .GIF animations
OLDER: It is already automated. You can just Exportthe Manipulate output to get your movie:
m=Manipulate[Plot[Sin[a x + b], {x, -3, 3}], {a, 1, 10}, {b, -3, 3}]
Export[""MyAutorun.avi"", m]

This tutorial discuss it. Here is the summary:

By default Export will generate an animation by running the Manipulate through one Autorun cycle
When a Manipulate output containing explicit bookmarks is exported to a video animation format using Export, the resulting video will be one cycle through the sequence generated by Animate Bookmarks.

"
pattern matching - How can I mix the behaviors of StringReplace and ReplaceAll in a single rule?,"
The following works:
list /. {ys_String, p_} :> {StringReplace[ys, 
    y : NumberString ~~ __ ~~ m : NumberString ~~ __ :> y <> ""+"" <> m <> ""/12""], p} // 
        ToExpression//N

(* Out[1]= {{65.25, 75.}, {65.3333, 75.1}} *)

The reason your construct failed is because the replacement rule, y+m/12 is not a string (you're performing additions and divisions on strings...). The following example makes it clear as to the difference:
StringReplace[""abc"", ""a"" -> ""x + y""]
(* Out[1]= ""x + ybc"" *)

StringReplace[""abc"", ""a"" -> ""x"" + ""y""]
(* Out[2]= ""x"" + ""y"" ~~ ""bc"" *)

~~ is otherwise known as StringExpression.
"
export - How to save animation in mp4 format instead of avi?,"
Edit 2
Strictly speaking, the answer to the question ""How to save animation in mp4 format"" is simply this:
Export[""MyAutorun3.mov"", m, ""VideoEncoding"" -> ""MPEG-4 Video""]

I'm adding this for completeness. The .mov file contains an MPEG-4 encoded video, whereas the default with Mathematica is Cinepak. The reason why we have to jump through additional hoops is that this  output file doesn't appear to work with the flash-based video players that ship with media9. 
Edited: use Quicktime Player instead of ffmpeg
On Mac OS X, there's an easier alternative to ffmpeg to create a movie that works with media9. It requires no additional software. 
First use the example from this post
m=Manipulate[Plot[Sin[a x + b], {x, -3, 3}], {a, 1, 10}, {b, -3, 3}]

Export as Quicktime, as F'x also suggested:
Export[""MyAutorun.mov"", m]

Open this movie in Quicktime Player (built-in on Mac) and choose File > Export ... with format 480p. The newly created movie (let's call it MyAutorun2.mov) can be incorporated in your $\LaTeX$ file, as in this example:
\documentclass{article}
\usepackage[english]{babel}
\usepackage{media9}

\begin{document}

\includemedia[
  activate=pageopen,
  width=200pt,height=170pt,
  addresource=MyAutorun2.mov,
  flashvars={%
src=MyAutorun2.mov
&scaleMode=stretch}
]{}{StrobeMediaPlayback.swf}
\end{document}

You could also export the Manipulate as SWF,
Export[""MyAutorun.swf"", m]

Flash seems to do everything mp4 would do in your case: it's small and can be embedded in PDF for Adobe Reader using the movie15 or media9 packages. 
To understand possible errors you may be seeing, I'll be more specific in describing what works for me:
Now create a $\TeX$ file with the contents
\documentclass{article}
\usepackage{media9}
\usepackage[english]{babel}

\begin{document}
\includemedia[
  activate=pageopen,
  width=393pt,height=334pt
]{}{MyAutorun.swf}
\end{document}

The result displays and runs for me in Adobe Reader X 10.1.2 on Mac OS X Lion. I think swf is the easiest way to get movies from Mathematica to PDF. Everything else requires some detour.
The disadvantage of directly embedding Mathematica's SWF export into the PDF is that there are no actually useable playback controls. For that, the video player solution is needed. So here is how that works for me:
With an exported 'mov`, run the following:
ffmpeg -i MyAutorun.mov -s 540x360 -vcodec libx264 MyAutorun.mp4

What I added here is an explicitly even pair of numbers as the frame size, and the codec info. Hopefully, this will help prevent the errors you're seeing.
Finally, I embed the resulting mp4 file with this $\LaTeX$ source:
\documentclass{article}
\usepackage[english]{babel}
\usepackage{media9}

\begin{document}

\includemedia[
  activate=pageopen,
  width=200pt,height=170pt,
  addresource=MyAutoRun.mp4,
  flashvars={%
src=MyAutoRun.mp4
&scaleMode=stretch}
]{}{StrobeMediaPlayback.swf}
\end{document}

I didn't worry about reproducing the aspect ratio of the movie correctly here. The main thing is of course that your ffmpeg sizes should be big enough to avoid a blurry image for the desired player width. This worked for me. 
"
A question about transforming one List into two Lists with additional requirements,"
Assuming valid data, I think this does what you need:
valid = {{1, 2}, {1, 3}, {{1, 0}, {0, 1}}, {1, 2}}

a={};
b=valid/.{x:List[_?NumericQ,_?NumericQ]:>(Position[a,x]/.{}:>{{Length[AppendTo[a,x]]}})[[1,1]]};
a
b

"
plotting - Visualizing a Complex Vector Field near Poles,"
Here are two suggestions for the function
f[z_] := 1/z;

First, instead of defining a region to omit from your plot, you should base the omission criterion on the length of the vectors (so that you don't have to adjust the criterion manually when switching to a function with different pole locations). That can be achieved like this:
With[{maximumModulus = 10},
 VectorPlot[{Re[f[x + I*y]], Im[f[x + I*y]]}, {x, -1.5, 1.5}, {y, -1, 
   1}, VectorPoints -> Fine, 
  VectorScale -> {Automatic, Automatic, 
    If[#5 > maximumModulus, 0, #5] &}]
 ]


The main thing here is that as the third element of the VectorScale option I provided a function that takes the 5th argument (which is the norm of the vector field) and outputs a nonzero vector scale only when the field is smaller than the cutoff value maximumModulus.
Another possibility is to encode the modulus not in the vector length at all, but in the color of the arrows:
VectorPlot[{Re[f[x + I*y]], Im[f[x + I*y]]}, {x, -1.5, 1.5}, {y, -1, 
  1}, VectorPoints -> Fine, 
 VectorScale -> {Automatic, Automatic, None},
 VectorColorFunction -> (Hue[2 ArcTan[#5]/Pi] &), 
 VectorColorFunctionScaling -> False]


What I did here is to suppress the automatic re-scaling colors in VectorColorFunction and provided my own scaling that can easily deal with infinite values. It's based on the ArcTan function.
As a mix between these two approaches, you could also use the ArcTan to rescale vector length. 
"
graphics - How to separate paths from the output of EdgeDetect?,"
You can use MorphologicalComponents to get the different loops:
With[{components = MorphologicalComponents@EdgeDetect@Graphics[Style[Text[""8""], 400]]},
    ColorNegate@Image[1 - Unitize[components - #]] & /@ Range[Max[components]]]


Trying this on other similar characters — {""A"", ""B"", ""g"", ""9""}

"
programming - What is the proper method to load a Mathematica package inside a DynamicModule,"
While Initialization is a useful option, it is only evaluated when the body of the DynamicModule is displayed on screen. See some explanation on the evaluation sequence here.
With DynamicModule
I've constructed a TestPackage` for this case, it contains the globally exported variable $Test, with a value of 123. The following example shows that the package is not loaded (note that you have to clear dynamic content and variables (e.g. restart kernel) for each example below to start from a clear state of memory):
DynamicModule[{}, $Test, Initialization :> (Needs[""TestPackage`""])]


$Test

It doesn't work with an explicit TestPackage`$Test call either indicating that $Test (and thus the body) is evaluated before the Initialization code. This is somewhat contraintuitive, as one expects the initialization code to be evaluated before anything else. I should note here that the package is loaded, it is just loaded too late. Any later cells calling for $Test return the correct value though. One way to overcome this in the given setup is to use the explicit name of $Test in a dynamic output, which updates the unrecognized $Test output when the package is finally loaded during evaluation:
DynamicModule[{}, Dynamic[TestPackage`$Test], Initialization :> Needs[""TestPackage`""])]


123

The second example is even more strange. While the package loading code is included in the body, $Test is still not recognized:
DynamicModule[{}, Needs[""TestPackage`""]; $Test]


Using the explicit name of the variable helps here, indicating that parsing (done before evaluation) causes $Test to be a local variable that is not recognized as TestPackage`$Test:
DynamicModule[{}, Needs[""TestPackage`""]; TestPackage`$Test]


123

Of course the easiest way is:
Needs[""TestPackage`""];
DynamicModule[{}, $Test]


123

Update
And the Wolfram way is (see this conference material):

""Can be solved by two Needs[] statements...one to fulfill Shift+Enter
  evaluation and one to fulfill Dynamic evaluation. Note that this is
  only an issue because of $ContextPath. Any other initialization code
  could have safely appeared one time inside of Initialization.""

Needs[""TestPackage`""]; 
DynamicModule[{}, Dynamic[$Test], Initialization :> Needs[""TestPackage`""])]


123

With Manipulate
Following the Wolfram way, one needs the outer package loading, but in Manipulate, SaveDefinitions works correctly grabbing the definition of $Test from the package:
Needs[""TestPackage`""];
Manipulate[$Test, {$Test, None}, SaveDefinitions -> True]


123

With Dynamic
According to the above examples, with Dynamic (each cell should be evaluated in a fresh kernel):
Dynamic[$Test, Initialization :> (Needs[""TestPackage`""])]


Global`$Test

Dynamic[TestPackage`$Test, Initialization :> (Needs[""TestPackage`""])]


123

Dynamic[Needs[""TestPackage`""]; $Test]


Global`$Test

Dynamic[Needs[""TestPackage`""]; TestPackage`$Test]


123

"
functions - FunctionInterpolation Errors / Question re Evaluation Order and Options,"
I don't think InterpolatingFunction is intended to work on vector functions. The doc page doesn't say anything about it. Try for instance
f = FunctionInterpolation[{x, x}, {x, 0, 6}]

And
Table[f[x], {x, 0, 6, 1}]

returns   
(*
==> {0., 0.9999652778, 1.998576389, 3., 4.004131944, \
4.994409722, 6.}
*)

So, no two dimensional output.
It's probably better to come up with three separate interpolating functions for each of the three components of the output.

Having said that, it doesn't look like this is the end of the problems.
xyz2llaPhi = GeoPosition[GeoPositionXYZ[obs + # look, ""WGS84""]][[1, 1]] &;
fPhi = FunctionInterpolation[xyz2llaPhi[d], {d, 2000000, 3700000}]

yields

Whereas
xyz2llaPhi[200000]

yields a nice numerical result:
(*
==> -34.86629487
*)

It looks like the combination of FunctionInterpolation and GeoPosition isn't a healthy one. Somehow, the index d is held unevaluated.
A workaround would be to generate a table of values and then use ListInterpolation.
"
How to divide a graph into connected components?,"
Here is one way:
Subgraph[g, #, VertexLabels -> ""Name"", ImagePadding -> 10] & /@ 
    ConnectedComponents[UndirectedGraph[g]]


The proper terminology for what you asked, as hinted by the code, is connected components of a graph. I had to convert a graph to undirected one, since connectivity in a directed graph is a stronger condition, and not what you were after here.
"
machine learning - Linear separability for a sum of kernel functions,"
Old question, but:
I'll assume first that the kernels correspond to finite feature maps. Say that $K_1(x, y) = \varphi_1(x)^T \varphi_1(y)$, $K_2(x, y) = \varphi_2(x)^T \varphi_2(y)$. Then
$$K_1(x, y) + K_2(x, y) = \begin{bmatrix}\varphi_1(x) \\ \varphi_2(x)\end{bmatrix}^T \begin{bmatrix}\varphi_1(y) \\ \varphi_2(y)\end{bmatrix}.$$
Thus, if a hyperplane defined by $(w_1, b_1)$ separates the dataset under the $\varphi_1$ map, the hyperplane defined by $\left(\begin{bmatrix}w_1 \\ 0\end{bmatrix}, b_1 \right)$ will separate the points in the same way under the combined mapping.
You can generalize this feature maps in any Hilbert space, since the space defined by $K_1 + K_2$ is the product of the spaces defined by $K_1$ and $K_2$ similar to vector concatenation in the finite case.
"
image processing - What's the difference between EdgeDetect and MorphologicalPerimeter (for a white background)?,"
No, they're not the same, and will not, in general, give the same result because they're two very different operations.

MorphologicalPerimeter gives a Boolean output according to the following logic:

1 — If the pixel value is 1 (i.e., white) and at least 1 pixel in its 8-pixel neighbourhood is 0.
0 in all other cases. 

Here's an example with a simple 20x20 image with 1 black pixel along the diagonal. You can actually follow the logic above to verify the output (assume 0 outside the edge for pixels along the border)
img = ColorNegate@Image@IdentityMatrix[20];
MorphologicalParameter[img]


EdgeDetect, by default, uses the Canny edge detector which is a lot more complicated, multi-step algorithm unlike MorphologicalPerimeter. Roughly speaking, it convolves it with a Gaussian filter, followed by a non-maximum suppression step, which basically sets all pixels that aren't a local-maxima to zero. You can read more about it in the Wikipedia article.
Performing an edge detection on the above image gives you:
EdgeDetect[img]


You can visibly see the difference between the two images above, especially at the corners and the borders.

"
Is the Wolfram | Alpha output in Mathematica not Alpha Pro?,"
I can't say that all the Alpha Pro features are available through V8 of Mathematica, but certainly many are.  Here are three examples:
Type ""derivative of x^2"" into Alpha.  If you are not logged into the Pro version, you will be unable to access the result, other than as a visual image.  In particular, you can't easily copy and paste results.
Or try, just ""z^2-1"" in Alpha.  You'll notice a number of pods that have an ""Enable Interactivity"" button.  If you press such a button, Alpha generates some type of groovy interactive CDF content, if you are logged into Pro.  Without Pro, you can't interact with that content.  In Mathematica, all those interactives are switched on by default.
Finally, Alpha Pro gives you direct access to scads of data for queries like ""US Population history"".  You need Pro to do this or, again, you can do it directly through Mathematica without Pro.
I would be surprised if all Pro features work immediately through Mathematica.  Do you have specific examples that you were thinking of?
"
Growth of functions - Mathmatica Stack Exchang,"
Yes, Mathematica can be used to characterize the asymptotic behaviour of functions, but maybe not in the straightforward way you intended. Let's see a few examples (I'll focus on asymptotic behaviour as $x\rightarrow\infty$, but behaviour around any other point works the same) of what we can do by looking at limits (using the Limit function):

How to check if $f(x) \in o(g(x))$, or $g(x) \in \omega(f(x))$
There, the question we can ask Mathematica is: what is the limit of $f(x)/g(x)$:

If the limit is zero, then $f$ is dominated by $g$, as in the example below, where
$$f(x)=x^2e^{-\sqrt x}\ \ \text{  and }\ \ g(x)=e^{-x}$$
In[1]:= Limit[(x^2*Exp[-Sqrt[x]])/Exp[x], x -> ∞]
Out[1]= 0

If the limit exists, but is not zero (it can be a finite number, an infinity, or an Interval): $f$ is not dominated by $g$ (and if the limit is $\infty$, then in fact $g$ is dominated by $f$). Three examples:
In[2]:= Limit[(3*x^2 + x + 1)/x^2, x -> ∞]
Out[2]= 3

In[3]:= Limit[Gamma[x]/Exp[x], x -> ∞]
Out[3]= ∞

In[4]:= Limit[x*Sin[x]/Sqrt[x], x -> ∞]
Out[4]= Interval[{0, ∞}]

If the limit is unknown to Mathematica, then you haven't learnt anything.


How to check if $f(x) \in O(g(x))$
$f(x) \in O(g(x))$ means that, for large enough $x$, $\left\vert f(x)/g(x)\right\vert$ is bounded. So, our options are as such:

If $\left|f(x)/g(x)\right|$ converges to a finite number (including zero, but not $\infty$), then that's it: $f(x) \in O(g(x))$
In[5]:= Limit[(3*x^2 + x + 1)/(Erf[x]*x^2), x -> ∞]
Out[5]= 3

If $|f(x)/g(x)|$ converges to an interval which does not include any infinity, the same is true:
In[6]:= Limit[Abs[Sin[x]/(2 + Cos[x])], x -> ∞]
Out[6]= Interval[{0, 1}]

If $\left|f(x)/g(x)\right|$ converges to $\infty$ or to an interval containing $\infty$, then $f(x) \not\in O(g(x))$.
Otherwise, you have learnt nothing.


The fine print: in many examples above, I calculate $f/g$ instead of $|f/g|$ because I know that the functions both have positive values. Also, if $g(x)$ takes zero as a value in more than a finite number of points, you need to be a little bit more careful than just calculating $f/g$.
"
sound - Can one find the beat of a tune with Fourier analysis?,"
Here's a possible starting point for a solution. It splits the sample list into chunks and measures the Norm of the sample Differences in each chunk, and then does the FFT on that data.
bpmplot[snd_, bpmmax_: 300] := 
Module[{samples, minfreq, signal, fft},
samples = snd[[1, 1, 1]];
minfreq = snd[[1, 2]]/Length[samples];
signal = (Norm[Differences[#]]) & /@ Partition[samples, 128];
fft = Abs[Fourier[signal][[;; Floor[bpmmax/(120 minfreq)]]]];
fft[[;; 10]] *= 0; (* remove very low frequencies *)
ListLinePlot[MapIndexed[{120 (#2[[1]] - 1) minfreq, #1} &, fft], 
PlotRange -> All, Frame -> True, FrameLabel -> {""BPM"", ""Signal""}, 
BaseStyle -> {FontFamily -> ""Calibri"", 20}]];

snd = Import[""C:\\Users\\Simon\\Desktop\\02 - Money For Nothing.wav""];

bpmplot[snd]


Google tells me that the BPM for this track is 134, and you can see that it has picked that frequency out quite well, though there are many other peaks too, especially the harmonic at 268 bpm.
"
probability or statistics - Is there a function to calculate studentized range?,"
I do not think there's one built-in, but it's fairly easy to write a function for it:
studentizedRange[data_List] := (Max[data] - Min[data])/StandardDeviation[data]

But I would also check out the ANOVA package for related functionality.
"
evaluation - How can I completely ban usage of some functions in output and mandate use of others?,"
You may try for example something like:
f[e_] := 100 Count[e, _Pochhammer, {0, Infinity}] + LeafCount[e];
FullSimplify[Pochhammer[k, n], ComplexityFunction -> f]

(*
->Gamma[k + n]/Gamma[k]
*)

"
stylesheet - Why does Installing small caps fonts in OS X cause notebook Text cells to use that font?,"
The Text style uses FontFamily->""Times"".  Your fonts are almost certainly set to have the same family name as the built-in font that Mathematica normally uses, and leaves the system with two possible sets of fonts to choose from.  Even though the internal font name being used is, e.g., Times-RomanSC, that's not the actual family name...that's the style name (I'm not sure how standard the term ""style name"" is, but it's the term that FontLab uses for this).
As a result, Mathematica asks for ""Times"", and this font shows up in the list of candidates.  Mathematica will choose the first font the system offers from that list.  I would have expected Mathematica to understand that this is a small caps variant, and not use the font unless you wanted small caps, but it's entirely possible that the variant information in the font is not declared in a way that Mac OS X recognizes, probably due to it using older, Type 1 technology.  I wouldn't be surprised if other applications on your system have similar problems.
If you could edit your small caps fonts to change the font family name, that would certainly fix things.  This isn't about the filenames being used by the font...this is about the inherent family name set as a property of the font itself.  You'll probably need to change the style name to match as well.
Otherwise, you could use the Format->Show Fonts menu item to see if it's possible to pick the correct Times font and, if so, determine what the properties are by looking at the underlying cell expression (Cell->Show Cell Expression).  Armed with that information, an expert could help you figure out how to modify options/styles to avoid this.
"
programming - Why does Mathematica choose the second function definition?,"
As far as I can tell, it should match the catch all rule. That's because _ isn't of the form x[]
Now, when you test the MatchQ expression, both arguments are first evaluated. So, you're actually doing MatchQ[maybe, maybe] which of course returns True.
You can do the checking as you intended to by first holding the arguments
MatchQ[Hold@PatternImplies[_Integer, _], 
 Hold@PatternImplies[(x : (Verbatim[Blank] | Verbatim[BlankSequence] |
         Verbatim[BlankNullSequence]))[h_], x[]]]

False

EDIT:
I now see what you intended with x[]. You could do x_[] instead. That would mean ""any no-argument expression whose head coincides with the previous pattern labelled x. If you write x[] it matches literally
"
functions - What default theoretical distribution does Mathematica use in PearsonChiSquareTest?,"
According to the documentation you linked, difference is:

PearsonChiSquareTest[data, NormalDistribution[]] tests whether the data is distributed according to a normal distribution of mean 0 and standard deviation 1.
PearsonChiSquareTest[data] is actually more flexible, and checks whether your data is distributed according to any normal distribution.

The difference becomes flagrant with data from a different distribution:
data = RandomVariate[NormalDistribution[1, 0.1], 10^4];
PearsonChiSquareTest[data]
(* Out[33]= 0.419701 *)

PearsonChiSquareTest[data, NormalDistribution[]]
(* Out[34]= 2.712072730217051*10^-23123 *)


In short, the following two statements are equivalent:
PearsonChiSquareTest[data]
PearsonChiSquareTest[data, NormalDistribution[μ, Σ]]

where the second one uses symbolic parameters in the distribution. You can retrieve information about the test by doing:
PearsonChiSquareTest[data, NormalDistribution[μ, Σ], ""HypothesisTestData""]

and exploring the different properties of this object. All properties can be listed by:
PearsonChiSquareTest[data, NormalDistribution[μ, Σ], ""HypothesisTestData""][""Properties""]

and the fitted distribution is recovered with:
PearsonChiSquareTest[data, NormalDistribution[μ, Σ], ""HypothesisTestData""][""FittedDistribution""]

Enjoy!
"
bugs - Random variables with transformed discrete distributions cannot be applied to Probability[] function?,"
The following computes the probability you asked for, but I'm at a loss to understand why your notation won't work. It seems correct to me.
Probability[
 3 x + 1 > y, {Distributed[x, Dx], Distributed[y, Dy]}]

(*
==> 147/289
*)

The Probability / Distribution functions are quite young and hence not fully bulletproofed and I have encountered a number of bugs myself. I suppose/hope that in the next release they will be solved. I suggest you contact Wolfram support (support@wolfram.com). But perhaps someone else here may find out what's wrong.
A few of mine:
No random variates from PDFs that stem from multivariate distributions:  
dist = ProbabilityDistribution[
   PDF[BinormalDistribution[{0, 0}, {1, 1}, 0]][{x, 
     y}], {x, -Infinity, Infinity}, {y, -Infinity, Infinity}];
RandomVariate[dist]

This works for 3, but not for 5 (and higher):
Expectation[x,x\[Distributed] OrderDistribution[{GeometricDistribution[0.1], 3}, 3]]
Expectation[x,x\[Distributed] OrderDistribution[{GeometricDistribution[0.1], 5}, 5]]

The following crashes the kernel after a minute or so (so, DO NOT EXECUTE):
PDF[TransformedDistribution[Sin[u], u \[Distributed] NormalDistribution[0, 1]], 0]

"
plotting - Aligning a DensityPlot with a Plot,"
AbsoluteOptions shows there to be several differences between the  output settings of the first and second plots:
Grid[Prepend[Transpose[
     AbsoluteOptions[#, {PlotRangePadding, AspectRatio, 
           Frame}] & /@ {plot1, plot2}], {""first"", ""second""}], Frame -> All]


It'll look better if you use the same aspect ratio (I used 1/GoldenRatio) and a frame in each picture. I also set PlotRangePadding-> None in the second case.

"
"programming - Can a Table iterator ""leak"" into a Module?","
I know the reason for the second giving you the error: i has been set to 1. Under normal operations, this will not happen as Table has the Attribute HoldAll, so even if i has a value, Table should be shielded from it. For example,
i = 5
Table[ i, {i , 3}]
(* Out[1] = 5 
   Out[2] = {1, 2, 3}
*)

However, in the large block of code, you use this construct:
With[{i = i}, Table[ ..., {i, ...} ]

So, it is likely that the second Table is executed in a similar manner, and that is where the problem lies. For instance,
With[{i = 1}, Table[i, {i, 5}]]
(* Table::itraw: Raw object 1 cannot be used as an iterator. >>
   Out[3] = Table[1, {1, 5}]
*)

With operates by replacing i in Table with its value prior to Table doing anything which circumvents the HoldAll.  Neither, Block nor Module have the same effect, so I would advise using them, instead, for this type of thing.

In your code for run2, you effectively have this code
Table[ With[{i2 = i1}, Table[ ..., {i2, ...}]], {i1, ...}]
(* I have renamed the variables for clarity, but the results are the
   same with them all set to i*)

Here, i1 is localized to the outer Table and the With sets i2 to the value of i1 which causes the error you're seeing.  The reason this shows up inside errorcorrection is that i1 is not localized to errorcorrection, but takes on the global (to it) value. 
Incidentally, this reveals that Table is using Block or Internal`InheritedBlock to perform its scoping. Consider, 
f[x_] := {x, i}
Block[{i = 3}, f[q]]
Internal`InheritedBlock[{i = 3}, f[q]]
Module[{i = 3}, f[q]]
With[{i = 3}, f[q]]
(*
Out[131]= {q, 3}
Out[132]= {q, 3}
Out[133]= {q, i}
Out[134]= {q, i}
*)

which reveals one of the key differences between the different scoping constructs. Here i in f is interpreted as Global`i, but Module and With effectively use Unique[i], instead. So, they return Global`i unevaluated.  (With actually performs a rewriting operation, but the effect is the same.) Block and Internal`InheritedBlock effectively define Unique[]`i and without any context qualifier on i in f, it is subsumed into the new context. The difference between them is that Block assumes that no definitions of i exists. But, Internal`InheritedBlock pulls in the global definitions into Unique[]` allowing for small changes to be made easily.
In the code, if i was not specified in the outer Table (as in the code for run3), then yes With would work as expected. But, the moral of the story is that Table need not be wrapped in any of scoping constructs as it does the scoping itself.
"
graphs and networks - How to display edge labels above edges?,"
GraphPlot[{{1 -> 2, ""1\[Rule]2""}, 4 -> 1, {2 -> 4, ""2\[Rule]4""}, 1 -> 5, 2 -> 5, 5 -> 4}, 
 EdgeRenderingFunction -> 
   ({If[#3 =!= None, 
           {Line[#], Inset[#3, Mean[#1], Automatic, Automatic, #[[1]] - #[[2]], 
           Background -> White]}, Line[#]]} &)]


"
"return value - Compile and ""True should be a machine-size real number..."" Error","
For the error handling use the compilers error handling mechanism:
cffail = Compile[{{x, _Real, 1}}, Exp[x], 
   ""RuntimeOptions"" -> {""RuntimeErrorHandler"" -> Function[$Failed]}];
cffail[{1000.}]

The Function can be anything (Throw[..],...).
For the summation you could use Total in stead:
Compile[{{x, _Real, 1}}, Total[x]]

"
Conditional break point in Wolfram Workbench?,"
One way that works already is to put a break point inside an If statement.
If[condition,
   dummyInstruction;
];

And put a breakpoint at dummyInstruction. I don't know if something like this could be done without modifying the code in break point properties like in some other environments.
"
Support for pro font families?,"
Getting the names of the fonts is pretty easy. I like Heike's solution, but I can remember the following procedure better. 
Just format the text in some text cell with any font style you like and then enter the menu command Cell > Show Expression (ctrlshiftE on a PC) revealing the formatting instructions.
Cell[TextData[StyleBox[""aaaaa"",
 FontFamily->""Myriad Pro Light"",
 FontWeight->""Demi"",
 FontSlant->""Italic""]], ""Text"",
 CellChangeTimes->{{3.543584575138007*^9, 3.5435845788282185`*^9}}]

Using this information:
Column[{
  Style[""Myriad Pro"", FontFamily -> ""Myriad Pro"", 80],
  Style[""Myriad Pro Cond"", FontFamily -> ""Myriad Pro Cond"", 80],
  Style[""Myriad Pro Cond Italic"", FontFamily -> ""Myriad Pro Cond"", 
   FontSlant -> ""Italic"", 80],
  Style[""Myriad Pro Cond Bold"", FontFamily -> ""Myriad Pro Cond"", 
   FontSlant -> ""Plain"", FontWeight -> ""Bold"", 80],
  Style[""Myriad Pro Cond Bold Italic"", 
   FontFamily -> ""Myriad Pro Cond"", FontSlant -> ""Italic"", 
   FontWeight -> ""Bold"", 80],
  Style[""Myriad Pro Cond Semibold"", FontFamily -> ""Myriad Pro Light"", 
   FontWeight -> ""Demi"", 80],
  Style[""Myriad Pro Cond Semibold Italic"", FontFamily -> ""Myriad Pro Light"", 
   FontWeight -> ""Demi"", FontSlant -> ""Italic"", 80]
  }
 ]



By the way: Although it is often quite possible to specify slant and weight in the font name, there is a good reason to specify them separately. Compare the parenthesis in the following:
Style[""Text (x) Text"", FontFamily -> ""Myriad Pro-Bold-Italic"", 80]


and
Style[""Text (x) Text"", FontFamily -> ""Myriad Pro"", FontWeight -> Bold,
  FontSlant -> Italic , 80]


For a lot of symbols, Mathematica substitutes the Mathematica font version for the one in the specified font. If you have specified slant and weight in the font name MMA doesn't pick up those font specifications, ending up with symbols that are unmatched in style to the rest of the text.
"
graphics - Procedure to find direction of triangle,"
Given that the triangle might not exactly be isosceles, let's characterize this direction as being from the triangle's center towards the most distant vertex:
ClearAll[direction];
direction[t_List] := 
 With[{center = Mean[t]}, 
  t[[First[Ordering[N[Norm /@ (# - center & /@ t)], -1]]]] - center]

(Edit As @R.M. notes, N needs to be applied for Ordering to work consistently and correctly.)
One advantage of this approach is that it works for any polygon.  Another is that it does not require any additional specification such as a tolerance for testing approximate equality of sides.
As an example,
t = {{30.07, 11.04}, {20.07, 35.905}, {40.905, 19.095}};
center = Mean[t];
Graphics[{White, EdgeForm[Black], Polygon[t], Red, Arrow[{center, center + direction[t]}]}]


Note that the direction is given as a vector (which carries the additional information about the distance from the triangle's center towards this extreme vertex).  For other forms of output, this is readily converted into a unit vector (by normalizing it) or an angle.

Edit
Notice that for squat, flat isosceles triangles (where the apex angle exceeds 60 degrees), this solution determines that the ""pointing direction"" is from the center towards one of the base vertices, not towards the apex.  If that is not the intention, then additional analysis is needed.  One way is to determine that among all the possible directions from the center, the one most different from the other two is the one to pick:
direction[t_List] := Block[{center = Mean[t], s, l, a},
  s = # - center & /@ t;
  l = Norm /@ s;
  a = Abs[RotateLeft[l, 1] - RotateLeft[l, 2]];
  s[[First[Ordering[N[a], 1]]]]
  ]

In this implementation (which is written for clarity rather than brevity), s lists the three possible directions, l lists their lengths, and for each entry in l, a lists the differences in lengths between the other two.  The last line returns the direction where that difference is the smallest (as a vector from the center to the vertex, exactly as before).
"
symbolic - Sophistication of Series[...],"
Try this
Normal@Series[expr/.{f->x f, g->x^2 g, h->x^3 h},{x,0,4}] /.x->1
"
Memory not freed after running Clear when using a Table,"
Have you tried setting $HistoryLength to zero:
$HistoryLength=0;

The memory is not freed, because the previous data is still available by Out[nn] or %nn.
Note that if you do this, using %, %%, %n etc., which some people use in example code will not work. And when a large data set is shown the ""Show More"" and ""Show Less"" buttons do not work. You can bypass both problems by setting $HistoryLength to 1 while still conserving a lot of memory.
"
chemistry - Automatic formatting of isotope symbols in a text cell,"
You can set it as an option as follows —
SetOptions[SelectedNotebook[], InputAutoReplacements -> {""1H"" -> SuperscriptBox[""H"", ""1""]}]

Now if you enter $1\mathrm{H}$ in a text cell, it will automatically convert it to $\mathrm{H}^1$.
Another possibility is using InputAliases, where you enter the replacement as Esc1HEsc. IMHO, this is a better way to handle auto replacements, because the intent to replace is quite clear, whereas with the first approach, it'll replace it even when you don't want it to (e.g., addresses in some countries). You can set an alias as: 
SetOptions[SelectedNotebook[], InputAliases -> {""1H"" -> SuperscriptBox[""H"", ""1""]}]


Creating auto-replacements for all isotopes:
I don't think creating a blind pattern based rule replacements to handle isotope auto-replacements is a good way to approach it, because you wouldn't want invalid isotopes like 2C or 207U to actually be replaced — you'd rather they be untransformed so that it serves as a visual error/typo check. A better and safe approach would be to whitelist the known isotopes and create rules only for those isotopes.
Fortunately, you can use Mathematica itself to query this info and create your custom rules as follows:
(* get info about known isotopes *)
isotopeInfo = {ElementData[#, ""Abbreviation""], ElementData[#, ""KnownIsotopes""]} & /@ 
    ElementData[]; 

(* function to assemble the superscripts *)
createSuperscripts[{e_String, w_List}] := 
    ToString[#] <> e -> SuperscriptBox[e, ToString[#]] & /@ w

(* map over all elements and create the aliases *)
isotopeRules = createSuperscripts /@ isotopeInfo // Flatten;
SetOptions[SelectedNotebook[], InputAliases -> isotopeRules]

With this set, you can now enter valid isotopes between two Esc presses and it will convert it to a superscript.

You can also extend this to include the atomic number by default as seen in common notation (although it is redundant info). Here's an example (you can do the styling as you please) that shows how, and it also uses an \[InvisibleSpace] from my very first question
(*get info about known isotopes*)
isotopeInfo = {ElementData[#, ""Abbreviation""], 
     ElementData[#, ""AtomicNumber""], ElementData[#, ""KnownIsotopes""]} & /@ ElementData[];

(*function to assemble the subsuperscripts*)
createSuperscripts2[{e_String, n_Integer, w_List}] := 
    ToString@# <> e -> RowBox[{SubsuperscriptBox[""\[InvisibleSpace]"", ToString@n, 
    ToString@#], e}] & /@ w

The last two steps are the same (except, use this function instead). Here's how it looks on mine:

"
calculus and analysis - Maximizing a function with assumptions,"
Maximize does not take $Assumptions into account by default, but wants the assumptions to be given explicitly:
Assuming[Abs[x]>=3,Maximize[-x^2,x]]
(*
==> {0, {x -> 0}}
*)

Maximize[{-x^2,Abs[x]>=3},x]
(*
==> {-9, {x -> -3}}
*)

However you can inject $Assumptions explicitly:
Assuming[Abs[x]>=3,Maximize[{-x^2,$Assumptions},x]]
(*
==> {-9, {x -> -3}}
*)

However for your particular example, Maximize doesn't seem to be able to find the maximum anyway.
"
probability or statistics - Identifying subsets with minimal standard deviation,"
A general solution:
getMinStdDev[data_?ListQ] := Module[{ip, fp, allowedParts},
  ip = IntegerPartitions[Length@data, Length@data, Range[3, Length@data]];
  fp = Flatten[Permutations /@ ip, 1];
  allowedParts = (data[[#[[1]] ;; #[[2]]]] & /@ 
                  Thread[List[(Accumulate@Join[{1}, #])[[;; -2]],Accumulate@#]]) & /@ fp;
  allowedParts[[Ordering[Total /@ Map[StandardDeviation[#]^2 &, allowedParts, {2}], 1]]]];

Usage
getMinStdDev@{10, 11, 10, 15, 14, 16, 9, 8, 7, 6, 8, 7}
getMinStdDev@{10, 11, 15, 12, 9, 8, 7, 6, 8} (*Yours*)
getMinStdDev@Join[RandomInteger[{1,5},5],RandomInteger[{5,10},5], RandomInteger[{10,15},5]]
(*
->
{{{10, 11, 10}, {15, 14, 16}, {9, 8, 7, 6, 8, 7}}}
{{{10, 11, 15, 12}, {9, 8, 7, 6, 8}}}
{{{3, 3, 5, 3, 2}, {9, 9, 5, 8, 8, 11}, {13, 15, 15, 13}}}
*)

"
plotting - Using ContourPlot3D on a region in $\mathbb{R}^3$,"
You can use the RegionFunction option with ContourPlot3D as follows:
  ContourPlot3D[x^2 + y^2 + z^2, {x, -3, 3}, {y, -3, 3}, {z, -3, 3}, 
  Contours -> 4, 
  RegionFunction -> Function[{x, y, z}, -4 < x + y < 4 && -4 < y + 2 z < 4 && -4 < x + z < 3], 
  ContourStyle -> {Red, Green, Yellow, Orange}, Mesh -> None]

which gives

Or, for a specific contour with the same region function, you can use
  ContourPlot3D[x^2 + y^2 + z^2 == 10, {x, -3, 3}, {y, -3, 3}, {z, -3, 3}, 
  RegionFunction ->  Function[{x, y, z}, -4 < x + y < 4 && -4 < y + 2 z < 4 && -4 < x + z < 3], 
  ContourStyle -> {Red, Green, Yellow, Orange}, Mesh -> None]

to get

"
list manipulation - Combining values in one column (or part) when values in another column (or part) match,"
The following also works (though its a bit messy to look at) and will probably be faster than pattern matching if you have large input data.
Transpose[{#[[All, 1, 1]], 
      Total[#[[All, All, 2]], {2}]}] &[#] & /@ (GatherBy[#, First] & /@
    data)

EDIT:
I should point out that there are at least a couple of different problems being solved in the answers posted here. The results posted by myself and @RM attempt to preserve the structure of the original data and so do not gather like dates if they are present in multiple sublists.
Answers posted by @David Carraher and @rcollyer ignore the structure of the original data and gather all like dates.
I'm not sure which is the correct approach in this case but it felt worth pointing out the difference.
"
Automatically generating a dependency graph of an arbitrary Mathematica function?,"
Preamble
The problem is not as trivial as it may seem on the first glance. The main problem is that many symbols are localized by (lexical) scoping constructs and should not be counted. To fully solve this, we need a parser for Mathematica code, that would take scoping into account. 
One of the most complete treatments of this problem was given by David Wagner in his Mathematica Journal article, and replicated partially in his book. I will follow his ideas but show my own implementation. I will implement a sort of a simplistic recusrive descent parser which would take scoping into account. This is not a complete thing, but it will illustrate certain subtleties involved (in particular, we should prevent premature evaluation of pieces of code during the analysis, so this is a good excercise in working with held/unevaluated expressions).
Implementation (for illustration only, does not pretend to be complete)
Here is the code:
ClearAll[getDeclaredSymbols, getDependenciesInDeclarations, $OneStepDependencies,
  getSymbolDependencies, getPatternSymbols,inSymbolDependencies, $inDepends];

SetAttributes[{getDeclaredSymbols, getDependenciesInDeclarations, 
   getSymbolDependencies, getPatternSymbols,inSymbolDependencies}, HoldAll];

$OneStepDependencies = False;

inSymbolDependencies[_] = False;

globalProperties[] =
    {DownValues, UpValues, OwnValues, SubValues, FormatValues, NValues, 
     Options, DefaultValues};


getDeclaredSymbols[{decs___}] :=
    Thread@Replace[HoldComplete[{decs}], HoldPattern[a_ = rhs_] :> a, {2}];

getDependenciesInDeclarations[{decs___}, dependsF_] :=
  Flatten@Cases[Unevaluated[{decs}], 
      HoldPattern[Set[a_, rhs_]] :> dependsF[rhs]];

getPatternSymbols[expr_] :=
  Cases[ 
     Unevaluated[expr], 
     Verbatim[Pattern][ss_, _] :> HoldComplete[ss], 
     {0, Infinity},  Heads -> True];

getSymbolDependencies[s_Symbol, dependsF_] :=
  Module[{result},
    inSymbolDependencies[s] = True;
     result = 
       Append[
         Replace[
            Flatten[Function[prop, prop[s]] /@ globalProperties[]],
            {
              (HoldPattern[lhs_] :> rhs_) :>
                With[{excl = getPatternSymbols[lhs]},
                 Complement[
                   Join[
                      withExcludedSymbols[dependsF[rhs], excl],
                      Module[{res},
                         (* To avoid infinite recursion *)
                         depends[s] = {HoldComplete[s]};
                         res = withExcludedSymbols[dependsF[lhs], excl];
                         depends[s] =.;
                         res
                      ]
                   ],
                   excl]
                ],
              x_ :> dependsF[x]
            },
            {1}
         ],
         HoldComplete[s]
       ];
    inSymbolDependencies[s] =.;
    result] /; ! TrueQ[inSymbolDependencies[s]];

getSymbolDependencies[s_Symbol, dependsF_] := {};


(* This function prevents leaking symbols on which global symbols colliding with 
** the pattern names (symbols) may depend 
*)
ClearAll[withExcludedSymbols];
SetAttributes[withExcludedSymbols, HoldFirst];
withExcludedSymbols[code_, syms : {___HoldComplete}] :=
   Module[{result, alreadyDisabled },
     SetAttributes[alreadyDisabled, HoldAllComplete];
     alreadyDisabled[_] = False;
     Replace[syms,
       HoldComplete[s_] :>
         If[! inSymbolDependencies[s],
            inSymbolDependencies[s] = True,
            (* else *)
            alreadyDisabled[s] = True
         ],
       {1}];
     result = code;
     Replace[syms, 
        HoldComplete[s_] :> 
           If[! alreadyDisabled[s], inSymbolDependencies[s] =.], 
        {1}
     ];
     ClearAll[alreadyDisabled];
     result
 ];


(* The main function *)
ClearAll[depends];
SetAttributes[depends, HoldAll];
depends[(RuleDelayed | SetDelayed)[lhs_, rhs_]] :=
   With[{pts = getPatternSymbols[lhs]},
      Complement[
        Join[
          withExcludedSymbols[depends[lhs], pts], 
          withExcludedSymbols[depends[rhs], pts]
        ],
        pts]
   ];
depends[Function[Null, body_, atts_]] := depends[body];
depends[Function[body_]] := depends[body];
depends[Function[var_, body_]] := depends[Function[{var}, body]];
depends[Function[{vars__}, body_]] := 
   Complement[depends[body], Thread[HoldComplete[{vars}]]];
depends[(With | Module)[decs_, body_]] :=
  Complement[
    Join[
      depends[body],
      getDependenciesInDeclarations[decs, depends]
    ],
    getDeclaredSymbols[decs]
  ];
depends[f_[elems___]] :=
  Union[depends[Unevaluated[f]], 
    Sequence @@ Map[depends, Unevaluated[{elems}]]];
depends[s_Symbol /; Context[s] === ""System`""] := {};
depends[s_Symbol] /; ! $OneStepDependencies || ! TrueQ[$inDepends] :=  
   Block[{$inDepends = True},
      Union@Flatten@getSymbolDependencies[s, depends ]
   ];
depends[s_Symbol] := {HoldComplete[s]};
depends[a_ /; AtomQ[Unevaluated[a]]] := {};

Illustration
First, a few simple examples:
In[100]:= depends[Function[{a,b,c},a+b+c+d]]
Out[100]= {HoldComplete[d]}

In[101]:= depends[With[{d=e},Function[{a,b,c},a+b+c+d]]]
Out[101]= {HoldComplete[e]}

In[102]:= depends[p:{a_Integer,b_Integer}:>Total[p]]
Out[102]= {}

In[103]:= depends[p:{a_Integer,b_Integer}:>Total[p]*(a+b)^c]
Out[103]= {HoldComplete[c]}

Now, a power example:
In[223]:= depends[depends]
Out[223]= 
{HoldComplete[depends],HoldComplete[getDeclaredSymbols],
 HoldComplete[getDependenciesInDeclarations],HoldComplete[getPatternSymbols],
 HoldComplete[getSymbolDependencies],HoldComplete[globalProperties],
 HoldComplete[inSymbolDependencies],HoldComplete[withExcludedSymbols],
 HoldComplete[$inDepends],HoldComplete[$OneStepDependencies]}

As you can see, my code can handle recursive functions. The code of depends has many more symbols, but we only found those which are global (not localized by any of the scoping constructs). 
Note that by default, all dependent symbols on all levels are included. To only get the ""first-level"" functions / symbols on which a given symbol depends, one has to set the variabe $OneStepDependencies to True:
In[224]:= 
$OneStepDependencies =True;
depends[depends]

Out[225]= {HoldComplete[depends],HoldComplete[getDeclaredSymbols],
HoldComplete[getDependenciesInDeclarations],HoldComplete[getPatternSymbols],
HoldComplete[getSymbolDependencies],HoldComplete[withExcludedSymbols],
HoldComplete[$inDepends],HoldComplete[$OneStepDependencies]}

This last regime can be used to reconstruct the dependency tree, as for example suggested in the answer by @Szabolcs.
Applicability
This answer is considerably more complex than the one by @Szabolcs, and probably also (considerably) slower, at least in some cases. When should one use it? The answer I think depends on how critical it is to find all dependencies. If one just needs to have a rough visual picture for the dependencies, then @Szabolcs's suggestion should work well in most cases. The present asnwer may have advantages when: 

You want to analyze dependencies in an arbitrary piece of code, not necessarily placed in a function (this one is easily if not super-conveniently circumvented in @Szabolcs's approach by first creating a dummy zero-argument function with your code and then analyzing that)
It is critical for you to find all dependencies. 

Things like
$functionDoingSomething = Function[var,If[test[var],f[var],g[var]]]
myFunction[x_,y_]:= x+ $functionDoingSomething [y]

will escape from the dependencies found by the @Szabolcs's code (as he mentioned himself in the comments), and can therefore cut away whole dependency sub-branches (for f, g and test here). There are other cases, for example related to UpValues, dependencies through Options and Defaults, and perhaps other possibilities as well. 
There may be several situations when finding all dependencies correctly is critical. One is when you are using introspection programmatically, as one of the meta-programming tools - in such case you must be sure everything is correct, since you are building on top of this functionality. To generalize, you might need to use something like what I suggested (bug-free though :)), every time when the end user of this functionality will be someone (or something, like other function) other than yourself.
It may also be that you need the precise dependency picture for yourself, even if you don't intend to use it programmatically further.  
In many cases however, all this is not very critical, and the suggestion by @Szabolcs may represent a better and easier alternative. The question is basically - do you want to create user-level or system-level tools.
Limitations, flaws and subtleties
EDIT
The current version of the code certainly contains bugs. For example, it can not handle the GraphEdit example from the answer of @Szabolcs without errors. While I hope to get these bugs fixed soon, I invite anyone interested to help me debugging the code. Feel free to update the answer, once you are sure that you correctly identified and truly fixed some bugs.
END EDIT 
I did not intend this to be complete, so things like UpSetDelayed and TagSetDelayed are not covered, as well as probably some others. I did not also cover dynamic scoping (Block, Table, Do, etc), because in most cases dynamic scoping still means dependencies. The code above can however be straightforwardly extended to cover the cases missed here (and I might do that soon).
The code can be refactored further to have a more readable / nicer form. I intend to do this soon.
"
plotting - Why plot returns empty in this example?,"
In your first example, the Plot is inside a Module that localizes t into something like t$23. So, when you run foo[s, t], you are actually running something similar to  
 t$23=t;
 r=E^-t$23 UnitStep[t$23];
 Plot[Chop@First@r,{t$23,0,20}]

The second line returns an expression of t. When you insert it in the last Plot, it doesn't run properly, because, the {t$23, ...} argument in Plot is held, it doesn't evaluate to t before plotting.
In the second example, however, you don't have this problem. r becomes an expression of whatever variable p you call in foo[s, p] (t in this case), and that's the same variable you are using in your Plot. Even if Plot holds its arguments, so it's ""immune to evaluation"", it's not immune to the lexical replacement Module does. 
First example analogy:
Module[{x = x2},
 {x, Hold[x]}]

{x2, Hold[x$14454]}

Second example analogy:
Module[{},
 {x, Hold[x]}]

{x, Hold[x]}

"
debugging - How can I get TracePrint to treat certain functions as atomic?,"
Maybe 
  TracePrint[g[1], TraceOff -> f]

?
"
export - How to solve issue with exporting / importing data to and from Excel,"
The last ""sheet"" in
data = {{{0.5, 0.166667}, {0.666667, 0.166667}, {0.166667, 
 0.333333}, {0.333333, 0.333333}, {0.5, 0.333333}, {0.666667, 
 0.333333}, {0.833333, 0.333333}, {0.166667, 0.5}, {0.333333, 
 0.5}, {0.5, 0.5}, {0.666667, 0.5}, {0.833333, 0.5}, {0.5, 
 0.666667}, {0.666667, 0.666667}}, {{1., 2., 6., 5.}, {3., 4., 9., 
 8.}, {4., 5., 10., 9.}, {5., 6., 11., 10.}, {6., 7., 12., 
 11.}, {10., 11., 14., 
 13.}}, {{RGBColor[0.9308155947203784, 0.9308155947203784, 
 0.9308155947203784]}, {RGBColor[1, 0, 0]}, 
RGBColor[0., 1., 
 0.14062714579995422], {RGBColor[1., 0.11317616540779736, 
 0.000015259021896696422]}, {RGBColor[1., 0.9651483939879454, 
 0.38461890592813003]}, {RGBColor[0.9685511558709087, 
 0.9685511558709087, 0.9685511558709087]}}}

(i.e. list3) is the source of the problem. If you fix the third element RGBColor[0., 1., 0.14062714579995422] and put {RGBColor[0., 1., 0.14062714579995422]} like you have for the others it exports correctly, which each element of data as a table on its own sheet.
Also, you can always force it to Export sheets, by specifying:
Export[""file.xls"", data, ""Sheets""]

"
options - Factorizing polynomials over fields other than $\mathbb{C}$,"
All of the polynomial functions, have an option Modulus which allows you to specify an integer field, like $\mathbb{Z}_5$. In particular, Factor works on your example polynomial
Factor[x^2+4, Modulus -> 5]
(* (1 + x) (4 + x) *)

Additionally, IrreduciblePolynomialQ works to determine irreducibility of $x^2+2
$, as follows
IrreduciblePolynomialQ[x^2 + 2, Modulus -> 5]
(* True *)

"
programming - How do Forms affect the interpretation of Expressions?,"
The error is exactly what Part says:

There is no such level in that expression, and to convince yourself, look at {a, b}[[1, 2]] :)
The reason you see it in the *Forms is because they're all wrappers that affect display. In other words, although you see it as an undirected edge, its actual head is *Form.
OutputForm[a \[UndirectedEdge] b] // FullForm
(* OutputForm[UndirectedEdge[a, b]] *)

The additional head now allows you to index [[1, 2]]. Going back to my earlier example:
f[{a, b}][[1, 2]]
(* b *)

"
How to insert graphics primitives into a plot?,"
You can display graphics primitives in your plot by using the Show command
Show[
  Plot[{1/Sqrt[2*Pi] Exp[-1/2*x^2]}, {x, -3, 3}, Filling -> Axis],
  Graphics[Line[{{1.6, 0}, {1.6, 0.4}}]],
  Graphics[{Thick, Red, Line[{{-0.4, 0}, {-0.4, 0.4}}]}],
  Graphics[Text[""Φ"", {-.6, 0.38}]],
  Graphics[Text[""μ"", {2, 0.1}]]
]

You can actually just combine all the Graphics objects into one list but I always keep them separate for legibility and editability since otherwise you have to remember to switch back and forth between e.g. color and line weight specifications.
Show[
  Plot[{1/Sqrt[2*Pi] Exp[-1/2*x^2]}, {x, -3, 3}, Filling -> Axis],
  Graphics[
     {Line[{{1.6, 0}, {1.6, 0.4}}],
      Thick, Red,
      Line[{{-0.4, 0}, {-0.4, 0.4}}],
      Thin, Black,
      Text[""Φ"", {-.6, 0.38}],
      Text[""μ"", {2, 0.1}]}
  ]
]


You can also achieve the same result by using the Epilog or Prolog option for Plot
Plot[
  {1/Sqrt[2*Pi] Exp[-1/2*x^2]}, 
  {x, -3, 3}, 
  Filling -> Axis, 
  Prolog ->
    {Line[{{1.6, 0}, {1.6, 0.4}}],
    Thick, Red,
    Line[{{-0.4, 0}, {-0.4, 0.4}}],
    Thin, Black,
    Text[""Φ"", {-.6, 0.38}],
    Text[""μ"", {2, 0.1}]}
]

The difference between Prolog and Epilog is in placing your graphics primitives behind or in front of the Plot, this may be important in certain circumstances.
Once you have composed your plot you can use the standard Export command to save it to a format of your choosing.
"
gui construction - Transparent background of content in a dialog window,"
A workaround might be if your looking for one colour for the whole window including the plot is to call the background colour at another place?
CreateDialog[
 DocumentNotebook[
  Column@{Slider@Dynamic@n, 
    Dynamic@Plot[Sin@x, {x, 0, n \[Pi]}, Frame -> True, Axes -> False,
       ImagePadding -> 30, ImageSize -> 300]}, 
  Background -> LightGray]]

this gives:

"
graphics - Scale Insetted Characters to Plot,"
""Vectorizing"" the font:
curve = First[First[ ImportString[ExportString[
        Style[""{"",FontFamily ->""Times"",FontSize -> 72],  ""PDF""], ""TextMode"" -> ""Outlines""]]];
cg = Graphics[curve]

and then your code, replacing the Inset[] clause by
Inset[Pane[cg, ImageSizeAction ->  ""ResizeToFit""], ....

Result (scales OK when resizing the Plot):

Edit
Full code follows, just in case you decide to edit your code:
curve = First[First[
    ImportString[
     ExportString[Style[""{"", FontFamily -> ""Times"", FontSize -> 72], 
      ""PDF""], ""TextMode"" -> ""Outlines""]]];
cg = Graphics[curve];
f = 1/x;
ϵpl = 
  Plot[{f}, {x, 0, 1}, PlotStyle -> Black, 
   PlotStyle -> AbsoluteThickness[1]];

ϵ1pl = 
  Plot[{f}, {x, 0.2, 0.4}, 
   PlotStyle -> Directive[Red, AbsoluteThickness[1.5]]];
ϵ1dashed = 
  ListPlot[{{{0.1, f /. x -> 0.27}, {0.27, f /. x -> 0.27}}, {{0.1, 
      f /. x -> 0.3}, {0.3, f /. x -> 0.3}}}, 
   PlotStyle -> Directive[Red, Dashed, AbsoluteThickness[1]], 
   Joined -> True];

Show[ϵpl, ϵ1pl, ϵ1dashed, 
 PlotRange -> {{0, 1}, {0, 6}}, Axes -> False, Frame -> True, 
 ImageSize -> 600, 
 FrameStyle -> Directive[AbsoluteThickness[1], FontSize -> 24], 
 FrameTicks -> False, FrameLabel -> {""\!\(\*
   StyleBox[\""r\"",\nFontSlant->\""Italic\""]\)"", ""\!\(\*
   StyleBox[\""ϵ\"",\nFontSlant->\""Italic\""]\)""}, 
 Epilog -> 
  Inset[Pane[cg, 
    ImageSizeAction -> 
     ""ResizeToFit""], {0.095, ((f /. x -> 0.27) + (f /. x -> 0.3))/
     2}, {0, 0}, {Automatic, (f /. x -> 0.27) - (f /. x -> 0.3)}]]

"
graphics - Why is ListDensityPlot unable to plot datasets with extreme ranges,"
The reason why ListDensityPlot doesn't plot it is because the meshes aren't being generated correctly:
ListDensityPlot[data #, Mesh -> All, ImageSize -> 300] & /@ {1, 100, 10^3, 10^4}


Now I don't know exactly how to fix this, but my guess is that the mesh function relies on the Delaunay triangulation of the set of points and somewhere in there, something is either dangerously close to machine precision or getting Chopped. Since the default tolerance for chopping is $10^{-10}$, it is plausible that this is what is happening.
"
List-operations only when restrictions are fulfilled (Part 2),"
You could define a transformation function according to 
transform[list_] := Module[{n, y, u, res},
  y = list[[1, 2]];
  n = LengthWhile[list, #[[2]] == y&];
  u = list[[n + 1, 2]];
  res = (y - u)/n;
  Join[Thread[{list[[;; n + 1, 1]], y + res}], list[[n + 2 ;;]]]]

and map that to you transformed data list:
data = {{{3544128000, 80}, {3544732800, 80}, {3545337600, 80}, {3545942400, 80}, 
  {3545942400, 160}, {3546547200, 160}, {3547152000, 0}}};
data1 = Transpose[{#[[All, 1, 1]], Total[#[[All, All, 2]], {2}]}] & /@ 
  (GatherBy[#, First] & /@ data);

transform /@ data1


{{{3544128000, 80/3}, {3544732800, 80/3}, {3545337600, 80/3}, 
  {3545942400, 80/3}, {3546547200, 160}, {3547152000, 0}}}


By the way, I get 
data1 == {{{3544128000, 80}, {3544732800, 80}, {3545337600, 80}, {3545942400, 240}, 
  {3546547200, 160}, {3547152000, 0}}}

instead of 
{{{3544128000, 80}, {3544732800, 80}, {3545337600, 80}, {3545942400, 240},{3546547200, 160}}} 

as posted in the question which is why I get an extra term {3547152000, 0} in the result above. 
"
Coulomb potential as a Fourier transform,"
The problem here is that Mathematica doesn't recognize {x, y, z} as some kind of a vector object that should be treated as grouped together; instead, it substitutes in three independent variables, and probably starts integrating them one by one. The result is a very complicated integral.
If you do the coordinate transformation yourself, you can reproduce the result. Simply use $\mathrm dp = \mathrm d\|p\|\|p\|^2\mathrm d\vartheta\sin(\vartheta)$ to transform to spherical. The resulting integral can be calculated:
Assuming[pAbs >= 0 && m > 0 && r > 0,
    (1/(2*Pi)^3)*Integrate[ (* phi integral *)
        Integrate[ (* |p| integral *)
            Integrate[ (* theta integral *)
                (Exp[I*r*pAbs*Cos[pTheta]]/(pAbs^2 + m^2))*pAbs^2*Sin[pTheta],
                {pTheta, 0, Pi}
            ],
            {pAbs, 0, Infinity}
        ],
        {pPhi, 0, 2*Pi}
    ]
]


$\dfrac{e^{-mr}}{4\pi r}$

"
Possible to draw an Item in a Grid with only 3 sides of a Frame?,"
How about this?
Grid[{{1, 2, 3}, {4, Item[5, Frame -> {{True, True}, {True, False}}], 6}}]


"
list manipulation - Adding rules to permutations,"
Having no idea what sort of rules you might want to try. Here is a potential solution that generates the next permutation in lexicographic order and determines if it fits a particular criterion crit.
Generate next permutation where lst is the current permutation of Range[n], rng is the original range.
nextP[lst_, rng_] :=
 Block[{k, l},
  k = Pick[Most@rng, Thread[Most[lst] < Rest[lst]]];
  If[k === {}, Return[{}]];
  k = Last[k];
  l = Pick[rng, Thread[lst[[k]] < lst]][[-1]];
  Flatten[{#1[[1 ;; k]], Reverse[#1[[k + 1 ;; -1]]]}] &[
   ReplacePart[lst, {k -> lst[[l]], l -> lst[[k]]}]]
  ]

This takes a positive integer n and and a function crit.
filteredPermutations[n_Integer?Positive, crit_] :=
 Block[{res, rng},
  res = rng = Range[n];
  Reap[While[True, res = nextP[res, rng]; If[res === {}, Break[]]; 
     If[crit[res], Sow[res]]]][[2, 1]]
  ]

For example, the permutations of Range[4] where the first element exceeds the last.
filteredPermutations[4, #[[1]] > #[[-1]] &]

==> {{2, 3, 4, 1}, {2, 4, 3, 1}, {3, 1, 4, 2}, {3, 2, 4, 1}, {3,4, 1, 2},
     {3, 4, 2, 1}, {4, 1, 2, 3}, {4, 1, 3, 2}, {4, 2, 1, 3}, {4, 2, 3, 1}, 
     {4, 3, 1, 2}, {4, 3, 2, 1}}

Note: This is going to be pretty slow for even moderate n.
Edit: This can be made quite a bit faster by using a compiled version of nextP.
nextPC = Compile[{{lst, _Integer, 1}, {rng, _Integer, 1}},
   Block[{out = lst, k = 1, n = Length[rng], 
     kbag = Internal`Bag[{-1}], lstk, l = 1, 
     lbag = Internal`Bag[{-1}]},
    While[k < n,
     If[lst[[k]] < lst[[k + 1]], Internal`StuffBag[kbag, k]];
     k++
     ];
    k = Max[Internal`BagPart[kbag, All]];
    If[k == -1,
     lst
     ,
     lstk = lst[[k]];
     While[l <= n,
      If[lstk < lst[[l]], Internal`StuffBag[lbag, l]];
      l++
      ];
     l = Max[Internal`BagPart[lbag, All]];
     out[[k]] = lst[[l]];
     out[[l]] = lst[[k]];
     Join[out[[1 ;; k]], Reverse[out[[k + 1 ;; -1]]]]
     ]
    ]
   ];

This one returns the last permutation rather than an empty list so we need a slightly modified version of filteredPermutations as well.
filteredPermutations2[n_Integer?Positive, crit_] := 
 Block[{res, rng, rev}, res = rng = Range[n];
  rev = Reverse[rng];
  Reap[While[True, res = nextPC[res, rng]; 
     If[res === rev, If[crit[res], Sow[res]]; Break[]];
     If[crit[res], Sow[res]]]][[2, 1]]]

Now to test it. Here I'm looking for all permutations of Range[8] such that the last element is 1 and the second is even.  Note that direct computation is much faster so if its possible to store all of the permutations in memory at once, that will be the way to go.
AbsoluteTiming[(r1 = filteredPermutations2[8, #[[-1]] == 1 && EvenQ[#[[2]]] &]);]

==> {0.4524058, Null}

AbsoluteTiming[(r2 = filteredPermutations[8, #[[-1]] == 1 && EvenQ[#[[2]]] &]);]

==> {1.8564238, Null}

AbsoluteTiming[(r3 = Select[Permutations[Range[8]], (#[[-1]] == 1 && EvenQ[#[[2]]]) &]);]

==> {0.1092014, Null}

r1 == r2 == r3

==> True

"
list manipulation - Threading behavior of SameQ vs. Equal,"
Thread doesn't hold its arguments. You can check its attributes.
So, before doing any threading, it evaluates its arguments. 
Now, understanding the behaviour you describe requires understanding the difference between Equal and SameQ. Equal is meant for math reasoning. For expressing an equality, which might involve a variable that at the time you don't yet know it's value. So, for example, x==8 returns unevaluated if x isn't defined.
SameQ however is a predicate. It will always return either True or False if the constructs are exactly the same (after evaluation). 
So, Thread[SameQ[{aa, bb, cc}, {dd, ee, ff}]] -> Thread[False]-> False
One can see this by running (thanks @rcollyer)
Trace[Thread[SameQ[{aa, bb, cc}, {dd, ee, ff}]], 
 TraceInternal -> True]

Out[1] = {{{aa, bb, cc} === {dd, ee, ff}, False}, Thread[False], False}

If you want to thread SameQ without evaluation, just use Unevaluated
Thread[Unevaluated@SameQ[{aa, bb, cc}, {dd, ee, ff}]]

{False, False, False}

Another construction that gives the result you want is the one suggested by @kguler in his comment and supported by @rcoller and his upvoters: MapThread. I'd suggest you search the docs if you don't know it
MapThread[SameQ, {{aa, bb, cc}, {dd, ee, ff}}]

"
equation solving - Number of iterations in NSolve,"
The main algorithm behind NSolve is, I believe, the Jenkins-Traub algorithm, which is indeed iterative in nature.  I don't believe that you can specifiy the number of iterates directly, however.  Isn't it better to specify the desired precision, though?  Mathematica tries to find the solution to a certain precision, and you can specify the precision that you want, as in
eqs = {R1==fR1, R2==fR2, P4==fP4, rho==fRho};
sols= NSolve[eqs, {P2, P4, a, rho}, Reals,
  WorkingPrecision -> 20];

You can always check the quality of the results, as well, using something like so:
(#[[1]] - #[[2]] & /@ eqs) /. sols

This will let you know exactly how close you are on each equation.
"
probability or statistics - How can an InverseQuantile or an interval valued Quantile function be implemented in Mathematica?,"
Something like this should be close:
InverseQuantile[list_, x_] := LengthWhile[list // Sort, # <= x &]/Length[list]

Depending on your definition of quantiles you may choose to have the test be # < x & or # <= x &
This is with # <= x &:
Table[
   {x, Quantile[{1, 2, 2, 4}, InverseQuantile[{1, 2, 2, 4}, x]]}, 
   {x, 1, 4, 0.1}
 ]

(* ==> {{1., 1}, {1.1, 1}, {1.2, 1}, {1.3, 1}, {1.4, 1}, {1.5, 1}, {1.6, 1}, 
 {1.7, 1}, {1.8, 1}, {1.9, 1}, {2., 2}, {2.1, 2}, {2.2, 2}, {2.3, 2}, 
 {2.4, 2}, {2.5, 2}, {2.6, 2}, {2.7, 2}, {2.8, 2}, {2.9, 2}, {3., 2}, 
 {3.1, 2}, {3.2, 2}, {3.3, 2}, {3.4, 2}, {3.5, 2}, {3.6, 2}, {3.7, 2}, 
 {3.8, 2}, {3.9, 2}, {4., 4}} *)

or, with Interval:
InverseQuantile[list_, x_] := 
 Interval[
  {
   LengthWhile[list // Sort, # < x &]/Length[list], 
   LengthWhile[list // Sort, # <= x &]/Length[list]
  }
 ]

InverseQuantile[{1, 2, 2, 4}, #] & /@ {0, 0.5, 1, 1.5, 2, 3, 4, 5}
(* {Interval[{0, 0}], Interval[{0, 0}], Interval[{0, 1/4}], Interval[{1/4, 1/4}], 
    Interval[{1/4, 3/4}], Interval[{3/4, 3/4}], Interval[{3/4, 1}], Interval[{1, 1}]} *)

Another approach would be to base InverseQuantile on empirical distributions and their CDF. Two possibilities are:
InverseQuantile[list_, x_] := CDF[SmoothKernelDistribution[list], x]

InverseQuantile[list_, x_] := CDF[HistogramDistribution[list], x]

Table[
   {x, Quantile[{1, 2, 2, 4}, InverseQuantile[{1, 2, 2, 4}, x]]}, 
   {x, 1, 4, 0.1}
 ]

    (* ==> {{1., 1}, {1.1, 1}, {1.2, 1}, {1.3, 1}, {1.4, 1}, {1.5, 1}, {1.6, 2},
            {1.7, 2}, {1.8, 2}, {1.9, 2}, {2., 2}, {2.1, 2}, {2.2, 2}, {2.3, 2},
            {2.4, 2}, {2.5, 2}, {2.6, 2}, {2.7, 2}, {2.8, 2}, {2.9, 2}, {3., 2},
            {3.1, 2}, {3.2, 2}, {3.3, 4}, {3.4, 4}, {3.5, 4}, {3.6, 4}, {3.7, 4}, 
            {3.8, 4}, {3.9, 4}, {4., 4}} *)

"
Finding a vector field from a set of points,"
I'll try to give you an answer complementary to Szabolcs’, because I understood your question in another way. If by “get a gradient using the points I have” you mean having a continuous color gradient in your plot of the data (and not calculating a gradient, as in “derivative”), then you can simply use DensityPlot with an Interpolation.
Let's get some data, taken at random points from the function $z=\sin x\ \sin y$:
points = RandomReal[{-5, 5}, {500, 2}];
data = {#1, #2, Sin[#1]*Sin[#2]} & @@@ points;

then plot it:
DensityPlot[
 Interpolation[data, InterpolationOrder -> 1][x, y], {x, -5, 
  5}, {y, -5, 5}, PlotRange -> {Full, Full, {-1, 1}}]


which you can compare to the original function I drew points from:
DensityPlot[Sin[x]*Sin[y], {x, -5, 5}, {y, -5, 5}]


"
"plotting - BoxWhiskerChart too slow on big datasets, how to speed it up?","
Even on my rather old laptop, calculating the various statistics used for plotting the whisker of data sets of that size takes less than a minute so I suspect the problem is the number of groups rather than the number of records in each group. For each box in your plot, Mathematica generates a Tooltip containing a DynamicsBox. With 300 boxes, this will slow down the front end quite a lot. 
It's a bit more involved than using BoxWhiskerChart out of the box, but as an alternative you could build a chart by hand using graphics primitives, for example
plot[data_] := DynamicModule[{n, min, max, q25, med, q75, fun},
  n = Length[data];
  {min, q25, med, q75, max} = 
   Transpose[
    Through[{Min, Quantile[#, 1/4] &, Median, Quantile[#, 3/4] &, Max}[#]] & /@ data];
  fun[dat_] := Transpose[{Range[n], dat}];
  Dynamic[Tooltip[Graphics[{
        {LightGray, Polygon[Join[fun[min], Reverse@fun[max]]]},
        {LightBlue, Polygon[Join[fun[q25], Reverse@fun[q75]]]},
        {Thick, Black, Line[fun[med]]},
        {Gray, Line[{{#, min[[#]]}, {#, max[[#]]}}]},
        {Thick, Blue, Line[{{#, q25[[#]]}, {#, q75[[#]]}}]}}, 
       Axes -> True, AspectRatio -> 1/GoldenRatio],
      Grid[{{""Index"", #}, {""Max"", max[[#]]}, {""75%"", 
         q75[[#]]}, {""Median"", med[[#]]}, {""25%"", q25[[#]]},
        {""Min"", min[[#]]}}, Frame -> All]] &@
    Clip[Round[MousePosition[""Graphics""] /. None -> {1}][[1]], {1, n}]]]

data = Table[RandomVariate[NormalDistribution[i, i^2], 1000], {i, .1, 1, 1/300}];

plot[data]


Here, I've chosen to plot the boxes and whiskers as polygons since with 300 boxes side-by-side it's hard to distinguish the individual boxes anyway. 
"
mathematical optimization - Strange domain dependency with Maximize,"
As Szabolcs stated, Maximize is calling NMaximize.
The problem is that the call is not being done with appropriate options for your case. Just compare for example:
NMaximize[{x*(1 - 0.01 x), x ∈ Integers}, x]
(*
x-> 19
*)

with
NMaximize[{x*(1 - 0.01 x), x ∈ Integers}, x, MaxIterations -> 300]
(*
x-> 50
*)

To understand better what is happening you may see the evaluation process:
f[x_] := x*(1 - .01 x);
{sol, pts} = Reap[
   NMaximize[{f[x], x ∈ Integers}, x, MaxIterations -> 300,  
    EvaluationMonitor :> Sow[{x, f[x]}]]];
{sol1, pts1} = Reap[
   NMaximize[{f[x], x ∈ Integers}, x,  
    EvaluationMonitor :> Sow[{x, f[x]}]]];

GraphicsGrid[{{
   Plot[f[x], {x, 0, 100}, Epilog -> Map[Point, Cases[First[pts] , x_]]],
   Plot[f[x], {x, 0, 100}, Epilog -> Map[Point, Cases[First[pts1], x_]]]}}]


Edit
As Szabolcs  commented below, the evaluation process is far from efficient.
Here you have the number of evaluations done for each integer x while the algorithm is trying to find the Max:
Histogram[(First@pts1)[[All, 1]], {-1, 20, 1}, AxesLabel -> {""x"", ""# of evals""}]


Edit
You could run
Histogram[Select[Length /@ Split@(First[pts1][[All, 1]]), # > 1 &]]

To see that it evaluates the same x several times is a row!
"
databaselink - How can I connect to a database using the 32 Bit ODBC on a Windows 7 (64 Bit) machine?,"
You might be facing the problem documented in Microsoft's knowledge base as KB942976.  In a nutshell, the system call that enumerates DSNs on a 64-bit system will also list 32-bit DSNs -- even though those DSNs cannot be accessed from a 64-bit application.  The knowledge base article states that there is no current resolution to this problem in the interest of backward compatibility (?).
It seems that you have only two choices:

Run the 32-bit version of Mathematica to continue using the 32-bit DSN, or
Create a new 64-bit DSN for use with 64-bit Mathematica.

"
compile - tol and None in output of CompilePrint,"
Without seeing the code that generated the above this is only a guess. If you look in: 
FileNameJoin[{$InstallationDirectory, ""AddOns"", ""Applications"", 
  ""CompiledFunctionTools"", ""PrintCode.m""}]

you'll find a line:
toInfixForm[_] := None

All infix form conversions not known (i.e. in that list in that file) are replaced by None.
It would be good to find out which expr is not mentioned in the toInfixForm such that it can be added. Presumably this is some compare function. In that same file you will also find tol.
"
plotting - How can I influence the spaces between labels on a BarChart,"
Here's one approach, which modifies the labels slightly to shift some of the labels down a bit.
BarChart[datalist[[All, {2, 3}]], ChartLayout -> ""Stacked"", 
   ChartLabels -> {
      MapIndexed[If[OddQ[First[#2]], #, Column[{"""", #}]] &, Transpose[datalist][[1]]], 
      None
      }]


"
Question about scoping data in a multi-level Manipulate construction,"
How about this:
DynamicModule[{k},
  Manipulate[
   Column[{j,
     Manipulate[k, {k, 1, 5, 1}, LocalizeVariables -> False],
     Button[""Check"", Print[k]]
   }],
   {j, 1, 10, 1}]
]

"
equation solving - Using the Krylov method for Solve: Speeding up a SparseArray calculation,"
I found a way to dramatically improve the performance of this algorithm by using the undocumented function SparseArray`KrylovLinearSolve. The key advantage of this function is that it seems to be a near-analog of MATLAB's pcg, and as such accepts as a first argument either:

a square matrix, or a function generating a vector of length equal to the length of the second argument.

One may discover this by giving incorrect arguments and noting the advice given in the messages produced as a result, in much the same way as one discovers the correct arguments for any undocumented function. In this case the message is SparseArray`KrylovLinearSolve::krynfa.
You only need to change one line in your code to use it, namely:
s = SparseArray`KrylovLinearSolve[
     alph l.# + AT[A[#]] &, g, 
     Method -> ""ConjugateGradient"", ""Preconditioner"" -> (p.# &), 
     Tolerance -> tol, MaxIterations -> maxit
    ];

where maxit should preferably be Automatic (meaning 10 times the size of the system to be solved) or larger. With the data given in your question it takes a few hundred iterations to converge to a tolerance of $10^{-4}$, but each iteration is quite fast, so it seems to make more sense to adjust the tolerance than the number of iterations if performance is still an issue. However, while I didn't investigate this, needing this many iterations to converge to a relatively loose tolerance may of course be symptomatic of a poorly conditioned system, so using a different preconditioner or the biconjugate gradient stabilized method (""BiCGSTAB"") could perhaps reduce the number of iterations required.
You will note that the options are exactly the same as for LinearSolve's ""Krylov"" method, so we may surmise that this function is probably called more or less directly by LinearSolve when Method -> ""Krylov"" is specified. In fact, if we assume that this is indeed the case and try
s = LinearSolve[
     alph l.# + AT[A[#]] &, g, 
     Method -> {""Krylov"",
       Method -> ""ConjugateGradient"", ""Preconditioner"" -> (p.# &), 
       Tolerance -> tol, MaxIterations -> maxit
      }
    ];

we find that it works equally well, so evidently LinearSolve does in fact provide just the same functionality as pcg as far as the first argument is concerned, but without this actually being documented anywhere as far as I can tell. So, the overall conclusion is that you can just use LinearSolve directly after all.
"
Is there a way to print out SQL queries made using DatabaseLink?,"
If you have full control over the MySQL database I think it lets you log every SQL statement from every client (query-log), which probably is the most simple way to get that information. You could also try to look at or even manipulate the sources, it looks like the relevant code is delivered as clear text in the following file in the Mathematica directory: SystemFiles/Links/DatabaseLink/Kernel/SQL.m. It isn't an easy read though and some of the relevant stuff might be buried in one of the java classes, but there seem to be sources also for those, if you really want to dig deep...
"
string manipulation - Interpreting text entry and splitting it in a Manipulate text field?,"
I think you can just use StringSplit at Whitespace characters.
Here is a toy example that might get you started.
Manipulate[
 PieChart[MapThread[Labeled[#2, #1] &, 
   Transpose[Tally@StringSplit[ngram, Whitespace]]]], {{ngram, 
   ""One fish two fish red fish blue fish"", ""n-gram""}}]


"
"finance - How do I define the ""Coupon"" within the function FinancialBond with a time-varying coupon","
The More Information section of the help file says


The coupon may be specified as a single rate or a time-dependent payment function.


So, you should use
""Coupon"" -> (Piecewise[{{.04125, #1 < 3}, {.06, 3 <= #1 < 5}, {.0775, 5 <= #1 < 7}}] &)

For example,
FinancialBond[{""FaceValue""->100,
 ""Coupon"" -> (Piecewise[{{.04125, #1 < 3}, {.06, 3 <= #1 < 5}, {.0775, 5 <= #1 < 7}}] &),
 ""Maturity""->5},{""InterestRate""->r,""Settlement""->0}]

outputs
(* 100/(1+r)^5+(0.00125 (224.+375. r+345. r^2+165. r^3+33. r^4))/(1.+r)^5 *)

"
graphics - Shading in squares crossed by a diagonal,"
You could do something like this
Manipulate[
 DynamicModule[{ptlst, height, length},
  {length, height} = Round[pt];
  ptlst = 
   Floor[1 + {height, length} #] & /@ 
    MovingAverage[
     Union@Join[Range[0, 1, 1/length], Range[0, 1, 1/height]], 2];
  Show[ArrayPlot[SparseArray[Thread[ptlst -> 1]], Mesh -> True, 
    MeshStyle -> Gray, DataReversed -> True],
   Graphics[{Red, Line[{{0, height}, {length, 0}}]}],
   PlotRange -> {{-1, 21}, {-1, 21}},
   GridLines -> {Range[0, 21], Range[0, 21]},
   GridLinesStyle -> LightGray]],
 {{pt, {10, 10}}, {1, 1}, {20, 20}, {1, 1}, Locator}
 ]


Explanation of the code
We're representing the squares in the rectangle by an array of 0's and 1's. We're assuming that the rectangle has dimensions {length, height} and is aligned with the origin.  The array is such that the unit square with lower left corner {k,l} corresponds to the element at index {l + 1, k + 1} in the array (the reversal of indices is because ArrayPlot plots an m by n array as a n by m rectangle).
The diagonal from {0,0} to {length, height} can be parameterized by {length, height} t where 0<=t<=1. To find all squares that are intersected by this diagonal, we first calculate the intersection points of the diagonal with the grid, i.e. we find a list of values for t such that either length t or height t is an integer. For two consecutive elements in this list, t0 and t1, the line segment from {length, height} t0 to {length, height} t1 will lie completely within one unit square. The coordinates of the lower left corner of this square are equal to Floor[{height, length} (t0+t1)/2] which corresponds to the element at index 1 + Floor[{length, height} (t0+t1)/2] in the array. 
"
MatchQ and patterns for similar lists,"
The following patterns give the required output:
p1 = p : {{_?NumericQ} ..} /; ! Equal @@ p
p2 = {{s_?NumericQ} ..};


MatchQ[#[[1]], #[[2]]] & /@ Tuples[{{list1, list2}, {p1, p2}}]

(*
==> {True, False, False, True}
*)

"
list manipulation - Computing the distance between two curves obtained from image data?,"
Lets start with an example image
img = Binarize@
  Image[Plot[{Sin[2 x], 2 + Cos[3 x]}, {x, 0, 2 Pi}, Axes -> False, 
    PlotStyle -> Black, Background -> White, ImagePadding -> None, 
    PlotRangePadding -> {None, .1}]]


To find the distance between the two curves you could do something like
data = ImageData[img];
w = Dimensions[data][[2]];
scale = .1/w;

averageRadiusList = Reap[Sow @@@ Position[data, 0], Range[w],
    {scale #1, scale (Max[#2] - Min[#2])/2} &][[2, All, 1]];

ListPlot[averageRadiusList]


What this code does is to find the indices of all black points in img. The combination of Sow and Reap will effectively group these coordinates by their column index and for each group return {scale c, scale (Max[rows]-Min[rows])/2} where c is the column index, and rows is a list of row indices of all black points in the plot that have column index c.
"
plotting - Labeling individual curves in Mathematica,"
You can make use of the following options in Plot, e.g. :
Plot[ Tooltip @ {x^2, x^3, x^4}, {x, -2, 2}, 
      PlotStyle -> {Red, Green, Blue}, 
      PlotRangePadding -> 1.1] /. {Tooltip[{_, color_, line_}, tip_] :>   
                                   {Text[Style[tip, 14], {.1, 0} + line[[1, -1]]], color, line}}


Update (05.02.2016)
Tried the above code in Mathematica 10.3.1 and it did not work. This code works:
Plot[Tooltip@{x^2, x^3, x^4}, {x, -2, 2}, 
  PlotStyle -> {Red, Green, Blue}, 
  PlotRangePadding -> 
   1.1] /. {Tooltip[{___, dir_Directive, line_Line, ___}, 
    tip_] :> {Text[Style[tip, 14], {.1, 0} + line[[1, -1]]], dir, 
    line}}

Edit
Since there was another question in the comments I add another way of labeling curves. 
If we have to plot a graph of a family of certain functions, and insert its definition i.e.

we can make use of Drawing Tools in the Front End (a shortcut Ctrl-D)  to insert some text supplemented by appropriate arrows pointing only  a few of all functions.
We paste a simple text i.e. output of Text[Style[""n = 13"", Large, Bold, Blue]] or the definition of the functions, by double-clicking the right button of the mouse, next once the left one and selecting from menu Paste into Graphic to insert a data from the clipboard. Similarly we choose arrows from the section Tools of Drawing Tools and adjust them by dragging apprporiately.  Alternatively to pasting the definition of functions with Drawing Tools, we can make use of also PlotLabel option of Plot to insert it, i.e. PlotLabel -> Subscript[f, n][x] == (1 - x^2/6 + x^4/120)^n 
Plot[ Evaluate[(1 - x^2/6 + x^4/120)^n /. n -> Range[1, 30, 3]], {x, 0, Sqrt[6] },
      AspectRatio -> Automatic, AxesOrigin -> {0, 0}, PlotStyle -> Thick ]


"
import - Is it possible to use Mathematica to record sound and/or vision?,"
SystemDialogInput[""RecordSound""] will bring up a dialog that let's you record sound.  It works both on Windows and Mac in v9, but only on Windows in earlier versions.  It doesn't work on Linux.
But what if you need to record sound without user interaction, and you want to avoid a modal dialog?  The right way is to use some external and documented tool (e.g. sox), but I happened to try to dissect the ""RecordSound"" dialog, and here are the results.  These may be Mac-specific.
On Mac, I believe some sort of initialisation may be needed, but I'm not entirely sure.  Evaluating
FrontEndExecute[FrontEnd`RecordSound[7, 0]]
FrontEndExecute[FrontEnd`RecordSound[8, 0]]

will probably do this.  This is the least clear point so far.  This may not be needed on Windows.
Now,

FrontEndExecute[FrontEnd`RecordSound[5]] will list the available devices by number
FrontEndExecute[FrontEnd`RecordSound[6, deviceNumber]] will list the available formats for the device
FrontEndExecute[FrontEnd`RecordSound[1, deviceNumber, formatNumber]] will start recording.  It returns control immediately.
FrontEndExecute[FrontEnd`RecordSound[2]] will stop recording and return the duration.
FrontEndExecute[FrontEnd`RecordSound[3]] will return the recorded sound (it's the ""OK"" button in the dialog)
FrontEndExecute[FrontEnd`RecordSound[4]] will probably discard the recorded sound (it's the Cancel button)
FrontEndExecute[FrontEnd`RecordSound[9, 0]] will return the current volume of the recorded sound, and is used for the progress indicator in the dialog.

Warning: This functionality is undocumented, and not meant for end users. I'm just guessing at how it works.  There's a real risk that playing with these will crash your front end, mess up its internal state or will cause a memory leak.  Use at own risk.
"
programming - Is there an open source implementation of Mathematica-the-language?,"
I've been collecting these links for a while, so this question is a good excuse for a link dump. I'm not sure which project is the ""best"", but I think that mathics and symja are two of the more active and developed projects.
Lisp:
MockMMA is probably the first implementation of the Mathematica language. It was written by Richard Fateman who had a bit of a scuffle with Wolfram Research over the code.
Python:
Mathics (which you mentioned in the question) is primarily a syntax layer ontop of sympy and sage, not an independent implementation of the Mathematica language.
Pythonica is an abandoned python implementation of Mathematica.
Java:
symja is a pure Java library for symbolic mathematics that uses Mathematica notation and supports Rubi Integration rules.
omath is an project that is still under development that will have a Mathematica like syntax, but does not aim to blindly copy Mathematica.
Go:
expreduce an experimental computer algebra system written in Go.

The omath page also has some interesting links to papers describing some of the Mathematica language's algorithms:
Matching in flat theories by Temur Kutsia.
A detailed description of Mathematica's flat pattern matching. (But quite technical!) (original link)
Mathematica as a Rewrite Language by Bruno Buchberger.
On the implementation of a rule-based programming system and some of its applications by Mircea Marin and Temur Kutsia.
These people obviously understand Mathematica's pattern matching enumeration system forwards and backwards.
Discussions about whether computer languages can be copyrighted, 1, 2, 3.
"
java - Efficiently deleting rows in many large text files,"
If you'll accept solutions involving other technologies, then how about using sed? On a unix system, to read in file1, delete row n and output to file2, you'd do:
sed -e 'nd' file1 > file2

The quotes in 'nd' are not necessary in this case, since there is only one instruction. However, if you're doing more complicated stuff with regular expressions, you should include the quotes so that the regex is not interpreted as something else. So it's safer to include it in general.
If you want to edit the file in place, then the command is
sed -i '' -e 'nd' test

Note that the ''after -i is necessary if you don't want a backup. If you omit that then sed assumes that the extension is being supplied via stdin, introducing additional files (which really are backups). 
If you want to backup your file, just in case, then use -i.abc where abc is any string of your choice (need not be limited to 3 chars) and the file will be backed up to file.abc.
You can now run any of these commands from Mathematica via Run[command] (where command is the string with the actual command). Of course, replace n above with your actual row number or if variable, modify Run[...] accordingly.

I don't use Windows, but cygwin should provide you with a linux environment for Windows.
If you only require sed then cygwin is an overkill (takes a lot of space and is quite slow). A native build of sed can be found as part of GnuWin32. Download here.
"
plotting - Create a CDF file with a plot that cannot be edited by double-clicking,"
Wrap the output of the CDF (the Plot command in your case) into Deploy, or add the Deployed -> True option to your Manipulate.
Using the Deployed option however does not solve all the problems. The documentation states, that Deployed -> True disables:

...general editing and selection in a cell

General editing/selection means that in the following example one can not select individual expressions of the list (e.g. ""text""), but still graphics editing is possible, as the screenshot clearly shows:
Manipulate[{""text"", Plot[x^n, {x, 0, 3}]}, {n, 0, 10}, Deployed -> True]


Thus to make output really bulletproof, wrap each Graphics object into Deploy as well:
Manipulate[{""text"", Deploy@Plot[x^n, {x, 0, 3}]}, {n, 0, 10}, Deployed -> True]

"
ocr - Can TextRecognize read digits?,"
(* Get your image *)
digits = ImagePartition[Import[""http://i.stack.imgur.com/cLncR.png""], 50];

(* Remove Borders and Binarize *)
d1 = Binarize[ImageCrop[#, 37], .5] & /@ Flatten@digits;

(* Keep only images with content (blanks affect the OCR) *)
d2 = Select[d1, Min@ImageData@# == 0 &];

(* Assemble as a line and ""read"" *)
TextRecognize@ImageAssemble@d2
(*
-> ""64776958729385431752328231""
*)

Edit
The following will reassemble your original image (but cleaner)
tr    = TextRecognize@ImageAssemble@d2;
posd2 = Flatten@Position[d1, x_ /; Min@ImageData@x == 0, {1}];
tp2   = Thread@List[posd2, Characters@tr];
(d1[[#[[1]]]] = Graphics[Text[Style[#[[2]], Large]], ImageSize -> 37]) & /@ tp2;
ia    = ImageAssemble@Partition[ImageCrop[#, 39] & /@ d1, 9]; 
ia1   = Map[ImageCrop[#, ImageDimensions@ia/3 + 3] &, 
            ImagePartition[ia, ImageDimensions@ia/{3, 3}], {2}];

GraphicsRow[{ImageAssemble@ia1, ImageAssemble@digits}]


"
Symmetric difference of a sample of lists,"
I think you are looking for this:
Complement[Join[list1, list2, list3], 
 Intersection[list1, list2, list3]]

or as suggested in the comments:
Complement[Union[list1, list2, list3], 
 Intersection[list1, list2, list3]]

(*
=> {a, b, e, f, g, h}
*)

Note, that the h is present here but not the d. I assume this is a typo in the question.
"
notebooks - How to make an unremovable modal window?,"
Not 100% solution, but this may work. Define:
dialog := 
 CreateDialog[{TextCell[""Click OK to close""], DefaultButton[]}, 
  Modal -> True, NotebookEventActions -> {""WindowClose"" :> dialog}]

Then call:
dialog

At least, it reappears :)
"
Match patterns on list of Strings,"
I am not sure how to do this using DeleteCases, but you can still use the Select function:
Select[data, StringTake[#, 1] != ""A"" &]

which has the desired result.
Edit Actually, you can also use DeleteCases like this:
DeleteCases[data, _?(StringTake[#, 1] == ""A"" &)]

"
plotting - Legend of a plot: how to increase the size of the line/marker?,"
If you're willing to abandon PlotLegends (which tkott advises in the comment and  many others would advise too), then you could work with the code posted in this related answer to achieve some customization. You'll have to execute the definitions in that post before trying the lines below.
Take the following two plots which generate the same curve first as a line and then as points from a table, using plot markers:
p = Plot[Evaluate[Table[1/x + i, {i, 0, 3, 1}]], {x, 0, 3}, 
   PlotRange -> {0, 3}];
q = ListPlot[
   Table[Evaluate@Table[{x, 1/x + i}, {x, .5, 3, .5}], {i, 0, 3, 1}], 
   PlotRange -> {0, 3}, PlotMarkers -> Automatic];

Now simply say
autoLegend[Show[p, q], {""Asymptote 1"", ""Asymptote 2"", ""Asymptote 3""}]

and the result is this:

You could replace autoLegend by deployLegend above if you want to be able to edit the result as a graphic. To customize the sizes inside the legend, I'll add some options:
autoLegend[Show[p, q], {""Asymptote 1"", ""Asymptote 2"", ""Asymptote 3""},
 ""LegendLineWidth"" -> 20,
 ""LegendLineAspectRatio"" -> .5,
 ""LegendGridOptions"" -> {Alignment -> Left, Spacings -> {1, 1}}]


The ""LegendGridOptions"" setting takes the same options as Grid and determines the horizontal and vertical space between entries in the legend. The ""LegendLineWidth"" and ""LegendLineAspectRatio"" have to be changed in tandem to get the markers and lines to fill the space properly. 
Edit
If the two plots p and q represent independent data (such as experimental  data versus theory curves), then the legend should have six instead of three entries. This is something autoLegend isn't able to figure out, so we have to do it using the lower-level function legendMaker. It needs to be given the styles for the lines and markers explicitly, as lists of six entries each. To specify that there should be no line or no marker, use the entry None.
The following example first defines the text for the legend, and the styles that appear in the two plots:
textLabels = 
  Map[Style[#, FontFamily -> ""Helvetica"", 
     GrayLevel[.9]] &, {""Asymptote 1"", ""Asymptote 2"", ""Asymptote 3"", 
    ""Data 1"", ""Data 2"", ""Data 3""}];

plotstyles = Map[ColorData[1][#] &, Range[3]];

manualPlotstyles = Join[plotstyles, {None, None, None}];

markers = {Style[""\[FilledCircle]"", Hue[0.67, 0.6, 0.6], 
    FontSize -> 8.96], 
   Style[""\[FilledSquare]"", Hue[0.9060679774997897, 0.6, 0.6], 
    FontSize -> 8.96], 
   Style[""\[FilledDiamond]"", Hue[0.1421359549995791, 0.6, 0.6], 
    FontSize -> 10.88]};

manualMarkers = Join[{None, None, None}, markers];

In the variables manualPlotstyles and manualMarkers, I added None in the list positions where either the line or the marker should be omitted. The result is overlayed with the combined plots (produced by Show):
Overlay[{
  Show[p, q, PlotLabel -> Style[""Comparison"", ""Subsection""]],
  legendMaker[
   textLabels,
   PlotStyle -> manualPlotstyles,
   PlotMarkers -> manualMarkers,
   Background -> Directive[Opacity[.5], Black],
   ""LegendLineAspectRatio"" -> .3,
   ""LegendGridOptions"" -> {Alignment -> Left, Spacings -> {.7, .1},
     Background -> {{GrayLevel[.8], None}, None}
     }
   ]},
 Alignment -> {-.8, -.7}]


This shows how some of the optional parameters can be used to get a different legend appearance.
"
functions - How to convert binary float to decimal float,"
You need to get the RealDigits first:
FromDigits[RealDigits[1.111111], 2]

This gives (after N) 1.98438 which matches the value solved for here.
If you want to work between any two bases, say you wanted to know how to write the number 18 in hex:
FromDigits[RealDigits[18, 16]]

(* Out[]:= 12 *)

Alternatively, if you just want to ""know"" what the number is, without needing to compute with it, you can use BaseForm:
BaseForm[18, 16]

"
How to create a list of pairs from 1d list(s)?,"
Ad. 1
ordering  not valid:
Subsets[A, {2}]


{{1, 2}, {1, 3}, {2, 3}}


or with ordering
Permutations[A, {2}]

Ad. 2
Outer[List, A, B]


{{{1, a}, {1, b}, {1, c}}, {{2, a}, {2, b}, {2, c}}, {{3, a}, {3, b}, {3, c}}}


or exactly
Outer[List, A, B] // Flatten[#, 1] &


 {{1, a}, {1, b}, {1, c}, {2, a}, {2, b}, {2, c}, {3, a}, {3, b}, {3, c}}


"
replacement - How to replace all occurrences of an element in a list?,"
You can use:
list /. {2 -> ""Test""}

(* Out[]:= {1, ""Test"", ""Test"", ""Test"", 3} *)

"
list manipulation - Append in For loop does not work,"
How about:
result = {};
For[i = 0, i < 6, i++, 
 s = Check[If[i == 3, Message[FindRoot::jsing, x, 1], i], ""Nan"", 
   FindRoot::jsing];
 Print[s];
 If[s == ""Nan"", Break[], result = {result, s}];]
Flatten[result]

or
result = {};
For[i = 0, i < 6, i++, 
 s = Check[If[i == 3, Message[FindRoot::jsing, x, 1], i], ""Nan"", 
   FindRoot::jsing];
 Print[s];
 If[s == ""Nan"", Break[], AppendTo[result, {s, dim}]];]
result

"
graphs and networks - Coloring edges in GraphPlot,"
l = {{1, 3}, {3, 4}};
GraphPlot[{1 -> 2, 3 -> 4, 1 -> 3, 2 -> 4, 1 -> 2, 3 -> 4}, 
 EdgeRenderingFunction -> (If[
     Intersection[l, {#2}] != {}, {Red, Arrow[#1, .1]}, 
                                  {Blue,Arrow[#1, .1]}] &)]


Edit
Using edge labels:
l = {1, 3};
GraphPlot[{{1 -> 2, 1}, {3 -> 4, 2}, {1 -> 3, 3}, {2 -> 4, 4}, {1 -> 2, 5}, {3 -> 4, 6}}, 
 EdgeRenderingFunction -> (If[
     Intersection[l, {#3}] != {}, {Red, Arrow[#1, .1]}, {Blue, Arrow[#1, .1]}] &)]


"
list manipulation - Reproducing nested loops using Map?,"
Is this what you want?
l1 = {a, b, c};
l2 = {aa, bb, cc};
sth[#1, #2] & @@@ Tuples[{l1, l2}]


{sth[a, aa], sth[a, bb], sth[a, cc], sth[b, aa], sth[b, bb], 
 sth[b, cc], sth[c, aa], sth[c, bb], sth[c, cc]}


"
plotting - Joining only particular dates with DateListPlot,"
Add in a Null data point to each series like this:
dataset1 = {{{1997}, 98/79}, {{1998}, 26/61}, {{1999}, 
    22/15}, {{2000}, 100/63}, {{2001}, Null}, {{2007}, 
    284/57}, {{2008}, 226/31}, {{2009}, 15/4}, {{2010}, 221/63}};

dataset2 = {{{1997}, 25/79}, {{1998}, 17/61}, {{1999}, 
    28/25}, {{2000}, 20/21}, {{2001}, Null}, {{2007}, 
    106/57}, {{2008}, 128/31}, {{2009}, 59/16}, {{2010}, 32/9}};

The plot then becomes:
DateListPlot[{dataset1, dataset2}, Joined -> True]


"
list manipulation - Problem with Union and Intersection,"
You're looking for Apply

Apply[Union, list]

which can be written in short form as 
Union@@list

"
algebraic manipulation - Why doesn't Mathematica  expand Cos[x]^3 Sin[x]^2?,"
The function you want for this kind of case is TrigReduce:

TrigReduce[expr]
  rewrites products and powers of trigonometric
  functions in expr in terms of trigonometric functions with combined
  arguments.

And it works:

"
performance tuning - Data fitting with Image processing feature detection,"
You can use image processing like in the example below to find the enclosing circle. I use FillingTransform to fill in the binarized image, which gives something like the plot on the left. Then using ComponentMeasurements, I obtain the centroid and the radius of a disk that has the same area as the points in the original image. Here's how it looks


data = RandomReal[NormalDistribution[], {100000, 2}]; (* test data *)
p = ListPlot[data, AspectRatio -> 1, Axes -> None];
f = FillingTransform@ColorNegate@Binarize@p // DeleteSmallComponents
{c, r} = 1 /. ComponentMeasurements[f, {""Centroid"", ""EquivalentDiskRadius""}]    
Show[Rasterize[p], Graphics[{Red, Circle[c, r]}]]

"
How to get graph layout that reflects edge weights?,"
Update: Since version 9, weighted layouts are available.  See this answer.

The short answer is, unfortunately no, in version 8.0.* at least, the built-in layout algorithms do not take edge weight into account. Consider a version of your example:
Unweighted
adjMat1 = {{Infinity, 1, 1, 1, 1}, {1, Infinity, 1, 1, 1}, {1, 1, 
    Infinity, 1, 1}, {1, 1, 1, Infinity, 1}, {1, 1, 1, 1, Infinity}};

Weighted
adjMat2 = {{Infinity, 8, 6, 3, 7}, {1, Infinity, 1, 1, 1}, {2, 5, 
    Infinity, 9, 4}, {1, 1, 1, Infinity, 1}, {1, 1, 1, 1, Infinity}};

Weighted adjacency matrix converted to multiedge rule form
multiedge = DeleteCases[ Flatten@Table[
    If[i == j, Null, Table[i -> j, {adjMat2[[i, j]]}]], {i, 
     Length[adjMat2]}, {j, Length@First@adjMat2}], Null]

(* Output:   {1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 1 -> 2, 
 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 3, 1 -> 4, 1 -> 4, 
 1 -> 4, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 1 -> 5, 
 2 -> 1, 2 -> 3, 2 -> 4, 2 -> 5, 3 -> 1, 3 -> 1, 3 -> 2, 3 -> 2, 
 3 -> 2, 3 -> 2, 3 -> 2, 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 4, 
 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 4, 3 -> 5, 3 -> 5, 3 -> 5, 3 -> 5, 
 4 -> 1, 4 -> 2, 4 -> 3, 4 -> 5, 5 -> 1, 5 -> 2, 5 -> 3, 5 -> 4} *)

This shows that any of the three plotting methods give essentially the same layout for the same layout (Method/GraphLayout) option.
Manipulate[
 Row[{GraphPlot[multiedge, MultiedgeStyle -> None, Method -> s], 
   GraphPlot[adjMat1, MultiedgeStyle -> None, Method -> s], 
   AdjacencyGraph[adjMat1 /. \[Infinity] -> 0, 
    GraphLayout -> s]}], {s, {""SpringElectricalEmbedding"", 
   ""SpringEmbedding"", ""HighDimensionalEmbedding"", ""CircularEmbedding"",
    ""RandomEmbedding"", ""LinearEmbedding""}}]


If you were to come up with your own algorithm for allowing for the weights, you could draw graphs using that algorithm using the VertexCoordinateRules option.
There is a Weighted option in the GraphUtilities package, but it doesn't apply to visualisation. 
"
simplifying expressions - What is the difference between a few simplification techniques?,"
The primary difference between Refine and the two *Simplify functions is that Refine only evaluates the expression according to the assumptions given. It might so happen to be the simplest form when evaluated, but it does not check to see if it is indeed the simplest possible form. You should use Refine when your goal is not to simplify the expression but to just see how the assumptions transform it (e.g., square root of a positive quantity).
Simplify, on the other hand, performs basic algebraic simplifications and transformations to arrive at the ""simplest"" result. Refine is one among them, and is also mentioned in its doc page. Here, ""simplest"" might not necessarily fit your definition of simple. It is what appears simple to Mathematica, and that is defined by LeafCount. Here's an example showing the difference between the two:
Refine[(x - 1)/Sqrt[x^2] + 1/x, x > 0]
(* Out= 1/x + (-1 + x)/x *)

Simplify[(x - 1)/Sqrt[x^2] + 1/x, x > 0]
(* Out= 1 *)

FullSimplify behaves the same as Simplify, except that it also does manipulations and simplifications when it involves special functions. It is indeed slower, as a result, because it has to try all the available rules. The list of special functions is found in guide/SpecialFunctions and it's not a non-standard usage of the term and you can also read about it on Wikipedia. So in all cases not involving special functions, you should use Simplify. You can certainly give FullSimplify a try if you're not satisfied with Simplify's result, but it helps to not start with it if you don't need it.
Here's an example showing the difference between Simplify and FullSimplify:
Simplify[BesselJ[n, x] + I BesselY[n, x]]
(* BesselJ[n, x] + I BesselY[n, x] *)

FullSimplify[BesselJ[n, x] + I BesselY[n, x]]
(* HankelH1[n, x] *)


A few more notes on Simplify and FullSimplify:
As you have noted, FullSimplify is slow — sometimes it can take hours on end to arrive at the answer. The default for TimeConstrained, which is an option, is Infinity, which means that FullSimplify will take its sweet time to expand/transform until it is satisfied. However, it could very well be the case that a bulk of the time is spent trying out various transformations (which might eventually be futile) and the actual simplification step is quick. It helps to try out with a shorter time, and the documentation has a good example that shows this. This holds for Simplify too.
Note that setting the option TimeConstrained -> t does not mean that you'll get your answer in under t seconds. Rather, it means that Mathematica is allowed to spend at most t seconds for a single transformation/simplification step.
Similarly, you can exclude certain functions from being simplified using ExcludedForms or include other custom transformations using TransformationFunctions. You can even change the default measure of ""simplicity"" using ComplexityFunction, and here is an answer that uses this. However, these options are not available in Refine.
These are actually well documented in the documentation for both functions, but is not widely known and can often be the key to getting the result quickly or in the form you want.
"
graphics - Create self-contained plots when Ticks or FrameTicks require external functions,"
Try giving the ticks as pure functions, so they actually get replaced 
The copying issue I don't quite get it. It seems that the returned box structure changed the integers into doubles (the last argument of FindDivisions, the 4, into 4. in this case). It could be fixed by rewriting the function as 
ff=Function[{xmin, xmax}, ({#1, """", 0.03`} &) /@  
 FindDivisions[{xmin, xmax}, Round@4]]

with Ticks -> ({#, #} &[ff]) as you wrote in the comment
I vote for bug, let's see what others think
"
plotting - ListContourPlot-ColorFunction,"
You can Rescale your points that are passed to ColorFunction so that they're between 0.05 and 0.95 as in the example below:
data = Table[Sin[i + j^2], {i, 0, 3, 0.1}, {j, 0, 3, 0.1}];
ListContourPlot[data, ColorFunction -> (ColorData[""Rainbow""][
    Rescale[#, {0, 1}, {0.05, 0.95}]] &)]


"
functions - Create string from character code,"
You can use
ToCharacterCode[""abcABCαβγ""]
(*
=>    {97, 98, 99, 65, 66, 67, 945, 946, 947}
*)
FromCharacterCode[%]
(*
=>    ""abcABCαβγ""
*)

To create unique symbols, use
Unique[""x""]

"
Graph does not accept Property Options,"
The following works:
ClearAll[g];
vertices1 = {1, 2, 3};
g = Graph[vertices1, {1 \[UndirectedEdge] 2, 2 \[UndirectedEdge] 3}];
PropertyValue[{g, 1}, VertexSize] = .3;
PropertyValue[{g, 1}, VertexCoordinates] = {0, 3}; 
PropertyValue[{g, 2}, VertexCoordinates] = {1, 2};
PropertyValue[{g, 3}, VertexCoordinates] = {3, 3};
g


"
graphics3d - Rotating 3DPlot into animated gif,"
I suppose you don't want something like this? (Sorry about the 750KB GIF...)

data = Table[Sin[x y], {x , 0, Pi, Pi/20},  {y, 0, Pi, Pi/20}];
animation = Table[ListPlot3D[data,
    DataRange -> {{-1, 1}, {-1, 1}},
    SphericalRegion -> True,
    Axes -> False, Boxed -> False,
    ViewVector -> {5 Sin[t], 5 Cos[t], Sin[10 t]}], {t , 0, Pi, 
    Pi/40}];
Export[""animated.gif"", animation, ""DisplayDurations"" -> .1]

"
string manipulation - Custom distance metric for agglomerative clustering in Mathematica,"
The tutorial tutorial/PartitioningDataIntoClusters has information on Distance functions (also for Strings, e.g. HammingDistance).
"
version 8 - What is the most convenient way to change options for Graph[] objects?,"
You could use SetProperty. For example
g = Graph[{1 -> 2, 2 -> 4, 3 -> 4}]

SetProperty[g, VertexLabels -> {""Name"", 2 -> ""Two""}]



"
How to recompute the layout of a Graph?,"
Imagine that you have a graph with quite a few complex custom properties - below every edge and vertex have their unique properties:
g = Graph[Table[Style[j, Hue[j/2^8 - 1]], {j, 0, 2^8 - 1}], 
  Table[Style[j \[UndirectedEdge] FromDigits[Drop[IntegerDigits[j, 2], 1], 2], 
    Hue[j/2^8]], {j, 0, 2^8 - 1}], GraphLayout -> ""RadialDrawing"", 
  GraphStyle -> ""LargeNetwork""]


To keep these properties and change the GraphLayout:
ToExpression@StringReplace[ToString[InputForm[g]], ""RadialDrawing"" -> ""SpringElectricalEmbedding""]


Alternatively you could just use Shift+Ctrl+E and retype the GraphLayout option.
Yet another alternative, which avoids potentially unsafe string replacements, is the following:
ReleaseHold[
 ToExpression[ToString[InputForm[g]], InputForm, Hold] /. 
  ""RadialDrawing"" -> ""SpringElectricalEmbedding""
]

This converts the Graph object to a non-atomic Mathematica expression with the head Graph.  Since this expression is not atomic, standard expression manipulation functions, including ReplaceAll, can be used on it.
"
programming - How to take several values out of a large expression?,"
As @Szabolcs points out in the comments, you can always use Part or Replace regardless what head your expression has.  I personally prefer ReplaceAll in cases such as this because I find it easier to tell what I intended with my code when I dig it up months or years later.
ef = 
  EdgeForm[Directive[Thickness[Large], Dashing[{Small, Small}], 
    Opacity[0.1`], RGBColor[0, 0, 1]]];

ef /. 
 EdgeForm[Directive[Thickness[t_], Dashing[d_], Opacity[o_], 
    col_]] :> {t, d, o, col}

==> {Large, {Small, Small}, 0.1, RGBColor[0, 0, 1]}

"
Determining the week of a year from a given date,"
Since I'm living in Europe I'm sticking to the European definition of week number which is equivalent to the ISO standard. According to this standard, a week starts on Monday and the first week is the week containing 4 January. Taking this into account you could do therefore do something like
weekNumberISO[date_] := Module[{day0, year},
  With[{days = {""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"", ""Sun""}},
   year = ToExpression[DateString[date, ""Year""]] ; 
   day0 = DatePlus[{year, 1, 4}, 
      {1 - Position[days, DateString[{year, 1, 4}, ""DayNameShort""]][[1, 1]], ""Day""}];
   1 + Floor[DateDifference[day0, date, ""Week""][[1]]]]]

For the North-American definition of week number, i.e. week 1 is the week containing 1 January and a week starts on Sunday, you would get something like
weekNumberUS[date_] := Module[{day0, year},
  With[{days = {""Sun"", ""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat""}},
   year = ToExpression[DateString[date, ""Year""]] ; 
   day0 = DatePlus[{year, 1, 1}, 
      {1 - Position[days, DateString[{year, 1, 1}, ""DayNameShort""]][[1, 1]], ""Day""}];
   1 + Floor[DateDifference[day0, date, ""Week""][[1]]]]]

"
equation solving - Trouble using FindInstance with MatrixRank,"
The problem with MatrixRank used in this way is explained in the Help:

"
import - How to scrape the headlines from New York Times and Wall Street Journal?,"
You can always do Import[""http://wsj.com"",""XMLObject""]. That has the side effect of producing some irregular XML whenever the underlying HTML doesn't quite map cleanly to XML, but it mostly produces an XMLObject[] expression tree that you can match over and extract data from, and I've never seen a web page for which it won't return something.
"
plotting - How to plot a barycentric line,"
A ternary plot is a plot on the nonnegative unit simplex in $\mathbb{R}^3$, so apply an affine change of basis (and rescale f1 to be sure its values lie on the simplex):
ClearAll[f1];
f1[x_] := {Abs[Sin[x]], Mod[x, 2], Abs[Cos[x]]};

With[{xyToTernary = {{0, 1, 1/2}, {0, 0, Sqrt[3]/2}}}, 
 ParametricPlot[xyToTernary . (f1[x] / Total[f1[x]]), {x, 1, 3^5}, 
  AxesOrigin -> {0, 0}, PlotRange -> {0, 1}, 
  Prolog -> {White, EdgeForm[Black], Polygon[{{0, 0}, {1, 0}, {1/2, Sqrt[3]/2}}]}]
 ]


Due to the nature of your function, it would be a good idea to break it at integral values of x by including the option Exclusions -> Range[3^5]:

If you would like to visualize the 3D to 2D relationship inherent in these plots, you can ask Mathematica to do the projecting for you (but the 2D quality is degraded):
Show[
 Graphics3D[{White, EdgeForm[Black], Polygon[{{1, 0, 0}, {0, 1, 0}, {0, 0, 1}}]},  
  ViewVector -> {1, 1, 1}, ViewPoint -> {-8, -8, -8}, 
  ViewVertical -> {0, 0, 1}, ViewCenter -> {1/3, 1/3, 1/3}, 
  ViewAngle -> \[Pi]/2,  Lighting -> {{""Ambient"", White}}],
 ParametricPlot3D[f1[x] / Total[f1[x]], {x, 1, 3^5}, 
  Exclusions -> Range[3^5]], Axes -> {True, True, True}
 ]

(Image not shown.)
"
list manipulation - Is there a faster way to create a matrix of indices from ragged data?,"
A modest improvement when you replace Replace[...] with Transpose@Thread:
 (udata = Sort[DeleteDuplicates[Flatten@testData], Less]; 
 dsptch = Dispatch[Thread[udata -> Range[Length[udata]]]]; 
 out1 = Replace[testData /. dsptch, a_Integer :> {a, a}, 1];) // AbsoluteTiming 
 (* {2.1282128, Null} *)

 (udata = Sort[DeleteDuplicates[Flatten@testData], Less]; 
 dsptch = Dispatch[Thread[udata -> Range[Length[udata]]]]; 
 out2 = Transpose@Thread[testData /. dsptch];) // AbsoluteTiming 
 (* {1.9421942, Null} *)
 out1==out2
 (* True  *)

"
front end - Command Completion,"
Changing shortcuts isn't that complicated. All you have to do is change one line in the file KeyEventTranslations.tr in a location in your file system specified by this command:
FileNameJoin[{$InstallationDirectory, ""SystemFiles"", ""FrontEnd"", 
  ""TextResources"", $OperatingSystem}]

Locate the following line in a text editor and change the key into the one you want:
Item[KeyEvent[""F2""], FrontEnd`CompleteSelection[True]]

I wouldn't use tab, as that already has a built-in meaning.
More information can be found here.
"
symbolic - Surprises simplifying simple polynomials,"
We get different results because Simplify, working with a smaller range of accessible transformations than FullSimplify does, applied to structurally very different expressions at the begining,  reaches only the local minimum of the default ComplexityFunction, being roughly close to LeafCount, unlike in case of FullSimplify even though its underlying ComplexityFunction may be the same.
Having defined :  
bySum = Sum[k^2, {k, 1, n}];
byBernoulli = (BernoulliB[3, n + 1] - BernoulliB[3])/3;

we get : 
bySum == byBernoulli // Simplify


True


because 
Simplify[byBernoulli - bySum]


0


even though Simplify yields different results here :
  {bySum, byBernoulli} // Simplify


This is because at the begining we have  very different forms of the expressions which  we can observe with help of TreeForm and LeafCount assessing the complexity :
LeafCount /@ { bySum, byBernoulli, byBernoulli - bySum }


{13, 26, 40}


TreeForm /@ {bySum, byBernoulli}


A kind of expression not involving special functions where  FullSimplify simplifies it in a much better way than Simplify one can find here. 
Knowing that algorithms behind FullSimplify contain a much wider range of transformations than Simplify the latter finds at certain stage  only a local minimum (not sufficient in case of byBernoulli // Simplify to reach the global minimum) of the actual complexity function  and therefore the resulting expressions are slightly different :
LeafCount /@ {bySum // Simplify, byBernoulli // Simplify}


{13, 15}


TreeForm /@ {bySum // Simplify, byBernoulli // Simplify}


unlike in case of FullSimplify :
{bySum , byBernoulli } // FullSimplify


We needn't use FullSimplify to get the same expressions,  a simpler solution of the problem would be this :
{bySum, byBernoulli} // Factor


which is the same as the result of FullSimplify for the both expressions as well as Simplify for bySum. It should be mentioned here, that FullSimplify when applied to  a factorizable polynomials tends to give that polynomial in the factorized form, i.e. Factor[poly] yields by default its factorized form if poly is factorizable in the field of rationals, however if we extend the rationals appropriately the results will be different, e.g. Factor[1 - 10 x^2 + x^4, Extension -> {Sqrt[2], Sqrt[3]}] (see this answer). So this is rather a special case, a more genreal approach (also for polynomials not factorizable in the rationals)
would be :
{bySum, byBernoulli} // Collect[#, n] & // Simplify


The result is the same as in the case of byBernoulli // Simplify. 
"
plotting - Changing the order of elements in a chart legend,"
Histogram[{bottom, middle, top}, 10, 
          ChartLayout -> ""Stacked"", 
          ChartLegends -> {""Bottom"", ""Middle"", ""Top""}] /. 
Column[l_List] :> Column[Reverse@l]


"
export - Mathematica output format for big numbers,"
You could define your own definitions for formatting numbers and variables. For example
WriteInput1[file_, var_, eqlist_] := 
 Module[{text, removewhite, eq2, gg, hh, format},

  format[a_?NumericQ] := Block[{Format},
    ToString@NumberForm[a, 10,
      NumberFormat -> (Module[{man},
          man = #1;
          If[StringTake[#1, -1] === ""."", man = man <> ""0""];
          If[#3 === """", man, Row[{man, ""*10^("", #3, "")""}]]] &)]];

  gg /: Format[gg[a_], InputForm] := OutputForm[format[a]];
  hh /: Format[hh[a_], InputForm] := OutputForm[
    StringReplace[ToString[a], {""["" -> """", ""]"" -> """", "","" -> """"}]];

  eq2 = eqlist /. Join[(# -> hh[#]) & /@ var, {a_?NumericQ :> gg[a]}];

  removewhite[x_String] := StringReplace[x, Whitespace -> """"];
  (*write equations*)

  text = Fold[# <> removewhite[ToString[#2, InputForm]] <> "";\n"" &,
    ""{"", eq2];
  text = text <> ""}"";
  WriteString[OpenWrite[file],text];
  Close[file];
  text
  ]

ToString uses Format to decide how to convert expressions to strings.
What I'm doing here is wrapping any occurrences of elements in var with hh and any numbers with gg and using TagSet to tell Format how to deal with expressions of the form gg[...] or hh[...]. 
Example
WriteInput1[""sys1.txt"", {x[1, 1], x[2, 1], x[1, 2]},
    {3.998723445*10^6 x[1, 1]^2, x[2, 1]^2, x[1, 2]^2}]

(* ==> {3.998723445*10^(6)*x11^2;
       x21^2;
       x12^2;
       }
*)

WriteInput[""sys1.txt"", {x[1, 1], x[2, 1], x[1, 2]}, 
    {3.0 x[1, 1]^2, x[2, 1]^2, x[1, 2]^2}]

(* => {3.0*x11^2;
      x21^2;
      x12^2;
      }
*)

"
programming - Figuring out how AbsoluteOptions works with Graphs,"
The difference in layout between g and g3 can be explained from the fact that their VertexLists are different:
g = RandomGraph[{6, 11}, VertexStyle -> {1 -> Red, 2 -> Green}, 
  VertexSize -> {1 -> Large, 2 -> Large}, VertexLabels -> ""Name"", 
  ImagePadding -> 15, EdgeLabels -> ""Name""];

VertexList[g]

(* ==> {1, 2, 3, 4, 5, 6} *)

g3 = Graph[EdgeList[g], someOptions];
VertexList[g3]

VertexList[g3]

(* ==> {1, 6, 3, 5, 2, 4} *)

Try for example
{g, Graph[VertexList[g], EdgeList[g], someOptions]}


"
programming - Open Excel file with Mathematica,"
You don't need the initial InstallNET[].  That should come after Needs[""NETLink""].
I made a post on this topic a while back, here: http://forums.wolfram.com/mathgroup/archive/2011/Oct/msg00386.html
Some code to illustrate the method:
Needs[""NETLink`""]
ReadFromExcel[file_String, cell_String, rows_Integer, cols_Integer] :=
   Module[{excel, workbook, worksheet, srcRange, data},
   NETBlock[InstallNET[];
    excel = CreateCOMObject[""Excel.Application""];
    If[! NETObjectQ[excel], Return[$Failed],
     excel[Visible] = True;
     workbook = excel@Workbooks@Open[file];
     worksheet = workbook@Worksheets@Item[1];
     srcRange = worksheet@Range[cell]@Resize[rows, cols];
     data = srcRange@Value;
     workbook@Close[False];
     excel@Quit[];
     ]];
   LoadNETType[""System.GC""];
   GC`Collect[];
   data];

ReadFromExcel[""testdata.xlsx"", ""B1"", 2, 3]


{{1., 2., 3.}, {4., 5., 6.}}


"
inverse - How to invert an integral equation,"
My interpretation of the question is that you want to find $x$ for given $f$, $g_2$ and $g_1$. Then just define $F=f/g_1$ and differentiate with respect to $x$ on both sides:
$\frac{d}{dx}F(x)=g_2(x)$
Now solve this equation for $x$. There's no integration involved. 
"
printing - How to print without having newline added automatically at the end?,"
For Example:
WriteString[""stdout"", ""First part of the result: "", DateString[]];
(*Perform some calc*)
i = 0;
WriteString[""stdout"", "" -- Addition to the result: "", DateString[],  ""\n""];


First part of the result: Thu 15 Oct 2015 12:58:29 -- Addition to the result: Thu 15 Oct 2015 12:58:29

"
What's a good style for inheriting Options[] of built-in function?,"
I use the first style you gave:
Options[tListPlot]=Join[
    Options[ListPlot],
    Options[tLegend],
    {
        Rule[ShowLegend,False]
    }
];

The function is then defined as
tListPlot[data_,options:OptionsPattern[]]:=...

I don't see any reason to use SetDelayed (:=) in this context. EDIT As Brett Champion mentions in the comments, the default options for 
System`Plot

will change if you use SetOptions on Plot. Hence, if you want your custom plot to always have the same options as Plot, use :=. I would prefer to specifically change the options for my Plot separately, so I would still use simply Set (=).
You might also want to check out this instructive question on Options in custom functions: Functions with Options
"
wavelet analysis - Detecting spikes by shrinking WaveletPacket basis using a specific threshold,"
I don't know if you are wedded to wavelets but...
Have you considered a ""compound median filter"" (q.v.) ?
For a list of data x and filter width 2r+1,  
MedianFilterRoot[x_, r_] := FixedPoint[MedianFilter[#, r] &, x]  
CompoundMedianFilter[x_, r_] := 
 Fold[MedianFilterRoot[#1, #2] &, x, Range[r]]   

Plotting CompoundMedianFilter[x,r-1]-CompoundMedianFilter[x,r] shows all spikes of width r. Your example with two consecutive spikes could be something like:  
data = Table[Sin[x] + Random[], {x, 1, 10, 0.1}]  
data[[20]] = 60; data[[21]] = 80; data[[40]] = 100;  

Running CompoundMedianFilter[data,0]-CompoundMedianFilter[data,1] returns two unit-width spikes of amplitude 20 and 100, at indices 21 and 40, respectively.
Similarly, CompoundMedianFilter[data,1]-CompoundMedianFilter[data,2] returns a width-2 spike of amplitude 59 at indices 20 and 21.
Hence, adjacent spikes are resolved with essentially undistorted amplitudes (for this example with relatively large spikes).  
To reconstruct the spike-free signal, subtract all spikes of significant amplitude (and any width) from the original data.
"
syntax - Why does the Front End group backslashes into pairs?,"
From the tutorial Special Characters - Strings And Characters

example

Comment/Uncomment behavior you describe also happens in version 8.0.4.0 on Vista.
"
plotting - Mathematica slope fields,"
I'm assuming here that the curves you mentioned are streamlines of the vector field. You can plot those automatically without having to solve any differential equations by using the options StreamPoints, for example to plot the stream lines going through the points
points =  Transpose@ArrayPad[{Range[-10, 16, 2]}, {{1, 0}, {0, 0}}]

(* ==> {{0, -10}, {0, -8}, {0, -6}, {0, -4}, {0, -2}, {0, 0}, {0, 2}, {0, 4}, 
        {0, 6}, {0, 8}, {0, 10}, {0, 12}, {0, 14}, {0, 16}} *)

you can do
slopefield = 
 VectorPlot[{1, .005*p*(10 - p)}, {t, -1.5, 20}, {p, -10, 16}, 
  FrameTicks -> None, AxesLabel -> {t, p}, Axes -> True, 
  VectorScale -> {Tiny, Automatic, None}, VectorPoints -> 15, 
  StreamPoints -> points,
  StreamStyle -> {Red, ""Line""}]


"
export - Save and call matrices with large output in Mathematica,"
Export[""A.wdx"", A];

will save matrix A in file ""A.wdx"" on disk. WDX format is binary, compressed, and cross-platform.
Restart Mathematica and evaluate
A = Import[""A.wdx""];

This will read ""A"" from disk file ""A.wdx"" and store it in symbol A.
Proceed with your computation.
"
functions - How to use ForAll in Reduce,"
This is a simple example. Suppose you have the following equation and you want to get the coefficients of it: 
gl = a x^3 + b x^2 + c x + d == -x + (-3 + x) (5 + x^2);
Reduce[ForAll[x, gl]]

Your output will be:
d == -15 && c == 4 && b == -3 && a == 1

"
graphics - Finding minimal region with padding and linear map to circle,"
As @whuber pointed it out in a comment, you are looking for α-shapes, where the parameter α defines the ""tightness"" of the wrapping of the boundary of a shape. I've found an implementation by YZ here from 2009, which I've fine-tuned and made faster by compiling down frequently used functions. Slowest part is the Delaunay triangulation, but there are known methods to boost its performance.
About the padding and linear mapping to a circle: it is left for someone else to do.
emptyQ = Compile[{{center, _Real, 1}, {alpha, _Real}, {plist, _Real, 
     2}}, Module[{empty = True, n = 1, x, y},
    While[empty && n <= Length@plist, {x, y} = plist[[n]] - center; 
     empty = Sqrt[Abs[x]^2 + Abs[y]^2] > alpha; n++];
    If[empty, 1, 0]],
   Parallelization -> True,
   CompilationTarget -> ""C""];

center = Compile[{{alpha, _Real}, {p1, _Real, 1}, {p2, _Real, 1}}, 
   Module[{x, y, lhalf},
    {x, y} = p2 - p1;
    lhalf = Sqrt[Abs[x]^2 + Abs[y]^2]/2;
    {(p2 + p1)/2 + Sqrt[(alpha/lhalf)^2 - 1] {{0, -1}, {1, 0}}.((p2 - p1)/2),
     (p2 + p1)/2 + Sqrt[(alpha/lhalf)^2 - 1] {{0, 1}, {-1, 0}}.((p2 - p1)/2)}],
   Parallelization -> True ,
   CompilationTarget -> ""C""];

f[alpha_, plist_, {id1_, id2_}] := Module[
   {p1 = plist[[id1]], p2 = plist[[id2]], c1, c2, lhalf, c1emptyQ, c2emptyQ},
   If[alpha <= Norm[p1 - p2]/2, False,
    {c1, c2} = center[N@alpha, p1, p2];
    Sow[{c1, c2}];
    c1emptyQ = emptyQ[c1, N@alpha, Delete[plist, {{id1}, {id2}}]];
    c2emptyQ = emptyQ[c2, N@alpha, Delete[plist, {{id1}, {id2}}]];
    (c1emptyQ == 1 && c2emptyQ == 0) || (c1emptyQ == 0 && c2emptyQ == 1)
    ]];

Now do the triangulation and check for each pair if the function f returns True or False:
n = 1000; (* number of points *)
alpha = .8;

Needs@""ComputationalGeometry`"";
points = Select[RandomReal[{0, 10}, {n, 2}],
    (Norm[# - {5, 5}] < 5 \[And] Norm[# - {7.5, 5}] > 2.5) &];

triangulation = 
  Union[Sort /@ 
    Flatten[Thread[List @@ #] & /@ DelaunayTriangulation@points, 1]];
centerList = Last@Last@Reap[
     boundary = Select[triangulation, f[alpha, points, #] &];
     ];

{
 ListPlot[points, PlotRange -> Full, AspectRatio -> 1, 
   ImageSize -> 300, Frame -> False, Axes -> False],
 Show[
  Graphics[{Red, Opacity@.2, 
    Map[Circle[#, alpha] &, centerList, {2}]}, ImageSize -> 300],
  Graphics@GraphicsComplex[points, Line@boundary]
  ],
 Graphics[GraphicsComplex[points, Line@boundary], ImageSize -> 300]
 }


Table[
 boundary = Select[triangulation, f[alpha, points, #] &];
 Graphics[GraphicsComplex[points, Line@boundary], PlotLabel -> Row@{""α = "", alpha}],
 {alpha, {.1, .2, .3, .4, .6, 1.}}]


"
list manipulation - ReplaceAll inside an Iterator,"
Mathematica throws the error because Table has the HoldAll attribute which prevents the replacement from being performed before Table sees the iterator.  You can force evaluation using Evaluate:
Table[x, Evaluate[{x, x0 - 3*xp, x0 + 3*xp, xp} /. exampleParams]]

Alternatively, instead of ReplaceAll, use With:
With[{x0 = 0, xp = 1}, Table[x, {x, x0 - 3*xp, x0 + 3*xp, xp}]]

In similar situations I like to use a custom-defined With-like function that can take parameter lists.  I described this function here and I'm going to reproduce it in this answer as well for completeness:
ClearAll[withRules]
SetAttributes[withRules, HoldAll]
withRules[rules_, expr_] :=
  First@PreemptProtect@Internal`InheritedBlock[
    {Rule, RuleDelayed},
    SetAttributes[{Rule, RuleDelayed}, HoldFirst];
    Hold[expr] /. rules
]

withRules[exampleParams, Table[x, {x, x0 - 3*xp, x0 + 3*xp, xp}]]

"
export - Exporting a CDF to HTML,"
You do not really need a tool to depoly your CDF to HTML. It is very simple to do by hand. Here is what I do

open your text editor and create a file called index.htm
<HTML>    
<BODY >
This is my CDF

<p>

<script src=""http://www.wolfram.com/cdf-player/plugin/v1.0/cdfplugin.js""
type=""text/javascript""></script><script type=""text/javascript"">// 
<![CDATA[
var cdf = new cdf_plugin();
cdf.addCDFObject(""source"", ""source.cdf"",840,1435);
// ]]></script>

<P>
</BODY>
</HTML>

From Mathematica, save your notebook as source.cdf (using SAVE AS->CDF). Save it to the same folder your created the above index.htm file to. So now your folder have 2 files in it: source.cdf and index.htm
use your ftp program and upload these 2 files to your web site tree where you want to put them.
that is all. Click on the index.htm and will run the CDF.

ps. If you want to just show the Manipulate part in your CDF and not the code around it, then before doing SAVE AS, select the code cells and do CELL->CELL properties-> and un check the open option so that the cell becomes closed. 
So that the code cells (or any other cell you choose to close) are not open for view. This way, when someone sees your CDF, they only see the GUI part (i.e. the manipulate) and not any other cell you did not want them to see).
"
programming - How to solve a problem in relative motion?,"
One of the nice things about Mathematica is that it supports many different styles of programming. I think your code has the aspect of more ""traditional"" code that one might write in a different programming language. Perhaps your code is correct in spirit, but it seems to me overly complicated and as written obviously is not okay because it throws a recursion error. 
You could increase the $RecursionLimit and depending on what exactly is wrong that might help, but I think in this case it is better to rewrite.
This is more along the lines of what you need perhaps,
 Clear[Vx, Vy, Pxi, Pyi];
 Pxi = 30 Cos[0.5 Pi - 0.2 t];
 Pyi = 80 + 30 Sin[0.5 Pi - 0.2 t];
 Vx = D[Pxi, t];
 Vy = D[Pyi, t];
 Sxf = 150 - 10*t;
 Table[({Pxi /. t -> u + Vx*u, Sxf} /. u -> T) /. 
 Solve[Pxi + Vx*T - (9.8/2)*T^2 == 0, T][[2]], {t, 0, 15, 0.1}]

Given expressions for position on the ferris wheel over time, it computes the components of the velocity vector. Then for a range of values of time, it prints out the pairs you requested. Needless to say this code is still not as elegant as it could be, I suspect, and I'm not sure the physics of the situation is correctly represented here, but you should be able to check against your analytical solution (this code produces an intersect of the boat and the jumpers at a position of around 10).
Note that you will run into trouble using == to check for equality since you are using discrete time steps and inexact numbers. You may need to use FindRoot or NSolve.
"
cluster analysis - Stopping Agglomerative clustering under a condition in Mathematica,"
(After belisarius's comment)
The hierarchical clustering invoked by using Method -> ""Agglomerate"" can be further customized, by using the undocumented ""Linkage"" suboption. I assume this is ultimately provides the same functionality as the Linkage option in the HierarchicalClustering package, which accepts the following values:

""Single""          smallest intercluster dissimilarity
""Average""         average intercluster dissimilarity
""Complete""        largest intercluster dissimilarity
""WeightedAverage"" weighted average intercluster dissimilarity
""Centroid""        distance from cluster centroids
""Median""          distance from cluster medians 
""Ward""            Ward's minimum variance dissimilarity
f                 a pure function


data = {{-1.1, 2.6}, {3.9, -0.8}, {4.2, -3.7}, {3.3, 3.5}, {3.9, 5.2},
    {4.1, -4.8}, {3.8, 3.7}, {5.6, 0.1}, {3.1, -5.2}, {-0.9, 2.3},
    {2.9, 4.1}, {-2.3, 3.9}, {-2.5, 3.}, {2.6, -5.5}, {5.2, 1.9},
    {-0.7, 1.3}, {0.9, 2.8}, {-1.5, 3.3}, {3.8, 1.2}, {2.6, -5.1},
    {-0.8, 3.2}, {4.7, 0.7}, {3., 3.}, {3.9, 3.6}, {4.5, 1.4},
    {4.2, 1.3}, {-1.1, 2.6}, {4.8, 2.4}, {3.3, -3.5}, {3.2, -4.6},
    {3.3, -4.9}, {3., 3.5}, {0.7, 2.1}, {3.2, -4.3}, {-2., 0.5},
    {-1.2, 2.}, {-1.6, 1.8}, {-3.5, 3.7}, {4.8, 0.2}, {3.3, 2.4},
    {-0.1, 2.1}, {-1.3, 2.5}, {4.4, 3.9}, {3.5, 0.2}, {0.1, 2.9},
    {-1., 1.6}, {-1.4, 4.5}, {3.2, 2.5}, {-1.6, 2.4}, {2.6, -5.1}};

{
 ListPlot[FindClusters[data], PlotStyle -> PointSize@.05],
 ListPlot[FindClusters[data, 
   Method -> {""Agglomerate"",
      ""Linkage"" -> (If[#3 > 1.9`*^-6, #1 + #2, (#1 + #2)^2] &)}], 
  PlotStyle -> PointSize@.05]
 }


"
data structures - How to create strong types?,"
In practice, enforcing strong types in Mathematica seldom pays off, just because, as mentioned by @belisarius, Mathematica is untyped (and perhaps more so than most other langauges, since it is really a term-rewriting system). So, most of the time, the suggestion of @Mr.Wizard describes what I'd also do. 
The way to define ADT-s (strong types) was described in depth by Roman Maeder, in his books on Mathematica programming. This requires something more than what you provided in your question - namely, a more formal definition of what is in your data structure (so that we can form constructors, selectors and mutators). I will give here a very simple example to show how ADT can be implemented in Mathematica. The key points are using UpValues and (mostly inert) symbols to serve as heads of new types. Consider a simple ""pair"" type:
ClearAll[pair];
pair /: getFirst[pair[fst_, sec_]] := fst;
pair /: setFirst[pair[_, sec_], fst_] := pair[fst, sec];
pair /: getSecond[pair[fst_, sec_]] := sec;
pair /: setSecond[pair[fst_, _], sec_] := pair[fst, sec];

We can now define some function on this new type:
Clear[sortPairsByFirstElement];
sortPairsByFirstElement[pairs : {__pair}, f_] :=
     Sort[pairs, f[getFirst[#1], getFirst[#2]] &];

And here is an example of use:
pairs = Table[pair[RandomInteger[10],RandomInteger[10]],{10}]


{pair[0,10],pair[4,7],pair[5,3],pair[10,9],pair[9,2],pair[6,10],pair[3,7],
       pair[4,2],pair[0,4],pair[3,9]}

 sortPairsByFirstElement[pairs,Less]


{pair[0,4],pair[0,10],pair[3,9],pair[3,7],pair[4,2],pair[4,7],pair[5,3],
        pair[6,10],pair[9,2],pair[10,9]}

You can enforce stronger typing on what can go into a pair. One thing I've done is to enforce that in the ""constructor"":
pair[args__] /; ! MatchQ[{args}, {_Integer, _Integer}] :=
    Throw[$Failed, pair];

The technique just described produces truly strong types, in contrast to the pattern-based typing. Both are useful and complementary to each other. One reason why such strong typing as described above is rarely used in Mathematica is that all the rest of the infrastructure usual for the strongly-typed languages (compiler, type system, smart IDE-s, type-inference) is missing here (so you'd need to construct that yourself), plus often this will induce at least some overhead. For example, we may wish to represent an array of pairs as a 2-dimensional packed array for efficiency, but here the pair type will get in the way, and we'd have to write extra conversion functions (which will induce an overhead, not to mention the memory-efficiency). This is not to discourage this type of things, but just to note that over-using them, you may lose some advantages that Mathematica offers.
"
output formatting - TeX and TraditionalForm,"
If you just want the output, well, write it manually. EscpwEsc gives you the piecewise bracket. Then you can insert a table (Insert->Table/Matrix) or learn the shortcuts with Ctrl, and CtrlReturn, etc.
I got this box structure. You can see the result by running.
RawBoxes@FormBox[
  RowBox[{""\[Piecewise]"", 
    GridBox[{{RowBox[{""0"", "",""}], 
       RowBox[{""t"", ""\[LessEqual]"", 
         SubscriptBox[""x"", ""min""]}]}, {RowBox[{FractionBox[
          RowBox[{""t"", ""-"", SubscriptBox[""x"", ""min""]}], 
          RowBox[{SubscriptBox[""x"", ""max""], ""-"", 
            SubscriptBox[""x"", ""min""]}]], "",""}], 
       RowBox[{SubscriptBox[""x"", ""min""], ""<"", ""t"", ""\[LessEqual]"", 
         SubscriptBox[""x"", ""max""]}]}, {RowBox[{""1"", "",""}], 
       RowBox[{""t"", "">"", SubscriptBox[""x"", ""max""]}]}}]}], 
  TraditionalForm]

You can then style it further to suit you...
"
import - How to monitor the progress of Read?,"
I am fairly sure that for files of this size, you'll have problems loading them into Mathematica (unless you have truly huge amount of RAM on your machine, but perhaps even in this case). If your file contains newline-terminated strings, or if you otherwise know its structure (types stored there), consider using ReadList or BinaryReadList. I gave one example in my post here. In this way, you can attach something like ProgressIndicator to it, and monitor the progress. Also, I would recommend to use something similar to  large data framework from this answer, to convert the contents of your file / parts of resulting expression, to a file-backed form, since operating on the entire dataset in-memory might not be possible and / or efficient for such huge amounts of data.
"
programming - How to use Mathematica functions in Python programs?,"
This solution can work with several programming languages. Check this GitHub repository of mine.
See this link.
I have found a solution. Works fine to me.
Steps:
1-Create a script named runMath with the content:
#!/usr/bin/env wolframscript
# for certain older versions of Mathematica replace 'wolframscript' by
# 'MathematicaScript -script' in the shebang line

value=ToExpression[$ScriptCommandLine[[2]]];

(*The next line prints the script name.*)
(*Print[$ScriptCommandLine[[1]]];*)

Print[value];

2-I gave execution privilege to the file.
sudo chmod +x runMath

3-Moved the file to the execution path
sudo mv runMath /usr/local/bin/

4-Created a new script called run with the content:
#!/usr/bin/python
from subprocess import *
from sys import *

command='/usr/local/bin/runMath'
parameter=argv[1]

call([command,parameter])

5-Moved to the execution path
sudo mv run /usr/local/bin

6-Finally, tested it:
$run Prime[100]
541

$run 'Sum[2x-1,{x,1,k}]'
k^2

$run Integrate[Log[x],x]
-x + x*Log[x]

$run 'Zeta[2]'
Pi^2/6

You can use with ou without '. The ' are needed to command with spaces.
$run 'f[n_] := f[n] = f[n - 1] + f[n - 2]; f[1] = f[2] = 1; Table[f[n],{n,5}]'
{1, 1, 2, 3, 5}

Happy!
"
polynomials - Why does Expand not work within a function?,"
To implement what you intended to do, I suggest to take a look at this approach :
hermite[0, x_] := 1
hermite[1, x_] := 2 x
hermite[n_Integer /; n >= 2, x_] :=
    hermite[n, x] = Expand[2 x*hermite[n - 1, x] - 2 (n - 1) hermite[n - 2, x]]

Now you shouldn't have problems anymore. 
Recalling that there are in Mathematica the Hermite polynomials $H_{n}(x)$  since the version 1, namely HermiteH function, we can check if the above is correctly implemented : 
And @@ SameQ @@@ ({hermite[#, x], HermiteH[#, x]} & /@ Range[100])


True


e.g.
hermite[10, x]


-30240 + 302400 x^2 - 403200 x^4 + 161280 x^6 - 23040 x^8 + 1024 x^10


The problem with your approach appears with so-called memoization of 
2 x*hermite[n - 1, x] - 2 (n - 1) hermite[n - 2, x] 

but not Expand[hermite[n, x]], so there you had i.e. 
hermite[5, x]


2 x (12 - 48 x^2 + 16 x^4) - 8 (-8 x + 2 x (-2 + 4 x^2))


instead of 

120 x - 160 x^3 + 32 x^5


We solved the problem by remembering 
Expand[ 2 x*hermite[n - 1, x] - 2 (n - 1) hermite[n - 2, x] ]

To avoid another possible problems with the variable n, I included a condition in the definition of hermite[n, x]. In your approach you had i.e. hermite[1, x] = 2 x; and so evaluating i.e.
Plot[{hermite[0, x], hermite[1, x]}, {x, -5, 5}]     (* A *)

a message is generated $RecursionLimit::reclim of  exceeded $RecursionLimit (by default its value is 256). To avoid this problem you have do this :
 Plot[ Evaluate @ {hermite[0, x], hermite[1, x]}, {x, -5, 5}]  (* B *)

With my approach you needn't evaluate the functions, so you can choose (* A *).
"
data structures - Using Memoization with a Mutable Object,"
For such small trees I would memoize those that already have the element...
ClearAll[leftsubtree, rightsubtree, nodevalue, emptyTree, treeInsert]
leftsubtree[{left_, _, _}] := left
rightsubtree[{_, _, right_}] := right
nodevalue[{_, val_, _}] := val
emptyTree = {};

treeInsert[emptyTree, elem_] := {emptyTree, elem, emptyTree}

(*This is the changed line*)
t : treeInsert[tree_, elem_] /; ! FreeQ[tree, elem] := t = tree

treeInsert[tree_, elem_] /; 
  OrderedQ[{nodevalue[tree], elem}] := {leftsubtree[tree], 
  nodevalue[tree], treeInsert[rightsubtree[tree], elem]}
treeInsert[tree_, elem_] := {treeInsert[leftsubtree[tree], elem], 
  nodevalue[tree], rightsubtree[tree]}

"
programming - Developing domain specific languages and computational knowledge engines using Mathematica,"
Some generalities
I'd first like to discuss some ideas behind DSLs, and why they are useful, and then give a few pointers to some specific examples. The main idea of a DSL (at least the way I understand it) is that, for a given domain, there may be a number of primitive operations, such that all or most other desired operations can be expressed as some combinations of these. The main difference between a DSL and a simple API approach is that in DSL, you can nest these operations, and combine them in non-trivial ways. Some typical ingredients of DSL construction may involve

Parsing and creating an AST (Abstract Syntax Tree) of your code. This part may or may not be present, since in Mathematica we more or less program already in parse trees (Mathematica expressions). One desired property for a parse tree is that it (and heads out of which it is built) is completely inert, so that no piece of it evaluates. For example, in the SymbolicC case, the heads constructing the Symbolic C expressions are completely inert. This is not an absolute requirement, since you may have other means to prevent evaluation, but, at least in my experience, it is often quite hard to control evaluation when some heads in the parse tree are allowed to evaluate.  I can see two kinds of situations when creating a separate parse tree (with different heads) may be needed:

The original expression (code) of the DSL can evaluate, and it is this evaluation which actually constructs the parse tree. This may be advantageous, since the original DSL code may be (much) more compact than the resulting AST.
The original DSL code is expressed in the ""wrong degrees of freedom"", which is, the operations natural for the end user of a DSL have a non-trivial mapping to the primitives, in which it is most natural to implement the desired operations. 

For the (mentioned below) code formatter example, both of the above points were true.
Actual implementation of a DSL. This involves implementing the actual interactions between your DSL primitives. If your DSL will be interpreted, this is an interpreter which would execute your AST, if it will be compiled, this will be a code generator which would generate Mathematica code from your AST. Either way, this is a necessary step, which forms the essence of your DSL and defines composition of elements (language primitives).
Frequent use of recursion. Recursion is natural in this setting, because it reflects the nested nature of programs, and composition of primitive operations. I would even consider its presence necessary for a DSL to be non-trivial. To give a few examples, CCodeGenerate function from SymbolicC is deeply recursive, and also in the code formatter  (mentioned below), all stages of the formatter heavily use recursion. Recursion is also central in the (also mentioned below) example from the book of Wellin et al.

Specific examples
SymbolicC and DatabaseLink are two examples of Mathematica DSLs which map Mathematica expressions to C code and SQL queries respectively. You can read their source code, it is quite instructive. In some sense, JLink can also be considered a DSL. Also in some sense, the new Statistics-related functionality forms a DSL. For more simple examples, you can look at my code formatter, which implements a simple but non-trivial formatting DSL (although I did not perform the refactoring which would make this totally apparent). Another good example is a simple graphic DSL developed in ""Introduction to programming with Mathematica"" by Wellin, Gaylord and Kamin (for the purposes of a pure Mathematica DSL, you can skip the parsing stage, or, more precisely, skip the lexical analysis, replacing their custom syntax with Mathematica expression-based syntax). This may actually be the easiest example to start with. 
Other ways to implement DSLs
One can take a less formal route, and implement DSL-s through code-generation, achieved by writing macros. I mentioned macros in my  answer on metaprogramming, and also mentioned the complications which currently accompany writing macros in Mathematica. Perhaps, the largest one is that there are no true compile and macro-expansion stages, since Mathematica is interpreted. But it should be possible to write a framework, which would introduce these, and then use it. The advantage of this method is that you can figure out your DSL's details as you go, just by eliminating boilerplate code as you see it. This may be a big advantage when you find it hard to formally specify your DSL, either because you are still learning the domain, or because it is not a priori clear what would make a good set of primitives in your DSL.
"
dynamic - Mathematica as a report generator,"
In addition to @Rojo's here's a more detailed explanation:
total = Dynamic[x + y]

Define the variable total that dynamically sums x and y
x = 10;
y = 5;

Now create a text cell by right clicking on the cell bracket at the right and choose style Text. I Type:
When I count the value x plus y I get: total

Now double click on total and right click and choose Create Inline Cell.
A background color will appear on the word total. Now double click again again on the word total , right click, and choose Evaluate in Place.
The TEXT cell now changed to:
When I count the value x plus y I get: 15

Every time x or y changes your text cell adjust the correct value
"
evaluation - Numbers in alternate bases transcend the evaluator?,"
To understand what's happening, the difference between evaluation and parsing needs to be made clear:

parsing means taking the string (the text) input to Mathematica and converting it to some internal representation of a Mathematica expression
evaluation means taking a Mathematica expression and transforming it according to some rules the evaluator knows about

The string 16^^abcdef gets directly parsed into an Integer.  11259375 gets parsed to the very same integer.  The way Mathematica stores integers internally does not include the base in which the number was originally.  16^^abcdef and  11259375  are two ways to write the exact same Mathematica expression.
The information about the base is lost at parse time, the evaluator never sees it.

If you read 16^abcdef as input interactively or from a file, you need to make sure you read it as a string (e.g. InputString) and avoid parsing it into a Mathematica expression. Then you can analyse the string an find out what is the base.
"
dynamic - Safely generating multiple controls from a list of variables,"
The best way may be to avoid such constructs, but, if you insist on using a list of variables like that, here is one way:
Thread[Hold[vars] /. OwnValues[vars]] /. Hold[v_] :> Slider[Dynamic[v], {0, 1}]

You can store variables wrapped in Hold rather than List, in which case the first step (involving OwnValues) can be skipped.
"
Assignment rule to distribute matrix-multiplication over custom notation,"
Unfortunately, this is not possible directly, at least as far as I know. The error message you are getting is just a manifestation of it. You are using UpValues, which have a fundamental limitation that they can only be attached to symbols on a level no deeper than 1. I discussed this more in my answer to this question.
Redefining built-in functions, OTOH, especially such fundamental ones as Plus, Times and Dot, is a bad idea most of the time. What you can do, is to create a lexical environment, where they will be replaced by some functions myPlus, myTimes, and myDot:
ClearAll[env];
SetAttributes[env,HoldAll];
env[code_]:= 
 With[{rules = {Times->myTimes,Plus->myPlus,dot->myDot}},
  Unevaluated[code]/.rules/.Reverse[rules,{2}]
 ] 

Now, for example, you can define (note that in the first definition, s comes with a blank _, which you missed):
ClearAll[myDot];
myDot[M_, myTimes[a_, Ket[s_]]] := 
   myTimes[a, VecToKet[myDot[M, KetToVec[Ket[s]]]]];
myDot[M_, myPlus[args__]] := 
   myPlus @@ Map[myDot[M, #] &, {args}];

And you use this as
env[X.(a*Ket[s])]


a VecToKet[X.KetToVec[Ket[s]]]

and also
env[X.(a*Ket[s1] + b*Ket[s2])]


a VecToKet[X.KetToVec[Ket[s1]]] + b VecToKet[X.KetToVec[Ket[s2]]]

The function env serves as a custom evaluator here. The disadvantage of this approach is that you will generally have to insert env everywhere in your code, because env binds lexically rather than dynamically. But as long as the operation of Times, Plus and Dot on your objects is simply undefined (which would be so for general symbolic objects), you may avoid this problem by replacing the simple implementation above with a more complex infinite-evaluation one:
ClearAll[env];
SetAttributes[env, HoldAll];
env[code_] :=
  With[{result = 
      With[{rules = {Times -> myTimes, Plus -> myPlus, Dot -> myDot}},
         Unevaluated[code] /. rules /. Reverse[rules, {2}]
      ]},
     env[result] /; result =!= Unevaluated[code]
  ]; 
env[code_] := code; 

which should also cover composition.
Finally, you can, if you wish, use $Pre to avoid typing env every time you compute things interactively: $Pre = env;
"
numerics - Solving a Volterra integral equation numerically,"
Mathematica is an incredible tool for checking conjectures and making sketches. I'm going to demonstrate it below.
Let's start with checking that in case when $R_0$ (I replaced it with $R$) is a polynomial, the solution of this Volterra equation reduces to linear ODE. Lets take some derivatives of the equation:
ClearAll[P, R, s, t];
eqn = P[t] == R[t] + Integrate[P[s] R[t - s], {s, 0, t}]
Table[D[eqn, {t, n}], {n, 0, 2}] // TableForm


We see that this process is somehow similar to integration by parts. If $R^{(n)}$ is zero here, we get an ODE. Let's check it out.
R = 1 + 2 #^2 &;
deg = Exponent[R[t], t];
Table[D[eqn, {t, n}], {n, 0, deg + 1}] // TableForm


The required initial conditions are obtained using intermediate derivatives:
iconds = Table[D[eqn, {t, n}] /. t -> 0, {n, 0, deg}];
TableForm[ndeqs = {D[eqn, {t, deg + 1}]}~Join~iconds]


Now we can solve this either numerically or symbolically: 
dsol = DSolve[ndeqs, P, t][[1, 1]]
ndsol = NDSolve[ndeqs, P, {t, 0, 1}][[1, 1]]
GraphicsRow[Plot[P[t] /. #, {t, 0, 1}, PlotRange -> All] & /@ {dsol, ndsol}]


Verifying that the symbolic solution is exact:
eqn /. dsol // Simplify
(* ==> True *)


Now, if kernel is not polynomial we can just interpolate it taking Chebyshev points of second kind for higher accuracy:
RR = Exp[-#] + #*Sin[#] - #*Cos[#^2] &;
deg = 9;
nodes = Table[(1 + Cos[(j \[Pi])/deg])/2, {j, 0, deg}] // N;
R = Evaluate[InterpolatingPolynomial[Transpose@{nodes, RR /@ nodes}, #]] &;
Plot[{RR[t] - R[t]}, {t, 0, 1}, PlotStyle -> Thickness[Large]]


As we see the error is rather small. Here I took kernel from Daniel Lichtbau's answer. Now we can reuse the above code and obtain the following plot of approximate solution:

This perfectly agrees with Daniel's results. Thank you.
"
plotting - Is there a simple way to plot complex numbers satisfying a given criteria,"
Use ContourPlot for equalities:
ContourPlot[
    Evaluate[z + Conjugate[z] == Abs[z]^2 /. z -> x + I y],
    {x, -2, 2},
    {y, -2, 2},
    FrameLabel -> Automatic
]




"
export - How to set PageWidth when using PutAppend to append expressions to a file?,"
I believe you should use streams:
stream = OpenWrite[""wraptest.m"", PageWidth -> Infinity];

Do[PutAppend[Table[i, {RandomInteger[100]}], stream], {i, 100}]

You can also use Write in place of PutAppend:
 Do[stream ~Write~ Table[i, {RandomInteger[100]}], {i, 100}]

Be sure to Close your stream when you are done:
Close[stream];

"
dynamic - Rounding problems inside InputField,"
This seems to work for me, is it what you need?
InputField[Dynamic[h2, If[NumericQ[#], h2 = Round[#, 0.001], h2 = h2] &]]

"
function construction - Generating date ranges,"
Perhaps this way:
Table[DatePlus[{2012, 4, 24}, 28*i], {i, 1, 40}]


{{2012, 5, 22}, {2012, 6, 19}, {2012, 7, 17}, {2012, 8, 14}, {2012, 9,
         11}, {2012, 10, 9}, {2012, 11, 6}, {2012, 12, 4}, {2013, 1, 
        1}, {2013, 1, 29}, {2013, 2, 26}, {2013, 3, 26}, {2013, 4, 
        23}, {2013, 5, 21}, {2013, 6, 18}, {2013, 7, 16}, {2013, 8, 
        13}, {2013, 9, 10}, {2013, 10, 8}, {2013, 11, 5}, {2013, 12, 
        3}, {2013, 12, 31}, {2014, 1, 28}, {2014, 2, 25}, {2014, 3, 
        25}, {2014, 4, 22}, {2014, 5, 20}, {2014, 6, 17}, {2014, 7, 
        15}, {2014, 8, 12}, {2014, 9, 9}, {2014, 10, 7}, {2014, 11, 
        4}, {2014, 12, 2}, {2014, 12, 30}, {2015, 1, 27}, {2015, 2, 
        24}, {2015, 3, 24}, {2015, 4, 21}, {2015, 5, 19}}

Of course you might want to finetune the number of 28-day intervals.
"
plotting - Plot CSV-data; make statistical statements in Mathematica / WA,"
If your data is Imported say in data then you can use data[[All,{1,2}]] to use the first column as x and the second as y value. Plotting all three data sets would be
ListPlot[{data[[All, {1, 2}]], data[[All, {1, 3}]], data[[All, {1, 4}]]}] 

If you want to print against row index, like in yopur figure you can use
ListPlot[{data[[All, 2]], data[[All, 3]], data[[All, 4]]}, Frame -> True,
  PlotRange -> {0, 1000}, FrameLabel -> {""row index"", None}]

Edit:
To make sure that you import the data correctly you have to enforce ""CSV"" format. Using the ""Table"" format will give you the following data:
data // FullForm


   List[List[""0.005,116,148,32""],List[""0.005,352,30,322""],List[""0.005,249,49,200""],List[""0.005,23,336,313""],List[""0.0051,130,89,41""],List[""0.0051,363,46,317""]]


As you see each line is interpreted as String. Use 
data = Import[""data.csv"", ""CSV"", ""HeaderLines"" -> 1]

instead.  Now
data // FullForm

correctly gives a list of numerical list elements and the above ListPlot works.

List[List[0.005`,116,148,32],List[0.005`,352,30,322],List[0.005`,249,49,200],List[0.005`,23,336,313],List[0.0051`,130,89,41],List[0.0051`,363,46,317]]


"
equation solving - Can Reduce *really* not solve for x here?,"
Use
Reduce[(1/x) Cosh[x/2] == Sqrt[2], x, Reals]

or 
Solve[(1/x) Cosh[x/2] == Sqrt[2], x, Reals]

the latter yields
{{x -> Root[{-E^(-(#1/2)) - E^(#1/2) + 2 Sqrt[2] #1 &,      0.75858229952537718426}]}, 
 {x ->  Root[{-E^(-(#1/2)) - E^(#1/2) + 2 Sqrt[2] #1 &, 5.4693513860610533998}]}}

For transcendental equations you may get with Reduce or Solve roots  represented symbolically by Root though  they are in general transcendental numbers, so their  values are written numerically beside the transcendental function written in the form of a pure function.
Plot[ (1/x) Cosh[x/2] - Sqrt[2], {x, -7, 7}, PlotStyle -> Thick, PlotRange -> {-4, 4}]


Edit
It should be emphasized that using domain specifications in Reduce or Solve you may still get messages of unsolvability of a given equation or a system (of eqations or/and inequalities), e.g.
Reduce[ x Cos[x/2] == Sqrt[2], x, Reals]


Reduce::nsmet: This system cannot be solved with the methods available to Reduce. >>
Reduce[x Cos[x/2] == Sqrt[2], x, Reals]


even though for a slightly different equation you can get the full solution, e.g. 
Reduce[x Cos[x/2] == 0, x, Reals]


In these two cases there is an infinite number of solutions, but the latter case is much easier, because a solution satisfies one of the two conditions : x == 0 or  Cos[x/2] == 0. In the first case we need to restrict a region where we'd like to find solutions. There we find all of them with Reduce (as well as with Solve) if in a given region there is only  a finite number of solutions, e.g. restricting the domain to real numbers such, that -25 <= x <= 25 i.e. adding a condition -25 <= x <= 25 to a given equation (now we needn't specify explicitly the domain to be Reals because Reduce[expr,vars] assumes by default that quantities appearing algebraically in inequalities are real):
sols = Reduce[x Cos[x/2] == Sqrt[2] && -25 <= x <= 25, x]


Defining 
f[x_] := x Cos[x/2] - Sqrt[2]

we can easily check that sols are indeed the solutions :
FullSimplify[ f[ sols[[#, 2]]]] & /@ Range @ Length[sols]


{0, 0, 0, 0, 0, 0, 0}


To extract only numerical values of the roots combined with zero we can do (see e.g. this answer):
Tuples[{List @@ sols[[All, 2, 1, 2]], {0}}]

Now we can plot the function with appropriately marked roots and the specified domain :
Plot[ f[x], {x, -40, 40}, PlotStyle -> Thick, 
             Epilog -> {Thickness[0.003], Darker@Red, Line[{{-25, 0}, {25, 0}}], 
                        PointSize[0.01], Cyan, Point /@ Tuples[{List @@ sols[[All, 2, 1, 2]], {0}}]}]


Here the dark red line denotes the domain of our interest, and the cyan points denote 
all roots of the function f in this region.
"
How to set different labelstyles for controls in manipulate?,"
You can use Style for the labels:
Manipulate[{jj, kk},
 {{jj, 2, Style[""Select j"", Bold, Larger]}, 1, 11},
 {{kk, 2, ""Select k""}, 1, 11}]

"
performance tuning - Shaving the last 50 ms off NMinimize,"
As promised in the comments on my first answer, here is an implementation of an all-compiled-code Nelder-Mead minimizer, which hopefully represents a more useful response to the question. The algorithm used here corresponds to that given by Lagarias et al. in SIAM J. Optim. 9 (1), 112 (1998) (abridged .pdf). It is compatible with Mathematica versions 6, 7, 8, and 9, but not 5.2 or any previous version. This is not only due to the use of the new-in-6 functions OptionsPattern, FilterRules, and OptionValue, but also to apparent limitiations of the compiler--in particular, the robustness of the type inference mechanism was not entirely satisfactory prior to version 6.
The code is many times faster than NMinimize in all versions, although I would recommend using Mathematica 8 or 9 if possible. The performance of the compiled code is much better here than in versions 6 and 7, and many more functions are supported for compilation. Compilation to native code via C can also result in substantially improved performance. In fact, LibraryLink and/or the Mathematica runtime seem to have gained additional performance improvements in version 9, so this seems to be the optimal version to use as of this posting, being about 25% faster even than version 8.
A very important consideration is that, if the minimand is not compilable, performance will suffer due to calls out of compiled code to perform top-level evaluations. Indeed, these calls are so expensive that the resulting compiled function may easily be slower than the equivalent top-level code. It's also worth noting that FindMinimum possesses a very efficient implementation, so if only local optimization is needed, that function is likely to remain the best choice. For global optimization, an advantageous strategy might consist of using this package to quickly explore large parts of the parameter space (perhaps trying many different initial simplices) followed by the use of the optimized values as a starting point for FindMinimum, which will provide tight convergence to the final result.
Unlike for NMinimize, constrained optimization is not supported, because the Nelder-Mead algorithm is fundamentally an unconstrained method. For constrained problems, NMinimize performs a sort of regularization of the minimand such that the minimum of the resulting function fulfils the Karush-Kuhn-Tucker conditions, thus allowing unconstrained methods to continue be used. I may include this in a future update, but currently it is not implemented. Another difference relative to NMinimize is the convergence criterion: the one used here can more easily distinguish slow convergence from the minimizer having stalled without finding a minimum, which is useful for poorly behaved minimands. Instead of PrecisionGoal/AccuracyGoal, one specifies a tolerance, ""ConvergenceTolerance"", for the minimum allowed change in the average function value (sampled at the vertices of the simplex) within a given number of iterations. The default settings typically result in tighter convergence than NMinimize achieves, while still terminating the optimization if it genuinely does not converge.
This latest update contains several fixes and improvements:

Option handling for NelderMeadMinimize has been fixed--options given for this function were incorrectly being overridden by those of NelderMeadMinimize`Dump`CompiledNelderMead in previous versions, which would have been confusing to the user.
It is now possible to refer to NelderMeadMinimize`Private`dimension in options. This value represents the dimension of the problem and allows one to specify this parameter in an abstract way. An application of this will be demonstrated below.
The interpretation of values given for the ""InitialPoints"" option has been improved.
Diagnostics in NelderMeadMinimize`Dump`CompiledNelderMead can now be enabled for any return type. When disabled (as by default), the operation counts will no longer be maintained and no reference to them will appear in the compiled code. When enabled, these values will be given along with their descriptions in NelderMeadMinimize`Dump`OperationCounts on return.
The code has undergone some general clean-up and should be easier to read as a result.
An additional test function, the rotated (nonseparable) hyperellipsoid, has been provided. The rotation should not present much of a hindrance for the Nelder-Mead algorithm, but this is not necessarily the case for other approaches, particularly when scaled to hundreds of dimensions, whereupon e.g. differential evolution begins to encounter difficulties with it. This function is therefore useful for comparative purposes.

The package can no longer be presented in a code block in this post because it is too long, so please download it from its GitHub repository here.
Because the question involves performing a large number of similar minimizations, and in order to avoid expensive calls out of compiled code, I decided to inline the minimand into the Nelder-Mead algorithm itself. For each function minimized with a given set of options, compiled code is generated on the first call and memoized in order to amortize the compilation overhead over subsequent calls. The minimization can be run again with a different starting simplex (or some other set of initial points, specified via the ""InitialPoints"" option), or with different settings for ""RandomSeed"", ""ConvergenceTolerance"", or MaxIterations without re-compilation. Changing any other parameters or options will result in a new minimizer being generated.
To further reduce overheads, very little error checking is done. In fact, only the forms of some of the arguments are verified. As a result, if incorrect parameters or options are specified, the resulting errors will be returned to the top level.
For testing, I've included a few simple problems: the n-dimensional shifted hyperellipsoid function and its rotated counterpart (Schwefel's problem 1.2) and the n-dimensional generalized Rosenbrock's function. Contrary to common belief, the latter is not a unimodal function for all n: as shown by Yun-Wei Shang and Yu-Huang Qiu in Evol. Comp. 14 (1), 119-126 (2006) (link), there are actually two minima for n $\ge$ 4, and the Nelder-Mead algorithm (which is not strictly a global optimization algorithm) might converge to either of them. While these problems are not very difficult, I think they serve well enough for expository purposes. So, let's test the code. First, a simple usage example:
NelderMeadMinimize[x^2 + y^2, {x, y}]

(* or, equivalently, *)
NelderMeadMinimize[Function[{x, y}, x^2 + y^2], {x, y}]

(* or even: *)
With[{cf = Compile[{{x, _Real, 0}, {y, _Real, 0}}, x^2 + y^2]},
 NelderMeadMinimize[cf, {x, y}]
]

(* -> {4.53016*10^-20, {x -> 1.90885*10^-10, y -> 9.41508*10^-11}} *)

(Note that when the minimand is passed as a pure or compiled function, the names of the variables are not actually important; they can be anything, as we demonstrate below. Note also that NelderMeadMinimize has HoldAll--although this can safely be removed if you prefer consistency with NMinimize to the convenience of not having to Block your variables.)
Now, a performance comparison:
(* Generate some variables *)
vars = Block[{x}, Unique[ConstantArray[x, 10], Temporary]];

(* First let's try NMinimize: *)
NMinimize[
  NelderMeadMinimize`Dump`Hyperellipsoid @@ vars, vars, 
  Method -> {""NelderMead"", ""PostProcess"" -> False}, MaxIterations -> 10000
 ] // Timing

(* -> {0.515625, {8.34607*10^-9, {
                  x$405 -> 0.999988, x$406 -> 1.000010, x$407 -> 1.,
              x$408 -> 1.000030, x$409 -> 0.999995, x$410 -> 1.00001,
                  x$411 -> 0.999999, x$412 -> 1.000020, x$413 -> 1.00001,
              x$414 -> 1.00001}}} *)

(* Now NelderMeadMinimize: *)
NelderMeadMinimize[
 NelderMeadMinimize`Dump`Hyperellipsoid, Evaluate[vars],
 CompilationTarget -> ""C""
] // Timing

(* -> {0.391375, {1.73652*10^-16, {
                  x$405 -> 1., x$406 -> 1., x$407 -> 1., x$408 -> 1.,
                  x$409 -> 1., x$410 -> 1., x$411 -> 1., x$412 -> 1.,
                  x$413 -> 1., x$414 -> 1.}}} *)

We've achieved much better convergence, somewhat faster than NMinimize. But this includes the time taken for compilation to C! Trying again now that the minimizer has already been generated reveals that almost all of the above timing is in fact due to the compilation step:
Do[
 NelderMeadMinimize[
  NelderMeadMinimize`Dump`Hyperellipsoid, Evaluate[vars],
  CompilationTarget -> ""C""
 ], {100}
] // Timing

(* -> {1.296875, Null} *)

On the second and subsequent minimizations, we beat NMinimize by a factor of around 40, despite a tighter convergence tolerance. Let's now even the odds, as it's well known that the Nelder-Mead algorithm is quite slow to converge to very tight tolerances:
Do[
 NelderMeadMinimize[
  NelderMeadMinimize`Dump`Hyperellipsoid, Evaluate[vars],
  ""ConvergenceTolerance"" -> 10^-9,
  CompilationTarget -> ""C""
 ], {100}
] // Timing

(* -> {0.953125, Null} *)

That's a better than 50-fold improvement over NMinimize in a more or less fair test, with each minimization of this 10-dimensional function taking under 10 ms. It may be of interest in some cases to record the number of function evaluations and the types of steps taken by the Nelder-Mead algorithm. If so, we may set the option ""Diagnostics"" -> True: after re-running the optimization we then find the relevant information recorded in the value of NelderMeadMinimize`Dump`OperationCounts:
NelderMeadMinimize`Dump`OperationCounts
(* {""Function evaluations"" -> 2441,
    ""Reflections"" -> 1289, ""Expansions"" -> 80,
    ""Contractions"" -> 347, ""Shrinkages"" -> 0} *)

If absolutely minimum overhead is required, the compiled minimizer can be called directly, with the requirements that the minimand is given as a Function or CompiledFunction and the starting simplex is fully specified (taking the form of an array of real numbers having dimensions {d + 1, d}, where d is the dimension of the problem). Also, to specify MaxIterations -> Infinity, the third parameter should be a negative integer. This works as follows:
Do[
 NelderMeadMinimize`Dump`CompiledNelderMead[
  NelderMeadMinimize`Dump`Hyperellipsoid, vars,
  CompilationTarget -> ""C""
 ][RandomReal[{0, 1}, {Length[vars] + 1, Length[vars]}], 10^-9, -1],
 {100}
] // Timing

(* -> {0.734375, Null} *)

This was a bit more work, but we have now achieved a 70-fold improvement over NMinimize. However, it should be noted that timings are generally much more sensitive to the initial simplex (and thus the number of iterations performed before convergence) than to the method in which the code is called. Working with the compiled minimizer directly is therefore perhaps better thought of as a means to incorporate it as a building block into other code (as shown below, where many minimizations are performed in parallel) than a means of achieving higher performance in its own right.
Now, we try to minimize the 50-dimensional Rosenbrock's function, even though the performance of the Nelder-Mead algorithm is usually worse (both slower and less reliable) than other methods (e.g. Storn-Price differential evolution) for high-dimensional minimization:
vars = Block[{x}, Unique[ConstantArray[x, 50], Temporary]];

NelderMeadMinimize[
 NelderMeadMinimize`Dump`Rosenbrock, Evaluate[vars],
 ""RandomSeed"" -> 10, CompilationTarget -> ""C""
] // Timing

(* -> {24.109375, {2.44425*10^-15, {
                   x$567 -> 1., x$568 -> 1., x$569 -> 1., x$570 -> 1., x$571 -> 1.,
               x$572 -> 1., x$573 -> 1., x$574 -> 1., x$575 -> 1., x$576 -> 1.,
                   x$577 -> 1., x$578 -> 1., x$579 -> 1., x$580 -> 1., x$581 -> 1.,
               x$582 -> 1., x$583 -> 1., x$584 -> 1., x$585 -> 1., x$586 -> 1.,
                   x$587 -> 1., x$588 -> 1., x$589 -> 1., x$590 -> 1., x$591 -> 1.,
               x$592 -> 1., x$593 -> 1., x$594 -> 1., x$595 -> 1., x$596 -> 1.,
                   x$597 -> 1., x$598 -> 1., x$599 -> 1., x$600 -> 1., x$601 -> 1.,
               x$602 -> 1., x$603 -> 1., x$604 -> 1., x$605 -> 1., x$606 -> 1.,
                   x$607 -> 1., x$608 -> 1., x$609 -> 1., x$610 -> 1., x$611 -> 1.,
               x$612 -> 1., x$613 -> 1., x$614 -> 1., x$615 -> 1., x$616 -> 1.}}} *)

We found the minimum in a reasonable time, although it required a non-default random seed to do so. As a performance comparison, a differential evolution minimizer I wrote in Python can minimize this function in about 21 seconds, which is certainly better considering that Python is interpreted while the result shown here is after compilation to C. However, this is still a huge improvement over NMinimize, which cannot detect convergence properly in this case, taking over 7 times as long trying (and ultimately failing) to find the minimum. In fact, we can do better if we employ the modified (""adaptive"") scale parameters proposed by Fuchang Gao and Lixing Han in Comput. Optim. Appl. 51 (1), 259-277 (2012) (.pdf available from Gao's website):
With[{dim := NelderMeadMinimize`Private`dimension},
 NelderMeadMinimize[
   NelderMeadMinimize`Dump`Rosenbrock, Evaluate[vars],
   ""ReflectRatio"" -> 1, ""ExpandRatio"" :> 1 + 2/dim,
   ""ContractRatio"" :> 3/4 - 1/(2 dim), ""ShrinkRatio"" :> 1 - 1/dim,
   CompilationTarget -> ""C""
  ] // Timing
]

(* -> {16.781250, {1.5829*10^-15, { identical result omitted }}} *)

As described in the paper, these parameter values improve the efficacy of the expansion and contraction steps for high-dimensional problems and help to prevent the simplex from degenerating into a hyperplane, which otherwise would lead to failure of the Nelder-Mead algorithm. Convergence is thus achieved more reliably, to tighter tolerances, and without having to adjust the random seed. What is not so clear from this example is that, in favorable cases, the performance improvements can also be very dramatic: for the 35-dimensional hyperellipsoid function, for instance, the modified parameters yield a tenfold reduction in execution timing versus the classical values. I would thus strongly recommend at least trying the modified settings for larger problems, hence the incorporation of the symbol NelderMeadMinimize`Private`dimension to represent the problem dimension when doing so.
Edit: response to Ajasja's edits
Re-compilation of the minimizer on every call for a CompiledFunction objective function was a result of my inadequate testing of this case, so thanks go to Ajasja for noticing and reporting this issue, as well as the bug in handling specified initial points. Until it was pointed out to me by Leonid, I had somehow managed to overlook the fact that CompiledFunctions contain (in their second argument) patterns specifying the types of the arguments they accept. Pattern matching a CompiledFunction against itself will therefore not produce a match unless Verbatim is used to wrap the CompiledFunction being treated as the pattern, and memoization of function values similarly will not work where a CompiledFunction appears in an argument unless Verbatim is used in defining the applicable DownValue. This issue has now been fixed and compiled objective functions will be properly memoized by the updated version (both posted code and downloadable files) above.
The second point regards the question of how to incorporate parameters in the objective function other than the values actually being minimized. In fact this was possible without any additional modifications right from the first posted version of the code, although I didn't make this explicit or specify how it can be done. I hope to rectify this omission now, alongside describing how to obtain the best performance from this approach.
Let's take an example related to the scenario described in the question: namely, fitting a model to data. Here we will perform least-squares fitting of a cubic polynomial, i.e. the minimand is,
Norm[data - (a + b x + c x^2 + d x^3)]

with data (ordinate values only) and x (abscissae) given, and a, b, c, and d being the values under optimization. (In principle, using the monomials as basis functions is less than ideal because of its numerical instability, which combines poorly with the Nelder-Mead algorithm's tendency to get trapped in local minima. Practically speaking, it works well enough as an example.) This can be given to NelderMeadMinimize essentially directly:
fitter = Block[{data = #},
  NelderMeadMinimize[
   Block[{x = Range@Length[data]}, Norm[data - (a + b x + c x^2 + d x^3)]],
   {a, b, c, d}
  ]
 ] &

The point to note here is that data appears lexically in the minimand, but not as a variable as far as NelderMeadMinimize is concerned. The first time this is called with actual data, compiled code will be generated that is a closure over the non-localized symbol data; where data is referenced, code is generated for a call into the main evaluator to retrieve its value. (The Block inside the minimand isn't relevant to this; it simply generates abscissae suitable for the given data and will be compiled completely since x is localized.) As it's the symbol data that appears inside the minimand and not actual data, compilation occurs only once rather than for every dataset fitted.
We try it:
datasets = Accumulate /@ RandomReal[{-1, 1}, {5, 100}];
fits = fitter /@ datasets;
fittedmodels = a + b x + c x^2 + d x^3 /. fits[[All, 2]];

Show[
 { Plot[fittedmodels, {x, 1, Last@Dimensions[datasets]}],
   ListLinePlot[datasets] }, PlotRange -> All
]

Giving:

which seems like it was reasonably successful. So, this is a fine proof of principle, but quite slow ($\approx$ 100 ms/fit) due to the expensive call out of compiled code on every objective function evaluation. Obviously, we can do much better.
Since the aim is to completely eliminate calls into the main evaluator while fitting an arbitrary number of datasets, the new option ""ReturnValues"" of NelderMeadMinimize`Dump`CompiledNelderMead will come in useful. This enables compiled minimizers to be generated that produce any of several different return values, facilitating their use as building blocks in other compiled code. The possible option values are:

""OptimizedParameters"": return a list of the values of the variables that minimize the objective function.
""AugmentedOptimizedParameters"": as for ""OptimizedParameters"", but with the corresponding (minimal) value of the objective function prepended.
""Simplex"": like ""OptimizedParameters"", but now returning a list of all d + 1 points of the final simplex obtained by the Nelder-Mead algorithm.
""AugmentedSimplex"": as for ""Simplex"", but with each point having the corresponding value of the objective function prepended to it.

It seems to me that ""ReturnValues"" -> ""OptimizedParameters"" is the most suitable for the present application, so let's proceed as such. We now turn to the question of the parameter value accesses.
As Leonid has noted here, if compiled closures are inlined (using CompilationOptions -> {""InlineCompiledFunctions"" -> True}) into other compiled code containing the values they close over, calls to the main evaluator can be eliminated entirely:
With[{
   minimizer = NelderMeadMinimize`Dump`CompiledNelderMead[
     Function[{a, b, c, d},
      Block[{x = Range@Length[data]}, Norm[data - (a + b x + c x^2 + d x^3)]]
     ], {a, b, c, d}, ""ReturnValues"" -> ""OptimizedParameters""
    ],
   epsilon = $MachineEpsilon
  },
  serialFitter = Compile[{{datasets, _Real, 2}},
    Table[minimizer[RandomReal[{0, 1}, {4 + 1, 4}], epsilon, -1], {data, datasets}],
    CompilationOptions -> {""InlineCompiledFunctions"" -> True},
    RuntimeOptions -> {""Speed"", ""EvaluateSymbolically"" -> False}, 
    CompilationTarget -> ""C""
   ];
  parallelFitter = Compile[{{data, _Real, 1}},
    minimizer[RandomReal[{0, 1}, {4 + 1, 4}], epsilon, -1],
    CompilationOptions -> {""InlineCompiledFunctions"" -> True},
    RuntimeOptions -> {""Speed"", ""EvaluateSymbolically"" -> False}, 
    CompilationTarget -> ""C"",
    Parallelization -> True, RuntimeAttributes -> {Listable}
   ];
 ];

Here the same minimand as used above is enclosed in a Function to make it suitable for NelderMeadMinimize`Dump`CompiledNelderMead, which is then called with this objective function and the option ""ReturnValues"" -> ""OptimizedParameters"" to generate a compiled minimizer that can be used from within other compiled code. Two callers are defined: serialFitter simply loops over each dataset given in its argument, while parallelFitter is Listable and automatically parallelizes over multiple datasets. Let's check them:
Block[{x = Range[50]},
 Round@serialFitter[{3 + x - 4 x^2 + 2 x^3, -8 - 2 x + 7 x^2 - x^3}] == 
  Round@parallelFitter[{3 + x - 4 x^2 + 2 x^3, -8 - 2 x + 7 x^2 - x^3}] ==
   {{3, 1, -4, 2}, {-8, -2, 7, -1}}
]

As expected, we get True, so these can both correctly fit cubic polynomials. What about performance?
datasets = Accumulate /@ RandomReal[{-1, 1}, {1000, 100}];

serialFitter[datasets]; // Timing
(* 7.813 seconds *)

parallelFitter[datasets]; // AbsoluteTiming
(* 2.141 seconds *)

So, we have 7.8ms and 2.1ms per dataset, respectively. While these datasets, the model being fitted, and the convergence tolerances are admittedly all different to those in Ajasja's problem, that's still not too bad at all in my opinion. Furthermore, if you have a computer with support for simultaneous multithreading (SMT, e.g. Intel HT), the performance of parallelFitter can be further improved by evaluating SetSystemOptions[""ParallelOptions"" -> ""ParallelThreadNumber"" -> n] (where the value n depends on the number of logical processors available). Evidently, Mathematica's compiled code is not quite optimal, even after being translated to C and compiled to native code, since I found that this setting provided about 20% better performance on an Intel i7-2600 CPU.
"
recursion - How can I solve a difference-differential equation?,"
For the simple example in the question, FindSequenceFunction can be used to infer the general form:
g[0]=Exp[2x];
g[n_]:=g[n]=Expand[D[g[n-1],x]]

FindSequenceFunction[g/@Range[5],n]
Out[3]= 2^n E^(2 x)

"
front end - Option to change cursor/caret shape,"
Alas, MMA doesn't obey the system-wide insertion point cursor size setting in Windows 7's ""Ease of access center"". 
Instead, to find the position of your latest edit you could use the Cell > Notebook history menu which will get you a graphical overview of your edits:

Clicking on a point in the edits display brings you to the specific cell. Floating your cursor above a point gets you a tooltip with the specific cell content.Just look for the right-most point; that should be your latest edit.
"
plotting - Display position information out of ListPlots inside a Manipulate,"
You may find a suggestion or two of interest in what follows (although it's not exactly what you asked for):
list1 = NestList[3 # (1.25 - #) &, .1, 20];
list2 = NestList[3 # (1.3 - #) &, .1, 20];
list3 = NestList[3 # (1.275 - #) &, .1, 20];

Manipulate[Grid[{{
   If[lists != {}, ListLinePlot[
  Tooltip@#[[windowStart ;; windowEnd]] & /@ (lists /. {1 -> 
       list1, 2 -> list2, 3 -> list3}), ImageSize -> 350, 
  AxesLabel -> {""element"", None}, PlotMarkers -> Automatic,
  GridLines -> {{n}, None},
  GridLinesStyle -> Directive[Blue, Thickness[.007], Dashed]]],
  Grid[Prepend[(lists /. {1 -> {1, list1[[n]]}, 
     2 -> {2, list2[[n]]}, 3 -> {3, list3[[n]]}}), {""list"", 
   ""element "" <> ToString[n + windowStart - 1]}], Frame -> All]
  } }],
 {{windowStart, 1, ""start element""}, 1, windowEnd - 1, 1},
 {{windowEnd, Length[list1], ""end element""}, 2, Length[list1], 1},
 {{n, 5, ""current element""}, 1, Length[list1], 1},
 {{lists, {1}}, {1, 2, 3}, CheckboxBar}]



I superimposed the graphs to save space. There are 3 lists in the present example. Two are selected and displayed.
You can select those lists you want to compare at any given moment.
A current element slider highlights the element that you are comparing at the moment.
A table of values shows the current value for each selected list
Tooltips can be read off by mousing over the line graph markers.
windowStart has a maximum value of the current value of windowEnd


Edit: Multiple plots
Alternatively, you may include multiple plots in a pane:
list1 = NestList[3 # (1.25 - #) &, .1, 20];
list2 = NestList[3 # (1.3 - #) &, .1, 20];
list3 = NestList[3 # (1.275 - #) &, .1, 20];

Manipulate[
 Pane[
  Grid[{{
   Column[If[lists != {}, ListLinePlot[
      Tooltip@#[[2]][[windowStart ;; windowEnd]], 
      ImageSize -> {350, 200}, AxesLabel -> {""element"", None}, 
      PlotMarkers -> Automatic,
      PlotLabel -> ""List "" <> ToString[#[[1]]],
      GridLines -> {{n}, None},

      GridLinesStyle -> 
       Directive[Blue, Thickness[.007], 
        Dashed]] & /@ (lists /. {1 -> {1, list1}, 2 -> {2, list2},
        3 -> {3, list3}})
   ]],
 Grid[
  Prepend[(lists /. {1 -> {1, list1[[n]]}, 2 -> {2, list2[[n]]}, 
      3 -> {3, list3[[n + windowStart - 1]]}}), {""list"", 
    ""element "" <> ToString[n]}], Frame -> All]
 } }], {500, 450}, Scrollbars -> {False, True}],
{{windowStart, 1, ""start element""}, 1, windowEnd - 1, 1},
{{windowEnd, Length[list1], ""end element""}, 2, Length[list1], 1},
{{n, 5, ""current element""}, 1, Length[list1], 1},
{{lists, {1}}, {1, 2, 3}, CheckboxBar}]

"
plotting - How to change the default ColorData used in Mathematica's Plot?,"
Update August 2014
The Legacy Solution below has been corrected to work in recent versions (9 and 10).
At the same time however the introduction of PlotTheme functionality makes my solution largely academic as plot themes are designed to combine in the same manner.  If no existing theme has the desired style you can create a custom one.
This example demonstrates setting new default plot colors as well a custom thickness and these correctly combining with the dashing directives in PlotStyle:
System`PlotThemeDump`resolvePlotTheme[""Thick5"", ""Plot""] := 
 Themes`SetWeight[{""DefaultThickness"" -> {AbsoluteThickness[5]}}, 
  System`PlotThemeDump`$ComponentWeight]

SetOptions[Plot, PlotTheme -> {""DarkColor"", ""Thick5""}];

fns = Table[x^n, {n, 0, 5}];
dash = Table[AbsoluteDashing[i], {i, 1, 6}];

Plot[fns, {x, -1, 1}, PlotStyle -> dash]



Legacy Solution
The following updated solution is based on the existing solutions from Janus and belisarius with considerable extension and enhancement.
Supporting functions
ClearAll[toDirective, styleJoin]

toDirective[{ps__} | ps__] := 
  Flatten[Directive @@ Flatten[{#}]] & /@ {ps}

styleJoin[style_, base_] :=
  Module[{ps, n},
    ps = toDirective /@ {PlotStyle /. Options[base], style};
    ps = ps /. Automatic :> Sequence[];
    n = LCM @@ Length /@ ps;
    MapThread[Join, PadRight[#, n, #] & /@ ps]
  ]

Main function
pp is the list of Plot functions you want to affect.
sh is needed to handle pass-through plots like LogPlot, LogLinearPlot, DateListLogPlot, etc.
pp = {Plot, ListPlot, ParametricPlot, ParametricPlot3D};

Unprotect /@ pp;

(#[a__, b : OptionsPattern[]] :=
   Block[{$alsoPS = True, sh},
     sh = Cases[{b}, (""MessagesHead"" -> hd_) :> hd, {-2}, 1] /. {{z_} :> z, {} -> #};
     With[{new = styleJoin[OptionValue[PlotStyle], sh]}, #[a, PlotStyle -> new, b]]
   ] /; ! TrueQ[$alsoPS];
 DownValues[#] = RotateRight[DownValues@#]; (* fix for versions 9 and 10 *)
) & /@ pp;


Usage
Now different plot types may be individually styled as follows:
SetOptions[Plot, PlotStyle -> ColorData[3, ""ColorList""]];

Or in groups (here using pp defined above):
SetOptions[pp, PlotStyle -> ColorData[3, ""ColorList""]];


Examples
PlotStyle options are then automatically added:
fns = Table[x^n, {n, 0, 5}];
dash = Table[AbsoluteDashing[i], {i, 1, 6}];

Plot[fns, {x, -1, 1}, PlotStyle -> dash]



Plot[...] and Plot[..., PlotStyle -> Automatic] are consistent:
Plot[fns, {x, -1, 1}]
Plot[fns, {x, -1, 1}, PlotStyle -> Automatic]




Pass-through plots (those that call Plot, ListPlot or ParametricPlot) can be given their own style:
SetOptions[LogPlot, PlotStyle -> ColorData[2, ""ColorList""]];

LogPlot[{Tanh[x], Erf[x]}, {x, 1, 5}]
LogPlot[{Tanh[x], Erf[x]}, {x, 1, 5}, PlotStyle -> {{Dashed, Thick}}]




PlotStyle handling can be extended to different Plot types.
I included ParametricPlot3D above as an example:
fns = {1.16^v Cos[v](1 + Cos[u]), -1.16^v Sin[v](1 + Cos[u]), -2 1.16^v (1 + Sin[u])};

ParametricPlot3D[fns, {u, 0, 2 Pi}, {v, -15, 6},
  Mesh -> None, PlotStyle -> Opacity[0.6], PlotRange -> All, PlotPoints -> 25]



Implementation note
As it stands, resetting SetOptions[..., PlotStyle -> Automatic] will revert the colors to the original defaults.  If this behavior is undesirable, the code can be modified to give a different default color, in the manner of Janus' also function, upon which my styleJoin is clearly based.
"
parallelization - DistributeDefinitions doesn't work as expected when used for table iterator bounds?,"
The problem is that capital-K is a reserved word.
?K


K is a default generic name for a summation index in a symbolic sum.

Other single-character variables to avoid are:
C, D, E, I, N, O

Generally, you should avoid using variables that start with a capital character. It is not forbidden, but starting with a lowercase character will prevent you from colliding with built-in definitions that all start with a uppercase character.
"
plotting - Labelling ArrayPlot Charts,"
The FrameTicks should be entered in the following format: 
FrameTicks->{
    {{ytick1, yvalue1}, {ytick2, yvalue2},...}, 
    {{xtick1, xvalue1}, {xtick2, xvalue2},...}
}

So here's an example for your case that shows how to label the ticks:
xticks = Transpose[{Range@15, Range[1997, 2011]}];
yticks = Transpose[{Range@5, {""Cats"", ""Dogs"", ""Sheep"", ""Frogs"", ""Mice""}}];
ArrayPlot[RandomReal[1, {5, 15}], FrameTicks -> {yticks, xticks}]


"
"export - Does Mathematica support variable frame rate for any video format, in analogue of GIF-style ""DisplayDurations""?","
This is a solution specifically using the QTKit library in Mac OS X. I'm calling it through the built-in Python interface, using a script that could also be run as a Python module or in standalone mode. 
Since the goal here is to make a Mathematica function, I wrapped the call in a Run command inside a function exportMov. This required stuffing the Python code into a string that shows up as a single huge line in the code below (Python is sensitive to the placement of newlines and indentation, so the spaces and \n characters in the string are all intentional). I've used the same technique for calling a Python script on the fly in this answer before. 
Edit:
The Python code is posted in a more readable and re-usable form on my website. End Edit.
exportMov[name_String, frames_List, delays_: {.03}] := Module[
  {
   outFile = ExpandFileName[name],
   fileNames,
   script =""printf \""from Foundation import NSNumber\nfrom AppKit import NSImage\nfrom QTKit import *\n\nclass QuickTimeError(Exception):\n    @classmethod\n    def from_nserror(cls, nserror):\n        return cls(nserror.userInfo()['NSLocalizedDescription'])\n\ndef createQT(infiles, sequence, durations, outfile):\n    attrs = {QTAddImageCodecType: 'avc1', QTAddImageCodecQuality: NSNumber.numberWithLong_(codecHighQuality)}\n    mov, err = QTMovie.alloc().initToWritableFile_error_(outfile, None)\n    if mov is None:\n        raise QuickTimeError.from_nserror(err)\n    n = len(durations)-1\n    i = 0\n    for index in sequence:\n        img = NSImage.alloc().initWithContentsOfFile_(infiles[sequence[index]])\n        t = durations[i]\n        if i<n:\n            i = i+1\n        else:\n            i = 0\n        time = QTMakeTime(t, 600)\n        mov.addImage_forDuration_withAttributes_(img, time, attrs)\n    mov.updateMovieFile()\n\nif __name__ == '__main__':\n    import os,sys,csv,string\n\n    buildfile = 'buildFile'\n    framedata = csv.reader(open(buildfile, 'rb'), delimiter=' ')\n    imagefiles = []\n    durations = []\n    for row in framedata:\n        if os.path.exists(row[0]):\n            imagefiles.append(row[0])\n            if len(row)>1:\n                durations.append(float(row[1]))\n            else:\n                durations.append(30)\n        else:\n            print row[0]+': File not found'\n    if len(imagefiles)==0:\n        print 'No images found. Movie not created'\n    else:\n        print 'Creating movie from frames'\n        outfileName = os.path.abspath('out.mov')\n        createQT(imagefiles, range(len(durations)), durations, outfileName) \n\"" | /usr/bin/python"",
   tempDir = 
    FileNameJoin[{$TemporaryDirectory, 
      ""MathematicaOutput"" <> StringJoin[Map[ToString, DateList[]]]}]
   },
  CreateDirectory[tempDir];
  SetDirectory[tempDir];
  Export[""frame00000001.png"", frames, ""VideoFrames""];
  fileNames = FileNames[];
  Export[""buildFile"", 
   MapThread[(# <> "" "" <> ToString[#2]) &, {fileNames, 
     600 PadRight[delays, Length[fileNames], delays]}], ""Text""];
  (* Process files *)
  Run[script];
  CopyFile[""out.mov"", outFile];
  (* Cleanup: *)
  Map[DeleteFile, FileNames[]];
  ResetDirectory[];
  DeleteDirectory[tempDir]
  ]

The example movie for which I defined the frames in the question above can now be exported as follows:
exportMov[""slowDownMovie.mov"", frames, 
 Append[Range[Length[frames] - 1]/20, 2]]

The frames are first exported as single images into a temporary directory, then assembled into a movie with the name given as the first argument. 
The third argument to exportMov is the list of frame durations, and that is of course the whole point of this function. In the above example, I used the same list of durations as for the GIF animation. The list of durations is optional (when omitted, a constant default duration is used). If the list of durations is shorter than the list of frames, then the given durations are repeated cyclically until all frames are used up.
"
calculus and analysis - Incorrect results for elementary integrals when using Integrate,"
An experimental internal function Integrate`InverseIntegrate helps here, although it's intended more for integrands involving logs. This is what it returns in the development version:
Integrate`InverseIntegrate[Exp[-x Cosh[t]], {t, 0, Infinity}, Assumptions -> Re[x] > 0]
(*  BesselK[0, x]  *)

"
output formatting - How to format numbers with at least one figure after the decimal point,"
Here is an idea:
SetAttributes[myForm, Listable]
myForm[x_] := 
 If[Abs[Mod[x, 1]] <= $MachineEpsilon, NumberForm[x, {Infinity, 1}], 
  x]

"
programming - Mathematica usage (success stories) for financial back-ends,"
Here are a few pointers.
For question 1 you can find information, for example here and here. There are some user stories on that page. Other companies/products in that area (and there are many more) are for example UnRisk or RapidBusinessModeling.
Concerning point 2, yes unit testing is available via Wolfram Workbench UnitTesting. In fact most of Mathematica's unit tests are done with this. To run unit tests outside of Workbench have a look here.
Concerning point 3, a large extend of Mathematica is written in Mathematica. More that 1MLOC can be managed with WolframWorkbench, no sweat. Concerning organization, a Mathematica Package is a unit which collects functionality in it's own context (name space).
"
Unsupervised Machine Learning Algorithm for Autonomous Image Processing and Tracking,"
Here is a starting point: Intrusion detection was featured on the Wolfram blog a while back :-) Perhaps that helps.
"
graphics - Visualizing the output of a Voronoi diagram computation,"
I didn't quite follow the description of your graph, but are you aware of this functionality?:
data = MapIndexed[Flatten[{##}] &, RandomReal[1, {100, 2}]];

ListDensityPlot[
 data,
 InterpolationOrder -> 0,
 ColorFunction -> Hue,
 Mesh -> All,
 Epilog -> Point@data[[All, {1, 2}]]
]


Specifically note InterpolationOrder -> 0.
"
output formatting - GridBox/packed array behaviour,"
Seems like GridBox doesn't work well with packed arrays. Or at least not with DisplayForm
r = RandomInteger[10, {4, 4}];
Developer`PackedArrayQ[r]
rnp = Developer`FromPackedArray[r];
DisplayForm[GridBox[r]]
DisplayForm[GridBox[rnp]]

DiagonalMatrix returns a packed array
Developer`PackedArrayQ[DiagonalMatrix[{1, 2, 3, 4, 5}]]


True

So, I'd say it's a bug, but a workaround to ensure it all works fine is to wrap your variable in FromPackedArray before putting it in the GridBox
foo = DiagonalMatrix[{1, 1}];
GridBox[Developer`FromPackedArray@foo] // DisplayForm

"
plotting - Exporting a 3D plot into a 3D viewing format and axis scaling,"
The ""original scaling"" of the displayed plot in Mathematica is determined by the BoxRatios setting for the plot, so it isn't intrinsic to the surface you're trying to export. When you export the plot, only the mesh is kept, with its actual 3D coordinates and without the scaling due to BoxRatios. 
Therefore, if you want to export the surface in a ""squished"" form, you'll have to do the squishing yourself:
p = Plot3D[x^2+y^2,{x,-10,10},{y,-10,10}];
With[{zScale = .05},
 Export[""squishedPlot.wrl"", 
  p /. Graphics3D[gr_, opts___] :> 
    Graphics3D[
     GeometricTransformation[gr, ScalingTransform[{1, 1, zScale}]], 
     opts]]
 ]

I checked that this produces the desired ""aspect ratio"" by importing the file into Blender.
"
Interlacing a single number into a long list,"
Another possibility:
Thread[{1997,data1}]

"
programming - Use OptionValue to deal with nested options,"
You can actually use OptionValue to extract options of options by doing something like OptionValue[option -> subOption]. For example
Options[ff] = {""fruit"" -> {apple -> 1, pear -> 2, orange -> 3}}
ff[OptionsPattern[]] := {apple, OptionValue[""fruit"" -> apple]}

ff[""fruit"" -> {apple -> 4}]

(* ==> {apple, 4} *)

"
matrix - Bordermatrix from $ \mathrm\LaTeX $,"
This seems to work, at least for your example:
TraditionalForm @ Grid[{{Null, Grid[{{x, y}}]}, {TableForm@{{A}, {B}}, 
  MatrixForm[IdentityMatrix[2]]}}]


You can make a little function that generalises it:
makeBordermatrix[mat_?MatrixQ, top_?VectorQ, side_?VectorQ] := 
 TraditionalForm@
  Grid[{{Null, Grid[{top}]}, {TableForm[Transpose@{side}], 
     MatrixForm[mat]}}]

So we have:
makeBordermatrix[IdentityMatrix[3], {x, y, z}, {A, B, C}]


"
output formatting - Width-dependent MatrixForm,"
This is a start. 
ClearAll[DecayingMatrixForm];
Unprotect[$OutputForms];
AppendTo[$OutputForms, DecayingMatrixForm];
Protect[$OutputForms];
DecayingMatrixForm /: 
 Format[DecayingMatrixForm[mat_?MatrixQ], StandardForm] :=
 With[{m = Map[Defer, mat, {2}], mw=matrixWidth[mat]},
  Dynamic[
   If[First@CurrentValue[""WindowSize""] > mw, 
    MatrixForm[m], m]]]

Here's the raw matrixWidth function. It is very raw, feel free to edit and improve it if you like, or replace it by a cool built-in...
fsize2pixels = Interpolation[{{6, 8}, {7, 9}, {7.5`, 10}, {8, 11}, {9, 
    12}, {10, 13}, {10.5`, 14}, {11, 15}, {12, 16}, {13, 17}, {13.5`, 
    18}, {14, 19}, {14.5`, 20}, {15, 21}, {16, 22}, {17, 23}, {18, 
    24}, {20, 26}, {22, 29}, {24, 32}, {26, 35}, {27, 36}, {28, 
    37}, {29, 38}, {30, 40}, {32, 42}, {34, 45}, {36, 48}}]

matrixWidth[mat_?MatrixQ] := 
 CurrentValue[""Magnification""] With[{w = Length@First@mat, 
   chars = Max[
     StringLength /@ StringJoin /@ Map[ToString, mat, {2}]]}, 
  116 + 0.5 fsize2pixels[CurrentValue[""FontSize""]] (chars + w + 1)]

"
plotting - Just what kind of transformations can TransformedDistribution handle?,"
TransformedDistribution contains a collection of identities known to it, like that of sum of normals being equal in distribution to another normal random variable, and a general machinery to work out properties of the functions of random variables. 
Most of the time the computation will be done by the general machinery, which relies on solvers, like Expectation and Probability. Hence TransformedDistribution will be as strong as those are. 
The major strength of TransformedDistribution, in my opinion, is that it allows for easy and efficient sampling. It is generally expensive to work out other properties of the random variable from this representation.
In this particular example of $(2 Z-1) X \stackrel{d}{=} -(-1)^Z X$ the underlying solvers did not know how to handle the mixed case of discrete and continuous distribution: 
In[11]:= di = 
  TransformedDistribution[(2 z - 1) x, {z \[Distributed] 
     BernoulliDistribution[1/2], 
    x \[Distributed] ExponentialDistribution[1]}];

In[12]:= CDF[di, z]

Out[12]= CDF[
 TransformedDistribution[(-1 + 
     2 \[FormalX]1) \[FormalX]2, {\[FormalX]1 \[Distributed] 
    BernoulliDistribution[1/2], \[FormalX]2 \[Distributed] 
    ExponentialDistribution[1]}], z]

As it is often the case, one can work out the answer in an alternative way:
In[13]:= CharacteristicFunction[di, t] // Simplify

Out[13]= 1/(1 + t^2)

In[14]:= pdf = 
 InverseFourierTransform[%, t, x, FourierParameters -> {1, 1}]

Out[14]= 1/2 E^-Abs[x]

"
matrix - Non-commutative symbolic linear algebra,"
Searke hints at the answer. Remembering that the dot product is a specific form of Inner:
Inner[Times,P,Q,Plus]

We can simply replace Times wtih NonCommutativeMultiply
Inner[NonCommutativeMultiply, P, Q, Plus]

With the output:
{
 {P1 ** Q1 + P12 ** Transpose[Q12],P1 ** Q12 + P12 ** Q2}, 
 {P2 ** Transpose[Q12] + Transpose[P12] ** Q1, P2 ** Q2 + Transpose[P12] ** Q12}
}

"
graphics - How can I model composite 3D structures?,"
Indeed it's very easy. Just use Show. Here is an example:
adhock = Graphics3D[{Blue, Cylinder[], Red, Sphere[{0, 0, 2}], Black, 
    Thick, Dashed, 
    Line[{{-2, 0, 2}, {2, 0, 2}, {0, 0, 4}, {-2, 0, 2}}], Yellow, 
    Polygon[{{-3, -3, -2}, {-3, 3, -2}, {3, 3, -2}, {3, -3, -2}}], 
    Green, Opacity[.3], Cuboid[{-2, -2, -2}, {2, 2, -1}]}];


parametric = 
  ParametricPlot3D[{(3 + Cos[v]) Cos[u], (3 + Cos[v]) Sin[u], 
    Sin[v]}, {u, 0, 2 Pi}, {v, 0, 2 Pi}, 
   PlotStyle -> Specularity[White, 50], Mesh -> None];


Show[adhock, parametric]


"
intrpolation of 3D data - Mathmatica Stack Exchang,"
Mathematica's interpolation function, Interpolation, works on multidimensional data. For example,
data = Flatten[Table[{x, y, x^2 + y^2}, {x, -10, 10}, {y, -10, 10}], 1];
int = Interpolation[data];

Then, you can extract the values for values between the data points:
int[1.1, 1.1]
(* ==> 2.42 *)

And Plot3D, or whatever else you want.
Plot3D[int[x, y], {x, -10, 10}, {y, -10, 10}]


Note, that the interpolation is pretty good:
exact[x_, y_] := x^2 + y^2
int[1.1, 1.1] == exact[1.1, 1.1]
(* => True *)

Or better yet (thanks @rcollyer):
(int[1.1, 1.1] - exact[1.1, 1.1])/exact[1.1, 1.1]
(* 1.83508*10^-16 *)


Update Leonid's comment below pointed out that the accuracy of Interpolation will be worse with an unstructured grid. For example:
dataDelete = Delete[data, RandomInteger[{1, Length[data]}]]
intD = Interpolation[dataDelete]

Then,
(intD[1.1, 1.1] - exact[1.1, 1.1])/exact[1.1, 1.1]
(* ==> 0.0743802 *)

which is worse. It seems particularly bad close to the origin:
Plot3D[(intD[x, y] - exact[x, y])/ exact[x, y], {x, -10, 10}, {y, -10, 10}]


"
numerics - Numerically obtaining the inverse Laplace transform of data,"
Here is my attempt at an answer - I had to make up an example, and obviously much of what follows is dependent on details of this example. 
Edit
However, what I believe this example shows quite clearly is that a finite set of tabulated data at discrete points does not suffice to guarantee a good inverse Laplace transform, because the analytic structure of the function that interpolates between these data points is not uniquely determined by a finite number of points. You'll need additional information beyond the data table to get a correct inverse transform.
End edit
Let's start with a known function and its known Laplace transform, so we have something to compare the numerical results to:
originalFunction[t_] := t^4 Sin[t];
l[s_] := Evaluate[LaplaceTransform[originalFunction[t], t, s]];

Now I sample the Laplace transform l at discrete points to simulate the data that would be the given quantities of the problem:
data = Table[{s, l[s]}, {s, -5, 5, .1}];

The numerical inversion of this Laplace transform now can be performed by assuming a fit to the data that has a sufficiently simple functional form that allows us to do the inversion. I'll make the ansatz that we can fit the data with a rational function, leaving the degree of the numerator and denominator as parameters that may have to be adjusted by trial and error:
fit[s_] := Evaluate[
   Block[{numeratorN = 5, denominatorN = 8},
    rationalFunction = 
     Total[Array[a, numeratorN + 1] s^Range[0, numeratorN]]/
      Total[Array[b, denominatorN + 1] s^Range[0, denominatorN]];
    rationalFunction /. 
     FindFit[data, rationalFunction, 
      Join[Array[a, numeratorN + 1], Array[b, denominatorN + 1]], s]]];

This fit function looks promising if we check the plot versus the data points:
Show[ListPlot[data, PlotRange -> All], 
 Plot[fit[s], {s, -5, 5}, PlotRange -> All]]


So we might feel somewhat confident that the inversion will work as follows:
fitInverse[t_] := Evaluate[InverseLaplaceTransform[fit[s], s, t]];

Unfortunately, the result isn't too good:
Plot[{originalFunction[t], Re@fitInverse[t]}, {t, -1, 1}, 
 PlotStyle -> {Directive[Thick, Red], Directive[Blue, Dashed]}]

 
The red curve is the original function that we're trying to recover with the inverse Laplace transform. This is a problem that will be hard to avoid in practice. In my example, I can indeed make the fit work out much better by just increasing the degree of the denominator to get a faster fall-off at infinity:
fit[s_] := Evaluate[
   Block[{numeratorN = 5, denominatorN = 10},
    rationalFunction = 
     Total[Array[a, numeratorN + 1] s^Range[0, numeratorN]]/
      Total[Array[b, denominatorN + 1] s^Range[0, denominatorN]];
    rationalFunction /. 
     FindFit[data, rationalFunction, 
      Join[Array[a, numeratorN + 1], Array[b, denominatorN + 1]], s]]];
Show[ListPlot[data, PlotRange -> All], 
 Plot[fit[s], {s, -5, 5}, PlotRange -> All]]


In the plot interval chosen here, you won't see any difference in the fit, compared to the first attempt. But the small change is enough to make the inversion work:
fitInverse[t_] := Evaluate[InverseLaplaceTransform[fit[s], s, t]];
Plot[{originalFunction[t], Re@fitInverse[t]}, {t, -1, 1}, 
 PlotStyle -> {Directive[Thick, Red], Directive[Yellow, Dashed]}]


The numerical inverse and the target function lie on top of each other now. So that's how you can do it in principle: Get a good fit to the data that also has the ""correct"" asymptotic behavior (i.e., falls off in the way you expect based on the physics or other knowledge about your data). Then do the InverseLaplaceTransform on that fit and hope for the best.
"
Improved interpolation of mostly-structured 3d data,"
How to figure out where the missing grid points are... This maybe not as robust as it gets 
Take your data
data = Flatten[Table[{x, y, x^2 + y^2}, {x, -10, 10}, {y, -10, 10}], 
   1];
dataDelete = Delete[data, RandomInteger[{1, Length[data]}]];

and extract the domain coordinates
d = dataDelete[[All, ;; -2]];

Choose the step to be the commonest of the differences in each direction
step = #2@
     First@Commonest[
       Join @@ Differences /@ Sort /@ GatherBy[d, #]] & @@@ {
    {First, Last},
    {Last, First}
   };

Choose the range, the limits, to be the minimum and maximum of all rows and coloumns
limits = Through@{Min, Max}[#] & /@ Transpose@d;

Take the complement of a perfect grid and your data grid
Complement[Tuples[Range @@ Transpose@limits], d]

I got {{-3, 6}}
"
Changing color of an object in an image,"
Here's a version using Manipulate with a Locator to pick the colour to replace. There is also a tolerance control which determines how wide a range of hues to replace.
i=Import[""http://i.stack.imgur.com/Qr7Tx.jpg""];

{h,s,b}=ColorSeparate[i,""HSB""];

colourchange[c_,from_,tol_,to_]:=Module[
{offset=Mod[c-from+0.5,1]-0.5},
If[Abs[offset]>tol,c,to]];

Manipulate[
ColorCombine[
{ImageApply[colourchange[#,ImageValue[h,pos],tol,ColorConvert[to,Hue][[1]]]&,h],s,b},
""HSB""],
{{to,Blue,""Change to""},Blue},
{{tol,-0.01,""Tolerance""},-0.01,0.5},
{{pos,{100,50}},Locator}]


"
plotting - How to properly plot a response of a transfer function in Mathematica?,"
o1 isn't always real - it has a small imaginary component.  For example o1 /. t -> 4 gives 0.995493 - 5.18448*10^-7 I.  What you could do is Chop the output response:
o1 = Chop @ OutputResponse[tfm, UnitStep[t], t];

This gives you a nice smooth graph.
But on the other hand if you look at the unchopped version o1 /. t-> 8 you get 831840. + 332820. I.  Not a small imaginary component at all - so maybe chopping it wasn't a good idea.
You could also try an exact equation by replacing 43.35 with 4335/100.  This gives real results, but goes haywire when t > 5.
Unfortunately I know nothing about transfer functions to say which might be right.
"
string manipulation - print the name of the variable in a list without evaluation,"
Also
SetAttributes[f, HoldAll];
f[x_] := #[[1]] <> ""="" <> #[[2]] &@ StringSplit[ToString@Definition@x, "":=""]

"
plotting - Vertical alignment of FrameTicks Text,"
Using Pane as in Szabolcs's answer or Framed (with FrameStyle->None) with a combination of settings for BaselinePosition, ImageMargins and FrameMargins:
  Graphics[Circle[], Frame -> True, 
  FrameTicks -> {{
  {{0, Style[Pane[Style[0.4, FontSize -> 48], 
    BaselinePosition -> (Top -> Bottom), 
    FrameMargins -> {{0, 0}, {0, 40}}, 
    ImageMargins -> {{0, 0}, {0, -40}}], 
   Background -> Green]}}, 
  {{0, Style[Pane[Style[0.4, FontSize -> 48], 
    BaselinePosition -> (Bottom -> Top), 
    FrameMargins -> {{0, 0}, {40, 0}}, 
    ImageMargins -> {{0, 0}, {-40, 0}}], 
   Background -> Green]}}}, {None, None}}]

you get

"
graphics - Plotting vectors originating from the origin in 3D,"
For your problem, it is probably easiest to build the graphic out of graphics primitives rather than use a pre-made convenience function such as ListPointPlot3D.
This is one way to do it:
data = {{1, 2, 3}, {3, 4, 5}, {5, 6, 7}};

Graphics3D[Arrow[{{0, 0, 0}, #}] & /@ data]


I simply used the Arrow graphics primitive.  I constructed a pure function that makes an arrow starting from the origin, and mapped it over the data.
"
dynamic - How to control variables of outer and inner Manipulates?,"
The outer Manipulate defines a list (voteList) for tracking all votes (thus I used integer values for k), and the inner Manipulate is using the actual value of the kth vote for the definition of vote. If the inner Yes/No setter is changed, it changes vote, voteList and the number of votes as well, due to the pure controlfunction SetterBar. I also moved the initialization code to the outer Manipulate, as votes should be local to the whole thing, not just the inner Manipulate.
Manipulate[Column[{
   Manipulate[
    vote,
    {{vote, voteList[[k]]}, {True, False}, 
     SetterBar[
       Dynamic[vote, (vote = #; voteList[[k]] = #; 
          votes = Total@Boole@voteList) &], {True -> ""Yes"", 
        False -> ""No""}] &}
    ],
   (*voteList,*)
   Button[""Votes: "" <> ToString@votes, Print[votes]]
   }],
 {k, 1, 5, 1, Appearance -> ""Labeled""},
 {voteList, ControlType -> None},
 {votes, ControlType -> None},
 Initialization :> {votes = 0, voteList = Table[False, {5}]}]


Of course in this example of yours there is no need to wrap the internal vote into Manipulate, but I guess that this was just a toy example of a more complex problem. I'm not sure my solution is eaxactly the thing you are looking for, but if you provide some feedback, I can modify the code to better fit your requirements.
"
plotting - Why does Plot3D omit parts of the surface at kinks?,"
The reason for this is automatic exclusion detection:
Here the discontinuity in the derivative is ugly:
Plot3D[Max[p^2 - q^2, 0], {p, 0, 1}, {q, -1, 1}, 
 Exclusions -> None]


We can get Mathematica to auto-detect it, and compute the contours precisely, making the plot smooth around the discontinuity:
Plot3D[Max[p^2 - q^2, 0], {p, 0, 1}, {q, -1, 1}, 
 Exclusions -> Automatic]


The side effect is a gap, as you noticed.  Often one would prefer this gap to be filled with the same style as the plot.  It can be accomplished by setting ExclusionsStyle, like this:
Plot3D[Max[p^2 - q^2, 0], {p, 0, 1}, {q, -1, 1}, 
 Exclusions -> Automatic, ExclusionsStyle -> Automatic]


EDIT:  As @celtschk notes, mesh lines or contour lines are not drawn inside the excluded region.  This is very visible for large exclusions and can be prevented by forbidding exclusions with Exclusions -> None.  Then the plot can be made smoother by increasing MaxRecursion and PlotPoints.  Here's an example:
Plot3D[UnitStep[y], {x, -1, 1}, {y, -1, 1}, Exclusions -> None, MaxRecursion -> 5]


"
"graphics - Unsatisfactory view of Panel, when transformed to pdf","
You could mimic the panelled look by doing something like
panelBox[pt0 : {x0_, y0_}, 
  pt1 : {x1_, y1_}] := {{GrayLevel[.7], Rectangle[pt0, pt1]}, {White, 
   Polygon[{Offset[{.3, .3}, pt0], Offset[{2, 2}, pt0],
     Offset[{2, -2}, {x0, y1}], Offset[{-2, -2}, {x1, y1}], 
     Offset[{-.3, -.3}, {x1, y1}], Offset[{.3, -.3}, {x0, y1}]}]},
  {GrayLevel[.2], 
   Polygon[{Offset[{.3, .3}, pt0], Offset[{2, 2}, pt0],
     Offset[{-2, 2}, {x1, y0}], Offset[{-2, -2}, {x1, y1}], 
     Offset[{-.3, -.3}, {x1, y1}], Offset[{-.3, .3}, {x1, y0}]}]}}

panel[gr_] := Module[{dim},
  dim = Dimensions[Rasterize[gr][[1, 1]]][[{2, 1}]];
  Graphics[{panelBox[{-10, -10}, dim + 10], 
    Inset[gr, Center, Center, dim]}, ImageSize -> dim + 20]]

panel[Import[""ExampleData/rose.gif""]]


"
X3D Export - adding a titl - Mathmatica Stack Exchang,"
I think the answer is: No, it cannot be done using Export alone. According to the documentation, there is no meta data listed in the elements available for export, nor in the options.
To accomplish what you would like to do, however, can be done via a two step process. First, save your plot as an X3D file, and the Import it as an XML file, as follows
Export[""plot.x3d""]
plotxml = Import[""plot.x3d"", ""XML""]

Then, it is just a matter of inserting your element into the XML tree. From a brief browsing of the X3D spec, I am not sure of the specific element you need to insert you data into. Likely, though, your new element will be a MetadataString, so it should look like
mdat = XMLElement[""MetadataString"", {""name"" -> ""Title"", ""value"" -> ""MyPlot"", ...}, {}]

And, once you have found which element it belongs in, you can use 
plotxml = plotxml /. XMLElement[""ParentElement"", attrs_, data_]:>
   XMLElement[""ParentElement"", attrs_, Append[data, mdat];

It is likely that you will have to specify the attrs list to only affect the specific element you are looking for.
"
front end - How can I style text like in a system usage message?,"
The style name is PrintUsage. It is defined in the stylesheet notebook Core.nb which you can find in the directory:
$InstallationDirectory\SystemFiles\FrontEnd\StyleSheets

It has the following settings:
CellFrame -> {{0, 0}, {0, 3}}
CellFrameColor -> RGBColor[1, 0.6000000000000001, 0] 
Background -> RGBColor[1, 0.993332, 0.899718] 

You can use the OptionInspector to set DefaultNewCellStyle or DefaultReturnCreatedCellStyle to PrintUsage. You can also change these settings  at the notebook, front-end session or front-end level using
SetOptions[xx,DefaultNewCellStyle->""PrintUsage""]

where xx is EvaluationNotebook[] or $FrontEndSession, or $DefaultFrontEnd.
A third alternative is to use the right-click context menu on a cell bracket,choose Style->Other and type PrintUsage in the dialog box to change the style of that cell. 
One important issue with the above approach is that a cell with PrintUsage style is not editable. So, you may want to define your custom style using something like 
this answer by Mike Honeychurch:   
SetOptions[EvaluationNotebook[], 
   StyleDefinitions -> 
   Notebook[{Cell[StyleData[StyleDefinitions -> ""Default.nb""]], 
   Cell[StyleData[""myPrintUsageStyle""], Editable -> True, Evaluatable -> True,
   CellFrame -> {{0, 0}, {0, 3}}, CellMargins -> {{66, 10}, {10, 5}},
   CellFrameColor -> RGBColor[1, 0.6000000000000001, 0], 
   Background -> RGBColor[1, 0.993332, 0.899718]]}, 
   Saveable -> True, StyleDefinitions -> ""PrivateStylesheetFormatting.nb""]];

and use it in place of PrintUsage using any of the usage options mentioned above, e.g.,
SetOptions[EvaluationNotebook[],  DefaultNewCellStyle -> ""myPrintUsageStyle""]

"
"Custom Format for ""constructors""","
I see in your question that you would rather not use MakeBoxes but I think this might be worth a try.
Pair /: MakeBoxes[linkedList : Pair[i_, p_Pair], fmt_] := 
 TagBox[ToBoxes[LinkedList @@ Flatten[linkedList]], 
  InterpretTemplate[Pair[i, p] &], Editable -> False, 
  Selectable -> True, SelectWithContents -> True]

The InterpretTemplate affects how Mathematica will see your expression whereas the TagBox is how you will see it. 
This allows for copy and paste and any of the various forms work just fine.
"
plotting - How can I plot more than one value in the same date?,"
This will plot the date values regularly spaced apart, with the dates as rotated string labels on the x-axis, in a fashion similar to that you describe in Excel.
With[{labels = Rotate[DateString@#, (3 \[Pi])/2] & /@ dateValues[[All, 1]]}, 
 ListPlot[dateValues[[All, 2]], 
  Ticks -> {Transpose[{Range@Length@labels, labels}], Automatic},Filling->Axis]]


With a little more fiddling, it is possible to get something that tries to reflect the proper flow of the time line. Though it constrains points to have a minimum spacing between them.
(* Ease points that are close to one another apart, 
by minimum separation MinSeparation * ( Max-Min ) of data  *)

Options[Relax] = {MinSeparation -> 0.02};
Relax[data_, OptionsPattern[]] := 
 With[{sep = OptionValue@MinSeparation (Max@data - Min@data)}, 
  Flatten[{First@data, First@data + Accumulate[If[# < sep, sep, #] & /@ Differences@data]}]]

Plot the values with date labels:
With[{labels = Rotate[DateString@#, (3 \[Pi])/2] & /@ dateValues[[All, 1]], 
  softCoords = Relax[AbsoluteTime /@ dateValues[[All, 1]]]}, 
 ListPlot[{softCoords, dateValues[[All, 2]]}\[Transpose], 
  Ticks -> {{softCoords, labels}\[Transpose], Automatic}, 
  Filling -> Axis, AxesOrigin -> {First@softCoords - 10^6, 80}]]


For your revised data here is the Plotting code:
With[{labels = 
   Rotate[DateString@#, (3 \[Pi])/2] & /@ dateValues2[[All, 1]], 
  softCoords = Relax[AbsoluteTime /@ dateValues2[[All, 1]]]}, 
 ListPlot[{
 {softCoords, dateValues2[[All, 2]]}\[Transpose], 
 {softCoords, dateValues2[[All, 3]]}\[Transpose], 
 {softCoords, dateValues2[[All, 4]]}\[Transpose]}, 
  Ticks -> {{softCoords, labels}\[Transpose], Automatic}, 
  AxesOrigin -> {First@softCoords - 10^6, 0}, 
  Joined -> {False, False, True}, Filling -> {1 -> {2}}]]

Giving a plot like this:

Relax generates a set of new coordinates for the data, which have been eased apart.
These new coordinates then form the basis of the Relaxed plot constructed using ListPlot.
Each set of data associated with a date can then be fed into ListPlot as a list of {softcoordinate,value } pairs ( i.e. {AbsoluteTime, value } ). This is achieved by the idiom:
{softCoords, dateValues2[[All, 2]]}\[Transpose]
"
Adding elements to a collection of lists,"
This would be a neat way to do it:
LISTS1 = {{1, 2, 3, 4, 5}, {2, 3, 4, 5, 6}, {3, 4, 5, 6, 7}, {4, 5, 6, 7, 8}};

MapIndexed[Join[Table[0, #2], #1] &, LISTS1]


{{0, 1, 2, 3, 4, 5}, {0, 0, 2, 3, 4, 5, 6}, {0, 0, 0, 3, 4, 5, 6, 7}, {0, 0, 0, 0, 4, 5, 6, 7, 8}}

"
import - Using Differences on data: trouble with floats and doubles,"
There are many ways to control the accuracy.
Here is one:
t = Table[x + RandomReal[{0, 10^-7}], {x, 0, 1, .1}]
Rationalize[#, 10^-3] & /@ Differences[t]
(* -> {1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10}*)

"
Tabulating Numeric Approximation,"
I recommend you look at RecurrenceTable as J. M. suggested. However to give you an idea of how you would implement subscripts (by which I think you mean recursion) in a ""normal"" way, here's a simple example using the Fibonacci sequence:
f[0] = 1;
f[1] = 1;
f[n_] := f[n - 1] + f[n - 2];

For performance you would also ""memoize"", which just means that you store every result so that you don't have to recalculate it later:
f[0] = 1;
f[1] = 1;
f[n_] := (
   f[n] = f[n - 1] + f[n - 2]
);

Notice that the f[n] = within the function is not f[n_] :=, because we aren't matching to a generic pattern and we don't need to recalculate the expression every time it's used. We're telling Mathematica that f applied to the specific value that n has at that time is whatever it calculates on the right-hand side at that time, so the usage there is like array indexing. It's the same as was done in the first two lines specifying f[0] and f[1].
And for the sake of completeness, here's the RecurrenceTable version of the Fibonacci sequence that I pulled straight out of the documentation:
RecurrenceTable[{a[n] == a[n - 1] + a[n - 2], a[1] == 1, a[2] == 1}, a, {n, 10}]

"
performance tuning - Efficiently generating n-D Gaussian random fields,"
Here's a reorganization of GaussianRandomField[] that works for any valid dimension, without the use of casework:
GaussianRandomField[size : (_Integer?Positive) : 256, dim : (_Integer?Positive) : 2,
                    Pk_: Function[k, k^-3]] := Module[{Pkn, fftIndgen, noise, amplitude, s2},
  Pkn = Compile[{{vec, _Real, 1}}, With[{nrm = Norm[vec]},
                                        If[nrm == 0, 0, Sqrt[Pk[nrm]]]], 
                CompilationOptions -> {""InlineExternalDefinitions"" -> True}];
  s2 = Quotient[size, 2];
  fftIndgen = ArrayPad[Range[0, s2], {0, s2 - 1}, ""ReflectedNegation""];
  noise = Fourier[RandomVariate[NormalDistribution[], ConstantArray[size, dim]]]; 
  amplitude = Outer[Pkn[{##}] &, Sequence @@ ConstantArray[N @ fftIndgen, dim]];
  InverseFourier[noise * amplitude]]

Test it out:
BlockRandom[SeedRandom[42, Method -> ""Legacy""]; (* for reproducibility *)
            MatrixPlot[GaussianRandomField[]]
        ]


BlockRandom[SeedRandom[42, Method -> ""Legacy""];
            ListContourPlot3D[GaussianRandomField[16, 3] // Chop, Mesh -> False]
            ]


Here's an example the routines in the other answers can't do:
AbsoluteTiming[GaussianRandomField[16, 5];] (* five dimensions! *)
   {28.000959, Null}

"
probability or statistics - Creating word histograms from lists of strings,"
I have a slightly different strategy for splittling the string than rcollyer, because you can stick the pattern into StringSplit directly instead of needing to do a StringReplace first to prepare the string for splitting. For instance:
In[141]:= StringSplit[""A dog is in the house."", Except[WordCharacter]]
Out[141]= {""A"", ""dog"", ""is"", ""in"", ""the"", ""house""}

Also, you can make StringHistogram simpler by using the built-in Tally function, which you've reimplemented (pretty darn well, I must say): 
StringHistogram[list_, opts : OptionsPattern[]] :=
 With[{tally = Tally@list},
  BarChart[tally[[All, 2]],
   BarOrigin -> Left,
   ChartLabels -> tally[[All, 1]],
   FilterRules[{opts}, Options[BarChart]]
   ]]

I use the BarOrigin option to make the bars come from the side, which makes everything much easier to read when you have many strings, and I pass options to BarChart in order to make tweaking things easier:
StringHistogram[
 StringSplit[StringData2, Except[WordCharacter]] // Flatten, 
 ImageSize -> 500, BaseStyle -> ""Label""]


"
"""Covering up"" text in Graphics","
You can use Inset:     
  Show[{Graphics3D[{Opacity[0.2], Sphere[], Opacity[1.0], Blue, 
  Inset[Graphics[Text[Style[""Surprise!"", Green, 24]]], {0, 0, 0}]}],
  ParametricPlot3D[{Sin[th] Cos[ph], Sin[th] Sin[ph], Cos[th]}, {th, 
   0, Pi}, {ph, 0, 2 Pi}, 
  RegionFunction -> Function[{x, y, z}, Abs[x] < .9], 
  PlotRange -> {-1, 1}, PlotStyle -> Red, Mesh -> None]}]

which gives

Alternatively, you can use Texture:
  text = Style[""Surprise!!"", 128];
  vrtxtxtrcoords = {{0, 0}, {1, 0}, {1, 1}, {0,  1}}; 
  Show[{Graphics3D[{Texture[text], 
  Polygon[{{-.2, -.3, -.3}, {-.2, .3, -.3}, {-.2, .3, .3}, {-.2,  -.3, .3}},  
  VertexTextureCoordinates -> vrtxtxtrcoords]}, 
  Lighting -> ""Neutral""], 
  ParametricPlot3D[{Sin[th] Cos[ph], Sin[th] Sin[ph], Cos[th]}, {th, 0, Pi}, {ph, 0, 2 Pi}, 
  RegionFunction -> Function[{x, y, z}, Abs[x] < .9], 
  PlotRange -> {-1, 1}, PlotStyle -> Red, Mesh -> None]}]

which gives

"
functions - How to find Matano plane,"
Maybe I'm missing something but isn't the value for z just the solution of the equation 
(z - xLimits[[1]])*yLimits[[1]] + (xLimits[[2]] - z)*yLimits[[2]] == area

where area is the total area under the graph, i.e.
area = NIntegrate[GetRLine3[{data}, 3][x], {x, xLimits[[1]], xLimits[[2]]}][[1]]

Therefore, z is equal to
z = (xLimits[[2]]*yLimits[[2]] - xLimits[[1]]*yLimits[[1]] - area)/
      (yLimits[[2]] - yLimits[[1]])

"
graphs and networks - How to find all vertices reachable from a start vertex following directed edges?,"
One can use VertexOutComponent[] to find all the vertices connected to a given vertex in a directed graph:
In[107]:= edges={1->3,1->4,2->4,2->5,3->5,6->7,7->8,8->9,9->10,6->10,1->6,2->7,3->8,4->9,5->10};
In[114]:= vertices=Sort@DeleteDuplicates[Flatten[List@@@edges]];
In[115]:= g=Graph[vertices,edges];
In[116]:= {#,VertexOutComponent[g,{#}]}&/@vertices//Grid
Out[116]= 1 {1,3,4,5,6,7,8,9,10}
2   {2,4,5,7,8,9,10}
3   {3,5,8,9,10}
4   {4,9,10}
5   {5,10}
6   {6,7,8,9,10}
7   {7,8,9,10}
8   {8,9,10}
9   {9,10}
10  {10}

It should work for any directed graph whether it's acyclic or not. The analogue of VertexOutComponent[] for undirected graphs is ConnectedComponents[].
"
graphics - Creating ghost trail effects,"
Here is a simple approach to create a ghost trail:
obj[{xfunc_, yfunc_}, rad_, lag_, npts_][x_] := MapThread[
 {Opacity[#1, ColorData[""SunsetColors"", #1]],
  Disk[{xfunc@#2, yfunc@#2}, rad Exp[#1 - 1]]} &, 
 Through[{Rescale, Identity}[Range[x - lag, x, lag/npts]]]]

frames = Most@Table[Graphics[obj[{Sin[2 #] &, Sin[3 #] &}, 0.1, 1, 500][u], 
  PlotRange -> {{-2, 2}, {-2, 2}}, Axes -> False, ImageSize -> 300,
  Background -> Black] ~Blur~ 3, {u, 0, 2 Pi, 0.1}];

Export[""trail.gif"", frames, ""DisplayDurations"" -> .03] 


"
pattern matching - Does Mathematica use first order or second order order unification?,"
I am not an expert in the field, but ...
According to Roman Maeder (and he is an expert):

The process of unification should be easy to understand for
  Mathematica users, since a weaker form of it —pattern matching— is the
  fundamental operating principle of Mathematica’s evaluator.

So, no unification is done in native Mma.
If you need it, Maeder presents in that 2 articles series a package with a modified evaluator that aims to bring second order unification to Mma.
Just for those to whom unification means only a physics Grail, should Mma have  unification you could do things like:
f[x_,a] /. f[b,y_]-> {x,y}
(*
-> {b,a}
*)

"
programming - Speed up Fourier for Booleans,"
Most of your questions can be answered experimentally. You can find out a lot about Mathematica by just interactively playing and timing results. Let's see how it works out in this case:

does it automatically optimize for the type of input data (just
  integers 0 and 1)?

d1 = RandomReal[1, 10^7];

Fourier[d1]; // AbsoluteTiming // First

(*  ==> 1.0650609  *)

d2 = RandomInteger[1, 10^7];

Fourier[d2]; // AbsoluteTiming // First

(*   ==> 1.1050632 *)

So, no difference between integers and reals in this case. Note that Mathematica doesn't know no numerical Boolean values (0, 1), but only True and False and you can't perform a Fourier on that.

Is Mathematica lazy enough to see that I only care about the first 100
  frequencies and won't calculate the others?

Mathematica has some clever optimizations going on under the hood, but this is not one of them. Compare the previous Fourier timing with this one:
Fourier[d1][[1 ;; 100]]; // AbsoluteTiming // First

(*  ==> 1.0740615  *)

The answer,therefore, is 'no'. The reason can be discovered easily, for instance, by using TracePrint 
Fourier[{1, 2, 3, 4, 5}][[1 ;; 3]] // TracePrint

 Fourier[{1,2,3,4,5}][[1;;3]]
  Part
  Fourier[{1,2,3,4,5}]
   Fourier
   {1,2,3,4,5}
  {6.708203932 +0. I,-1.118033989-1.538841769 I,-1.118033989-0.363271264I
   ,-1.118033989+0.363271264 I,-1.118033989+1.538841769 I}
  1;;3    
   Span    
   1    
   3   
 {6.708203932 +0. I,-1.118033989-1.538841769 I,-1.118033989-0.363271264 I
  ,-1.118033989+0.363271264 I,-1.118033989+1.538841769 I}[[1;;3]]

 {6.708203932 +0. I,-1.118033989-1.538841769 I,-1.118033989-0.363271264 I}

As you can see, Part, the function lurking behind [[...]] is performed on the full output of Fourier, which itself, is fully unaware that pieces of its output will be picked away.

Can I give it some hints about the input?

Usually, no, you can't. Compile itself needs to know the types of its inputs, but most other Mathematica functions are just as happy with reals as with integers. Exceptions are, of course, functions that explicitly deal with integers like IntegerDigits. 
Functions you write yourself can be typed. For instance,
f[x_Integer,y_Integer] := IntegerDigits[x][[y]]

only takes integers as arguments. 
"
plotting - Animate ParametricPlot3D for two different parametric equations,"
Maybe you want an animation parameterized by the time $t$? This would do it in an interactive way:
With[{missileSize = 10},
 Manipulate[
  Graphics[{
    {Red,
     Disk[
      {100 t, 80 t - 16 t^2}, missileSize
      ]},
    {Blue,
     Disk[
      {500 - 200 (t - 2), 80 (t - 2) - 16 (t - 2)^2}, missileSize
      ]}
    },
   Frame -> True,
   GridLines -> Automatic,
   PlotRange -> {{0, 800}, {-200, 400}},
   AspectRatio -> Automatic],
  {t, 0, 7}]
 ]

Alternatively, you could create an animation like this:
t = Table[Graphics[{
     {Red,
      Disk[
       {100 t, 80 t - 16 t^2}, 10
       ]},
     {Blue,
      Disk[
       {500 - 200 (t - 2), 80 (t - 2) - 16 (t - 2)^2}, 10
       ]}
     },
    Frame -> True,
    PlotRange -> {{0, 800}, {-200, 400}},
    AspectRatio -> Automatic],
   {t, 0, 5, .1}];

ListAnimate[t]


The animation above was created with
Export[""missiles.gif"", t]

Edit
Since it was asked in the comment, I'll add the 3D analogue here, too - although Verbeia already did something like it with Manipulate:
xMin = 0;
xMax = 800;
yMin = -200;
yMax = 200;
zMin = -200;
zMax = 400;
ground = {Green, 
   Polygon[{{xMin, yMin, zMin}, {xMin, yMax, zMin}, {xMax, yMax, 
      zMin}, {xMax, yMin, zMin}}]};

t = Table[
   Graphics3D[{ground, {Red, 
      Sphere[{100 t, 0, 80 t - 16 t^2}, 10]}, {Blue, 
      Sphere[{500 - 200 (t - 2), 0, 80 (t - 2) - 16 (t - 2)^2}, 10]}},
     Boxed -> True, 
    PlotRange -> {{xMin, xMax}, {yMin, yMax}, {zMin, zMax}}], {t, 0, 
    6, .1}];

ListAnimate[t]


If you compare to the 2D code, I just replaced Disk by Sphere, made the height the z coordinate and set the y coordinate of the projectiles to 0. 
The other changes are just small tweaks: I defined the plot range as variables so I can use them to define a rectangular Polygon representing the ground. Instead of the Framed option, there is the Boxed option (which can also be omitted or set to False).
"
probability or statistics - What do the options of SmoothKernelDistribution do?,"
You can click on each of these variables in the help for further explanation.
MaxMixtureKernels: the maximum number of kernels to generate the estimate from. The example in the help file makes this quite clear:

As you can increase the number of kernels (tent poles, if you will) from 10, 15, 25, to 100, the smoother the estimate becomes, at the expense of complexity (more parameters to estimate).
InterpolationPoints: How many points the interpolation function (kernel density estimate) is to be evaluated at.

10 points on the left, 100 on the right. First you fix the number of kernels (consider the previous diagram), then you select where to sample the interpolant.
MaxRecursion: An option for the Plot function to achieve better results in places where more samples are needed. Again, the help file provides some illuminating illustrations:
MaxRecursion http://reference.wolfram.com/mathematica/ref/Files/MaxRecursion.en/O_4.gif
Here the levels of recursion runs from 0,1,2,4.
"
Comfortable Edge Labeling of Undirected Graph,"
You may:
Show@Table[
  CompleteGraph[3, 
   EdgeLabels -> {1 \[UndirectedEdge] 3 -> Placed[1, p]}, 
   ImagePadding -> 10], {p, {1/6, 1/2, 5/6}}]


"
front end - Remove CellMargins option from many cells,"
Add the following line to the end of the notebook you want to update:
NotebookPut[NotebookGet[] /. Verbatim[Rule][CellMargins, e__] -> Sequence[]];

And evaluate it. You should get a new notebook for which all CellMargins have been deleted. 

Looks like you can use the UI pretty easily to do this. First, highlight all the cells (if you want all the cells to have the same margins, just hit CTRL+a. 
Then, go to Format -> Options Inspector (also can use CTRL+SHIFT+O). In the search box, you can type in CellMargins:

Here, I've set the marings to be {{66,10},{5,25}}. It looks like the default is {{66,10},{5,10}} and the settings are {{left,right},{top,bottom}}
"
programming - How can I add row and column header images to my TableForm output?,"
You can use the TableHeadings option to supply the row and column headings (which can also be images). Here's an example (data is the matrix in your question):
lena = ImageResize[ExampleData[{""TestImage"", ""Lena""}], {64, 64}];
TableForm[With[{min = Min[#]}, # /. min -> Style[min, Red]] & /@ data, 
    TableHeadings -> {ConstantArray[lena, 3], ConstantArray[lena, 9]}]


"
programming - What is the equivalent of a prototypical Manipulate in lower level functions?,"
Start from 
{Slider[Dynamic[x], {1, 5, 1}], Dynamic[x]}


Next localize control variable:
DynamicModule[{x}, {Slider[Dynamic[x], {1, 5, 1}], Dynamic[x]}]


And add some interface elements:
Panel@DynamicModule[{x},  Column[{Slider[Dynamic[x], 
{1, 5, 1}], Panel[Dynamic[x], ImageSize -> 200]}]]


Add even more
Panel@DynamicModule[{x},   Column[{Row[{""x"", Spacer[10], 
Animator[Dynamic[x], {1, 5, 1}, AnimationRunning -> False, 
ImageSize -> Small]}], Panel[Dynamic[x], ImageSize -> 235]}]]


"
cdf format - Trouble with CDF on Mac OSX,"
Perhaps this is caused by an interaction between the embedding JavaScript and the Page Zoom feature in Safari. If you reset the page zoom to ""Actual Size"" by pressing Command-0 (or from the View menu), it hopefully will allow you to interact with the controls again. 
After that, it may even be possible to return to a larger zoom setting and still have the CDF work properly, because the display script may receive updated values for the available window size that it needs to calculate the offset between your mouse pointer and the controls.
"
Need tips on improving this directed graph,"
  g = Graph[Tooltip /@ t, 
  VertexSize -> 
  Append[Thread[{5, 7, 11, 13, 17} -> {""Scaled"", .01}, List, 1], {""Scaled"", .005}],
  VertexStyle -> Thread[{5, 7, 11, 13, 17} -> Red],
  VertexLabels -> Placed[""Name"", Tooltip], 
  GraphLayout -> ""RadialDrawing"", ImageSize -> 700] //  Rotate[#, 90 Degree] &

gives

Does not quite line up the nodes for the first five primes in the list, but it is a cheap alternative to building a custom layout from scratch using VertexCoordinates.
EDIT: If the size of graph is reduced, one can use GraphPlot and its options to vertically line up the first five nodes. For this to work, I had to reduce the number of nodes to plot:
 tX = {}; z = 4; While[z < 240, y = Prime[z++]; prev = y; u = {};  x = y; 
 While[x >= y, prev = x; x = lopf[3 x + 1]; 
 u = AppendTo[u, {DirectedEdge[prev, x]}]; tX = AppendTo[tX, u];]];
 tX = Union[Flatten[tX]];
 tX2 = tX /. DirectedEdge[x_, y_] :> Rule[x, y];

With this dataset
 GraphPlot[tX2, PlotStyle -> Gray, 
 VertexRenderingFunction -> Function[{p, l}, 
  Tooltip[{If[MemberQ[{5, 7, 11, 13, 17}, l], 
  Sequence @@ {Red, PointSize[.015]}, 
  Sequence @@ {Blue, PointSize[.008]}], Point[p]}, Text[l]]], 
 VertexCoordinateRules ->  Thread[{5, 7, 11, 13, 17} -> {0, Automatic}, List, 1], 
 DirectedEdges -> True,
 ImageSize -> 400]

gives

EDIT 2: Aligning the first  5 nodes in graph g above:
coordlist = PropertyValue[{g, #}, VertexCoordinates] & /@ VertexList[g][[;; 5]];
coordlist[[All, 2]] = 4;
Fold[SetProperty[{#1, #2}, 
    VertexCoordinates -> coordlist[[VertexIndex[g, #2]]]] &, g, 
       VertexList[g][[;; 5]]] 
// Rotate[#, 270 Degree] &


"
front end - No Syntax Highlighting of Package Functions,"
I don't know what is causing your problem, but presumably you can still specially color the symbols in those contexts as I do.  For example:
SetOptions[$FrontEnd, 
  AutoStyleOptions -> {""SymbolContextStyles"" ->
     {""Units`"" -> Brown, ""PhysicalConstants`"" -> Orange}
   }
]


Since the above suggestion doesn't have effect on your machine even when you deselect highlighting of ""Global symbols that have no value assigned"" in the Preferences dialog, it sounds like something is really broken. Obviously backing things up first, try deleting the user configuration files. 
"
probability or statistics - Non-linear trend reduction with missing data,"
You can try to fill the missing values if it is suitable for your data by:

mean values
mean values of same class
the most probable value
Spline smoothing
You can filter the data through a linear filter

But if you are building a nonlinear model in general, you should not detrend data before estimating nonlinear models. In the case of nonlinear grey-box models, do not detrend the data to make sure that the models represent the actual physical levels.
"
import - How can I read in specific information from a TeX-file?,"
The regular expression approach is my favorite, but I would do it a little differently to make it more robust. The approach by David didn't quite get the } treated right. The approach by R.M relied on the newline characters in the file (but newlines are optional in $\TeX$). So here is what I believe fixes these problems.
First define the example $\TeX$ content:
tex = ""\\commandnameA{Bob}
    blabla
    \\commandnameB{It wasn't Bob}
    \\commandnameC{2012}
    bla
    \\commandnameD{$\\frac{1}{3}$}
    \\commandnameE{\\commandnameF{It was Bob!}}
    \\commandnamefilename{29}"";

Now comes the function that does the translation:
translate[t_] := 
 Module[{regex = 
    RegularExpression[
     ""\\\\commandname[^{]*{([^{}]*({[^}]*})*([^{}]*))}""]},
  Flatten[{t, StringCases[t, regex :> translate[""$1""]]}]
  ]

And finally the application:
Rest[translate[tex]]


{""Bob"", ""It wasn't Bob"", ""2012"", ""$\\frac{1}{3}$"", ""\\commandnameF{It \
  was Bob!}"", ""It was Bob!"", ""29""}

The translate function finds matching braces following any of the \commandname keywords, and applies itself recursively to the resulting content.
It returns the supplied argument plus the result of the recursive translation. 
Therefore, the first entry in the result of translate is always the original text. That is why I use Rest to print the desired sub-strings.
"
Drawing Graph Products - Mathmatica Stack Exchang,"
I do feel that the question could be a bit more clear.  When you write ""each copy of the factors can have LinearEmbedding"", do mean that each factor is, in fact, a path graph?  Assuming so, perhaps something like the following could work.  (Seems to complicated, I admit.)
m = 3;
n = 2;
g1 = Graph[
   Table[UndirectedEdge[Subscript[u, i], Subscript[u, i + 1]], {i, 1, m - 1}],
   VertexLabels -> ""Name"",
   VertexCoordinates -> Table[{0, i}, {i, 1, m}]
   ];
g2 = Graph[
   Table[UndirectedEdge[Subscript[u, i], Subscript[u, i + 1]], {i, 1, n - 1}],
   VertexLabels -> ""Name"",
   VertexCoordinates -> Table[{i, 0}, {i, 1, n}]
   ];
g1g2 = Graph[
   Flatten@Join[
     Table[
      UndirectedEdge[{Subscript[u, i], Subscript[u, j]}, 
        {Subscript[u, i], Subscript[u, j + 1]}], {i, 1, m}, {j, 1, n - 1}],
     Table[
      UndirectedEdge[{Subscript[u, i], Subscript[u, j]}, 
         {Subscript[u, i + 1], Subscript[u, j]}], {i, 1, m - 1}, {j, 1, n}]
     ],
   VertexLabels -> ""Name"",
   VertexCoordinates -> Flatten[Table[{i, j}, {i, 1, m}, {j, 1, n}], 1]
   ];
size[1] = {100, 200};
size[2] = {200, 100};
size[3] = {300, 200};
Row[MapIndexed[Show[GraphComputation`GraphConvertToGraphics[#],
    ImageMargins -> 5, ImageSize -> size[#2[[1]]]] &, 
  {g1, g2, g1g2}],
 ImageSize -> 700, Alignment -> Center]


The bulk of this code involves the layout of the graph.  If you simply want a generalized Cartesian product of graphs without regard to the layout, then that's a bit easier.
SeedRandom[1];
g1 = RandomGraph[{5, 5},VertexLabels -> ""Name""];
g2 = RandomGraph[{5, 8},VertexLabels -> ""Name""];
makeCartesianProductEdge[u_, UndirectedEdge[u2_, v2_]] := UndirectedEdge[{u, u2}, {u, v2}];
makeCartesianProductEdge[UndirectedEdge[u1_, v1_], v_] := UndirectedEdge[{u1, v}, {v1, v}];
g1g2 = Graph[Flatten[{
     Table[makeCartesianProductEdge[u, e],{u, VertexList[g1]}, {e, EdgeList[g2]}],
     Table[makeCartesianProductEdge[e, u],{u, VertexList[g2]}, {e, EdgeList[g1]}]}], 
     VertexLabels -> ""Name""];
graphToGraphics[g_Graph] := GraphComputation`GraphConvertToGraphics[g];
graphToGraphics[else_] := else;
GraphicsGrid[Partition[graphToGraphics /@ {g1, g2, g1g2, SpanFromLeft}, 2]]


If you want a linear embedding of non-path graphs, then you'll need to do something to keep the edges from lying on top of one another.
g1 = Graph[EdgeList[g1], VertexCoordinates -> Table[{i, 0}, {i, 1, Length[VertexList[g1]]}]];
g2 = Graph[EdgeList[g2], VertexCoordinates -> Table[{i, 0}, {i, 1, Length[VertexList[g2]]}]];
g1g2 = Graph[EdgeList[g1g2], VertexCoordinates -> VertexList[g1g2]]


Perhaps the following EdgeShapeFunction will help, but I doubt it.
esf[{u_, v_}, ___] := {Opacity[0.3], Arrow[BSplineCurve[Table[
  (u + v)/2 + Norm[v - u] {Cos[t], Sin[t]}/2,
  {t, ArcTan @@ (v - u), ArcTan @@ (v - u) + Pi, Pi/5}]]]};
GraphicsRow[SetProperty[#, EdgeShapeFunction -> esf] & /@ {g1, g2, g1g2}]


"
export - How to remove an expression from a file?,"

Functions like Read, Skip and Find usually operate on streams in an
  entirely sequential fashion. Each time one of the functions is called,
  the current point in the stream moves on.

In a Sequential file you can´t delete entries. The only option is shifting the ""tail"" of the file upwards.

"
programming - Is Mathematica a Turing-complete language?,"
It has already been proven that the  Rule 110 cellular automata is Turing complete. Since Mathematica can implement this cellular automata, it must be true that Mathematica is Turing complete.
Incidentally, it has been claimed that HTML + CSS3 is Turing complete, and Mathematica is a bit more expansive than that combination. So it should not be surprising that Mathematica is also Turing complete.
All this is with the standard limitation that a 'real' turing machine needs unlimited memory and time, both is not available to any physical thing.
"
"Problem using OptionValue with functions defined by SubValues, and the use of Options for function dispatch","
There are two problems I see with this code. The first one, and the one which gives you immediate problem you reported, is that, as it looks, short (magical) form of OptionValue does not work with SubValues - based definitions. So, you should replace
OptionValue[""type""]

with 
OptionValue[{opts}, ""type""]

Or, if you wish to associate the option with pump directly and use it within the SubValue, you need to use
OptionValue[pump, {opts}, ""type""]

instead.
The second, ""conceptual"" problem, is that you are really trying to use options for function dispatch, but in doing this your way, you give up the powerful rule-based function dispatch mechanism that is naturally available in mma. This is what I would do instead:
ClearAll[pump, dispatch];
(a : pump[_, __])[""curve QH"", opts : OptionsPattern[""type"" -> ""plot""]] :=
    dispatch[pump, OptionValue[{opts}, ""type""]][a, ""curve QH"", opts];

dispatch[pump, ""plot""][_, _, opts : OptionsPattern[]] :=
   Plot[x, {x, 0, 2}, Frame -> True, FrameLabel -> {""a"", ""b""}, 
      Evaluate[FilterRules[{opts}, Options[Plot]]]];

dispatch[pump, ""table""][_, _, opts : OptionsPattern[]] :=
   Table[x, {x, 0, 2, 0.1}]

I delegated the dispatch to a new (extra) symbol dispatch, introduced specifically for this purpose. This looks cleaner and more extensible to me than using Which statement.
EDIT
Addressing the issue raised in comments: note that, as another manifestation of OptionValue - OptionsPattern magic being lost for SubValues- based functions, the above solution, as written, will not provide the intended default behavior, when the ""type"" option is not explicitly given. To make that work, one can do:
(a : pump[_, __])[""curve QH"", opts : OptionsPattern[""type"" -> ""plot""]] :=
    dispatch[
       pump, 
       OptionValue[{opts,""type"" -> ""plot""}, ""type""]
    ][a, ""curve QH"", opts];

adding the default option explicitly in OptionValue.
"
attributes - Package automated way of ReadProtecting all symbols,"
My guess would be this:
ToExpression[
   Names[""pack`*""], 
   InputForm, 
   Function[sym,SetAttributes[sym, {ReadProtected(*,Locked*)}],HoldFirst] 
]

The problem is that functions defined with # - & notation do not hold their arguments.
"
assignment - What is the story with Removed symbols?,"
Some observations on Removed
Removed is not a normal head, but rather a print form. Consider a definition
x := y

Once we Remove the y, we invalidate x in a subtle but permanent way - reintroducing the y into the session won't help. Remove is really a rather special-purpose destructuve operation, aimed more at removing auto-generated symbols. In a system of inter-connected functions (possibly from different packages), for this reason Remove is safe only if nothing depends on the symbol being removed. Resolving shadowing is the only mainstream (frequent, non-advanced) application of Remove I am aware of.
I learned from the book of David Wagner (""Power programming with Mathematica"",page 251), that while the removed symbol is printed (and has a FullForm) as Removed[""sym""], applying Head to it yields Symbol. The reason for that is that  Removed[""sym""] still represents a symbol, albeit marked for removal. For code like this: 
Clear[b];b := a;Remove[a];b

you can not, e.g., ""resurrect"" a in b with this: 
b /. Removed[x_] :> ToExpression[x]


Removed[""a""]

but, since Removed[""a""] represents a symbol marked for removal, this will work, to at least reconstruct the value of b: 
b /. Cases[b, s_Symbol :> (s :> a), {0, Infinity}, Heads -> True]


a

You can also analyze which symbols in some expression were Remove-d, by something like this:
Clear[removedNames];
removedNames[expr_] :=
  Flatten[
    StringCases[
      ToString /@ Union@Cases[expr, _Symbol, Infinity, Heads -> True],
      ShortestMatch[""Removed["" ~~ x__ ~~ ""]""] :> x]
  ]

So that
removedNames[OwnValues[y]]


{""x""}

Summary
So, to summarize: 

Removed is not a normal head but a display form. 
When you Remove a symbol, Removed[sym] still represents this symbol, but being marked for removal. My understanding is that this is still a reference to the symbol table, but it becomes opaque and not bound to the symbol name any more. However, apparently, Mathematica still allows you to manipulate it, pretty much as if you manipulated the normal symbol. In particular, you can, for the purposes of pattern-matching, still count on it being a Symbol. This allows us to do some things as if the symbol in question has not been removed, particularly by using local rule substitutions.
As you demonstrated, you can still change some ...Values for Remove-d symbols with local rules. While it looks like you can reconstruct many of the symbol's properties (except explicit symbol name), I would however limit such uses of these symbols to extreme cases when you need to make some definitions valid in a given Mathematica session. 

EDIT:  one constructive use - catching bugs induced by Remove
Here is one possibly constructive use of the above behavior. Remove-ing symbols is dangerous because it subtly invalidates definitions for other symbols which were referencing the symbols being removed. We may wish to know when this happens, but often the effects are silent and insidious. Here is a function which enables one to trigger such events:
ClearAll[remove];
SetAttributes[remove, HoldAll];
remove::remvd = ""Stymbol `1` was removed!"";
remove[s_Symbol, failCode_: Throw[$Failed, remove]] :=
  Module[{defs},
    With[{strsym = ToString[HoldForm[s]]},
       With[{body := (
          Message[remove::remvd , Style[strsym, Red]];
          failCode
           )},
        defs :=
          Module[{},
            OwnValues[s] = HoldPattern[s] :> body;
            UpValues[s] = HoldPattern[_[___, s, ___]] :> body;
          ]]];
    Remove[s];
    defs;]; 

What it does is to assign certain definitions to symbols already after they have been removed, using the behavior discussed above. These definitions execute arbitrary user-defined code when evaluation comes to the Remove-d symbol, in most cases (except when the symbols are inside HoldAllComplete heads). To augment it, here is a dynamic environment, in which Remove will behave that way:
ClearAll[withCustomRemove];
SetAttributes[withCustomRemove, HoldAll];
withCustomRemove[code_,failCode_: Throw[$Failed, remove]] :=
  Module[{inRemove},
    Internal`InheritedBlock[{Remove },
     Unprotect[Remove];
     Remove[arg_] /; ! TrueQ[inRemove] :=
         Block[{inRemove = True}, remove[arg,failCode]];
     Protect[Remove];
     code]];

and here is an example of use. First, the usual behavior:
ClearAll[f, a];
f[x_] := x + a;
g[] := Hold[a];
Remove[a];
{f[1], g[]}


{1+Removed[a],Hold[Removed[a]]}


Now, with our functions:
withCustomRemove[
   ClearAll[f, a];
   f[x_] := x + a;
   g[] := Hold[a];
   Remove[a];
]
{f[1], g[]}


  During evaluation of In[78]:= remove::remvd: Stymbol a was removed!

  During evaluation of In[78]:= Throw::nocatch: Uncaught Throw[$Failed,remove]
           returned to top level. >>

  Hold[Throw[$Failed,remove]]


One can specify a different behavior to be triggered on such an event. One can also generalize to Remove with several arguments. The idea is that you can take the code which is suspicious, and execute it inside withCustomRemove - which may often enable you to catch bugs related to attempts to use Remove-d symbols.
"
programming - Is pure pattern matching without PatternTest and Condition Turing-complete?,"
I cannot offer a rigorous answer to this question, but I will offer some thoughts...
This question asks whether the set of functions computable using basic patterns and MatchQ is isomorphic to the subset of Turing-computable functions whose results can be expressed in a single bit.  The one-bit subset restriction is important since MatchQ is clearly not fully Turing-complete since it cannot handle functions outside of that subset.
Basic pattern-matching would seem to be a very close approximation of boolean circuits.  With suitable input encoding, we can implement the basic operations thus:

    a OR b    -->    a | b
    NOT a     -->    Except[a]
    a AND b   -->    Except[Except[a], b]

For bounded input sizes, boolean circuits are known to be able to compute any boolean function (see, for example, Theorem 1.8.1 on page 32 of Clote and Kranakis: Boolean Functions and Computation Models).  The emphasis here is on bounded.  Boolean circuits are known not to be Turing-equivalent due to non-uniformity.  That is, a fixed-size Turing program can handle any input size while a boolean circuit must grow (exponentially!) in size as input size increases.
What is not clear to me is whether the other pattern-matching features add capability that will let us will evade this conclusion.  Perhaps some creative use of BlankSequence, Repeated, Longest, Shortest, PatternSequence, etc. takes us outside of the realm of boolean circuits and toward (one bit) Turing-equivalence.
"
front end - keyboard sequence for Magnify in version 8?,"
The keyboard sequence is Alt-W M on both Windows and Linux. This will open a drop down menu where you can select the magnification.
"
import - Behavior of ImportString in Mathematica,"
I have no idea why the first ImportString brings things in as strings, but if you import as ""CSV"" instead, it works as you want.
In[22]:= ImportString[
  ""129,160,16,4
  130,160,14,5"", ""CSV""] // InputForm
Out[22]= {{129, 160, 16, 4}, {130, 160, 14, 5}}

You can use InputForm to force the display of quote marks; you don't need the much more verbose FullForm.
"
curated data - Highlighting individual countries on a world map,"
In the example code, CountryData[#, ""AntarcticNations""] is a built in predicate that returns True or False.  You need something similar for your countries.  Perhaps,
myCountries={
  ""Germany"",""Hungary"",""Mexico"",""Austria"",
  ""Bosnia"",""Turkey"",""SouthKorea"",""China""};
Graphics[{If[MemberQ[myCountries,#],Orange,LightBrown],
  CountryData[#,""SchematicPolygon""]}& /@ CountryData[]]


"
numerics - Output of NonlinearModelFit differs from the correct result,"
This is the fit returned by Mathematica :
nlm = NonlinearModelFit[data, b*t^a, {a, b}, t]

The model is 
nlm[t]

(* 1.34232 t^0.615024 *)

The residuals (model(x)-y) are :
nlm[""FitResiduals""]

(* {-0.158097,-0.0558756,0.059473,0.0967975,0.00211152,0.132971,-0.103818,-0.0577413} *) 

The sum of the squares of the residuals is :
res1 = Total[nlm[""FitResiduals""]^2]

(* 0.0728215 *)

An explicit check :
Total[(nlm[#[[1]]] - #[[2]])^2 & /@ data]

(* 0.0728215 *)

The sum of the squares of the residual relative to the other model is  
y[t_] = 1.23 t^0.6548

res2 = Total[(y[#[[1]]] - #[[2]])^2 & /@ data]

(* 0.152818 *) 

Since res1 < res2 I would say that Mathematica returns a better fit. Why do you say the best fit is the second function ?
"
Plotting different PDFs of a distribution in the same graph,"
Here is a simple way. The Evaluate is needed to ensure the line colors are different (see this question for an explanation of this).
Plot[Evaluate[
  PDF[WeibullDistribution[1/#, 10 #], x] & /@ Range[2, 5]], {x, 0.1, 5}]


As noted in the documentation, Plot and related functions quite happily draw multiple lines if they are given a list of functions (or data in the case of ListPlot and friends) as their first argument.
Notice the use of Map (/@) and a pure function to avoid having to type out the WeibullDistribution bit of the code multiple times. (This page in the documentation will be useful in this regard.)
"
How to Combine Pattern Constraints and Default Values for Function Arguments?,"
Perhaps this?
foo[x : (_?IntegerQ) : 1] := x;

foo[]
foo[7]
foo[""string""]


1
7
foo[""string""]



Update: since version 10.1 one does not need to explicitly include the default in the pattern as described below; see:

Version inconsistency with optional arguments: what if the default value doesn't match the pattern?

As Leonid reminds, if the default value does not match the test function it will not be returned.  To allow for this you can explicitly include the value in the pattern:
ClearAll[foo]
foo[x : (_?IntegerQ | ""default"") : ""default""] := x;

foo[]
foo[7]
foo[""string""]


""default""
7
foo[""string""]



In the comments magma makes an excellent point.  You can use multi-clicking, or as I prefer Ctrl+. to examine parsing.  See this answer.
"
front end - How to Enable Syntax Coloring of Pattern Match Variable Only (i.e. Without Coloring any Associated Pattern)?,"
I don't think it's possible, but I hope for an answer proving me wrong.
I don't think you can do anything about how the front-end interprets what you type as boxes.
If you could do that, you could make something like x_Integer parse into a certain StyleBox. However, it's interpreted as a single word. Try it, and in the cell expression you'll see BoxData[""x_Integer""]. I doubt the front-end allows you any way of treating parts of a word differently than others.
The front-end has some options regarding the syntax coloring, but, as you said, I found none that could apply to this. There are also some styles in the core.nb stylesheet that can be customized, such as the color of unmached brackets, but none related and particularly, none referring to ""parts of words"". 
Similarly, the option AutoStyleWords only helps with specific full words (in box type cells). As John Fultz said in this answer
""This will only work to style things which are lexically word-type tokens. You cannot, for example, auto-style two words in sequence, a subexpression with an operator, or a substring of a word token.""
Conclusion
I'm not totally certain, but my best guess is that your only chance is by brute force. This means, some trigger, that runs code that reads your cell's box expressions and turns them into what you like. The trigger could be a CellEventHandler that catches keystrokes, or a ScheduledTask, or some manual input, palette, hotkey, context menu, etc.
Leonid is using this approach in his syntax highlighter package, and if this is important to you, my bet is that the road through this link is your tough but best chance
"
plotting - Custom formatting for DateListPlot,"
Somehow DateListPlot is resistant to many styling options. Without fiddling with the internals, here is a starting point.
WeekendQ[date_] := 
 With[{d = DateString[date, ""DayName""]}, 
  MatchQ[d, ""Saturday"" | ""Sunday""]]
weekStyle = {Blue};
weekendStyle = {PointSize -> .015, Directive[Red]};
styleList = 
  Map[If[WeekendQ[#], weekendStyle, weekStyle] &, questionTimes];
DateListPlot[Partition[Transpose[{questionTimes, hours}], 1],
 PlotStyle -> styleList, Filling -> Bottom, GridLines -> False,
 FillingStyle -> ColorData[1][1],
 Frame -> {True, True, False, False},
 PlotRange -> {0, 24}, 
 Prolog -> {LightGray, Rectangle[Scaled[{0, 0}], Scaled[{1, 6/24}]], 
  Rectangle[Scaled[{0, 20/24}], Scaled[{1, 1}]]}]

Looks like:

"
list manipulation - Is there a bug in Pick?,"
This confused me as well, but using Trace revealed what is going on:
Trace@Pick[{1, 2, 3, 4, 5}, selection, elem_ /; elem =!= 0]

{{selection,{0,1.2,3,0.,5}},
 Pick[{1,2,3,4,5},{0,1.2,3,0.,5},elem_/;elem=!=0],
 {{0,1.2,3,0.,5}=!=0,True},
 {1,2,3,4,5}}

The key is the 4th line: note that the pattern is applied to the full list, at level 0.  The full list selection does match (because it is not structurally equivalent to 0) thus the full first argument is picked out.
The reason why we don't see this behavior with Equal (i.e. ==) is that {0, 1.2, 3, 0., 5} != 0 stays unevaluated.
(I did not find a way to restrict at which levels Pick operates, but it is possible to tweak the pattern instead, e.g. elem_?NumericQ/;elem=!=0, possibly with a performance hit.)
"
How to use Interpolation to fill in missing data,"
You have to provide the values of independent variable. Assuming that the points correspond to equidistant values of an independent variable, you can do this, for example:
int = 
 Interpolation[
   Select[Transpose[{Range[Length[data]], data}], NumericQ[Last[#]] &],
   InterpolationOrder -> 1
 ]

Of course, you may wish to scale the independent variable here in some way.
"
graphics - Combining Rasterize with ParametricPlot,"
First, you have to define bkgd differently because it's not a disk unless you make it a Graphics first: 
bkgd = Rasterize[Graphics@Disk[{0, 0}, 0.09]];

Then use Inset:
ParametricPlot[{t, t^2}, {t, 0, 1}, 
Epilog -> {Inset[bkgd, {.5, .5}, Automatic, .2]}]


The position and size of the disk image are controlled by the last three arguments of Inset.
You will note that the last argument (the size scale) is a factor relative to the   plot region (with 1 corresponding to the whole width).
"
algebraic manipulation - Is it possible to have Mathematica move all terms to one side of an inequality?,"
Are you looking for Subtract?
eq=x>=y
Subtract@@eq>=0

gives:

x-y>=0

Edit
If one wants a function, which keeps the order sign and adds the 0, one may use:
oneSide=(Head[#][Subtract@@#,0]&)

and call e.g.  eq//oneSide
"
evaluation - Unexpected differences with various uses of NormFunction,"
This must have to do with the symbolic preprocessing, happening in FindFit. In all cases when you get 2.13284, this was a result of symbolic preprocessing, which was possible because the norm function could be evaluated on symbolic arguments. The subsequent result is likely explained by the mechanism described by @Searke. 
But if you define your own norm as
ClearAll[norm];
norm[vec_?(VectorQ[#, NumericQ] &), alpha_] := Norm[vec, alpha];

and replace Norm with norm in all your examples, you always get 2.12467. You can gain more insight into this by using Trace with TraceInternal -> True. 
"
plotting - Why can't I use Show with BoxWhiskerChart?,"
The reason this is cut off is because the ListLinePlot's PlotRange does not cover all the values:
ListLinePlot[d2]


When this is included in the Show it is still cut off. If, instead, you do:
ListLinePlot[d2,PlotRange->All]


it includes all the points. Then, the whole thing will show up when you use Show:
Show[BoxWhiskerChart[d1, ""Outliers""], ListLinePlot[d2, PlotRange -> All]]


"
evaluation - Make a button that evaluates a function over and over,"
Maybe you could do something like this
SetAttributes[redoButton, HoldRest]
redoButton[str_, fun_] := DynamicModule[{result = Null}, 
   Column[{Button[str, result = fun], Dynamic[result]}]]

redoButton[""press"", RandomInteger[20]]

"
simplifying expressions - Does the Im function work with symbolic arguments?,"
You should assume that your variables are real, (if you want M to proceed further) because Mathematica treats variables in general as complex. One of many ways to do it :
 expr = A ((Cos[k y] + I Sin[k y]) 2 I Sin[t ω]); 
 Refine[ Im[ expr], (A | k y | t ω) ∈ Reals]


2 A Cos[k y] Sin[t ω]


We needn't use ComplexExpand defining expr, but in this case it is the simplest approach (pointed out by Heike) :
ComplexExpand @ Im @ expr

Some other ways of imposing assumptions : 
Assuming[(A | k y | t ω) ∈ Reals, Refine[ Im[ expr] ] ]

another way yielding the same result :
Block[{$Assumptions = A ∈ Reals && k y ∈ Reals && t ω ∈ Reals},
       Refine @ Im[ expr] ]


 2 A Cos[k y] Sin[t ω]


"
graphics - Is it possible to make more room in a graph layout for my VertexRenderingFunction?,"
Generally I'd recommend using Graph instead of GraphPlot. One way to solve your specific problem is to affect VertexCoordinates to scale your graph:
M = {{0, 0, 1, 0}, {1, 0, 0, 1}, {1, 1, 0, 0}, {0, 1, 0, 0}};
Manipulate[ AdjacencyGraph[M, DirectedEdges -> True, VertexShapeFunction -> 
({EdgeForm[Black], LightRed, Disk[#1, {.7, .1}], Black, 
Text[Subscript[""C"", #2], #1]} &),  VertexCoordinates -> scale   
AbsoluteOptions[AdjacencyGraph[M], VertexCoordinates][[2]]], {{scale, 2}, .1, 3}]


"
tensors - Problems with CircleTimes and infix notation,"
Infix is only an output form. You most probably want the expression which you'd get when typing v1 ⊗ v2 into Mathematica, which is entered with either \[CircleTimes] or Escc*Esc. 
As you can see by typing v1 ⊗ v2 //FullForm, this is CircleTimes[v1, v2]. The same is true for longer chains of ⊗, i.e. v1 ⊗ v2 ⊗ … ⊗ vn has the internal form CircleTimes[v1, v2, …, vn].
Also note that a complicated procedural code isn't necessary either, because Mathematica already brings the building blocks you need. Therefore the function you want should be written
TensorBasis[labels_List,d_Integer] := Outer[CircleTimes, Sequence@@Table[labels,{d}]]

"
"front end - Syntax Coloring for ""Possible Unwanted Assignment"" Issue","
This is because you are using = (the assignment operator) in the condition (not the body) of While.  It is a typical beginner mistake to use = where == is meant, so Mathematica warns about this.
Since you also use several ; in the condition, it gets a little confused and only highlights one of the = signs, not all of them.
"
programming - How can I suppress Print in parallel evaluation?,"
You can use dynamic scoping, i.e. the Block construct, to temporarily ""forget"" or redefine Print.
ParallelTable[
Block[{Print},
Print; Unprotect[Print]; Print = Null &
function[x],
{x,0,10}
]

This works with ParallelTable for me.
"
performance tuning - How to reduce the InterpolatingFunction building overhead?,"
You can use binary search with Compile. I failed inlining (Compile was complaining endlessly about types mismatch), so I included a binary search directly into Compile-d function. The code for binary search itself corresponds to the bsearchMin function from this answer.
Clear[linterp];
linterp =
   Compile[{{lst, _Real, 2}, {pt, _Real}},
     Module[{pos  = -1 , x = lst[[All, 1]], y = lst[[All, 2]], n0 = 1, 
          n1 = Length[lst], m = 0},
      While[n0 <= n1, m = Floor[(n0 + n1)/2];
        If[x[[m]] == pt,
          While[x[[m]] == pt  && m < Length[lst], m++];
          pos = If[m == Length[lst], m, m - 1];
          Break[];
        ];
        If[x[[m]] < pt, n0 = m + 1, n1 = m - 1]
      ];
      If[pos == -1, pos = If[x[[m]] < pt, m, m - 1]];
      Which[
        pos == 0,
           y[[1]],
        pos == Length[x],
           y[[-1]],
        True,
        y[[pos]] + (y[[pos + 1]] - y[[pos]])/(x[[pos + 1]] - 
              x[[pos]])*(pt - x[[pos]])
      ]],
      CompilationTarget -> ""C""];

This is about 20 times faster, on my benchamrks:
AbsoluteTiming[
   Table[Interpolation[list,InterpolationOrder->1][q],{q,0.0006,0.4,0.00001}];
]


{1.453,Null}

AbsoluteTiming[
   Table[linterp[list,q],{q,0.0006,0.4,0.00001}];
]


{0.063,Null}

"
graphics3d - ParametricPlot3D output without the meshlines,"
This appears to work for older versions of Mathematica
tube=ParametricPlot3D[2{Cos[t],Sin[t],u},{t,0,2Pi},{u,-5,5}]
tube /. Polygon[a__]:> {EdgeForm[], Polygon[a]}

"
Construct Context-free Grammar for the Language,"
As a hint, your first step is incorrect.  Once you've tried building each side independently, you will not have a way to ensure that they have the same number of 1s.
Instead, try building the string from the outside inward.  If you were going to put 0s and 1s into each half of the string, how would you ensure that you did so in a way that always ensured that the number of 0s and 1s was the same?
Hope this helps!
"
pattern matching - Successful match in Replace but not in Cases?,"
MatchQ looks to see if the whole expression matches the pattern, so you need to add a blank to allow for the other elements of s:
MatchQ[k, s[l[m, X_], l[j, X_], ___]]

Cases takes a list and checks each element in turn, so I think the pattern matcher only gets to see each l[a,b] in isolation. The best I could come up with is:
Cases[Subsets[k, {2}], s[l[m, X_], l[j, X_]] -> a[X]]

Further investigation
Here are a couple of questions about Cases I have tried to answer experimentally. I don't know if this helps anyone else much, but it was useful for me to go through it and I think I now understand how Cases behaves, even if the why is a mystery.
Q1. Does Cases take into account Orderless ?
In[1]:= SetAttributes[a,{Orderless}]
In[2]:= Cases[a[x,y],a[y,_]->0,{0}]
Out[2]= {0}

A1. Yes, it does. The pattern matcher understands that a[x,y] === a[y,x] which matches the pattern.
Q2. Does Cases take into account Flat ?
In[3]:= SetAttributes[a,{Flat}]
In[4]:= Cases[a[x,y,z],a[onebit_,anotherbit_]:>{onebit+anotherbit},{0}]
Out[4]= {{a[x]+a[y,z]}}

A2. Yes, it does. The pattern matcher understands that a[x,y,z] === a[a[x],a[y,z]] which matches the pattern.
Q3. Given that Cases can use the above transformation, will it get a ""hit"" on the pattern a[x] ?
In[5]:= Cases[a[x,y,z],a[x]->b,{0,Infinity}]
Out[5]= {}

A3. No, even though the transformed expression a[a[x],a[y,z]] clearly contains a match for a[x] at level 1, this doesn't count. Cases appears to require the entire expression at level n to match the pattern. The logic appears to be:

Level 0: expression a[x,y,x] does not match a[x]
Level 0: transformed expression a[a[x],a[y,z]] does not match a[x]
Level 1: expression x does not match a[x]
Level 1: expression y does not match a[x]

etc...
This is in contrast to ReplaceAll, which does pick up the a[x] in the transformed expression:
In[6]:= a[x,y,z]/.a[x]->b
Out[6]= a[b,y,z]

So it seems like ReplaceAll applies Flat and Orderless transformations outermost, and then for each transformed expression it digs down into the subexpressions looking for a match. Whereas Cases digs down into the subexpressions of the untransformed original expression outermost, and for each subexpression it tries the various Flat and Orderless transformations looking for a match.
I realise this is probably a complete misrepresentation of how the pattern matcher actually works, but as a hand-waving mental picture it seems to explain the different behaviour of Cases and ReplaceAll
"
plotting - How to plot CDF of a Poisson distribution in Mathematica,"
It is worth noting two characteristic features of the question:

The sum is a complementary cumulative distribution function for a Poisson distribution: it's built in to Mathematica and needn't be computed explicitly.
The use of $C+1$ as a starting index in the sum, as well as the expression 1:1:20 in the code, indicate $C$ is considered an integer: this needs to be a discrete plot.

It can also help to draw clear parallels between the ΜATLAB approach and an idiomatic Mathematica approach.  How about this?
Module[{c = Range[20], γ = 0.75, p},
 p = {# Log[#], 1 - CDF[PoissonDistribution[#^γ], #]} & /@ c;
 ListLogPlot[p]
]


"
performance tuning - Why do images in a PopupMenu sometimes make a program load sluggishly?,"
First, let me note that 50kB for such a simple graphics is unbelievably much. In fact, I had to create large and randomized raster icons to achieve such a size. Your things on the other hand look really simple and should be extremely small as vector-graphics.
So here is what I tried:
n = 200;
MapIndexed[Export[StringJoin[""tmp/"", ToString[#2[[1]]], "".pdf""], 
       Colorize[
    Blur[ImageAdd[RandomImage[0.6, {n, n}], 
      Rasterize[Style[#1, 24, White, 
                 Background -> Gray], ""Image"", ImageSize -> {n, n}, 
       Background -> Gray]], 5]]] & , 
   {""="", ""<"", ""\[LessEqual]"", "">"", ""\[GreaterEqual]"", ""\[NotEqual]""}]

This gives you icons in pdf format which are about 56k big and look like this


Using these icons and including them with With into your Manipulate the execution of the code takes under a second until the content is displayed and ready. 
The thing which is expensive here, is only the loading of pdf files from disk. Two points:

I use With since than the icons are planted directly into the Manipulate and it works even after restarting the kernel
I use the parameter ""Image"" inside Import because usually images are a lot faster than Graphics objects.

blub
With[{srules = (#1 -> 
       First[Import[StringJoin[""tmp/"", ToString[#1], "".pdf""], 
         ""Images""]] & ) /@ 
         Range[6]}, 
 Manipulate[If[newProblem, {op2, a2, b2, newProblem} = 
          {RandomInteger[{1, 6}], RandomInteger[{-5, 5}], 
     RandomInteger[4], False}]; 
      If[a >= 0, a = Min[a, 10 - Abs[b]], a = Max[a, -10 + Abs[b]]]; 
      solution = solutions[op2, a2, b2]; attempt = solutions[s, a, b]; 
      If[problemDisplay != 3 && solution === attempt, success, 
   plunk[]]; 
      Pane[Grid[DeleteCases[{If[problemDisplay == 1, 
                {Panel[
         Style[solution /. {(b7_) || (a7__) :> 
             Row[Riffle[{b7, a7}, Style[""  Or  "", 
                                  Gray]]]}, 19, 
          FontFamily -> ""Times""]]}], If[problemDisplay == 2, 
                {Panel[absValueEquation[op2, a2, b2]]}], 
              {Show[{axes[{{-10.9, 10.9}, {-0.5, 
            If[MemberQ[display, 3] || MemberQ[display, 4], 2.5, 
                            1]}}], arrows[a, b], 
         segments[s, Blue, a, b]}, BaseStyle -> 16, 
                  ImageSize -> 550, AspectRatio -> Automatic]}, 
      If[MemberQ[display, 1], 
                {Style[
         attempt /. {(b_) || (a__) :> 
            Row[Riffle[{b, a}, Style[""  Or  "", Gray]]]}, 19, 
                    FontFamily -> ""Times""]}], 
      If[MemberQ[display, 2], {absValueEquation[s, a, b]}], 
              Null}, Null], Spacings -> {2, 1}], 540, 
   Alignment -> Center], 
     {{problemDisplay, 3, ""problem:""}, {1 -> ""solutions"", 
    2 -> ""equation or inequality"", 
         3 -> ""none""}, ControlType -> RadioButtonBar, 
   ControlPlacement -> Top}, 
     {{newProblem, False}, {False, True}, 
   Enabled -> problemDisplay != 3, 
       ControlPlacement -> Top}, {{s, 2, """"}, srules, PopupMenu, 
   ControlPlacement -> Bottom}, 
     {{display, {1}, ""display:""}, {1 -> ""solutions"", 
    2 -> ""equation or inequality"", 3 -> ""a"", 
         4 -> ""b  ""}, ControlType -> CheckboxBar, 
   ControlPlacement -> Bottom}, 
     {{a, 1}, -10, 10, 1, Appearance -> ""Labeled"", ImageSize -> 500, 
       ControlPlacement -> Bottom}, {{b, 2}, -10, 10, 1, 
   Appearance -> ""Labeled"", 
       ImageSize -> 500, ControlPlacement -> Bottom}, {{a, 1}, -10, 
   10, 1, ControlType -> None}, 
     {{b, 2}, -10, 10, 1, ControlType -> None}, {{a2, 3}, -10, 10, 1, 
   ControlType -> None}, 
     {{b2, 4}, -10, 10, 1, ControlType -> None}, {{op2, 1}, 1, 6, 1, 
   ControlType -> None}, 
     AutorunSequencing -> {1, {2, 3}, {3, 3}}, 
  TrackedSymbols :> Manipulate, 
     Initialization :> {axes[plotRange_] := 
     Plot[0, {x, -10, 10}, Axes -> {True, False}, 
              Ticks -> {Range[-10, 10, 1], None}, 
      PlotRange -> plotRange, BaseStyle -> 16, 
              ImageSize -> {550, 55}, AspectRatio -> Automatic]; 
          absValueEquation[operator_, center_, span_] := 

     Tooltip[Style[
       If[MemberQ[display, 3], 
        Row[{""|"", Style[""x"", Italic], "" - ("", center, 
                      "")|"", 
          operator /. {1 -> "" = "", 2 -> "" < "", 3 -> "" \[LessEqual] "", 
            4 -> "" > "", 5 -> "" \[GreaterEqual] "", 
                          6 -> "" \[NotEqual] ""}, span}], 
        Row[{""|"", Style[""x"", Italic], Which[center < 0, "" + "", 
                        center == 0, """", center > 0, "" - ""], 
          Which[center < 0, Abs[center], center == 0, 
                        """", center > 0, center], ""|"", 
          operator /. {1 -> "" = "", 2 -> "" < "", 
            3 -> "" \[LessEqual] "", 
                          4 -> "" > "", 5 -> "" \[GreaterEqual] "", 
            6 -> "" \[NotEqual] ""}, span}]], 19, 
       FontFamily -> ""Times""], 

      Row[{Style[""|"", 14], Style[""x-a"", 12, Italic], Style[""| "", 14], 
        operator /. opRules, 
                  Style[""b"", 12, Italic]}]]; 
    arrows[center_, span_] := 

     Graphics[{If[
        MemberQ[display, 
         3], {{AbsoluteThickness[2], Gray, Arrowheads[0.03], 
                      Arrow[{{center, 2.2}, {center, 0}}, 0.25]}, 
         Text[Style[""a"", Italic], 
                      {center, 2.2}]}, Black], 
       If[MemberQ[display, 4] && span != 0, 
                  {{Brown, AbsoluteThickness[1], Arrowheads[{0.02}], 
          Arrow[{{center, 1.25}, 
                          {center + span, 1.25}}, 0.05]}, 
         Text[Style[""+b"", Italic], 
                      {center + span/2, 1.65}]}, Black], 
       If[MemberQ[display, 4] && span != 0, 
                  {{Brown, AbsoluteThickness[1], Arrowheads[{0.02}], 
          Arrow[{{center, 1.25}, 
                          {center - span, 1.25}}, 0.05]}, 
         Text[Style[""-b"", Italic], 
                      {center - span/2, 1.65}]}, Black], 
       If[MemberQ[display, 3] && 
                    MemberQ[display, 4] && 
         span != 0, {{AbsoluteThickness[2], Gray, Arrowheads[0.03], 

          Arrow[{{span + center, 2.2}, {span + center, 0}}, 0.25]}, 

         Text[Style[""a+b"", Italic], {span + center, 2.2}]}, Black], 

       If[MemberQ[display, 3] && MemberQ[display, 4] && span != 0, 
                  {{AbsoluteThickness[2], Gray, Arrowheads[0.03], 
          Arrow[{{center - span, 2.2}, 
                          {center - span, 0}}, 0.25]}, 
         Text[Style[""a-b"", Italic], {center - span, 2.2}]}, 
                  Black], 
       If[MemberQ[display, 4] && 
         span == 0, {Text[Style[""b=0"", Italic], 
                      {center, 1.65}]}, Black]}]; 
    solutions[op_, center_, span_] := 

     Module[{operator = 
        op /. {1 -> Equal, 2 -> Less, 3 -> LessEqual, 4 -> Greater, 
                      5 -> GreaterEqual, 6 -> Unequal}}, 
      Reduce[operator[Abs[x - center], span], x, 
                Reals]]; 
    plunk[n_: 0] := EmitSound[Sound[SoundNote[n, 0.25, ""Woodblock""]]]; 
          success := EmitSound[Sound[SoundNote[""F"", 1, 99]]]; 
    radius = 0.2; 

    opRules = {1 -> Style[""=  "", 14], 2 -> Style[""<  "", 14], 
      3 -> Style[""\[LessEqual]  "", 14], 
              4 -> Style["">  "", 13], 
      5 -> Style[""\[GreaterEqual] "", 14], 
      6 -> Style[""\[NotEqual] "", 14]}; 

    pt[loc_, type_: ""Closed""] := 
     If[type == ""Open"", Circle[loc, radius], Disk[loc, radius]]; 

    segments[o_, c_, a1_, b1_] := 
     Graphics[{{If[(o == 2 || o == 4 || o == 6) && b1 >= 0, 
                    {c, pt[{b1 + a1, 0}, ""Open""], 
          pt[{-b1 + a1, 0}, ""Open""]}, c], 

        If[(o == 1 || o == 3 || o == 5) && b1 >= 0, {c, 
          pt[{b1 + a1, 0}], 
                      pt[{-b1 + a1, 0}]}, c], AbsoluteThickness[4], 
        If[(o == 2 || o == 3 || o == 6) && 

          b1 > 0, {Line[{{Abs[b1] + a1 - radius, 
             0}, {-Abs[b1] + a1 + radius, 0}}]}, Black], 

        If[(o == 4 || o == 5 || o == 6) && b1 >= 0, {c, 
          Arrow[{{Abs[b1] + a1 + radius, 0}, 
                          {10.9, 0}}], 
          Arrow[{{-Abs[b1] + a1 - radius, 0}, {-10.9, 0}}]}, Black], 
                  If[(o == 4 || o == 5 || o == 6) && b1 < 0, 
                    {c, Line[{{a1 - radius, 0}, {a1 + radius, 0}}], 
          Arrow[{{a1 + radius, 0}, 
                          {10.9, 0}}], 
          Arrow[{{a1 - radius, 0}, {-10.9, 0}}]}, Black]}}]}]]

"
dynamic - Manipulate BarChart with Mathematica,"
Here's my attempt. The tricky part turned out to be to only change the height of a bar when the mouse cursor is close enough to its top edge. By default, the vertical distance between the mouse cursor and the top edge needs to be less than .5 in order to drag the bar. You can change this value by setting the option ""resolution"". 
I've also implemented the constraint that the sum of the heights is constant so when one bar is dragged the heights of other bars change to keep the total height constant. 
Note that dragBar accepts any option of BarChart so you can still use all the  features of BarChart.
SetAttributes[dragBar, HoldFirst];
Options[dragBar] = Append[Options[BarChart], ""resolution"" -> .5];

dragBar[values_, opt : OptionsPattern[dragBar]] := 
 DynamicModule[{widths, ind, pt = {0, 0}, index},
  widths = Reap[BarChart[ConstantArray[1, Length[values]], 
      ChartElementFunction :> ((If[Head[#1] === List, Sow[#1[[1]]]];) &), 
      FilterRules[{opt}, Options[BarChart]]]][[2, 1]];
  ind[x_] := Piecewise[
    Table[{i, widths[[i, 1]] < x < widths[[i, 2]]}, {i, Length[widths]}], 0];

  LocatorPane[Dynamic[pt,
    {(index = ind[#[[1]]]; 
      If[index == 0 || Abs[#[[2]] - values[[index]]] > OptionValue[""resolution""], 
        index = None]) &,
     (If[IntegerQ[index],
        values += (values[[index]] - #[[2]])/(Length[values] - 1);
        values[[index]] = #[[2]]]) &,
     None}],
   Dynamic[BarChart[values, FilterRules[{opt}, Options[BarChart]]]], Appearance -> None]]

values = RandomInteger[10, 10];
dragBar[values, BarSpacing -> .6]


"
plotting - Creating a stacked RectangleChart,"
Actually, RectangleChart does accept ChartLayout -> ""Stacked"". Consider for example
data = Table[{i^2, RandomReal[]}, {i, 5}, {j, 5}];

RectangleChart[data, ChartLayout -> ""Stacked""]


"
kernel - Generating figures over remote connection (using terminal),"
Since graphics can no longer be exported without access to a front end, even with remote connections you have to have X11 installed and working on your local machine. Therefore, the first thing you should do is: go to the web site http://xquartz.macosforge.org/landing/ and download the latest version of X11 appropriate for your OS X version. After installing it, everything should work.
Edit
In view of the comments, it's worth asking what the alternatives are to creating graphics on a remote host. Since the X11 protocol slows down the interaction between Kernel and FrontEnd, it's not practical on Mac OS X to create graphics that way any more. Unless you have older versions of Mathematica running on the remote host, that's the end of the line for this approach. 
So what to do? You can hope you have a VNC server so you can start the interactive session entirely on the host. That's a good solution if it's available. 
If not, then perhaps you'll be best off running the graphics generation as a background job on your own computer. If you have a multicore machine, you can start a Kernel session in the Terminal and let it run there, while doing other things in an interactive notebook session. At least in this way, you won't have to worry about not finding the FrontEnd. 
On my Mac, I've set up a math command that starts /Applications/Mathematica.app/Contents/MacOS/MathKernel from the Terminal (see this page for details), and in such a Kernel session I would then (without calling JavaGraphics) do the graphics generation, e.g.:
t = Table[ParametricPlot3D[{Sin[u], Sin[v], Sin[u + v]}, {u, 0, 2 Pi}, {v,0, 2 Pi}, RegionFunction -> Function[{x, y, z}, z < a], PlotRange -> {{-1, 1}, {-1, 1}, {-1, 1}}],{a, -1,1,.01}];
Export[""t.gif"",t]

While that's running, I'm able to use the Mathematica notebook interface in parallel. 
I said not to call JavaGraphics, because once that is initialized the Kernel session will want to display all the pictures you create. One can turn that off again by adding DisplayFunction->Identity to the plot command options, but if the plan is to do a non-interactive job, I'd suggest not loading JavaGraphics in the first place. 
"
export - How to change working directory for calculation and save,"
The Documentation page for ResetDirectory says under ""MORE INFORMATION"" field:

Successive calls to ResetDirectory yield earlier and earlier current
  directories.  
ResetDirectory uses the directory stack given by DirectoryStack[].
ResetDirectory removes the last element from the directory stack,
  and makes the second-to-last element current.

And the page for DirectoryStack[] says:

Each call to SetDirectory prepends one element to the directory stack;
  each call to ResetDirectory drops one.

So it is not surprizing that DirectoryStack[] initially is a blank list. The call to SetDirectory adds to this list one element: previous working directory. To get the current working directory you should evaluate Directory[].
"
custom notation - Having the derivative be an operator,"
A general idea as to how this can be done in a consistent way is explained in the help documents under NonCommutativeMultiply. The thing is that you want to use your operators in an algebraic notation, and that's what that page discusses. 
If, on the other hand, you're happy with a more formal Mathematica notation, then you would have the easier task of defining operators simply as 
dx := D[#, x] &
dy := D[#, y] &

and using them as follows:
dx@f[x, y, z]


$f^{(1,0,0)}(x,y,z)$

Combining operators would then be done using Composition: 
dxy = Composition[dx, dy];
dxy[f[x, y, z]]


$f^{(1,1,0)}(x,y,z)$

Edit
Here is another approach that's sort of intermediate between the very simple D[#,x]& scheme and the more complicated realization of an operator algebra in the linked reference from the documentation.
To make the operators satisfy the axioms of a vector space, we'd have to define their addition among each other and the multiplication with scalars. This can be done most conveniently if we don't use patterns to represent the operators, but Functions. So here I repeat the operator definitions - they act the same way as the dx, dy defined above, but their definition is stored differently:
dx = Function[{f}, D[f, x]];
dy = Function[{f}, D[f, y]];

Now I define the multiplication of an operator with a scalar: 
multiplyOp[scalar_, op_] := Function[{f1}, scalar op[f1]];

For simplicity, I always assume that the scalar is given as the first argument, and the second argument is an operator, e.g., dx etc. Note that the arguments here are not x or y (the assumed independent variables on which functions depend), because multiplyOp maps operators onto operators.
Finally, we need the addition of two (or more) operators, which is again a mapping from operators (a sequence of them) onto operators:
addOps[ops__] := Function[{f1}, Total@Map[#[f1] &, {ops}]];

Both addition and multiplication are mapped back to their usual meaning in these functions, by defining how the combined new operators act on a test function f1 (which is in turn a function of x, y, and z - depending on the dimension).
To illustrate the way these operations are used, take the example in the question,
$\left(\partial_x+\partial_y+z\right)x\psi$
and write it with our syntax:
addOps[dx, dy, multiplyOp[z, Identity]]@(x ψ[x, y])


$x \psi ^{(0,1)}(x,y)+x \psi ^{(1,0)}(x,y)+\psi (x,y)+x z \psi (x,y)$

This is the correct result (the result quoted originally in the post was actually missing an x). 
Note how I added the scalar z above: in this syntax, it first has to be made into an operator using multiplyOp[z, Identity]. The Identity operator is very useful for this. 
Of course these expressions with addOps and multiplyOp aren't as easy to read as the ones with simple + signs, but on the bright side it can also be beneficial pedagogically to separate the ""operator operations"" clearly from the operations between the functions they act on. 
Edit 2
In response to the comment, I'll add a nicer notation, but without modifying the last approach. So I'll simply introduce new symbols for the operations defined above, using some of the operator symbols that Mathematica knows in terms of their operator precedence, but has no pre-defined meanings for:

CirclePlus ⊕ typed as escc+esc
CircleDot ⊙ typed as escc.esc
CircleTimes ⊗ typed as escc*esc

I'll use them as follows:
CirclePlus[ops__] := addOps[ops];
CircleDot[scalar_, op_] := multiplyOp[scalar, op];
CircleTimes[ops__] := Composition[ops];

With this, we can now use Infix notation to write in a more ""natural"" fashion:
(dx ⊕ dy ⊕ z⊙Identity)@(x ψ[x,y])


$x \psi ^{(0,1)}(x,y)+x \psi ^{(1,0)}(x,y)+\psi (x,y)+x z \psi (x,y)$

As the third operator, CircleTimes ⊗, I've also defined the composition of operators. That allows us to do things like commutators:
commutator = dx ⊗ x⊙Identity ⊕ (-x)⊙Identity ⊗ dx;

I'm relying on the fact that ⊙ has higher precedence than ⊗ which in turn has higher precedence than ⊕ (according to the documentation).
As expected, the commutator is unity, as we can check by applying to a test function:
commutator@f[x]


f[x]

"
list manipulation - Finding all length-n words on an alphabet that have a specified number of each letter,"
Permutations is already duplicate-aware:
Permutations[{""A"", ""A"", ""B""}]


{{""A"", ""A"", ""B""}, {""A"", ""B"", ""A""}, {""B"", ""A"", ""A""}}


Perhaps you are looking for combinations of a particular length (which can then be permuted).  One way to get those is this:
f[k_, {}, c__] := If[+c == k, {{c}}, {}]

f[k_, {x_, r___}, c___] := Join @@ (f[k, {r}, c, #] & /@ 0~Range~Min[x, k - +c])

Use:
f[4, {1, 3, 2}]


{{0, 2, 2}, {0, 3, 1}, {1, 1, 2}, {1, 2, 1}, {1, 3, 0}}


These represent the words of length 4 for a list with unique items repeated, 1, 3, and 2 times at most.
You can then construct the actual words from these lists, e.g.:
char = {""A"", ""B"", ""C""};

StringJoin@MapThread[ConstantArray, {char, #}] & /@ f[4, {1, 3, 2}]


{""BBCC"", ""BBBC"", ""ABCC"", ""ABBC"", ""ABBB""}


Or:
Inner[#2 ~Table~ {#} &, f[4, {1, 3, 2}], char, StringJoin]


{""BBCC"", ""BBBC"", ""ABCC"", ""ABBC"", ""ABBB""}


And with permutations:
Inner[#2 ~Table~ {#} &, f[4, {1, 3, 2}], char, Join]

Permutations /@ %


{{B,B,C,C},{B,B,B,C},{A,B,C,C},{A,B,B,C},{A,B,B,B}}

{{{B,B,C,C},{B,C,B,C},{B,C,C,B},{C,B,B,C},{C,B,C,B},{C,C,B,B}}, . . . }


"
front end - How to let output and message be print to two separate external files?,"
Sounds like you are looking for $Messages and $Output, and maybe also $PrePrint or $Post. $Messages and $Output are a list of streams to which corresponding output is written (note that $Output is only getting output from Prints, not from return values of shift-return-evaluations). To cover return values of shift-return-evaluations you might want to manipulate $PrePrint or $Post so it will also write to the desired output file.
You can open a file for each with OpenWrite and append the resulting streams to the two lists and the messages and output will be written to those files. You can use the option FormatType of OpenWrite to write to those files in OutputForm. But since these are text files the outcome is not very useful in my opinion: For lengthy expressions the multiline ASCII art is usually harder to read than input form and these files will not be readable for any program. So I'd rather stick with the default InputForm.
For return values of shift-return-evaluations you could use something like:
$PrePrint = Function[Write[outstream,#];#]

where outstream is the open stream to your output file.
"
evaluation - A notebook created on demand from a main document showing executable input along with output cells,"
With minor modification of your code, you can use      
   button3[expr_, sz_: 300] := 
   Button[""Show expression"", 
   nb = CreateDocument[{ExpressionCell[expr, ""Input""], 
   ExpressionCell[
   Button[""Evaluate"", 
    CellPrint@ExpressionCell[expr /. Defer[x_] :> x, ""Output""]], 
   ""Input""]}, WindowSize -> {sz, sz}]];
   button3[Defer@Expand[(x + y)^2]]

or
   button3[expr_, sz_: 300] := 
   Button[""Show expression"", 
   nb = CreateDocument[{ExpressionCell[expr, ""Input""], 
   ExpressionCell[
   Button[""Evaluate"", 
    CellPrint@ExpressionCell[ReleaseHold@expr, ""Output""]], 
   ""Input""]}, WindowSize -> {sz, sz}]];
   button3[HoldForm@Expand[(x + y)^2]]

EDIT: I would go with Heike's s solution. But the following maybe of pedagocial value: ClearAll[func] preceeding definitions of functions that you edit/re-edit until you find a working version is a good practice. Forgetting this is the reason for the convoluted workaround in my original answer. So, the following works as OP intended:
   ClearAll[button4]; 
   SetAttributes[button4, HoldFirst]; 
   button4[expr_, sz_: 300] := 
   Button[""Show expression"", 
   nb = CreateDocument[{ExpressionCell[Defer@expr, ""Input""], 
   ExpressionCell[expr,""Output""], 
   ExpressionCell[Button[""Close window"", NotebookClose[nb]]]}, 
   WindowSize -> {sz, sz}]]; 
   button4[Expand[(x + y)^2]]

"
curated data - Finding all dictionary words that can be made with a given set of characters (Wordfeud/Scrabble),"
My attempt:
First we define the existing row, using dots to represent empty squares, and our hand of 7 letters.
row=""...t.t...r..e.."";
letters=""aodalip"";

Next define a function to count how many times each of our letters appears in a given string. Also run this function on our letters, to count how many of each we have.
lettercount[str_]:=StringCount[str,#]&/@Characters[letters];
mylettercounts=lettercount[letters];

Next consider where our new word could start and finish. It can't start immediately to the right of an existing letter, nor can it finish immediately to the left of an existing letter.
cantstarthere=StringPosition[row,Except["".""]][[All,1]]+1;
startpoints=Complement[Range[14],cantstarthere];
cantendhere=cantstarthere-2;
endpoints=Complement[1+Range[14],cantendhere];

Now that we have the list of valid start and end points, construct a list of substrings of row that could become our new word. It is also handy to keep note of what the start point is for each one. An additional constraint is that our new word must include one of the existing letters, so we remove any substrings of row which are all dots.
subrows=Flatten[Table[{m,StringTake[row,{m,n}]},{m,startpoints},{n,Select[endpoints,#>m&]}],1];
subrows=Select[subrows,Not@StringMatchQ[#[[2]],"".""..]&];

Now convert each substring of row into a regular expression, replacing each dot with ([any of our letters]).
starts=subrows[[All,1]];
regexes=StringReplace[subrows[[All,2]],"".""->""([""<>letters<>""])""];

Next we search the dictionary for any words matching the regular expression. A slight wrinkle is that we might have used one of our letters twice, so we use the regular expression again in StringCases to pick out which letters were used to match the ([any of our letters]) templates. We use this information to weed out any words which we can't actually make.
results=Table[
reg=regexes[[j]];
possiblewords=DictionaryLookup[RegularExpression[reg]];
lettersused=Flatten[StringCases[#,RegularExpression[reg]->""$1$2$3$4$5$6$7""]&/@possiblewords];
okay=(Max[(lettercount[#]-mylettercounts)]<1)&/@lettersused;
{starts[[j]],Pick[possiblewords,okay]}
,{j,Length[regexes]}];

Finally do a bit of tidying up, and present the words we can make along with their start points.
Column[DeleteDuplicates[Flatten[#]]&/@SplitBy[Select[results,#[[2]]!={}&],First]/.{a_Integer,b__}:>Rule[a,{b}]]


1->{dolt,plot}
2->{apt,dot,lit,lot,oat,opt,pat,pit,pot}
3->{at,it}
4->{tat,tot,total}
6->{ta,ti,to,tad,tap,til,tip,top,tapir}
8->{air,oar,par,lard,lira,lord,para,parade,parole,paroled}
9->{or,pro,drape,pride,prole}
10->{rape,ride,rile,ripe,rode,role,rope,raped,riled,riped,roped}
12->{lea,led,lei,pea,deal,deli,lead,leap,peal}

"
string manipulation - Thousands separator (comma) option for NumberString/StringCases?,"
This is admittedly a bit of a hack, but you could remove the commas first, using StringReplace:
StringCases[
 StringReplace["" 1,142.123 "", "","" -> """"], 
 Whitespace ~~ NumberString ~~ Whitespace, 1]

(* ==> {"" 1142.123 ""} *)

"
syntax - Constructing a Summation with a Variable Number of Inner Sums,"
Let's concentrate on the inner multiple sum. First note that we know d because it is given from the outer sum. If we want to write the expression 
$$-\exp\left[k_1+k_2+\ldots+k_d\right]$$
in Mathematica we could do this very easy. First we create the list {k[1],k[2],...,k[d]} and remember, that this is internally nothing more than List[k[1],k[2],...,k[d]]. If we would now replace the List head with Plus, then it is exactly what we want. For this we can use Apply which is written @@ in infix notation. That leaves how to create the {k[1],k[2],...,k[d]} list. Here we can use Table or Array or we think of it as _mapping the function k over the list {1,2,...,d}. This can be written as
k /@ Range[d]

for a known d. All together this gives
Exp[-Plus @@ k /@ Range[d]] 

Now we need to build a multiple Sum, summing over d different k. Again, this can be done in several ways. One way is to create a function which gets as arguments the indices for a Sum
f = Function[Sum[1, ##]]

I only use 1 in the sum for the sake of simplicity.
You may ask now, what this ## is: it's the sequence of all arguments given to f.  So lets try it:
In[63]:= {Sum[1, {3}], f[{3}]}

Out[63]= {3, 3}

In[62]:= {Sum[1, {3}, {5}], f[{3}, {5}]}

Out[62]= {15, 15}

Seems to work. The only think which is left now, is to create the ranges {k[i],1,q} where i is always a concrete number. Here we can use again the trick with Range and for a known d this gives a list of ranges:
{k[#], 1, q} & /@ Range[d] 

(* For d = 3 for instance
Out[64]= {{k[1], 1, q}, {k[2], 1, q}, {k[3], 1, q}}
*)

The last thing is to think about, that our Sum function needs a Sequence of arguments and the above is a List. But we already solved the problem of replacing the List with something different by using @@. This gives all together:
Sum[Exp[-Plus @@ k /@ Range[d]], ##] & @@ ({k[#], 1, q} & /@ Range[d])

Don't be afraid of the expression, because now you know every single piece of it and you know what every piece does. You could try it by for instance
With[{d = 4},
 Sum[Exp[-Plus @@ k /@ Range[d]], ##] & @@ ({k[#], 1, q} & /@ Range[d])
 ]

and get $$\frac{e^{-4 q} \left(e^q-1\right)^4}{(e-1)^4}$$ or you use this to plant it directly into your outer sum
mysum[p_Integer] := 
 Sum[Exp[-d]*
     Sum[Exp[-Plus @@ k /@ Range[d]], ##] & @@ ({k[#], 1, q} & /@ 
     Range[d]), {d, 1, p}]

I put it into a function mysum, because p needs to be a number to make all the Ranges work. Now you should check mysum[2]
$$\frac{e^{-2 q-2} \left(e^q-1\right)^2}{(e-1)^2}+\frac{e^{-q-1}
   \left(e^q-1\right)}{e-1}$$
"
reference request - What Mathematica book to buy?,"
After having used Mathematica for a couple of years, more or less only to abuse it as a neat plotting and integral solving engine, Leonid Shifrin's Mathematica Programming was my first book that brought me closer to actually understanding how Mathematica works. I soon lost my fear of # & @ @@ @@@ /@ //@.
(Plus the book is free, and if you still need help: Leonid is a regular on this site.)
"
list manipulation - Counting elements skipped using Reap & Sow,"
If you want to count the dropped values, for each application of your distance function you have exactly one outcome. Either the value is fine and included in you list or the value is dropped. 
In my opinion a simpler approach is to not use Reap and Sow. Instead, use a simple Map and transform the list afterwards. Furthermore, you have to note that your first element is always dropped because you set z to your first element of the list and get zero in the numerator of your distance function.
Maybe a better approach is here to not include the first element of the list manually but to fix the initial value of z. If your data is always positive, you could do for instance
Block[{z = First[data]/(2 + delta)},
 If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data
 ]

Test this in comparison with your function:
data = {7, 1, 8, 9, 6, 3, 1, 2, 4, 3, 7, 9, 2, 7, 3, 9, 7, 1, 10, 3};
delta = .4;

Block[{z = First[data]/(2 + delta)},
 If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data
]

(* 
{7, 1, 8, Dropped, Dropped, 3, 1, 2, 4, Dropped, 7, Dropped, 2, 7, 3, 
 9, Dropped, 1, 10, 3}
*)

Now the only thing you have to do is to gather all Dropped symbols, count them and give the other list as your result:
myfilter[data_] := {#1, ""Dropped"" -> Length[#2]} & @@
  GatherBy[Block[{z = First[data]/(2 + delta)},
    If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data
    ], # === Dropped &]

and then
In[68]:= myfilter[data]

Out[68]= {{7, 1, 8, 3, 1, 2, 4, 7, 2, 7, 3, 9, 1, 10, 3}, 
 ""Dropped"" -> 5}

Update
If you want to build a list where you see where and how many drops happened you could leave out the GatherBy thing and work on the number list with the Dropped inside. Example:
data = {7, 1, 8, 9, 6, 3, 1, 2, 4, 3, 7, 9, 2, 7, 3, 9, 7, 1, 10, 3};
delta = .4;

res = Block[{z = First[data]/(2 + delta)}, 
 If[Abs[# - z]/z > delta, z = #; z, Dropped] & /@ data]

Split[res, #1 === #2 === Dropped &] /. 
   {{i_Integer} :> i, d : {Dropped ..} :> {Length[d]}}

(*
{7, 1, 8, {2}, 3, 1, 2, 4, {1}, 7, {1}, 2, 7, 3, 9, {1}, 1, 10, 3}
*)

I packed the drop-length information inside list braces so one sees what is output and what is drop-information.
Note, when I see this right the second argument to Split is not necessary because it cannot happen that there are same numbers next to each other. 
"
Constructing a function with Flat and OneIdentity attribute with the property that otimes[a]:>a,"
I see now. The problem arises with Flat then. Just set the attributes after setting the definitions. Or at least the Flat attribute
ClearAll[otimes];
SetAttributes[otimes, OneIdentity]
otimes[a_] := a
SetAttributes[otimes, Flat]

Check out this answer for more details on why this works.
Basically, MMA remembers if the symbol was Flat or not at the time each DownValue is defined. The infinite recursion is more related to this:
SetAttributes[f, Flat];
Replace[Hold@f[2], Hold@f[i_] :> Hold[i]]

So, when you did otimes[2] and it checked the otimes[a_]:=a downvalue, it matched a with otimes[2], so you got your infinite recursion
"
output formatting - Functions in a different context are replaced with infix forms of their namesake in System`,"
It seems like the StandardForm (default for output) of Times in any context (or Plus, etc) is with the * and + symbols.
But your assumption isn't wrong I think, the symbols * and + are mapped to System Times and System Plus. Try
PrependTo[$ContextPath, ""blo`""];
blo`Times[a_, b_] := 8;

FullForm@MakeExpression[RowBox[{""a"", ""*"", ""b""}], StandardForm]

I think that this goes against Mathematica policy that ""StandardForm generates output that gives a unique and unambiguous representation of Mathematica expressions, suitable for use as input""
"
syntax - What does the slash-colon symbol do?,"
/: is the short-hand notation for TagSetDelayed, which is creating UpValues.  It's useful for over-loading how a particular function behaves with a specific head.  For example:
In[1]:= h /: Plus[x : h[arg1_, arg2_], y : h[arg3_, arg4_]] := Plus[arg1, arg2, arg3, arg4]

In[2]:= h[1, 2] + h[3, 4]
Out[2]= 10

The benefit being you don't have to Unprotect[Plus] to set the definition, and if you Remove[h] this definition will be wiped out as well.
"
recursion - Solving recurrence relation using Mathematica defined in a piecewise way,"
This works:
RSolve[{
  p[1] == l p0/m,
  p[n + 1] == l /(2 m) p[n]},
  p[n], n]
 (*
  -> {{p[n] -> 2^(1 - n) (l/m)^n p0}}
 *)

(The overspecification of p[0] and p[1] is not to the taste of RSolve)
Another way:
k[0] = k0;
k[1] = l k[0]/m;
k[i_] := l k[i - 1]/(2 m) /; i > 1;
FindSequenceFunction[Table[k[i], {i, 1, 10}], n]
(*
-> 2^(1 - n) k0 (l/m)^n
*)

Edit
Reader, beware! As of v8.0, RSolve and FindSequenceFunction are both immature implementations (I think), and there a lot of cases where the output is just the input.
"
Connecting to a remote machine,"
From your update, your situation is very similar to mine, where I can connect to hostA through the internet, but to hostB only via hostA. Here is the pared down settings from my ~/.ssh/config that you can adapt to your machines:
Host hostA
    HostName hostA.school.edu
    User rm
    ForwardX11 yes
    ForwardX11Trusted yes       
    ControlMaster auto
    ControlPath ~/.ssh/control:%h:%p:%r

Host hostB
    Hostname hostB.school.edu
    User rm
    ProxyCommand ssh -T -a hostA nc %h %p

Here, using ControlMaster and ControlPath lets you tunnel all subsequent connections to hostA via an existing connection. So this means that you need to have only 1 open connection (need password, if not using keys) and you needn't enter your password again as long as that session is alive (extremely convenient and useful in general!).
The second, using ProxyCommand allows you to login to the second through the first. So if you have one open connection to hostA, you can then simply ssh hostB on your local machine and the connection will automatically be routed through hostA. Now if you didn't set up ControlMaster and ControlPath, you'll have to enter 2 passwords — one for hostA and another for hostB.
"
evaluation - Speeding up mathematica by subsitituting numerical values,"
I await a more complete question, but for now my best guess is:
a = 0.5; b = 0.2;

Do[N[.95*a + (1. - .95) b], {1*^5}] // AbsoluteTiming


{0.0670038, Null}


Do[N[k*a + (1. - k) b /. k -> .95], {1*^5}] // AbsoluteTiming


{0.3310190, Null}


With[{k = 0.95},
  Do[N[k*a + (1. - k) b], {1*^5}]
] // AbsoluteTiming


{0.0800046, Null}


With on the outside does the replacement before evaluating the Do loop.

Seeing your application I can recommend another considerable improvement.  Even in your new form, With is inside Plot and reevaluated many times.  If you force this to evaluate first it will be much faster.  Here are three ways to do that, take your pick:
Plot[#, {x, 0., 1.}] & @ With[{k = x}, Mean[k*m1 + (1. - k)*m2]]

Plot[Evaluate @ With[{k = x}, Mean[k*m1 + (1. - k)*m2]], {x, 0., 1.}]

Plot[With[{k = x}, Mean[k*m1 + (1. - k)*m2]], {x, 0., 1.}, Evaluated -> True]

Please note two things:

In each case above the global symbol x is not localized, as a result of the pre-evaluation.  If it is possible to vary k directly, e.g. Plot[... {k, 0, 1}] you should probably do it.
Because of the pre-evaluation you will find that the various lines are now styled in different colors.  See this question and answers for an explanation.  If you want uniform color lines add the option PlotStyle -> ColorData[1][1] to Plot.

"
plotting - Shading between polar graphs,"
You have a (or more) curves. If you don't use PolarPlot you could use ParametricPlot instead but you would have to make the transformation from polar coordinates by yourself.
Knowing this, you could think about what your functions mean. For instance 2 (1 - Cos[phi]) is just the radius of your curve for a given phi. If you want to draw the region outside your curve, the only thing you have to do is (attention, I'm mixing polar and Cartesian coord.):
Check a every point $\{x,y\}$ whether the radius $\sqrt{x^2+y^2}$  is larger than $2(1-\cos(\varphi))$  where $\varphi=\arctan(y/x)$.
Using this, your filling can be achieved with RegionPlot and your graphics
Show[
 PolarPlot[Evaluate[{{1, -1} Sqrt[2 Cos[t]], 
   2 (1 - Cos[t])}], {t, -\[Pi], \[Pi]}],
 RegionPlot[
  Sqrt[x^2 + y^2] > 2 (1 - Cos[ArcTan[x, y]]) &&
  Sqrt[x^2 + y^2] < Re@Sqrt[2 Cos[ArcTan[x, y]]]
  , {x, -2, 2}, {y, -3, 3}],
 PlotRange -> All
 ]


If you encounter dark mesh lines in the filling and want to get rid of them, please read the question of david here. You then have to include 
Method -> {""TransparentPolygonMesh"" -> True}

as option.
"
programming - Iteration of a function,"
J.M.'s comment points you in the direction of why this doesn't work. Iterating $x^7$ 50 times (even if $k=0$) is $(x^7)^{50}$.
(x^7^50)

(* x^1798465042647412146620280340569649349251249 *)

That exceeds the maximum number representable in Mathematica: 
In[1]:= $MaxNumber

Out[1]= 5.297557459040040*10^323228467

Even if we considered $x^2 + k$ instead of $x^7 + k$, it will still overflows.
ff[x0_, k_] := NestList[ #1^2 + k &, x0, 50]

In[10]:= ff[1., 0.1]


 During evaluation of In[10]:= General::ovfl: Overflow occurred in computation. >>


Out[10]= {1., 1.1, 1.31, 1.8161, 3.39822, 11.6479, 135.773, 18434.5, 
 3.39832*10^8, 1.15486*10^17, 1.33369*10^34, 1.77873*10^68, 
 3.16389*10^136, 1.00102*10^273, 1.002046001003433*10^546, 
 1.004096188126972*10^1092, 1.008209155011116*10^2184, 
 1.016485700248229*10^4368, 1.033243178809133*10^8736, 
 1.067591466555603*10^17472, 1.139751539462343*10^34944, 
 1.299033571706781*10^69888, 1.687488220421276*10^139776, 
 2.847616494060564*10^279552, 8.108919697245777*10^559104, 
 6.575457865638055*10^1118209, 4.323664614278137*10^2236419, 
 1.869407569676091*10^4472839, 3.494684661562269*10^8945678, 
 1.221282088375859*10^17891357, 1.491529939387699*10^35782714, 
 2.224661560089872*10^71565428, 4.949119056941505*10^143130856, 
 2.449377943978157*10^286261713, Overflow[], Overflow[], Overflow[], 
 Overflow[], Overflow[], Overflow[], Overflow[], Overflow[], 
 Overflow[], Overflow[], Overflow[], Overflow[], Overflow[], 
 Overflow[], Overflow[], Overflow[], Overflow[]}

Of course, if you have a starting value $x0<1$, your original function is fine, and converges quickly. 
In[12]:= ff7[x0_, k_] := NestList[ #1^7 + k &, x0, 50]

In[13]:= ff7[0.5, 0.1]

Out[13]= {0.5, 0.107813, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, \
0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, \
0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, \
0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1}

Power values below 1 are also fine: 
In[16]:= ff2[x0_, k_] := NestList[ #1^0.8 + k &, x0, 50]

In[17]:= ff2[1., 0.8]

Out[17]= {1., 1.8, 2.40036, 2.81475, 3.08851, 3.2649, 3.37689, \
3.44736, 3.49147, 3.51898, 3.53611, 3.54676, 3.55338, 3.55748, \
3.56003, 3.56162, 3.5626, 3.56321, 3.56359, 3.56382, 3.56397, \
3.56406, 3.56411, 3.56415, 3.56417, 3.56418, 3.56419, 3.56419, \
3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, \
3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, \
3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642, 3.5642}

But in this case, I question why keeping the last ten iterations makes any sense. The function will have converged by then. It is behaviour of the first ten iterations that is more interesting.
"
plotting - Show parameters on graph,"
The following is what you get using the code posted in my answer linked here:
All you have to do is make the plot, and call the function autoLegend I defined in the link:
styles = {Black, Directive[Dashed, Black], 
  Directive[DotDashed, Black], Directive[Dotted, Black]}
parameters = {1/2, 1/3, 1/5, 1/1000};
p = Plot[Evaluate[
    PDF[ExponentialDistribution[#]][x] & /@ parameters], {x, 0, 50}, 
   AxesOrigin -> {0, 0}, PlotStyle -> styles];
autoLegend[p, parameters]


"
plotting - Plot curves different way so that one can see them when printing black and white,"
In addition to Dashing, there are also DotDashed and Dotted line styles. So you could define a set of plot styles as follows, varying first the dashing and second the gray shade:
styles = Flatten@
  Table[{Directive[color], Directive[Dashed, color], 
    Directive[DotDashed, color], 
    Directive[Dotted, color]}, {color, {Black, Gray}}]

Then the plot that is supposed to be printed in black and white would be created by this:
p = Plot[Evaluate[
   PDF[ExponentialDistribution[#]][x] & /@ {1/2, 1/5, 1/25, 
     1/1000}], {x, 0, 50}, AxesOrigin -> {0, 0}, PlotStyle -> styles]


"
combinatorics - Mathematica function/package for shuffle permutations,"
1) The number of all (p,q) shuffles is
Binomial[p+q,p]

since when you chose the first p elements, the whole thing (and its order) is given.
2)The actual shuffles are given by: (See JM's comment below*)
With[{x = Range@#1}, {#, Complement[x, #]} & /@ Subsets[x, {#2}]] &[p + q, p]

Example:
p = 3; q = 2;
With[{x = Range@#1}, {#, Complement[x, #]} & /@ Subsets[x, {#2}]] &[p + q, p]

(*
->
{{{1, 2, 3}, {4, 5}}, {{1, 2, 4}, {3, 5}}, {{1, 2, 5}, {3, 4}}, {{1, 3, 4}, {2, 5}}, 
 {{1, 3, 5}, {2, 4}}, {{1, 4, 5}, {2, 3}}, {{2, 3, 4}, {1, 5}}, {{2, 3, 5}, {1, 4}}, 
 {{2, 4, 5}, {1, 3}}, {{3, 4, 5}, {1, 2}}}

3) The sign of each permutation (for the above shuffles) is given by:
Signature/@ With[{x=Range@#1}, Join[#, Complement[x, #]] & /@ Subsets[x, {#2}]] &[p+q,p]

Example:
p = 3; q = 2;
Signature/@ With[{x=Range@#1}, Join[#, Complement[x, #]] & /@ Subsets[x, {#2}]] &[p+q,p]
(*
-> {1, -1, 1, 1, -1, 1, -1, 1, -1, 1}
*)

"
Plotting the results of iterating a function,"
There is no a in your definition of the function w[], so it's no wonder that you can't get it to work. 
You could try the following, but you would hit the same Overflow problems as in your previous question.
w[a_] := Take[NestList[f[a], 0, 1000], 100]

I would suggest an alternative approach using NestWhile: 
w[a_] := NestWhile[f[a], 0, Abs[#] < 1000. &, 1, 100]

You will only get the ""last"" element in the iteration, defined either as the 100th iteration - it will have converged by then if it was going to - or the last iteration before the absolute value of the result broke through 1000 (i.e. it was diverging). That way, you break out before the iteration overflows.
You can then get your list of results using the Table function (notice I've also preserved the values of $a$, which I've labeled $i$ for the purpose of defining the iteration in the table, so the values of the $a$ parameter are shown correctly in the subsequent plot:
result=Table[{i, w[i]}, {i, -0.2, 1.8, 0.01}];

And plot using ListLinePlot:
ListLinePlot[result, PlotRange -> All, Frame -> True, AxesOrigin -> {0, 0}]


One thing I would mention is that it's not clear whether you should focus on a single starting point. You could instead define:
ff[a_, x0_] := NestWhile[#^2 + a &, x0, Abs[#] < 100. &, 1, 100]

And construct your results as:
result = Table[{i, ff[i, 0.1]}, {i, -0.2, 1.8, 0.01}];

You could then even have a two dimensional table:
result2 = Flatten[
  Table[{i, j, ff[i, j]}, {i, -0.2, 1.8, 0.01}, {j, -0.2, 0.9, 0.1}],  1];

Which you could visualise using ListDensityPlot:
ListDensityPlot[result2]


"
programming - How to avoid conflicts between local variable names and symbolic arguments in Block constructs?,"
If you don't want to have the Module inside the function, you can also put it around the function, and then use Block inside, as in
Module[{s,r},
  f[param_List]:=Block[{s = First[param], r = Rest[param]}, ... ]
]

However, for this special case, I'd use the abilities of the pattern matcher:
f[{s_,r___}] := ...

"
programming - Using Apply inside Compile,"
First question : With accepts a syntax like
  With[{var:=value}, expression]

in which case, value is injected into expression unevaluated. As far as I know, this syntax is not documented. You can achieve a similar effect with the replacement rules, by using 
Unevaluated[expression]/.HoldPattern[var]:>value

There are some subtle differences between the semantics of With and repalcement rules though, mostly related to the treatment of nested scoping constructs and variable name conflicts in them. 
Second question: vars appear twice because they must first be Block-ed, and then there is a massive assignment to them performed in the body of the Block. This is probably the most economical way of blocking a number of variables and assigning values to them simultaneously - otherwise a more complex code-generation will be needed. You can see another example of that in   this answer (and if you look at the revision history for that answer, you can find an alternative, harder way to do this, in one of the previous revisions).
Third question: this does not work because the apply function was made HoldAll (which isn't quite necessary), and the pattern-matching does not work. There were some past discussions on this topic on SO, but can't find them right now. But I discussed this topic at length also in my book. The idea is that at the pattern-matching time, all seen by apply is a variable objectiveFunction, and because it does not evaluate it, the pattern _CompiledFunction is not matched. The solution is to make apply HoldRest, and then it works:
ClearAll[apply];
SetAttributes[apply, HoldRest];
apply[...]:=...

"
programming - Question about collections of custom GUI controls for Mathematica,"
One of the excellent places to look is the Wolfram Demonstration Project. There are many cases with custom controls there. You can test out controls immediately and download the source code. Because I know that site pretty well I will keep the list here. 
Relief-Shaded Elevation Map

3D Waves

Potter's Wheel

Motion Blur

Contours of Algebraic Surfaces

Polar Area Sweep

Color Quantization... Tracing Contour... Creating Posters...

Relationship between the Tone Curve and the Histogram of a Photographic Image

Complex nested controls: Two-Dimensional Block Cellular Automata with a 2×2 Neighborhood

Interesting type - the content is the control: Block Builder

Constrained locators: Sweet Heart

"
plotting - How to plot a curve with border around the line?,"
You could plot the curve twice, with two different styles:
Plot[{Sin[x], Sin[x]}, {x, 0, 2 Pi}, 
     PlotStyle -> {Directive[Thickness[0.03], White], Black}]


Changing the background to gray:
Plot[{Sin[x], Sin[x]}, {x, 0, 2 Pi}, 
     PlotStyle -> {Directive[Thickness[0.03], White], Black}, 
     Background -> Gray]


"
programming - Bifurcation Diagram for 1D Map,"
Perhaps you are looking to build a bifurcation diagram. There are a few approaches in Mathematica mentioned in Documentation, which I give below. Also please take a look at apps of similar nature at the Wolfram Demonstration Project. I do not have time to dive into your specific problem, and give classic examples of logistic map which also a quadratic function.
Simplest way
ListPlot[ParallelTable[Thread[{r, Nest[r # (1 - #) &, 
Range[0, 1, 0.01], 1000]}], {r, 0, 4, 0.01}], PlotStyle -> PointSize[0]]


Using RecurrenceTable
k = 1000; r = Range[3., 4., 1/(k - 1)];
rhs[x_?VectorQ] := r x (1 - x);
iterates = RecurrenceTable[{x[n + 1]==rhs[x[n]], x[0] ==ConstantArray[1./\[Pi], k]}, 
           x, {n, 10^4, 2 10^4}];
data = Transpose[Ceiling[iterates k]];

count[data_, i_] := Module[{c, j},
   {j, c} = Transpose[Tally[data]];
   Transpose[{j, ConstantArray[i, Length[j]]}] -> Log[N[c]]];

S = SparseArray[Table[count[data[[i]], i], {i, k}], k];
ArrayPlot[Reverse[S], ColorFunction -> ""Rainbow""]


Structuring data for ArrayPlot
line[r_, dy_, np_, n0_, n_] := Module[{pts},
  With[{logistics = Function[x, r x (1 - x)]}, 
  pts = Join @@ NestList[logistics, Nest[logistics,RandomReal[{0, 1},np],n0],n - 1]];
  Log[1.0 + BinCounts[pts, {0, 1, dy}]]]

    With[{w = 400, h = 250, r0 = 2.95, r1 = 4.0}, 
     ArrayPlot[ParallelTable[line[r, 1/(w - 1), w, 500, 50], 
     {r, r0, r1, (r1 - r0)/(h - 1)}], ImageSize -> {w, h}, PixelConstrained -> True]]


"
Export Plots to $\LaTX$ - Mathmatica Stack Exchang,"
I usually Export to hi-res PNG bitmaps for ease of use (there are a number of discussions on how best to export high-quality images on this forum. Take a peek at the right column of this page under ""Related""). Personally I like notebooks that do not need any mouse-clicking or any other user interaction to produce output which makes reruns that much more comfortable and and most of all reproducible.
For ease of use when dealing with many different graphics I prepare a notebook for each of these and also generate the LaTeX code for insertion in my document. The graphics get their name from the notebook so you can easily spawn different versions by renaming the notebook. 
plot = Plot[Sin[x], {x, 0, 10}]


(*gfxname = StringTake[FileNameSplit[NotebookFileName[]][[-1]], {1, -4}]*)

EDIT: more concise and portable:
gfxname = FileBaseName[NotebookFileName[]]


""2012-05-04_Plot_Export""

Export[gfxname <> "".png"", plot];

StringReplace[""\\begin{figure}[!htb]\\centering
 \\includegraphics[width=1\\textwidth]{XXX}
 \\caption{Put your caption here.} 
 \\label{fig:XXX}
 \\end{figure}
 "", ""XXX"" -> gfxname]

The resulting output can be copied as plaintext or you might even splice it directly into your document (although this is a bit much for casual use).
\begin{figure}[!htb]\centering
\includegraphics[width=1\textwidth]{2012-05-04_Plot_Export}
\caption{Put your caption here.} 
\label{fig:2012-05-04_Plot_Export}
\end{figure}

"
color - Is there a way to access the (lexically) current colour inside Graphics?,"
CurrentValue[""Color""] seems to be doing the trick (not documented).
mydisk[p_, r_] := {Dynamic[EdgeForm[Darker[CurrentValue[""Color""]]]], 
  Disk[p, r]}

Dynamic is needed because the value has to be evaluated by FrontEnd at the time of rendering. Here is the result:
Graphics[{EdgeForm[AbsoluteThickness[10]], Red, mydisk[{0, 0}, 1], 
  Green, mydisk[{1, 1}, 1]}]


CurrentValue is like a box of chocolate. It has a lot of features (mostly FE callbacks), many undocumented, but usually a very present surprise when it works.
A few other items that work with CurrentValue: ""Thickness"", ""Opacity"", ""Dashing"", ""FontFamily"", ""FontSize"", ""FontSlant"", ""FontWeight"", ""FontColor"" and ""FontOpacity"".
"
education - Some way to identify the source of a notebook file?,"
Mathematica notebook files are plain text files.  This means that you can open them up with a text editor and check their contents.
Notebook files don't seem to contain any information that could be used to track their source (the computer on which they were created).  What it does contain, and you might be able to use, is the creation and modification dates of all cells (CellChangeTimes cell option).
You can access this information using the Front End as well.  Go to Cell -> Notebook History....  It will give you a window that will show the modification times of each cell (an interval for each single edit that happened in the notebook's lifetime), to 1-second precision.  You can click a line in the graph view to select that cell and see the creation and last modification time, or you can click ""Copy raw data"" to get all the data (use DateList to convert them to something more human readable from the AbsoluteTime format).
If two homework submissions have the same modification times, up to the second, then it's likely they have a common source.
With a bit of programming you can automate the process of checking all submissions against each other, and selecting those whose first few modification times coincide.
"
front end - Text replacement rules in $FrontEnd?,"
Normally you could use:
SetOptions[$FrontEndSession,
  InputAutoReplacements -> {""<-"" -> ""\[LeftArrow]""}
]

But this fails because Mathematica already parses <- differently.  Specifically the documentation states:

In expression input, automatic replacements can be performed only on strings of characters that correspond to complete input tokens. 

You can see that this setting works for other strings, e.g.:
SetOptions[$FrontEndSession,
  InputAutoReplacements -> {""stuff"" -> ""\[LeftArrow]""}
]

Then typing (with a space):
x stuff 

Will render:
x \[LeftArrow] 

"
Using function with multiple definitions in Manipulate,"
As already explained: MatchQ[0, 0.] is False.
Generally, I suggest using:
boxcox[data_, x_ /; x == 0] := Log[data]

This works even for expression that are not expressly 0 or 0., e.g.:
MatchQ[E^(I Pi/4) - (-1)^(1/4), x_ /; x == 0]


True


It also works in cases like this:
MatchQ[0.0000000000000000000, x_ /; x == 0]


True


Compare:
MatchQ[0.0000000000000000000, 0 | 0.]


False


"
programming - Finding a percolation path,"
A percolation network is just a kind of network, so I went in the direction of proposing a graph-theoretic approach. You seem to be measuring distances between nodes multiple times, but given the points don't move, you need only do it once:
ed = Outer[EuclideanDistance, randPts, randPts, 1];

You can get the positions of the nodes you are trying to connect like so:
leftmost = Position[randPts, {Min[randPts[[All, 1]] ], _}][[1, 1]]

rightmost = Position[randPts, {Max[randPts[[All, 1]] ], _}][[1, 1]]

Here is an auxiliary function that determines which nodes are no more than r distance from each other. I exclude zero distances to avoid the complication of self-loops.
linked[mat_?MatrixQ, r_?Positive] := Map[Boole[0 < # < r] &, mat, {2}]

It is easy to use this auxiliary function to create an adjacency matrix which can be visualised with the correct coordinates using the VertexCoordinates option.
gg = AdjacencyGraph[linked[ed, 2.], VertexCoordinates -> randPts]


Finding out whether the left-most and right-most points are connected is a matter of determining if FindShortestPath yields a non-empty result.
FindShortestPath[gg, leftmost, rightmost]
(* ==> {56, 16, 126, 156, 142, 174, 65, 49, 23, 88, 6, 45, 122, 68, 131, 139, 80} *)

Let's put all this together. I am going to build the option to test if the network is a percolation network in the same function that visualises the network.
Options[isPercolationNetwork] = {ShowGraph -> False}

isPercolationNetwork[points : {{_?NumericQ, _?NumericQ} ..}, 
  r_?Positive, opts : OptionsPattern[]] :=
  Module[{ed = Outer[EuclideanDistance, points, points, 1], 
   leftmost =  Position[points, {Min[points[[All, 1]] ], _}][[1, 1]], 
   rightmost = Position[points, {Max[points[[All, 1]] ], _}][[1, 1]]},
  With[{gg =  AdjacencyGraph[linked[ed, r], VertexCoordinates -> points]},
   If[OptionValue[ShowGraph],
    HighlightGraph[gg, PathGraph[FindShortestPath[gg, leftmost, rightmost]]], 
    Length[FindShortestPath[gg, leftmost, rightmost] ] > 1]]
  ]

If the option ShowGraph is True, it shows the graph and the connecting path; if it is False, it just returns True or False.
isPercolationNetwork[randPts, 2., ShowGraph -> True]


It is pretty straightforward to put all this together to find the minimum distance to create a percolation network.
minimumPercolationNetwork[points:{{_?NumericQ, _?NumericQ}..}, r0_?Positive] :=
 Module[{r = r0},
  While[isPercolationNetwork[randPts, r], r = r - 0.01]; 
  Print[r + 0.01]; 
  isPercolationNetwork[points, r + 0.01, ShowGraph -> True] ]

And the result:
minimumPercolationNetwork[randPts, 3.]


1.97



Execution is reasonably fast: Timing of the above example was a bit above 6s on my machine, but it depends on the initial value you pick for r.
"
list manipulation - Recursion on a moving window,"
From your question, it looks like you need to implement some form of a linear predictor and step forward in time starting with an initial state. The solution is still the same as my previous version — i.e., using Nest, but it's now written in a clearer form:
predict[samples_] := Total[samples] (* Replace Total with your function *) 
step[state_, n_: 2] := state ~Join~ {predict[state[[-n ;;]]]}
Nest[step[#, 3] &, initialState, 10] (* enter your lag (here 3), initialState, iterations *)

An example to generate the Fibonacci series with the above:
Nest[step, {0, 1, 1}, 10]
(* {0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144} *)


Original answer:
You can do it easily with NestList:
NestList[myFunction, initialState, 5]
(* {{1, 2, 3}, {2, 3, 1}, {3, 1, 3}, {1, 3, 3}, {3, 3, 5}, {3, 5, 5}} *)

"
coding style - Are these nested Tables necessary?,"
No, they are not needed. You can specify as many ""iterators"" (the parameters of the form {x, xmin, xmax} or {x, xmin, xmax, dx}) as you wish. (See the last form list in the documentation.)  For example,
Table[i j, {i, 3}, {j, 3}]

produces
{{1, 2, 3}, {2, 4, 6}, {3, 6, 9}}

Additionally, any iterator can rely on those that came before it, but not those that come after it, in the list, e.g.
Table[i j, {i, 3}, {j, i, 3}]

gives
{{1, 2, 3}, {4, 6}, {9}}

while 
Table[i j, {i, j, 3}, {j, 3}]

generates the error
Table::iterb: ""Iterator {i,j,3} does not have appropriate bounds.""

"
syntax - Finding the position of a specific value in a list,"
You can use the Position function. Which returns a list of the positions of the pattern you are searching for.
k = RandomInteger[10, {10, 2}]
(* ->{{2, 10}, {9, 3}, {9, 10}, {8, 1}, {2, 0}, {10, 10}, {10, 0}, {10,6}, {3, 1}, {3, 2}} *)

Position[k, 3]

returns
{{2, 2}, {9, 1}, {10, 1}}

Which is a list of the indices of the three occurrences of 3 in the list, k.
"
"printing - How can parts of a list of lists be printed to the nb, at regular interval positions?","
You can select every 21st element using
mylist[[21;; ;; 21]]

You can print them using 
Do[Print[mylist[[i]]], {i, 21, 441, 21}]

Regarding memory, having these displayed in the Front End will take more memory than just having the data in kernel memory, so Print /@ mylist[[21;; ;; 21]] may be better.  Why do you want to print them?  If you're aim is to write to a file, there are other ways.
EDIT
To number the parts, you can use Do[Print[Style[i/21, Large]; Print[mylist[[i]]], {i, 21, 441, 21}]
"
performance tuning - How to read data file quickly?,"
For a one-off read you can Skip a number of records:
str = OpenRead[""test.tsv""];
Skip[str, Record, n - 1];
data = ReadList[str, {Record, Number, Record}, 100, RecordSeparators -> {""\t"", ""\n""}];
Close[str];

If you will be reading from the same file many times, it may be worth building an index you can use with SetStreamPosition
str = OpenRead[""test.tsv""];
index = Table[pos = StreamPosition[str]; Skip[str, Record]; pos, {100000}];

readlines[n_, m_] := Block[{},
SetStreamPosition[str, index[[n]]];
ReadList[str, {Record, Number, Record}, m, RecordSeparators -> {""\t"", ""\n""}]]

data = readlines[50000,100]

On my PC building the index took about half a second for 10^5 rows in the file, assuming it scales linearly this would be about a minute for 10^7 rows. So this is only worth doing if you are going to be doing a lot of reads.
"
grid layouts - Generating schedules/timetables in Mathematica,"
If you can put your schedule into a list like this:
schedule =  {
   {""Lundi"", ""09:30"", 1, ""Inorg 1"", ""N-515"", Lighter[Orange, 0.5]},
   {""Lundi"", ""10:30"", 1, ""Physique 4"", ""N-515"", Lighter[Cyan, 0.5]},
   {""Mardi"", ""9:30"", 2, ""Macromol 2"", ""G-815"", Lighter[Green, 0.3]},
   {""Mardi"", ""14:30"", 1, ""Inorg 1"", ""répet N-515"", Lighter[Orange, 0.5]}, 
   {""Mecredi"", ""9:0"", 2, ""Analytique 2"", ""G-815"", Lighter[Gray, 0.5]},
   {""Mecredi"", ""11:00"", 0.5, ""Inorg"", ""N-515"", Lighter[Orange, 0.5]},
   {""Mecredi"", ""12:30"", 1, ""Organique 3"", ""répet 1015"", Lighter[Yellow, 0.2]},
   {""Mecredi"", ""13:30"", 2, ""Physique 4"", ""G-615"", Lighter[Cyan, 0.5]},
   {""Jeudi"", ""9:30"", 1, ""Analytique 2"", ""G-615"", Lighter[Gray, 0.5]},
   {""Jeudi"", ""10:30"", 2, ""Organique 3"", ""répet 1015"", Lighter[Yellow, 0.2]},
   {""Jeudi"", ""14:00"", 2, ""Physique 4"", ""N-515"", Lighter[Cyan, 0.5]},
   {""Vendredi"", ""09:30"", 1, ""Macromol 2"", ""G-615"", Lighter[Green, 0.3]},
   {""Vendredi"", ""10:30"", 1, ""Organique 3"", ""G-615"", Lighter[Yellow, 0.2]}
   };

then a Manipulate like this:

isn't too difficult to make, just fiddly in places. Unfortunately, ""pretty"" isn't an easy word - much gets lost in translation... :) My attempt may be more to my taste than yours...
days = {""Lundi"", ""Mardi"", ""Mecredi"", ""Jeudi"", ""Vendredi""};
timeStringToDecimal[time_] := Module[
  (* 24 hour clock, of course *)
  {hours = 
    ToExpression[First[StringSplit[time, "":""]]], 
    minutes = ToExpression[Last[StringSplit[time, "":""]]]},
  N[hours + (minutes / 60)]]

eventStart[time_] := 
  timeStringToDecimal[time];

eventStarts = 
  With[{time = #[[2]]}, timeStringToDecimal[time]] & /@ schedule;

firstEvent = Min[eventStarts]; lastEvent = Max[eventStarts];

eventsForDay[day_] :=
  Select[schedule, #[[1]] == day &] ;

graphicsForEvent[event_, boxHeight_, opacity_, y_] := Module[
   {eventStartPoint = eventStart[event[[2]]],
    eventDuration = event[[3]],
    eventName = event[[4]], 
    eventLocation = event[[5]]},
   {event[[6]],
    Opacity[opacity],
    Rectangle[{eventStartPoint, y}, {eventStartPoint + eventDuration, 
      y + boxHeight}, RoundingRadius -> 0.1],
    Opacity[1],
    Black,
    Text[eventName,  {eventStartPoint + eventDuration /2, 
      y + (2 * boxHeight/3)}],
    Text[eventLocation, {eventStartPoint + eventDuration /2, 
      y + (boxHeight/3)}]
    }
   ];

Manipulate[
 yH = Length[days];
 g = Graphics[{
    Reap[
      Do[{
        (* background grid boxes - continue for an extra 2 hours *)
        Sow[Table[{Lighter[Gray, .9], 
              Rectangle[{t, yH }, {t + 0.45, yH + boxheight}]}, 
             {t, Floor[firstEvent], lastEvent + 2, 0.5}]];
        (* event boxes *)
        Do[
         Sow[
          graphicsForEvent[event, boxheight, opacity, yH]], 
           {event, eventsForDay[day]}];
          yH = yH - (boxheight + boxspacing )}, 
       {day, days}]][[2]]}, 
   BaseStyle -> {fontHeight, FontFamily -> ""Helvetica"", Bold}, 
   ImageSize -> 800, 
   Epilog -> 
    {
     Table[{Gray, 
       Line[{{x, Length[days] + boxheight}, {x, Length[days] + 1}}], 
       Text[x, {x + 0.1, Length[days] + (boxheight * 1.15)}]}, 
       {x, Floor[firstEvent], Ceiling[lastEvent] + 2}]
     }
   ],
 {opacity, 0.5, 1},
 {boxheight, 0.5, 1.5, Appearance -> ""Labeled""},
 {boxspacing, 0.1, 0.5, Appearance -> ""Labeled""},
 {{fontHeight, 10}, 7, 12, Appearance -> ""Labeled""},
 Button[""Export as PDF"", Export[""g.pdf"", g]],
 ContinuousAction -> False
 ]

"
debugging - Wolfram Workbench - Mathematica Development Alternatives,"
There are indeed some open source alternatives, as other posters have suggested, but you will miss the unique facilities of WB to develop state of the art documentation. So if you want to develop some serious work in MMA, for yourself or others, you should seriously consider WB. Having said that, I use WB in a (probably) unconventional way. Within WB you can select which editor you want to use for the various file types. The default being: editing the .m file with the internal WB editor. Well, I instead chose to edit the .nb (package) file using the standard front end (linked to WB), this action will automatically update the .m file and then use all the standard WB facilities to integrate documentation. In this way you have the all the cool front-end editing tools plus all the cool WB documentation and debugging tools at your disposal.
This technique is described in more detail in my answer in Managing formatted usage messages in Wolfram Workbench
"
plotting - Coloring Points in a List Plot,"
One way is to use Joined -> True and replace Line with Point afterwards:
ListPlot[RandomReal[1, {100, 2}], PlotStyle -> Thick, Joined -> True, 
  ColorFunction -> Function[{x, y}, Hue[(x + y)/2]]] /. Line[a__] :> Point[a]


"
programming - How do I access the name of a list in a function?,"
You need to use HoldForm instead of Hold.
Clear@f
SetAttributes[f, HoldAll]
f[data_?VectorQ] := f[data, ToString@HoldForm@data]
f[data_?VectorQ, name_?StringQ] := ""Save data as "" <> name

With this:
f[ape]
(* ""Save data as ape"" *)

f[ape, ""bird""]
(* ""Save data as bird"" *)

To get Null or False for f[ape+bear], you can use StringFreeQ[name, ""+""] to see if the input is of that form. Similarly, ""{"" for list arguments (no need to check for ""}""). So the second definition for f above would be:
f[data_?VectorQ, name_?StringQ] := 
    If[StringFreeQ[name, ""+"" | ""{""], ""Save data as "" <> name, False]

f[{1, 2, 3}]
(* False *)

f[ape + bear]
(* False *)

"
vrsion 8 - Customiz startup - Mathmatica Stack Exchang,"
I find it easiest to create a Notebook with the features I want, and then open that Notebook to launch Mathematica.
Save this code as a .nb file.  If you want Mathematica to also open ""Maximized"" rather than in the slightly-less-than-Maximized form it usually does, also create a shortcut to this Notebook and change the properties to Maximized, then use that.
Notebook[{},
  Saveable->False,
  WindowSize->Scaled[1],
  WindowMargins->{{Automatic, 0}, {Automatic, 0}},
  Magnification->1.3,
]

"
Splitting a list at a particular position,"
This can be accomplished easily using Part ([[ ]]) and Span (;;), as follows:
data = {{x1, y1}, {x2, y2}, {x3, y3}, {x4, y4}, {xz, yz}};
data[[;; 3]]
data[[4 ;;]]

(* ->
{{x1, y1}, {x2, y2}, {x3, y3}}
{{x4, y4}, {xz, yz}}
*)

"
export - CDF file posted in WordPress won't run,"
I downloaded your notebook to my Download directory and opened it. The Download directory is unsafe. This is what it looked like:

So the reason why you get a grey box in your embedded CDF is that it is perceived as being unsafe.
Modify your code to this:
cdf.embed('http://www.abstractmath.org/Mathematica/Elaborate Riemann 
Example.cdf', 427, 536,{fullscreen:'true'});

and it will allow the enable dynamics button to appear. You can then switch on the dynamic content and the CDF will be treated as safe. This will get you to the next stage. Whether or not it will work after that will depend on what other things you have in your CDF -- i.e. as long as you have content that is allowed (no import/export etc.) it should work.
"
notebooks - Is it possible to embed the Mathematica editor?,"
Here is an idea - it's by no means perfect, but then again, the comments indicate that there won't be a perfect solution:

In your .NET application, create a web view (I don't know the details for this, but that would go beyond the scope of this forum anyway - I've done similar things in Cocoa on Mac, so you should be able to find analogous libraries for .NET)
As the URL for the web view, give the address of an HTML page with an embedded  Mathematica CDF notebook. This could mean simply using an <embed> tag, as described on Wolfram's web site. Here I'm talking about a HTML file stored locally with your .NET bundle.
Make sure you use the non-free version of a CDF (the one you get via Save As...). It should allow you to edit inside of it. 
Of course the next question is how to exchange data. That depends on what data you need. But basically, you can try to do it with Export (or Import) from the CDF. This is where the ""deployed"" free CDF will not work, but the non-free ones (requiring Mathematica to be installed) will, at least according to what I'm seeing on my machine. Then the .NET application would have to be notified when an exported file is ready to be passed to it. The CDF could accomplish that on its own, or you could have the .NET application monitor a certain data file (used by the CDF) for changes. 

Regarding the data exchange problem, see also this CDF related post.
"
How do I get VertexList to work directly on older graphs defined using rules?,"
The built-in function VertexList (or System`VertexList) requires that you input a graph object (i.e., something with the head Graph), whereas {a -> b} has the head List. So if you have a list of rules denoting the edges, then just wrap it in Graph for it to work. For example:
VertexList[Graph[{a -> b}]]    
(* {a, b} *)


The weird behaviour you see only when you load the GraphUtilities` package is because the package adds a definition to System`VertexList. Note that there is no such function as GraphUtilities`VertexList as you seem to assume in the question. 
If you browse $InstallationDirectory/AddOns/Packages/GraphUtilities/GraphUtilities.m you'll find the following in the code (line numbers in comments):
(* 449 *) u = Unprotect[{AdjacencyMatrix, EdgeList, VertexList}];   
(* 464 *) VertexList[x_?InternalGraphQ, r___] := With[{res = Network`GraphPlot`VertexList[x, r]},
(* 465 *)     res/;ListQ[res]];    
(* 483 *) Protect @@ u;    
(* 487 *) InternalGraphQ := Network`GraphPlot`GraphQ;

Essentially, the modification made is to simply call Network`GraphPlot`VertexList if your input is a list.
So to get a consistent behaviour for VertexList, you simply need to add the definition above and you needn't load GraphUtilities` just to get this behaviour.
"
"graphics - Using Mathematica or WebMathematica to develop interactive, crowdsourced timeline visualizations","
Since it appears that you wish to use live input for your Timeline, webMathematica will be the best solution.  CDF cannot accept anything but input from what is in the file itself. 
Documentation can be found here: http://www.wolfram.com/products/webmathematica/
User Guide is located here: http://reference.wolfram.com/mathematica/webMathematica/tutorial/Overview.html
"
front end - Automating Esc [[ Esc formatting?,"
Some approaches are discussed in this question on StackOverflow. Original references to these go to Szabolcs's webpage and a MathGroup posting by Mr.Wizard. 
To summarize, you copy the file: $InstallationDirectory/SystemFiles/FrontEnd/TextResources/Macintosh/KeyEventTranslations.tr to $UserBaseDirectory/ (with the same directory tree) and add the following modifications after EventTranslations[{ in the file:
Item[KeyEvent[""["", Modifiers -> {Control}],
        FrontEndExecute[{
            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],
                ""\[LeftDoubleBracket]"", After]
        }]],
Item[KeyEvent[""]"", Modifiers -> {Control}],
        FrontEndExecute[{
            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],
                ""\[RightDoubleBracket]"", After]
        }]], 
Item[KeyEvent[""]"", Modifiers -> {Control, Command}],
        FrontEndExecute[{
            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],
                ""\[LeftDoubleBracket]"", After],
            FrontEnd`NotebookWrite[FrontEnd`InputNotebook[],
                ""\[RightDoubleBracket]"", Before]
        }]], 

These provide the following shortcuts:

〚 using Ctrl+[
〛 using Ctrl+]
〚〛 using Ctrl+Cmd+]

Replace Command with Alt for Windows/Linux and modify the paths above accordingly. 
You can also try Andrew Moylan's suggestion, in the same post, but I haven't tried it.
"
Is it possible to make a variable wrapped in Dynamic non-dynamic?,"
You have the option of only updating the Dynamic object when a specified set of symbols changes, but all symbol values will update when an update is triggered.  For example:
a = 1; b = 2;
Dynamic[{a, b}, TrackedSymbols :> {a}]

Then evaluating b = 3; should not change the output.  Nevertheless, when you evaluate a = 4; you will get {4, 3} rather than {4, 2}.
You could use Dynamic only on the objects you want to be dynamic, e.g. {Dynamic[a], b}, but since this is an obvious solution there is presumably a problem with that.

Incorporating my comment for persistence:
If I understand your problem you can force evaluation of the symbols outside of Dynamic, e.g. Dynamic[{a, #}]& @ b will use the fixed value of b, assuming that b has a value at the time of evaluating that expression.
"
plotting - Mapping multiple parameters of a function to specific values,"
There are two main ways of accomplishing this, both have their merits, but Map may be easier to understand initially.  For instance, using (b/a)*((a/x)^(b+1)) I would do the following,
(#[[2]]/#[[1]])(#[[1]]/x)^(#[[2]]+1)& /@ parameters

where #[[1]] and #[[2]] are a and b, respectively. But, this makes it difficult to read, alternatively you can use With to improve the readability, as follows,
With[{a = #[[1]], b = #[[2]]}, (b/a)*((a/x)^(b+1))]& /@ parameters

It is longer, but it is more readable. I tend to use With in this way. The second method is to use Apply, as outlined by R.M. Here With can also be used,
With[{a = #1, b = #2}, (b/a)*((a/x)^(b+1))]& @@@ parameters

but it is less likely to be confusing when you come back to the code a month later.
"
plotting - Change the height of a function being plotted,"
Maybe AspectRatio -> Automatic which gives a 1:1 scaling of your function? 
Plot[Sin[x], {x, -12, 12}, AspectRatio -> Automatic]


If you take issue with the tight spaced tick-marks you can control that with Ticks:
Plot[Sin[x], {x, -12, 12}, AspectRatio -> Automatic, Ticks -> {Automatic, {-1, 1}}]


"
equation solving - Conditional expression,"
It's a bit unclear to me what you are asking, but if I interpret your question and your comment to Peter Breitfeld's answer correctly you want to solve the system
eqs = {g'[x] == 1, x^2 + x + c == 0}

for x and c. This can be done using Solve, e.g.
Solve[eqs, {x, c}]

(* output: {{x -> -(I/2), c -> 1/4 + I/2}, {x -> I/2, c -> 1/4 - I/2}} *)

"
plotting - How can I plot Intensity values(Z) based on X and Y position. Data stored as 3 columns in CSV file,"
(*Testing ...
First we generate some points*)
points = Flatten[Table[{x, y, PDF[BinormalDistribution[{0, 0}, {1, 2}, .5], {x, y}]}, 
                       {x, -3, 3, .1}, {y, -3, 3, .1}], 1];
(*
Now we export it as a csv
*)
Export[""c:\\points.csv"", points];

(* The file looks like this:
-3.,-3.,0.0010207851317789406
-3.,-2.9,0.0010190852401957891
-3.,-2.8,0.0010140025313558822
-3.,-2.7,0.0010055876210847213
-3.,-2.6,0.0009939239359647277
...
*)
(* Finally import it and plot*)

ListDensityPlot[Import[""c:\\points.csv""]]


Edit
I had no problems at all downloading your sample file and plotting it:

"
"warning messages - What do I do when I get an ""Iterator does not have appropriate bounds"" error?","
This is because the number you used is extremely large.  The number of iterations supported (in either Table or Do) seems to be $2^{31}-1$, i.e. the maximum size of a signed machine integer.  I believe this is also an upper bound on the size of an array in Mathematica.
This limitation is not unreasonable: the size of the Table you are trying to construct is too large to fit into memory anyway.  (Even if each element could be stored on a single byte, you'd be asking for 600 GB of memory.)
If you change the step size in the iterator to a large number, it will work:
Table[600851475143/i, {i, 1, 600851475143, 100000000}]

"
Combining lists - Mathmatica Stack Exchang,"
You need Join : 
list = Join[list1, list2]

sometimes you would choose :
listU = Union[list1, list2]

The latter doesn't include duplicates, as the first approach could, if some of elements in list1 and list2 were common.  
Edit
It should be emphasized that since for small lists different approaches (pointed out in the other answers)  are elegant and quite satisfactory, however for big lists Join is much superior. We compare their efficiency in a few different cases : 

lA1 = RandomReal[1, {500000, 2}];
lA2 = RandomReal[1, {500000, 2}];

Join[lA1, lA2]; // AbsoluteTiming // First
## & @@@ {lA1, lA2}; // AbsoluteTiming // First
{lA1, lA2}~Flatten~1; // AbsoluteTiming // First


0.0210000
0.8090000
0.4620000


lB1 = RandomReal[1, {2500000, 2}];
lB2 = RandomReal[1, {1500000, 2}];

Join[lB1, lB2]; // AbsoluteTiming // First
## & @@@ {lB1, lB2}; // AbsoluteTiming // First
{lB1, lB2}~Flatten~1; // AbsoluteTiming // First


0.0820000
3.1500000
1.9000000


lC1 = RandomReal[1, {300000, 2}];
lC2 = RandomReal[1, {900000, 2}];

Join[lC1, lC2]; // AbsoluteTiming // First
## & @@@ {lC1, lC2}; // AbsoluteTiming // First
{lC1, lC2}~Flatten~1; // AbsoluteTiming // First


0.0220000
0.9320000
0.6640000



We can see that Join is roughly about 20-30 times faster than {list1, list2}~Flatten~1; and the latter is about 1.5-2 times faster than  ## & @@@. 
"
evaluation - Why doesn't Evaluate appear to work in this RegionPlot example with MatchQ?,"
As it turns out, the Evaluate is only evaluated immediately if it is top level in the argument, as the following code shows:
ClearAll[test];SetAttributes[test,HoldAll];test[x_]:=Hold[x]
test[Evaluate[1+1]]
(*
==> Hold[2]
*)
test[f[Evaluate[1+1]]]
(*
==> Hold[f[Evaluate[1+1]]]
*)

Since in your code it is not top level, it is passed on together with the rest of the expression to RegionPlot. It is evaluated at a point where the variables already have numerical values. And this gives a complex result with imaginary part numerically zero, as the following proves:
ClearAll[f];SetAttributes[f,HoldAll];f[x_]:=Block[{a=1.,b=1.},x]
f[Head[Evaluate[(a+I b)(a-I b)]]]
(*
==> Complex
*)
f[(a+I b)(a-I b)]
(*
==> 2.+0. I
*)

You can get rid of the numerically zero imaginary part by using Chop:
RegionPlot[MatchQ[Chop@Evaluate[Expand[(a+I b) (a-I b)]],_Real],{a,-2,2},{b,-2,2}]

More generally, to evaluate just part of an expression passed to a function with HoldAll attribute, you can use With:
With[{expr=Expand[(a+I b)(a-I b)]},
     RegionPlot[MatchQ[expr,_Real],{a,-2,2},{b,-2,2}]]

"
How to import all files of a folder at once?,"
Have a look at FileNames:
files=FileNames[""*.pdf"", NotebookDirectory[]]


{""a.pdf"",""b.pdf"",""c.pdf""}

will get you a list of all files in the directory where your notebook resides (of course you can choose any path) that match ""*.pdf"". You can then import the files like this:
Import[#]&/@files

or if you want certain files (look at the help for Part and Span):
Import[#]&/@files[[-3;;-1]] (*last three files*)
Import[#]&/@files[[1;;10]]  (*first ten files*)

If you want to use more arguments with Import like in your question then you can add them after the #, e.g. like this: Import[#,""Text""]&/@files. Otherwise you can save typing effort by choosing the the shorter version Import/@files (as pointed out by @AlbertRetey).
"
dynamic - Detecting KeyUp events,"
To answer the second part of your question, you can use CurrentValue[""EventKey""] to get the current key that is being pressed. Modifying your example above:
EventHandler[InputField[], ""KeyDown"" :> Print[CurrentValue[""EventKey""]]]

"
evaluation - DSolve cannot solve for certain branches of the solution,"
I can offer a small workaround. Your problem is equvalent to
sol=FullSimplify[DSolve[{y'[x] == A0 + A1 y[x] + A2 y[x]^2, y[0] == y0}, y[x], x]]


By expanding and comparing with your variables:
y'[x] == c d - (c + b d) y[x] + b y[x]^2
y'[x] == A0 + A1 y[x] + A2 y[x]^2

We can get your formulation by the substitution:
PowerExpand[FullSimplify[sol /. {A0 -> c d, A1 -> -(c + b d) , A2 -> b}]]


You can check now by direct substitution that this is indeed solution to your differential equation. 
==== Edit: answering ""why does not work?"" question ===
I can try to guess the trouble of your formulation - I think it is in your choice of parameters. As Sjoerd C. de Vries in his answer noticed a general solution leads to
DSolve[y'[x] == c*(d - y[x]) - b*(d - y[x])*y[x], y, x]


Now Solve cannot ""solve"" your initial value problem:

Using Reduce you can arrive to a complex conditions set for the solution:

Which looks glorious ;-) but not simple. With a bit different formulation above (via A0, A1, A2) you do not run into this problem - Solve can handle easily your initial condition. This is rather a rare case - you were lucky to hit exactly problematic choice of parameters. This was some quick thinking - it's subject to verification. 
"
combinatorics - Combinatorica Graph from Edge List,"
Two examples:
   Needs[""Combinatorica`""]
   GraphicsRow[
    {ShowGraph[ 
       g1 = Graph[{{{1, 2}}, {{2, 3}}, {{3, 1}}}, {{{1, 1}}, {{2, 1}}, {{3, 3}}}], 
        VertexNumber -> True], 
     ShowGraph[
      g2 = Graph[
            {{{1, 2}, EdgeLabel -> ""lbl1""}, {{2, 3}, EdgeColor -> Green}, 
             {{3, 1}, EdgeLabel -> ""(3,1)"", EdgeDirection -> True, EdgeLabel -> True, 
                EdgeLabelPosition -> UpperLeft}}, 
           {{{1, 1}, VertexLabel -> True, VertexLabelColor -> Blue, 
   VertexLabelPosition -> LowerRight}, 
             {{2, 1}, VertexNumber -> True, VertexNumberColor -> Orange}, 
             {{3, 3}}}]
    ]}]

to get

EDIT: Before loading Combinatorica you can transform the data using:
   toCombGrphData[gr_] :=  gr // 
       Sequence @@ {EdgeList[#] /. UndirectedEdge[x__] :> {List[x]}, 
                    List /@ (AbsoluteOptions[#, VertexCoordinates][[2]])} &

Update: For Version 9, we need to change the part specification above from [[2]] to [[1,2]] (thanks: @sam84).
Example:
  combgrpg = toCombGrphData[CompleteGraph[3]]

gives the edge list and vertex coordinates needed as input for Combinatorica ``Graph`:
  (*  Sequence[{{{1, 2}}, {{1, 3}}, {{2, 3}}}, {{{0.866025, -0.5}}, {{-0.866025, -0.5}}, {{-2.44929*10^-16, 1.}}}] *)

Then, 
  Needs[""Combinatorica`""]

  ShowGraph[Graph[combgrph]]

gives

"
combinatorics - When to use built-in Graph/GraphPlot vs. Combinatorica,"
You should always use the built-in Graph unless there is a specific reason to use Combinatorica instead.
Valid reasons to use Combinatorica could be:

Working with very old code, originally written for Combinatorica
The need for an algorithm that is neither available as a built-in, nor in any supported package. (There are still a few of these, e.g. ListGraphs).  Update: The IGraph/M package now provides replacements for many of such Combinatorica functions. As for ListGraphs, I suggest using the geng tool from the Nauty suite. It's output format, Graph6, can be read directly by Mathematica.
You are learning about graph theory and combinatorics from the Combinatorica Book

Problems when using Combinatorica:

Not supported anymore. There will be inconvenient conflicts with built-in symbols. See here for how to make this less painful.  Minor compatibility problems with recent Mathematica versions could happen.
The documentation is lacking.  The expectation is that you would buy the Combinatorica Book.
Performance is not great.  All functions are implemented purely in Mathematica.  (On the upside: you can read the source code, and the algorithms/implementations are explained in the Combinatorica Book.)  Because of this is not suitable for ""network science"" type applications.  It is meant for (mathematical) graph theory.


Here's the guide on replacing Combinatorica with builtin functionality:

http://reference.wolfram.com/language/Compatibility/tutorial/Combinatorica.html

The GraphUtilities` package contains the ToCombinatoricaGraph function which can convert a built-in Graph expression to a Combinatorica`Graph, in case you need some algorithms from Combinatorica.

A for GraphPlot, it is purely for visualization, and almost all of its functionality is already built into Graph.
"
list manipulation - Are there guidelines for avoiding the unpacking of a packed array?,"
I will try to list some cases I can recall. The unpacking will happen when:

The result, or any intermediate step, is a ragged (irregular) array. For example
 Range /@ Range[4]

To avoid this, you can try to use regular structures, perhaps padding your arrays with zeros appropriately
The result (or any intermediate step) contains numbers of different types, such as a mix of integers and reals, or when some of the elements are not of numeric types at all (symbols, expressions)
This usually happens by mistake for 1D lists. For multi-dimensional lists, there are several ways out. One is to convert all numbers to a single type (e.g. Reals to Integers or vice versa), when that is feasible. One such example is here.
Another way out is to store an array parts separately. For example, you have two arrays of the same length, but different element types, which logically belong together (such as a result of Tally operation on reals, for example, as illustrated below). While our usual reaction would be to store it in transposed (and thus unpacked) form, one can also store them as {list1,list2}, which will be unpacked, but the parts list1 and list2 inside it will remain packed - just don't transpose it. One example of such treatment is here
This trick can be generalized to even ragged arrays. In the already cited post, I used it to convert an imported ragged array to a more space-efficient form, with elements being packed arrays, with 
packed =  Join @@Map[Developer`ToPackedArray, list]

Some of the numbers don't fit into the numerical precision limits (for example, very big integers). This can be insidious, because this may be data-dependent and happen in the middle of a computation, and it may not be clear what is going on.
Here, you can try to predict in advance whether or not this is likely, but other than that, there is little of what can be done, short of changing the algorithm.
The packed array is a part of an expression used with some rule-based code and subject to pattern-matching attempts. This will happen in cases when the match is not established before the pattern-matcher comes to the array. Here is an example:
Cases[f[g[Range[5]]], g[l_List] :> g[l^2], Infinity]

During evaluation of In[14]:= Developer`FromPackedArray::unpack: 
Unpacking array in call to f. >>


{g[{1, 4, 9, 16, 25}]}

while this does not unpack:
f[g[Range[5]]] /. g[l_List] :> g[l^2]


f[g[{1, 4, 9, 16, 25}]]

This happened because Cases searches depth-first (and therefore reaches elements before heads, and then must unpack), while ReplaceAll replaces from expressions to sub-expressions. I  discussed this  extensively here.
This situation is typical for the pattern-matching - it will generally unpack. Note also that the pattern-matching goes inside held expressions, and will unpack even there:
FreeQ[Hold[Evaluate@Range[10]], _Integer]

The only way I know to generally prevent it is to make sure that the pattern will either match or be rejected before the pattern-matcher comes to a given packed array. Note that there are certain exceptions, e.g. like this:
MatchQ[Range[10], {__Integer}]

In which case, there is no unpacking. 
In certain cases, you will not see the unpacking message, but the result returned by a function may be packed or unpacked, depending on its type. Here is an example:
tst = RandomInteger[10,20]


{6,9,9,4,6,4,0,9,7,1,3,2,2,0,7,2,1,0,7,5}

ntst = N@tst;

tally = Tally[tst]


{{6,2},{9,3},{4,2},{0,3},{7,3},{1,2},{3,1},{2,3},{5,1}}

ntally = Tally[ntst]


{{6.,2},{9.,3},{4.,2},{0.,3},{7.,3},{1.,2},{3.,1},{2.,3},{5.,1}}

Developer`PackedArrayQ/@{tally,ntally}


{True,False}

You can see that the ntally was returned as an unpacked array, because it contains elements of different types, and there was no message to tell us about it, since indeed, nothing was unpacked - the result is a new array.
As I metnioned already, one way here is to separate frequencies and elements themselves, and store them separately packed.
As elaborated by @Mr.Wizard, Apply leads to unpacking. This also refers to Apply at level 1 (@@@). The way out here is just not to use Apply - chances are, that you can achieve your goal by other means, with packed lists.
Map will unpack on short lists, with lengths smaller than ""SystemOptions""->""CompileOptions""->""MapCompileLength"". This may come as a surprise, since we are used to the fact that Map does not unpack. For example, this unpacks:
Map[#^2 &, Range[10]] 

The way out here would be to change the system options (""MapCompileLength"") accordingly, to cover your case, or (perhaps even better), to manually pack the list with Developer`ToPackedArray after Map is finished. This often does not matter much for small lists, but sometimes it does.
Map will also unpack for any function which it can not auto-compile:
ClearAll[f];
f[x_] := x^2;
Map[f, Range[1000]]

while this does not unpack:
Map[#^2 &, Range[1000]]

The solution here is to avoid using rule-based functions in such cases. Sometimes one can also, perhaps, go with some more exotic options, such as using something similar to a withGlobalFunctions macro from this answer (which expands certain rule-based functions at run-time).
Functions like Array and Table will produce unpacked arrays for functions or expressions which they can not auto-compile. They will not produce any warnings. For example:
Array[f, {1000}] // Developer`PackedArrayQ


False

Similar situation for other functions which have special compile options.
In all these cases, the same advice:  make your functions/expressions (auto)compilable, and / or change the system settings. Sometimes you can also manually pack the resulting list afterwords, as an alternative.
While this reiterates on one of the previous points,  innocent-looking functions which combine packed arrays of different types will often unpack both:
Transpose[{Range[10], N@Range[10]}]

In cases like this, often (also as mentioned already) you can live with such lists as they are, without transposing them. Then, the sub-lists will remain packed.
When you use Save to save some symbol's definitions and Get to get them back, packed arrays will be generally unpacked during Save. This is not the case with DumpSave, which is highly recommended for that. Also, Compress does not unpack.
Import and Export will often not preserve packed arrays. The situation is particularly grave with Import, since often it takes huge memory (and time) to import some data, which could be stored as a packed array, but is not recognized as such. 

There are probably many more cases. I intend to add to this list once I recall some more, and invite others to contribute. One characteristic feature of unpacking is, however, general: whenever a final result or some intermediate expressions can not be represented as regular arrays (tensors) of the same basic type (Integer, Real or Complex), most of the time unpacking will happen. 
"
evaluation - Attaching persistent assumptions to symbol definition,"
A slightly more flexible approach is to use assumptions as an option for u[..]:
ClearAll[u, assuming, asmptns];
asmptns = And @@ 
Flatten@{(# > 0) & /@ {λ, w, R, r, θ}, (# ∈ Reals) & /@ {λ, w, R, r, θ}, -π < θ <= π};
Options[u] = {""assuming"" -> asmptns};
u[p_, m_, λ_, w_, R_, ψ_, ψ0_, r_, θ_] := 
Sqrt[(2 p!)/((1 + DiscreteDelta[0, m]) π (m + p)!)] 
Exp[I (2 p + m + 1) (ψ - ψ0)]/w ((Sqrt[2] r)/w)^ m 
LaguerreL[p, m, (2 r^2)/ w^2] 
Exp[-I (2 π)/λ r^2/ 2 (1/R - I λ/(π w^2)) + I m θ];
Abs[u[0, 0, λ, w, R, 0, 0, r, θ]]^2 // 
Simplify[#, OptionValue[u, ""assuming""]] &

gives

and, re-simplify with modified assumptions
SetOptions[u, ""assuming"" -> asmptns && (w == 2)];
Abs[u[0, 0, λ, w, R, 0, 0, r, θ]]^2 // 
Simplify[#, OptionValue[u, ""assuming""]] &

to get

"
graphs and networks - Visualize the output of Trace in a tree structure,"
This shows a graphical tree of the expression.
HoldForm[{{{{x, 5}, 3 + 5, 8}, 8^2, 64}, {{x, 5}, 5 - 1, 4}, 
   Mod[64, 4], 0}] // TreeForm


"
plotting - How does one set a logarithmic scale in a ContourPlot?,"
One possibility is to plot the contour plot with linear scales using ContourPlot and use ListLogLogPlot to transform this plot to one with logarithmic scales:
pl = Normal@
  ContourPlot[
   Sin[3 x] + Cos[3 y] == 1/2, {x, .01 Pi, 3 Pi}, {y, .01 Pi, 3 Pi}, 
   PlotPoints -> 30]


ListLogLogPlot[Cases[pl, Line[a_, b___] :> a, Infinity], 
 Joined -> True, Frame -> True, PlotRange -> All, AspectRatio -> 1, 
 PlotStyle -> ColorData[1][1]]


"
probability or statistics - Doing a chi-square independence test in Mathematica,"
When conducting a Chi-square test on a two-way table, you want to create and inspect the following.  (The calculations are made in a way that generalizes to any $r$ by $c$ table.)

The data:
data = {{11, 206}, {32, 1374}}; 
rc =  {{""Row 1"", ""Row 2""}, {""Column 1"", ""Column 2""}};
TableForm[data, TableHeadings -> rc]

The fit.  This is obtained from the row and column sums:
fit = Outer[Times, Plus @@@ data, Plus @@@ Transpose[data]] / Plus @@ Flatten[data];
TableForm[fit // N, TableHeadings -> rc]

The residuals, equal to the differences between the data and the fit:
residual = data - fit;
TableForm[residual // N, TableHeadings -> rc]

(For a 2 by 2 table, all residuals will have equal size.)
The squared residuals, scaled by the reciprocal of the fit.  Where these are substantially larger than $1$ in absolute value, they signal bad fits:
χ2array = residual^2 / fit;
TableForm[χ2array // N, TableHeadings -> rc]

In this example, the entry for row 1, column 1 has a value of 4.8, suggesting a (slightly) bad fit there.  The other entries are all small, indicating decent to excellent fits.  (Appropriately signed square roots of these values are normally considered ""residuals"", but it's not really necessary to do this extra computation.)
The sum of these scaled squared residuals.  This is the chi-squared statistic, $\chi^2$.  It is an overall measure of how well the fit matches the data.
χ2 = Plus @@ Flatten[χ2array];
χ2 // N

Here, it equals 5.68632.
The p-value.  This assesses the chance that a chi-squared random variable could attain a value of $\chi^2$ or larger.  As a preliminary step, we need to compute the ""degrees of freedom"" (df) of the statistic.
df = Length[Flatten[data] ] - Length[data] - Length[Transpose[data]] + 1;
1 - CDF[ChiSquareDistribution[df], χ2] // N

This calculation returns 0.0170977, or about 1.7%, based on one degree of freedom.

In a full report of the test, all these results would be presented.  In an  abbreviated report, only df, $\chi^2$, and the p-value would be given (as computed in steps 5 and 6).
Finally, to conduct the test at the 5% level, one would remark that the p-value is less than 5%.  Because you have generated these intermediate results and inspected the residual tables (steps 3 and 4), you might remark that this low p-value appears to be due solely to a lack of fit in the first row and column.  You might urge some caution in the interpretation because (looking at the data and fit tables, steps 1 and 2) you notice the counts in this cell (11 and 5.75) are small.  In fact, you might elect to confirm your result with a permutation test or, when applicable, Fisher's Exact Test.
As a double-check--because these calculations have been coded from scratch--you might compare the results to a calculation with other software, such as R; e.g.,
chisq.test(matrix(c(11,32,206,1374), nrow=2), correct=FALSE)

This produces the abbreviated summary:

X-squared = 5.6863, df = 1, p-value = 0.01710

By saving the result of this calculation you can inspect the auxiliary material and compare it with the Mathematica calculations.  Unlike R (or almost any other statistical program), Mathematica will present exact results: simply remove the ""// N"" bits from the code.  (It can be surprising how many people have gotten into trouble by over-rounding intermediate results in their statistical calculations; using exact arithmetic avoids that problem.)
"
programming - Question about modifying a Slider2D control,"
Something like the following?
 Manipulate[If[(iOld != i || jOld != j), lata[[1]] = i; lata[[2]] = j];
 i = lata[[1]];
 j = lata[[2]];
 iOld = i;
 jOld = j;
 lata, 
 Column[{Row[{Opener[Dynamic[zz]], "" lata""}], 
 PaneSelector[{True -> 
 Row[{Column[{Row[
  {Control[{{i, 0, """"}, {-5, -5}, {5, 5}, {0.25, 0.25}, Animator[#, {-5, 5, 0.25}, 
     AnimationRunning -> False, AnimationRate -> 4/5, Appearance -> Small, 
     AppearanceElements -> {""ResetButton"",""PlayPauseButton"", ""StepLeftButton"", 
              ""StepRightButton"", ""FasterSlowerButtons"", ""DirectionButton""}] &}], 
   Spacer[5], 
   Control[{{i, 0, """"}, {-5, -5}, {5, 5}, {0.25, 0.25}, 
          InputField[#, FieldSize -> {4, 1}] &}]}] , 
   Row[{Control[{{j, 0, """"}, {-5, -5}, {5, 5}, {0.25, 0.25}, 
        Animator[#, {-5, 5, 0.25}, AnimationRunning -> False, 
        AnimationRate -> 4/5, Appearance -> Small, 
        AppearanceElements -> {""ResetButton"",""PlayPauseButton"", ""StepLeftButton"", 
           ""StepRightButton"", ""FasterSlowerButtons"",""DirectionButton""}] &}], 
   Spacer[5],             
   Control[{{j, 0, """"}, {-5, -5}, {5, 5}, {0.25, 0.25}, 
          InputField[#, FieldSize -> {4, 1}] &}]}]}], Spacer[15], 
   Control[{{lata, lata, """"}, {-5, -5}, {5, 5}, {0.25, 0.25}}]}],
  False -> 
  Control[{{lata, lata, """"}, {-5, -5}, {5, 5}, {0.25, 0.25}}]}, 
  Dynamic[zz]]}], 
  Initialization -> {lata = {0, 0}, i = lata[[1]], j = lata[[2]], jOld = j, iOld = i}]

screenshots:


"
plotting - About number truncation of ticks display in ListPlot,"
You can define your own function for FrameTicks :
ticks[min_, max_] := {#, NumberForm[#, 20]} & /@ 
  N[FindDivisions[{min, max}, 5]]

ListPlot[{RandomReal[#] + 10^4, 
    RandomReal[#]} & /@ (Range[100] 10^-10), Frame -> True, 
 FrameTicks -> {{Automatic, None}, {ticks, None}}]


Just choose your own preferred presentation format of the given values...
ticks[min_, max_] := {#, Grid[{{min}, {""+""}, {# - min}}]} & /@ 
  N[FindDivisions[{min, max}, 5]]

ListPlot[{RandomReal[#] + 10^4, 
    RandomReal[#]} & /@ (Range[100] 10^-10), Frame -> True, 
 FrameTicks -> {{Automatic, None}, {ticks, None}},FrameStyle->Medium]


"
output formatting - Rationalize the Denominator by Default,"
In the old days, when ""making the Numerator rational"" was often wanted, I came up with the following set of rules:
EvaluiereAt[pos:(_Integer|{__Integer}),f_:Identity][expr_]:=
  ReplacePart[expr,pos->Extract[expr,pos,f]];
EvaluiereAt[pos:{{__Integer}..},f_:Identity][expr_] :=
  Fold[ReplacePart[#1, #2 -> Extract[#1, #2, f]] &, expr, Reverse[Sort[pos]]];

$pinkHoldColor = ColorData[""HTML""][""HotPink""];
pinkHold[x_] := Style[Tooltip[HoldForm[x], ""held""], $pinkHoldColor];

Attributes[rootRational] = {Listable};
rootRational[expr_] := 
  Module[{zw, res, pos}, zw = expr /. Sqrt[a_] :> Sqrt[Together[a]];
   res = zw /. Sqrt[a_/b_] :> Sqrt[Expand[a b]]/b;
   res = res /. {a_./(b_ + d_. Sqrt[c_]) -> (a (b - d Sqrt[c]))/(b^2 -
           d^2 c), 
      a_./(b_ - d_. Sqrt[c_]) -> (a (b + d Sqrt[c]))/(b^2 - d^2 c)};
   res = res /. Sqrt[Rational[a_, b_]] :> pinkHold[Sqrt[a b]]/b;
   res = res /. (a_/Sqrt[b_]) :> a pinkHold[Sqrt[b]]/b;
   res = res /. 
     b_. Power[a_, Rational[-1, 2]] :> b pinkHold[Sqrt[a]]/a;
   pos = Position[res, _?NumberQ];
   If[Flatten[pos] =!= {}, res = EvaluiereAt[pos][res]];
   res];

Attributes[pinkUnhold] = {Listable};
pinkUnhold[expr_] := 
  ReleaseHold[expr /. Style[Tooltip[a_, __], __] -> a];

the function rootRational tries to achieve this. To show, that something is in HoldForm, I marked it with a pink color. To ReleaseHold and take away the color an tooltip there is the function pinkUnhold.
Examples:
w = Sqrt[6]/9 
% // rootRational 
% // pinkUnhold Clear[a]; 
w = Sqrt[(1 + a)/(1 - a)] // rootRational 
% // FullSimplify 
rootRational[Sqrt[b]/b] 
rootRational[1/Sqrt[b]]


"
list manipulation - Smooth/histogram a 2D set,"
Let's start with your sample data:
In[1]:= data = {{0.1, 1.0}, {0.2, 2.0}, {0.3, 3.0}, {0.35, 3.5}, {0.4, 4.0}, {0.5, 5.0}};

First we can use GatherBy to group entries by bin:
In[2]:= GatherBy[data, Ceiling[First[#], 0.2] &]

Out[2]= {{{0.1, 1.}, {0.2, 2.}}, {{0.3, 3.}, {0.35, 3.5}, {0.4, 4.}}, {{0.5, 5.}}}

Then select the second element of each pair (Last) and calculate the means:
In[3]:= Mean[Last /@ #] & /@ %

Out[3]= {1.5, 3.5, 5.}

"
plotting - Background Shading in Histogram3D,"
Is this what you mean? I put different colors in the background, to make clear what I added:
Show[Histogram3D[dataHistogramSet, FaceGrids -> {Bottom, Front, Left},
   ChartStyle -> ""GrayTones"", ViewPoint -> {2.78, 1.3, 1.43}, 
  PlotLabel -> ""Histogram of Dataset 1""],
 Graphics3D[
  Translate[{EdgeForm[],
    {Red, 
     Polygon[{{1995, 0, 0}, {1995, 0, 100}, {2002, 0, 100}, {2002, 0, 
        0}, {2002, 300, 0}, {1995, 300, 0}}]}, {Orange, 
     Polygon[{{2002, 0, 0}, {2002, 0, 100}, {2005, 0, 100}, {2005, 0, 
        0}, {2005, 300, 0}, {2002, 300, 0}}]}, {Yellow, 
     Polygon[{{2005, 0, 0}, {2005, 0, 100}, {2010, 0, 100}, {2010, 0, 
        0}, {2010, 300, 0}, {2005, 300, 0}}]}}, {0, -3, -3}]]
 ]

!
"
How to draw a directed graph with arrows showing vertically from bottom to top,"
As mentioned by others, you could use LayeredGraphPlot for this. However, LayeredGraphPlot orders vertices in such a way that directed edges are generally pointing down. To flip the graph over, you could reverse the edges and supply a custom EdgeRenderingFunction, e.g.
edges = {2 -> 1, 3 -> 1, 4 -> 1, 5 -> 2, 6 -> 1, 7 -> 3, 8 -> 7, 9 -> 8};
LayeredGraphPlot[Reverse /@ edges, DirectedEdges -> True,
 EdgeRenderingFunction -> (Arrow[Reverse[#1], .05] &)]


"
dynamic - Manipulating a continuous stream of sounds,"
The key to getting separate sounds to join smoothly is to make the waveform continuous. For example this sound contains an integer number of cycles, and we can emit a sequence of these with no audible gaps:
testsound=Sound[SampledSoundFunction[Sin[0.4Pi #]&,1000,8000]];
Do[EmitSound[testsound],{5}]

Contrast with this next one, where I have adjusted the frequency slightly:
testsound=Sound[SampledSoundFunction[Sin[0.401Pi #]&,1000,8000]];
Do[EmitSound[testsound],{5}]

There is also a timing problem to be dealt with. As noted in the question, if the sounds are too short there will be gaps between them. If the sounds are too long they will queue up and lag behind the Locator motion. The update rate of the Locator position is not uniform, so we can't simply pick a single ""perfect"" duration for the sounds. We could use ""Preemptive"" as a second argument to EmitSound to force the sound to play right now, but this will scupper the attempt to make the waveform continuous.
My approach is to measure the time between updates to the Locator position, and use this as the duration of the sound to play. The idea is that this should keep the time elapsed moving the Locator roughly in step with the cumulative duration of sounds played. The sound duration is however clipped to prevent any overly long or short sounds.
So here is my attempt at the problem. I have defined these functions:
soundfunc takes a frequency and a number of samples, and returns a Sound with the frequency tweaked to ensure an integer number of cycles over the duration of the sound.
killsound immediately stops any currently playing sound. This is used to stop sound output sharply when the Locator is released.
valtofreq simply converts a function value in the range -1 to +1 to a frequency.
soundfunc[f_,n_]:=Sound[SampledSoundFunction[Sin[2Pi  Round[f,8000/n]#/8000.]&,n,8000]]
killsound := EmitSound[SampledSoundList[{0.}, 8000], ""Preemptive""]
valtofreq[val_] := 500 (1.3 + val)

pt = {0, 0};(*initialize locator*)
func = Sin[Pi*2*#1*#2] &;(*arbitrary surface*)

LocatorPane[Dynamic[pt,{
(t2=t1=AbsoluteTime[];f=valtofreq[func@@#])&,
(pt=Clip@#;f=valtofreq[func@@#];
t2=AbsoluteTime[];deltat=t2-t1;t1=t2;
EmitSound[soundfunc[f,Round[8000Clip[deltat,{0.001,0.2}]]]];)&,
(killsound)&}],
ContourPlot[func[x,y],{x,-1,1},{y,-1,1},ImageSize->200]]

It's not perfect, but it works reasonably well if the Locator is moved slowly. There is still a definite sense of separate notes strung together, rather than the continuously varying pitch the question asks for. It should be possible to make it smoother by varying the frequency gradually from the beginning to the end of each Sound, but it wasn't immediately obvious to me how to do that while maintaining the waveform continuity.
"
partitions - Subsets of a list,"
I would use:
data = {1, 20, 3, 40};

Join @@ Permutations /@ IntegerPartitions[Length@data];

results = Internal`PartitionRagged[data, #] & /@ %


{{4}, {3, 1}, {1, 3}, {2, 2}, {2, 1, 1}, {1, 2, 1}, {1, 1, 2}, {1, 1, 1, 1}}

{{{1, 20, 3, 40}},
 {{1, 20, 3}, {40}},
 {{1}, {20, 3, 40}},
 {{1, 20}, {3, 40}},
 {{1, 20}, {3}, {40}},
 {{1}, {20, 3}, {40}},
 {{1}, {20}, {3, 40}},
 {{1}, {20}, {3}, {40}}}



IntegerPartitions is used get the ways in which you can split a list, to be used with the function above.  Permutations is used to get all orders of these.  By the way, you could use the function Compositions from the Combinatorica package in place of both of these if you want to include zeros.
These specifications are fed to Internal`PartitionRagged which splits a list into given lengths, e.g. [{1,2,3,4,5}, {2,1,2}] -> {{1,2}, {3}, {4,5}}.  Users of Mathematica versions prior to 8 can use my dynamicPartition function in its place.
"
How to visualize large graphs with directed edge bundling?,"
CommunityGraphPlot has this feature implemented internally:
g = ExampleData[{""NetworkGraph"", ""DolphinSocialNetwork""}];
CommunityGraphPlot[g]


The information about bundling is calculated by CommunityGraphPlot (i.e. it is not supplied with the example data), though unfortunately there are no documented options available to finetune the bundling (but see below), only the region (CommunityRegionStyle) and boundary styles (CommunityBoundaryStyle). 
Though one can extract from the community graph the BezierCurve that generates the bundled edges (with low opacity EdgeStyle by default), it will contain references to vertex coordinates like DynamicLocation[""VertexID$1"", Automatic, Center]. Unfortunate again that due to the dynamical nature of a CommunityGraphPlot, ordinary Graph functions like VertexList or PropertyValue[{g, 1}, VertexCoordinates] will fail, so there is no easy way to extract the real vertex coordinates which otherwise could have been matched with the various ""VertexID$1"" references.
The method to find communities can be customized with FindGraphCommunities.
Undocumented functionality
You have to dig deep to ultimately find any bundling-related code in GraphComputation`GraphCommunitiesPlotDump`communitiesPlot. It accepts the following internal options (above default ones):
 ""EdgeLayout"" -> Automatic
 ""CommunityEdgeWeight"" -> Automatic
 ""CommunityRegionFunction"" -> Automatic

If ""EdgeLayout"" has the value ""DividedEdgeBundling"", the following suboptions are available to control the bundling process (with their defaults):
""CoulombConstant"" -> 4.5
""VelocityDamping"" -> 1
""SmoothEdge"" -> True

Examining its internal usage and a bit of experimentation yielded the following results:
SetProperty[g, {GraphLayout -> {""EdgeLayout"" -> {""DividedEdgeBundling"",
      ""CoulombConstant"" -> 5, ""VelocityDamping"" -> .6, ""SmoothEdge"" -> True},
    ""VertexLayout"" -> {Automatic}}}]


SetProperty[g, {GraphLayout -> {""EdgeLayout"" -> {""DividedEdgeBundling"", 
      ""CoulombConstant"" -> 100, ""VelocityDamping"" -> .5, ""SmoothEdge"" -> False}}}]


SetProperty[g, {
  GraphLayout -> {""EdgeLayout"" -> {""DividedEdgeBundling"", 
      ""CoulombConstant"" -> 44, ""VelocityDamping"" -> .87, ""SmoothEdge"" -> False}}}]


SetProperty[g, {
  GraphLayout -> {""EdgeLayout"" -> {""DividedEdgeBundling"", 
      ""CoulombConstant"" -> 100, ""VelocityDamping"" -> .5, ""SmoothEdge"" -> False},
    ""VertexLayout"" -> {""SpringEmbedding"", ""EdgeWeighted"" -> True,
       ""Multilevel"" -> False}}}]


For larger graphs it really helps to use transparent edges:
sm = SocialMediaData[""Facebook"", ""FriendNetwork""];
{
 SetProperty[sm, {ImageSize -> 300, GraphLayout -> {""EdgeLayout"" -> None}}],
 SetProperty[sm,
  {ImageSize -> 300, EdgeStyle -> Opacity@.1,
   GraphLayout -> {""EdgeLayout"" -> {""DividedEdgeBundling"", 
       ""CoulombConstant"" -> 500, ""VelocityDamping"" -> .5, ""SmoothEdge"" -> False}}}]
 }


"
graphics - How to change ColorFunction after plotting,"
One solution that works quite well and is fast (interpolation would've been slow), is to use Nearest on a fine grid. The advantage is that you don't have to re-evaluate your plot, or modify it prior to generating it like Yu-Sung's answer does. Here's an example:
(* Create a rule list of original RGB colors to value and a nearest function *)
list = List @@ ColorData[""LakeColors""][#] -> # & /@ Range[0, 1, 0.001];
nf = Nearest[list];

(* function to convert original RGB triplets to those of chosen color data *)
convert[s_String][x_List] := List @@ ColorData[s][First@nf[x]]

(* Apply to plot *)
plot /. Rule[VertexColors, x_List] :> Rule[VertexColors, (convert[""Temperature""] /@ x)]



"
Solving complx quations - Mathmatica Stack Exchang,"
Unless I'm mistaken, the reason why this doesn't work is that Solve and Reduce do not have an Assumptions option, so Assuming has no effect on them.
Using Reduce
We can tell Reduce that these variables are all real-valued like this:
Reduce[a + I b == zr + I zi && Element[{a, b, zr, zi}, Reals], zi]

(* ==> (zr | b) \[Element] Reals && a == zr && zi == b *)

Using Solve
There's a note in the documentation:

Solve[expr && vars \[Element] Reals, vars, Complexes] solves for real values
  of variables, but function values are allowed to be complex.

However, Solve[a + I b == zr + I zi && (a | b | zr | zi) \[Element] Reals, zi, Complexes] returns {} which means that there are no solutions.  Why does this happen?  zi has a real value only if a == zr, so in general (for arbitrary a, zr values) there is no real solution for zi.  The main difference between Reduce and Solve is that Reduce will try to generate those specific conditions under which a solution exists while Solve does not.

Why doesn't Assuming work?
Generally, Assuming works by setting $Assumptions temporarily:
In[1]:= $Assumptions
Out[1]= True

In[2]:= Assuming[x > 0, $Assumptions]
Out[2]= x > 0

It will have an effect on functions that have an Assumptions option.  These functions have Assumptions -> $Assumptions as a default setting:
In[3]:= Options[Integrate]
Out[3]= {Assumptions :> $Assumptions, GenerateConditions -> Automatic,
  PrincipalValue -> False}

In[4]:= Options[Simplify]
Out[4]= {Assumptions :> $Assumptions, ComplexityFunction -> Automatic,
  ExcludedForms -> {}, TimeConstraint -> 300, 
 TransformationFunctions -> Automatic, Trig -> True}

It will not have an effect on functions that do not have this option:
In[5]:= Options[Solve]
Out[5]= {Cubics -> True, GeneratedParameters -> C, 
 InverseFunctions -> Automatic, MaxExtraConditions -> 0, 
 Method -> Automatic, Modulus -> 0, Quartics -> True, 
 VerifySolutions -> Automatic, WorkingPrecision -> \[Infinity]}

In[6]:= Options[Reduce]
Out[6]= {Backsubstitution -> False, Cubics -> False, 
 GeneratedParameters -> C, Method -> Automatic, Modulus -> 0, 
 Quartics -> False, WorkingPrecision -> \[Infinity]}

I could imagine though that Solve or Reduce make internal use of some function that does take $Assumptions into account.  I do not know if this is the case or not, but I doubt that generally $Assumptions would have an effect on them.
"
numerical integration - How to use NDSolve to track a deviation from equilibrium?,"
Now, you did put some pressure on me by giving a working example :-). This is most probably not a solution yet, but some thoughts after trying to run your code:
Problem Size: that's another point in making your question more friendly to people trying to answer it: make the problem size as small as possible, it's just no fun to wait minutes for a result just to see it's structure. I reduced your example from 141 equations to 11, which will of course be much simpler to handle. In this case the 141 equations are solved very fast with machine precision, but it took too long to run these with the high precision that you define, so I stopped it and reduced the problem size. Trying new things as your event handler to detect deviation from equilibrum is also something I'd strongly recommend to first try with a problem as simple as possible. Only when you have that working alright you should run your real problem.
WorkingPrecision: since you give it equations with lower precision than what you want NDSolve to use it complains (thats the NDSolve::precw warning). What it basically does (I think) is giving that warning and ignore it. If you want it to really use that precision, you'll need to give your input in at least that precision. What I tried was making the input exact with Rationalize[...,0] which indeed will not give the NDSolve::precw warning anymore. I don't think you'll actually need it, at least for my reduced example the (trivial) result doesn't change when using MachinePrecision but of course will be much faster...
Real Number: the warning about something not being a real number is issued because the right hand side of the initial conditions ci is not set to a number but to a list with one number, which you can see when looking e.g. at ci[[3]]. It's easy enough to change that by adding another 1 to Part. With these changes the code will work in Version 8, but not in Version 7. I think this is probably because of an error which will replace the integers in y[n][t] to real numbers, so in the event checks there appears something like y[20.][0.0144971] which doesn't work. One way to circumvent that is to replace those integers with strings, like I show in the code below. For other readers I'd like to emphasize that this is only necessary for Version 7 (and maybe earlier versions as well). 
Version Information: I admit that in this case this was absolutely not to be expected, but part of your problem seem to be a bug in version 7. Noone trying with version 8 could have ever see that error, so this information was essential to have a chance to help you, so if not using the most recent version it probably is always useful to include that information as you did.
RuleDelayed for event specification: You will notice that I have used RuleDelayed (shortcut: :>) instead of Rule (shortcut ->) to define the values for the option ""EventAction"" as well as ""Event"". This is probably only necessary for ""EventAction"" always, but usualy is also a good idea for ""Event"": you want these expression only to be evaluated at every single step and the RuleDelayed will ensure that this is so.
Altogether the following will work with no errors (but doesn't stop because the problem doesn't actually show the behavior that the event tries to tests for):
psi = Pi;
Do[w[i] = 1/2, {i, 1, 11}];
fext = 1;
k = 35529/1000.;
ci = Table[y[i][0] == RandomReal[{-Pi, Pi}], {i, 1, 11}];
AppendTo[ci, y[0][0] == y[11][0] - psi];

lckm = {y[0]'[t] == fext, y[11]'[t] == fext, 
   Table[y[i]'[t] == 
     w[i] + k (Sin[y[i + 1][t] - y[i][t]] + 
         Sin[y[i - 1][t] - y[i][t]]), {i, 1, 10}]};

sol = NDSolve[{lckm, ci}, Table[y[i], {i, 0, 11}], {t, 0, 800}];

v1 = y[10][t] /. sol[[1]];
v2 = y[11][t] /. sol[[1]];
norm = Sin[v1 - v2] /. t -> 800;
k = 35526/1000.;
ci = Table[
   y[i][0] == Part[{y[i][t] /. sol} /. t -> 800, 1, 1], {i, 1, 11}];
AppendTo[ci, y[0][0] == y[11][0] - psi];

lckm = {
   y[0]'[t] == fext,
   y[11]'[t] == fext, 
   Table[y[i]'[t] == 
     w[i] + k (Sin[y[i + 1][t] - y[i][t]] + 
         Sin[y[i - 1][t] - y[i][t]]), {i, 1, 10}]
   };

sol = NDSolve[Evaluate[{lckm, ci} /. y[n_] :> y[ToString[n]]], 
   Table[y[ToString[i]], {i, 0, 11}], {t, 0.0, 800}, 
   Method -> {""EventLocator"", 
     ""Event"" :> (Abs[Sin[y[""10""][t] - y[""11""][t]]/norm - 1] - 1/10
       ), ""EventAction"" :> Print[""t:"", t]}, MaxSteps -> Infinity];

Plot[Evaluate[Table[y[ToString[k]][t] /. sol, {k, 1, 11}]], {t, 0, 800}]

If your real problem needs it and you want NDSolve to really use WorkingPrecision->30, then you could run the NDSolve as here:
sol = NDSolve[Evaluate[Rationalize[{lckm, ci}, 0]], 
   Table[y[i], {i, 0, 11}], {t, 0, 800},
   WorkingPrecision -> 30, AccuracyGoal -> 15, PrecisionGoal -> 15, 
   MaxSteps -> Infinity
   ];

which will not issue any warnings and should really use the higher precision, but of course will take a lot longer than the standard settings (I think it will switch to use software floating point arithmetic for these settings, which is a lot more expensive...).

PS: (you'll note that I coudn't resist to get rid of the For-loop, for reasons I gave in Are there any cases when For[] loops are reasonable?).
"
variable definitions - Define a mathematical set,"
Perhaps the following
SetAttributes[set, Orderless];

set[elms___] := 
 With[{nodups = DeleteDuplicates@{elms}}, 
  set @@ nodups /; {elms} =!= nodups]

So set[a, b, c, d] would represent a set with elements a, b, c, and d.
To compare, just use == or ===. It automatically sorts and removes duplicates
s1 = set[a, b, c, d];
s2 = set[""o"", b, a, aa, dd];

s1 == set[b, b, d, a, c]


True

It seems like built-ins Intersection, Union, and Complement work also with any head so you could use them naturally with set (However, they probably sort first, not taking advantage of the fact that your sets are already sorted.)
Intersection[s1, s2]


set[a, b]

Union[s1, s2]


set[""o"", a, aa, b, c, d, dd]

Complement[set[a, b, c, d, e], s1]


set[e]

If you ever need to convert to lists, just do List@@s1
"
list manipulation - Point belonging to a Disk in a Cartesian Coordinate System,"
Edit: Version 1 using Nearest
I think Nearest can be put to good use here anyway. This one uses the idea (inspired by @DanielLichtblau) that you can carry useful information in a NearestFunction that is not relevant for the actual distance by scaling those values with a small factor, finding the nearest points/vectors and the re-scaling the stowaways. While this is not exact, it can be very useful if you want to use ""mixed"" vectors and still get the performance gained by repeated use of a NearestFunction (here together with timing information). 
Slight reformatting (scaling time with small factor):
fixations2 = Flatten[#]*{1, 1, 2^-20} & /@ fixations;

adding a 0 for compatibility...
Disks2 = Insert[#, 0, 3] & /@ Disks;

here we go (NearestFunction nf is called with additional arguments {n, radius}):
nf = Nearest[fixations2];

hits = Map[#*{1, 1, 2^20} &, 
   nf[#[[1 ;; 3]], {Infinity, #[[-1]]}] & /@ Disks2, {2}][[All, All, 
   3 ]]


{{155}, {}, {}, {145}, {}, {160}, {}, {377, 130}}

Total /@ hits


{155, 0, 0, 145, 0, 160, 0, 507}

This should scale pretty well with larger samples.
Version 2 (straightforward)
Another, very simple version with a bit of pattern mumbo-jumbo for versatile use with different input types (will become slow for large sample numbers):
fixations = {{{20.3899, 14.8931}, 238}, {{27.0063, 18.8899}, 
    428}, {{25.8113, 24.8679}, 377}, {{24.2579, 22.022}, 
    106}, {{25.3208, 24.022}, 130}, {{21.739, 12.1792}, 
    175}, {{29.2673, 8.88994}, 295}, {{30.3868, 17.6572}, 
    160}, {{31.217, 22.6761}, 145}, {{22.9686, 20.6918}, 
    155}, {{19.6321, 20.2704}, 145}};

Disks = {{22.8176, 19.9696, 0.974938}, {29.5314, 10.7197, 
    0.974938}, {17.5112, 19.7207, 0.974938}, {30.8997, 23.2454, 
    0.974938}, {28.0588, 6.09759, 0.974938}, {30.8524, 17.0661, 
    1.53205}, {21.0393, 10.7137, 1.53205}, {25.451, 25.1336, 1.53205}};

timeindisk[{{x_?NumericQ, y_?NumericQ}, time_}, {u_?NumericQ, 
   v_?NumericQ, r_?NumericQ}] := 
 If[Norm[{x, y} - {u, v}] <= r, time, 0]

timeindisk[#, Disks[[1]]] & /@ fixations


{0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0}

Threaded over fixes:
timeindisk[fixes_List, {u_?NumericQ, v_?NumericQ, r_?NumericQ}] := 
 timeindisk[#, {u, v, r}] & /@ fixes

timeindisk[fixations, Disks[[1]]]


{0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0}

Threaded over fixes and disks:
timeindisk[fixes_List, disks_List] := timeindisk[fixes, #] & /@ disks

times = timeindisk[fixations, Disks]


{{0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
        0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 145,
         0, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0, 0, 
        160, 0, 0, 0}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {0, 0, 377, 0, 
        130, 0, 0, 0, 0, 0, 0}}

(*    Time within disks: Total*)
Total /@ times


{155, 0, 0, 145, 0, 160, 0, 507}

"
Filter a list generated with Tuples,"
While you've already gotten an answer to your question, filtering out the unwanted tuples after generating all of them can be a huge waste of memory if there are many such tuples. Therefore it may be a better idea to generate only the wanted tuples to begin with. The following function does that:
noreptuples[{f_List, r__List}] := 
  Flatten[Function[x, (Prepend[#1, x] & ) /@ noreptuples[DeleteCases[{r}, x, {2}]]] /@ f, 1]

noreptuples[{l_List}] := List /@ l

Note that I didn't time this function; it probably is slower for some cases (straightforward Mathematica code vs. likely very optimized code for Tuples) and faster for others (due to less elements to process).
For the example in your question, 160000 tuples are generated, from which only 2880 tuples remain. Given that each tuple has 8 numbers, and assuming storage in a packed array (basically, 4 bytes per integer), you are generating an array of almost 5 megabytes, and after filtering keep only about 90 kilobytes of that. Given that the memory needed for the tuples grows exponentially with tuple length, this means that the filtering method may quickly become impractical.
"
How to modularize custom controls for Manipulate?,"
Not sure if this helps, but you can define a control in Manipulate as
Manipulate[
  some code,
  {{var, init, label}, func}, 
  ...
]

where func is a function defining a custom control. The first argument given to func is then Dynamic[var]. 
As an example, suppose that instead of an ordinary slider you want a red dot which you can move along a scale. You could define your customSlider as
customSlider[Dynamic[i_], str_, b_, e_, st_] :=
 LocatorPane[Dynamic[{i, 0}, (i = Round[#[[1]], st]) &],
   Dynamic[
    Graphics[{Red, Disk[{i, 0}, Abs[e - b]/40]},
     PlotRange -> {{b, e}, All},
     ImagePadding -> 10,
     PlotLabel -> Row[{str,i}], Axes -> {True, False}]], Appearance -> None]

You can then use this control in Manipulate as
Manipulate[{i, 2 i, 3 i},
 {{i, 0}, (customSlider[#1, "" i= "", -11, 11, 1] &)}, 
 SaveDefinitions -> True]


"
bugs - Mathematica script - passing command line arguments,"
Solution (tested on Linux)
Use this as first line of your script:
#!/usr/local/bin/MathematicaScript -runfirst ""$TopDirectory=\""/usr/local/Wolfram/Mathematica/8.0\"""" -script

If you installed Mathematica in a different directory, you have to adjust the path of $TopDirectory.
How did I debug this?
The first error message is quite clear: the system cannot open the file /SystemFiles/CharacterEncodings/ISO8859-1.m and obviously the system is correct, because this file does not exist in this directory.
You could now use strace to track down what happens (maybe you better redirect the output into a file)
strace -s 128 ./script.m 1 2 3 4 5

Looking into the output you probably stumble over the line
execve(

""/usr/local/Wolfram/Mathematica/8.0/SystemFiles/Kernel/Binaries/Linux-x86-64/MathKernel"", 
["""", ""-runfirst"", ""$TopDirectory=\""/usr/local/Wolfram/Mathematica/8.0\"""", ""-script"", 
""./script.m"", ""--"", ""./script.m"", ""1"", ""2"", ""3"", ""4"", ""5""]

, [/* 54 vars */]) = 0

You see that basically you script-call is of course just a call to the MathKernel. If you execute this on the command-line, your script runs fine. This seems to suggest, that by providing 5 or more parameters, the setting of the $TopDirectory is somehow removed. Therefore, I tried to set it explicitly in the MathematicaScript-call which seems to work.
"
dynamic - Why do buttons with ChoiceDialog freeze the front end?,"
Try the following two alternatives, pressing the button while the Do loop is waiting.
Button[""Click Here"", Print[10!], Method -> ""Preemptive""]
Do[Print[x]; Pause[5], {2}]
(*
 -> x
 -> 3628800
 -> x
*)

and   
Button[""Click Here"", Print[10!], Method -> ""Queued""]
Do[Print[x]; Pause[5], {2}]
(*
 -> x
 -> x
 -> 3628800
*)

Some Explanation:
You can see that in the first case, the Do loop is interrupted for processing the Button procedure, but in the second case it is just queued and the Button processing is postponed until the Do loop ends. 
In the case of the ""Preemptive"" method, Mma wants to assure that you are not stealing the CPU forever and impeding the Do loop finalization, so it gives you a certain time slice to process the Button procedure. If you yield control to human input (as in InputString[]), that time slice expires and thus the results you are getting.
"
graphs and networks - Is it possible to generate a Hasse diagram for a defined relation?,"
In versions 10+, we can compose TransitiveReductionGraph and RelationGraph to get a Hasse diagram function with takes the same arguments and options as RelationGraph: 
ClearAll[hasseF]
hasseF = TransitiveReductionGraph @* RelationGraph

Examples:
hasseF[SubsetQ, Subsets[Range[4]], VertexShapeFunction -> ""Name""]


substringQ[s1_, s2_] := UnsameQ[s1 , s2] && StringMatchQ[s1, ___ ~~ s2 ~~ ___]

hasseF[substringQ, {""a"", ""b"", ""c"",""ab"", ""ac"",""abc"", ""abcd""},
   VertexShapeFunction -> ""Name""]


"
"import - When importing GIF animation, how to find the correct list of ""DisplayDurations""?","
I don't know if you can persuade Import to return the correct durations, but luckily the format of .gif files is pretty straight forward so it's not that hard to extract the correct durations manually from the raw data.
In an animated gif the frame durations are stored in a so called Graphic Control Extension or GCE preceding each frame. A GCE starts with the byte sequence 21 F9 04 followed by 4 data bytes and is closed by 00. Of these data bytes, the second and third byte are the frame duration in hundreds of seconds ordered least significant byte first.
So a crude way to extract the frame durations is to read in the file, find the positions of the byte sequence 21 F9 04 and extract the fourth and fifth byte after each of these positions, e.g.
lst = BinaryReadList[""~/test.gif""];
seq = FromDigits[#, 16] & /@ StringSplit[""21 f9 04""];
pos = Position[Partition[lst, 3, 1], seq];
durations2 = (Extract[lst, pos + 4] + 256 Extract[lst, pos + 5])/100

(* ==> {1/20, 1/10, 3/20, 1/5, 1/4, 3/10, 7/20, 2/5, 9/20, 1/2, 2} *)

"
numerics - Finding a fit to a multi-dimensioned function,"
Without a specific example, I can only make general suggestions here.
The first thing that comes to mind is that you could fit each of the two components of your vector field independently. I.e., if  $\vec{f}: \mathbb{R}^2\to\mathbb{R}^2$ is split up into $\vec{f} = \{f_x, f_y\}$ with $f_{1,2}: \mathbb{R}^2\to\mathbb{R}$, then FindFit would work on each of these component functions. 
If you don't want the fits to be determined independently, it could still be possible to use FindFit by introducing an auxiliary variable $s$ that labels the two component functions above, $f_s$, and then provide the fitting data with this variable s included. Here, s can only have two discrete values (I borrowed the idea from spin-half quantum mechanics). Let's choose s = 0 for the function $f_x$ and s = 1 for $f_y$. So you'd have data in the form
data = {{x1, y1, 0, fx1}, {x1, y1, 1, fy1}, ...}

where fx1 is the first value of $f_x$ and fy1 the first value of $f_y$, both at the point x1, y1.
Your model could then look something like this:
model[x_, y_, s_] := modely[x, y]*s + modelx[x, y]*(1 - s)

where modely[x, y] is the model for $f_y$ and modelx[x, y] is the model for $f_x$. The variables in the FindFit call would be x, y, s, and the parameters  in the models modelx, modely could be the same (or different). 
There are probably many other reasonable ways to do such a fit, but these are some ideas.
"
plotting - How to export transparent raster plots?,"
Instead of using Save Image As... you can use the Export command, like this:
Export[""transparent.png"", Graphics[Circle[]], Background -> None]

For this to work it is important that Background -> None is also set inside Graphics.  This is the default though so unless you changed it, it should be fine.
Similarly, to convert to an image with alpha channels, use
Rasterize[Graphics[Circle[]], ""Image"", Background -> None]

The output of this can be saved even using Save Image As..., but this effort needed is the same because of the Rasterize function.
"
equation solving - How to find the smallest root,"
Briefly, one can use  : 
Reduce[ D[ F[x], x] == 0, x, Reals]

or if the function is not strictly monotonic one should select the maximal element out of the result in the boolean form, e.g.
Max @ (( List @@ Reduce[ D[ F[x], x] == 0, x, Reals] // Quiet)[[All, 2]])

The major problem is to provide some examples to demonstrate how it works. Since there have been none I will give the following :
Ex. 1. a class of $C^{1}$ functions
We define a family of differentiable i.e. $C^{1}$ functions F numbered with an eps parameter  :
P[x_] := a x^3 + b x^2 + c x + d
W[x_, eps_] := P[x] //. Flatten @ Solve[{ #^2 == P[#], 1 == P[1], 2 # == P'[#], 1 == P'[1]}, 
                                        {a, b, c, d}]& @ (1 - eps)
Z[x_, eps_] := P[x] //. Flatten @ Solve[{ # == P[#], 2 == P[2], 1 == P'[#], 0 == P'[2]},
                                        {a, b, c, d}]& @ (2 - eps)
F[x_, eps_] := Piecewise[{ { x^2, 0 < x < 1 - eps}, 
                           { W[x, eps], 1 - eps <= x < 1}, 
                           { x, 1 <= x < 2 - eps}, 
                           { Z[x, eps], 2 - eps <= x < 2},
                           { 2, x >= 2} } ]

This definition is slightly involved because it is constructed with a few pieces of differentiable functions. The result fulfills the requirements. We introduced auxiliary functions P, W and Z  to define F (monotonic, differentiable, and constant after x exceeds a certain point x0, (here x0 == 2)).
Now we can test the result for any eps (every eps > 0 define a differentiable function F[x, eps] ), e.g.   
 Manipulate[ Plot[ F[x, eps], {x, 0, 2.3}, PlotRange -> {0, 2.3}] // Quiet, {eps, 0, 1}]

or showing a graph of F[x, eps] with a running parameter eps on the background of graphs for various eps :   
    Animate[ 
        Show[ Plot[ Evaluate @ Table[ F[x, ep], {ep, 0, 1, 0.1}], {x, 0, 2.3}, 
                    PlotRange -> {0, 2.1}, ImageSize -> {650, 450}] // Quiet, 
              Plot[ F[x, eps], {x, 0, 2.3}, PlotRange -> {0, 2.1}, 
                    PlotStyle -> Thick, ImageSize -> {650, 450}] // Quiet, 
              Graphics[{ PointSize[0.015], Magenta,
                         Point @ {{1 - eps, F[1 - eps, eps]}, {2 - eps, F[2 - eps, eps]}}}]
            ],  {eps, 0, 1}]


Reduce[ D[F[x, 0.4], x] == 0, x, Reals] // Quiet
Max @ ( List @@ Reduce[ D[ F[x, 0.4], x] == 0, x, Reals] // Quiet)[[All, 2]]


 x <= 0 || x > 2.
 2.


The answer is x == 2.
Edit
We would like to test the method when the interesting point changes its location, therefore we add another class of functions to demonstrate the reliability of the approach based on Reduce. 
Ex. 2. a class of $C^{\infty}$ functions
We construct a family of G functions numbered with an eps parameter, but this family is smooth (i.e. $C^{\infty}$) and the gluing point x == x0 is movable : 
G[x_, eps_] := 
    Piecewise[{ {1 - eps^2/10 - eps Exp[-(1/(1 - 1/eps - x))], x < 1 - 1/eps},
                {1 - eps^2/10, x >= 1 - 1/eps} }]

This family of functions G is not analytic of course, (precisely, the only point where the functions are not analytic is x == 1 - 1/eps), however they  are still smooth, i.e. we can find their derivatives of any order in x == 1 - 1/eps, for any eps, e.g. 
Limit[ Table[ D[G[x, eps], {x, n}], {n, 1, 10}], x -> 1 - 1/eps, Direction ->  1]
Limit[ Table[ D[G[x, eps], {x, n}], {n, 1, 10}], x -> 1 - 1/eps, Direction -> -1]


{0, 0, 0, 0, 0, 0, 0, 0, 0, 0}
{0, 0, 0, 0, 0, 0, 0, 0, 0, 0}


thus its expansion in a Taylor series around x0 == 1 - 1/eps is constant  unlike the function itself for x <= x0.
We can test that for any eps we get the correct result :
Manipulate[{Reduce[ D[ G[x, eps], x] == 0, x] // Quiet, 1 - 1/eps}, {eps, 0.1, 1}]


and we make a plot of a few functions :
GraphicsColumn[
    {Plot[ Evaluate @ Table[ G[x, eps], {eps, 0.2, 1.1, 0.1}], {x, -5, 2}, 
           PlotStyle -> Thick, PlotRange -> All, PerformanceGoal -> ""Speed""], 

     Plot[ Evaluate @ Table[ G[x, eps], {eps, 0.5, 0.9, 0.1}], {x, -5, 2},  
           PlotStyle -> Thick, PlotRange -> {{-1.5, 0.1}, {0.9, 0.98}}, 
           PlotPoints -> 200, MaxRecursion -> 8]}]


"
plotting - About the number format in ticks,"
Perhaps this?
LogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}, Frame -> True, 
 FrameTicks -> {{{#, Superscript[10, Log10@#]} & /@ ({10^0, 10^-1, 
       10^-2, 10^-3, 10^-4, 10^-5}), None}, {None, None}}]



Here's a completely different approach, manipulating the existing tick labels in the generated graph, and preserving the unlabeled ticks.  This seems much cleaner to me than Peter's approach, assuming that it works on version 8 as it does on version 7.
format =
  Replace[#, {p_, n_?NumericQ} :> {p, Superscript[10, Round@Log10@n]}, {#2}] &;

ticks = MapThread[format, {Options[#, {Ticks, FrameTicks}], {3, 4}}] &;

Use:
p = LogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}, Frame -> True];

Show[p, ticks[p]]



Update 2015
The new Ticks subsystem
Recent versions of Mathematica use a different ticks rendering system wherein functions specified for Ticks or FrameTicks are passed to the Front End (which calls the Kernel) rather than being evaluated beforehand.  If we look at the options of p above we now see:
Options[p, {Ticks, FrameTicks}]


{
 Ticks -> {Automatic, Charting`ScaledTicks[{Log, Exp}]}, 
 FrameTicks -> {{Charting`ScaledTicks[{Log, Exp}], 
    Charting`ScaledFrameTicks[{Log, Exp}]}, {Automatic, Automatic}}
}


We could use these functions to compute tick specifications external to plotting, but to follow the spirit of the new paradigm we can modify the output of these functions instead.
ScaledTicks returns (at least?) three different label formats which we must handle:
Charting`ScaledTicks[{Log, Exp}][-11.7, 1.618][[2 ;; 4, 2]] // InputForm


{Superscript[10, -4], 0.001, NumberForm[0.01, {Infinity, 3}]}


The Superscript is already our desired format.  The other two may be handled with replacement:
format2 =
  Replace[#, n_?NumericQ | NumberForm[n_, _] :> Superscript[10, Round@Log10@n]] &;

We can then use this to apply the formatting:
relabel = # /. CST_Charting`ScaledTicks :> (MapAt[format2, CST[##], {All, 2}] &) &;

LogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}] // relabel


relabel also works with framed plots.
Spelunking internal functions
One may be interested is the source of the original label formatting.  Charting`ScaledTicks calls:
Charting`SimplePadding

which takes the option ""CutoffExponent"" which we would like to use, but unfortunately ScaledTicks overrides it.  If we use:
ClearAttributes[Charting`ScaledTicks, {Protected, ReadProtected}]

And then modify the definition to replace:
""CutoffExponent"" -> 
 If[{Visualization`Utilities`ScalingDump`f, 
    Visualization`Utilities`ScalingDump`if} === {Identity, Identity}, 6, 4]

With:
""CutoffExponent"" -> 1

We will find that the desired formatting has been effected:
LogPlot[Abs[BesselJ[1, x] Sin[x]^2], {x, -10, 10}, Frame -> True]


This modification is inadvisable however, and sadly Charting`ScaledTicks does not itself take ""CutoffExponent"" as an option that would be passed on.  One could modify its definition to add this option, but it is safer to use relabel defined above.
"
graphics3d - Extract current viewing parameters from a 3D view?,"
You can dynamically extract ViewPoint and others like this (also useful for synchronization of different plots etc.):
vp = Options[Graphics3D, ViewPoint][[1, 2]];

Graphics3D[Cuboid[], ViewPoint -> Dynamic[vp]]


This value is now constantly updated:
Dynamic[vp]


{1.3, -2.4, 2.}

This seem also to work fine with other functions that use the ViewPoint option. Below, ViewPoint and ViewVertical are in sync for both objects:
{vp, vv} = Options[Graphics3D, {ViewPoint, ViewVertical}][[All, 2]];

Grid[{{Graphics3D[Cuboid[], ViewPoint -> Dynamic[vp], 
    ViewVertical -> Dynamic[vv]], 
   ParametricPlot3D[{Cos[u], Sin[u] + Cos[v], Sin[v]}, {u, 0, 
     2 Pi}, {v, -Pi, Pi}, ViewPoint -> Dynamic[vp], 
    ViewVertical -> Dynamic[vv]]}}]


"
polynomials - Computing the genus of an algebraic curve,"
For computing the genus of a plane algebraic curve implicitly defined by a squarefree polynomial $f(x,y)$ there are different softwares available in the literature.
Remark: I assume you are interested in computing the genus when the coefficients of the defining polynomial of the curve are either integers or rationals right? This is the case of exact data. For instance, $f(x,y)=x^2-y^3$ represents an exact data polynomial, but $f'(x,y)=1.00 \, x^2-1.01 \, y^3$, with $n=0.01$ the noise in the coefficients is an inexact data polynomial. Basically, the algorithms/their implementations for computing the genus are divided into two main classes: the algorithms for exact data and the algorithm for exact and inexact data.
Alternatives: In the case of exact data you can use some libraries, I find the following the most practical:

algcurves in Maple. See the author's instructions on how to compute the genus.
normal.lib package in Singular

In Mathematica there is no implementation (at present time from my knowledge) of an algorithm for computing the genus of plane algebraic curve. There are several reasons for this, if you want to know more about these details, just let me know.
We also have an implementation for computing the genus of a plane algebraic curve at, please see here.
Roughly, the implementation is in C++ (see the instructions for more details). Our library computes the genus of curves defined by polynomials with exact data and with inexact data. We did not write our library in Mathematica for different ""strong"" reasons, so if you really want to use Mathematica for computing the genus I am afraid I do not have a good news for you. But, for the exact case, the algcurves package is very good, and for the exact and inexact case (or simply the exact case) you can use our library. I hope this is not too confusing for you.
If you need more help/information, please just let me know.
Note: Here are some reasons for which we did not implement at first our algorithm for genus computation in Mathematica (Artes, thanks for the question on this issue, I was kind of hoping to discuss a bit more about this). 
For computing the genus, we need an algorithm for solving the following decisive problem: for a real plane algebraic curve C defined by the polynomial f(x,y)=0, we need to compute a graph G=(V,E), where V is a set of points in the 2-dimensional Euclidean plane together with their Euclidean coordinates and E is a set of edges connecting them. In addition, the graph G has the special property that it can be continuously deformed into the curve C. Intuitively, the computed graph G is a piecewise linear approximation of the differential curve C. At present (from my knowledge) in Mathematica there are no algorithms for computing the graph G for an input curve C. Still, at present we are working (I am actually very interested in this problem) on developing a new algorithm for computing such a special graph G for a real plane (and space) real algebraic curve. And I am working on the implementation of the algorithm in Mathematica. After this algorithm will be available in Mathematica, we can have an implementation for the genus of a plane algebraic curve in Mathematica as well.
"
image processing - Filtering pixels of a certain color,"
i = Import[""http://i.stack.imgur.com/zzUdB.gif""];

{h, s, b} = ColorSeparate[i, ""HSB""];

Manipulate[
 Column[
  {
   Graphics[{Hue[c], Rectangle[]}, ImageSize -> 40],
   ImageMultiply[i, 
    Binarize[Abs[Mod[ImageData[h] - c, 1, -1/2]] // Image, 
      tolerance] // ColorNegate]
   }
  ],
 {c, 0, 1},
 {{tolerance, 0.1}, 0, 0.5}
 ]





GIF image source 
"
performance tuning - How can I use Mathematica's graph functions to cheat at Boggle?,"
Preview and comparative results
The implementation below may be not the most ""minimal"" one, because I don't use any of the built-in functionality (DictionaryLookup with patterns, Graph-related functions, etc), except the core language functions. However, it uses efficient data structures, such as Trie, linked lists, and  hash tables, and arguably maximally avoids the overheads typical in Mathematica programming. The combined use of Trie, linked lists, and recursion allows the main function to copy very little. The use of trie data structure allows me to be completely independent of the system DictionaryLookup function. 
Why is this critical here? Because the nature of the problem makes only a single last letter important for the next traversal step, and constructing the whole word (containing all previous letters) just to check that it exists is a waste, and this is arguably the reason why other solutions are both much slower and do not scale so well.
Also, the preprocessing step, while rather costly (takes about 6 seconds on my machine), has to be done only once, to initialize the ""boggle engine"" (moreover, the resulting trie can be stored in e.g. .mx file for later reuse, avoiding this overhead for subsequent uses), while in other posted solutions some preprocessing has to be done for every particular board.
The main message I want to deliver is that, for the top-level Mathematica code, the choice of efficient data structures is crucial. Our Mathematica programming instincts demand that we reuse as much of the built-in functionality as possible, but one always has to question how well the existing functionality matches the problem. In this particular case, my opinion is that neither the built-in Graph - related functions nor the DictionaryLookup with patterns bring much to the table. To the opposite, these functions force us to use unnatural for this problem data representations and/or algorithms, and this is what leads to the slowdowns. I may be over-emphasizing this point, but this was exactly the essence of the question.
Now, some timing comparisons (note that for the solution of @R.M., I had to include the pieces defining adjnodes, letters and dict variables, into the timing measurements):

Board 4x4 (the original one):

Pillsy   3.3 sec
R.M.     1.4 sec
L.S.     0.04 sec

Board  5x5:
""E I S H R
 B D O I O
 T R O E X
 Z U Y Q S
 I A S U M""


Pillsy   18.8 sec
R.M.     7.6  sec
L.S.     0.05 sec

Board 7x7
""E I E G E O T
 A O B A U R A
 N E I P L A Y
 O O I I C A T
 I I F U N L A
 S T I N G E W
 U H L E O X S""


Pillsy   373.8 sec
R.M.     191.5 sec
L.S.     0.18 sec


So, you can see that for larger boards, the difference between the running times is even more dramatic, hinting that the solutions have different computational complexities. 
I took the trouble to perform and present all these timings because I think that this problem  is an important counterexample to the ""conventional wisdom"" to favor shorter implementations utilizing built-ins over the hand-written top-level mma code. While I agree that in general this is a good strategy, one has to always examine the case at hand. To my mind, this problem presents one notable exception to this rule. 
Implementation
The following solution will not use Mathematica graphs, but will be about 100 times faster (than the timings you cite), and will rely on this post. I will borrow a function which builds the word tree from there:
ClearAll[makeTree];
makeTree[wrds : {__String}] := makeTree[Characters[wrds]];
makeTree[wrds_ /; MemberQ[wrds, {}]] := 
     Prepend[makeTree[DeleteCases[wrds, {}]], {} -> {}];
makeTree[wrds_] := 
    Reap[If[# =!= {}, Sow[Rest[#], First@#]] & /@ 
       wrds, _, #1 -> makeTree[#2] &][[2]]

Its use is detailed in the mentioned post. Now, here is a helper function which will produce rules for vertex number to letter conversion, and adjacency rules:
Clear[getLetterAndAdjacencyRules];
getLetterAndAdjacencyRules[letterMatrix_?(MatrixQ[#, StringQ] &)] :=
  Module[{a, lrules, p, adjRules},
    lrules = Thread[Range[Length[#]] -> #] &@Flatten[letterMatrix];
    p = 
      ArrayPad[
          Partition[Array[a, Length[lrules]], Last@Dimensions@letterMatrix], 
          1
      ];
    adjRules = 
      Flatten[
       ListConvolve[{{1, 1, 1}, {1, 2, 1}, {1, 1, 1}}, p] /. Plus -> List /.
         {left___, 2*v_, right___} :> {v -> {left, right}} /. a[x_] :> x];
    Map[Dispatch, {lrules, adjRules}]
  ];

It is pretty ugly but it does the job. Next comes the main function, which will find all vertex sequences which result in valid dictionary words:
EDIT
Apparently, there is a problem with Module-generated inner functions. I used Module in getVertexSequences initially, but, because in my benchmarks I happened to use a previous incarnation of it with a different name (where I did not yet modularize the inner functions), I did not see the difference. The difference is an order of magnitude slow-down. Therefore, I switched to Block, to get back the performance I claimed (You can replace back the Block with Module to observe the effect). This is likely related to this issue, and is something anyone should be aware of IMO, since this is quite insidious.  
END EDIT
Clear[getVertexSequences];
getVertexSequences[adjrules_, letterRules_, allTree_, n_] :=
Block[{subF, f, getWordsForStartingVertex},
  (* A function to extract a sub-tree *)
  subF[v_, tree_] := 
    With[{letter = v /. letterRules},
      With[{res = letter /. tree},
        res /; res =!= letter]];
  subF[_, _] := {};
  (* Main function to do the recursive traversal *)
  f[vvlist_, {{} -> {}, rest___}] := f[Sow[vvlist], {rest}];
  f[_, {}] := Null;
  f[vvlist : {last_, prev_List}, subTree_] :=
     Scan[
       f[{#, vvlist}, subF[#, subTree]] &,
       Complement[last /. adjrules, Flatten[vvlist]]
     ];
  (* Function to post-process the result *)
  getWordsForStartingVertex[v_] :=
    If[# === {},
       #,
       Reverse[Map[Flatten, First@#], 2]
    ] &@Reap[f[{v, {}}, subF[v, allTree]]][[2]];
  (* Call the function on every vertex *)
  Flatten[Map[getWordsForStartingVertex, Range[n]], 1]
]

At the heart of it, there is a recursive function f, which acts very simply. The vvlist variable is a linked list of already visited vertices. The second argument is a sub-tree of the main word tree, which corresponds to the sequence of already visited vertices (converted to letters. To understand better what the sub-tree is, see the mentioned post). When the sub-tree starts with {} -> {}, this means (by the way word tree is constructed), that the sequence of vertices corresponds to a valid word, so we record it. In any case, if the subtree is not {}, we Scan our function recursively on adjacent vertices, removing from them those we already visited.
The final functions we need are the one to convert vertex sequences to words, and the one to construct the trie data structure. Here  they are:
Clear[wordsFromVertexSequences];
wordsFromVertexSequences[vseqs_List, letterRules_] :=
   Map[StringJoin, vseqs /. letterRules];

ClearAll[getWordTree];
getWordTree[minLen_Integer: 1, maxLen : (_Integer | Infinity) : Infinity] :=
  makeTree[
     Select[ToLowerCase@DictionaryLookup[""*""], 
     minLen <= StringLength[#] <= maxLen &]];

The function to bring this all together:
ClearAll[getWords];
getWords[board_String, wordTree_] :=
   getWords[ToLowerCase@ImportString@board, wordTree];
getWords[lboard_, wordTree_] :=
   Module[{lrules, adjrules},
   {lrules, adjrules} = getLetterAndAdjacencyRules[lboard ];
   wordsFromVertexSequences[
       getVertexSequences[adjrules, lrules, wordTree, 
          Times @@ Dimensions[lboard]],
       lrules
   ]
];

Illustration
First, construct a full tree of all words in a dictionary. This preprocessing step can take a little while:
largeTree = getWordTree[];

Now, construct the word matrix:
wmat = ToLowerCase@ImportString@
  ""F X I E
   A M L O
   E W B X
   A S T U""


{{""f"", ""x"", ""i"", ""e""}, {""a"", ""m"", ""l"", ""o""}, {""e"", ""w"", ""b"",""x""}, 
         {""a"", ""s"", ""t"", ""u""}}

Next, construct the rules for vertex-to-letter conversion and adjacency rules:
({lrules,adjrules} = getLetterAndAdjacencyRules[wmat])//Short[#,3]&


{Dispatch[{1->f,2->x,3->i,4->e,5->a,6->m,7->l,8->o,9->e,10->w,11->b,
  12->x,13->a,14->s,15->t,16->u},-DispatchTables-],
    Dispatch[{1->{2,5,6},<<14>>,16->{11,12,15}},<<1>>]}


We are now ready to use our function:
(seqs = getVertexSequences[adjrules,lrules,largeTree,16])//Short//AbsoluteTiming


{0.0185547,{{1,5},{1,5,2},{1,5,6,9},{1,6},<<89>>,{15,14},
     {15,16,11},{15,16,11,14},{15,16,12}}}


Note that it took very little time to get the result. We can finally convert it to words:
wordsFromVertexSequences[seqs,lrules]//Short


{fa,fax,fame,fm,xi,xml,xl,<<84>>,twas,tb,ts,tub,tubs,tux}

The way to call a final function:
(* Do this only once per session *)
$largeTree = getWordTree[3];

board = ToLowerCase@ImportString@""F X I E
  A M L O
  E W B X
  A S T U""

getWords[board, $largeTree]


{fax,fame,xml,imf,eli,elm,elma,<<59>>,stub,twa,twa,twas,tub,tubs,tux}

(note that the result differs from that in illustration section, since I am now using the word tree with words with less than 3 letters excluded - using the $largeTree rather than largeTree now).
Discussion
Of course, I was a bit cheating in the sense that the preprocessing time takes a while, but this has to be done only once. My main point is that I think, the Trie data structure (my interpretation of it) is the right one here, and coupled with linked lists and hash tables (Dispatch-ed rules), it leads to a rather simple solution. The essence of the solution is expressed in function f, which is just a few lines long and more or less self-documenting. And, also, the solution itself turns out quite fast (especially given that this uses just the top-level mma, no packed arrays, Compile, etc). 
EDIT 2
To address the question in your edit, and generally the question on applicability of Mathematica's new Graph functionality to this problem: I think, that while you can use new Graphs to solve the problem, it is not a natural choice here. I may be wrong, of course, but these are my reasons:

The graph traversal you need for this problem does not fit directly into either one of DepthFirstScan and BreadthFirstScan built-in graph-traversal functions. Rather, it is a kind of enumeration of all possible depth-first traversals starting at a given vertex.
Those traversals should stop as soon as it becomes clear that no words can be constructed by going to any of the adjacent vertices. This can be also achieved in DepthFirstScan through the use of Catch and Throw, but it is rather inelegant, and will also induce an overhead.
The general ideology of DepthFirstScan and BreadthFirstScan is somewhat similar to a visitor design pattern used for a tree traversal. The idea is that the traversal is done for you, while you have to supply the functions to be called on tree (or graph) nodes. This approach works well when your traversal matches exactly the one implemented by the pattern. For example, most of the time, a tree is traversed depth-first. However, I had many chances to observe (in other languages) that as soon as I have to modify the traversal even slightly, using the tools like that creates more problems than it solves.
The main question to ask yourself is this: does you traversal (sequence of visited vertices) depend on the content of the vertices (information you get during the traversal)? If yes, then it is more than likely that custom general traversal functions will not give you a good solution, because you then need more control over the way traversal is performed. The whole idea of visitor pattern (used for tree traversals) and the like is that you can separate the traversal itself from the information-processing during the traversal, and it's just not true for data-dependent traversals, where you can not really decouple traversal from the data-processing of the tree (or graph) nodes.

I think that we should separate cases where graphs represent just a useful abstraction to think about the problem, from those where the problem can be solved by means of more or less standard graph-theoretical functionality (in particular that present in Mathematica), once it is reformulated in an appropriate way. The case at hand clearly looks to me like belonging to the first category. 
"
dynamic - Strange behavior of CreateDialog's WindowSize option,"
The following works for me with Mathematica 8.0.4
DynamicModule[{switch = 1},
CreateDialog[
globalvar = DocumentNotebook@TextCell@Dynamic@Switch[switch, 1, ""A"", 2, ""B""], 
WindowSize -> {200, 100}]];

However making the variable local to the DynamicModule does not work:
DynamicModule[{switch = 1, localvar},
CreateDialog[
localvar = DocumentNotebook@TextCell@Dynamic@Switch[switch, 1, ""A"", 2, ""B""], 
WindowSize -> {200, 100}]];

It also fails if the variable is localized in a Module wrapping the whole thing:
Module[{localvar},
DynamicModule[{switch = 1},
CreateDialog[
localvar = DocumentNotebook@TextCell@Dynamic@Switch[switch, 1, ""A"", 2, ""B""],
WindowSize -> {200, 100}]]];    

"
Quadruple-precision (128 bit) arithmetic,"
As the comments indicate, there is no completely hardware-based solution - but that doesn't mean you can't do some tweaking. The trick is always: stick with machine precision as long as you can, then switch to arbitrary precision only to refine your results. 
Instead of making up an example (which is hard because Mathematica implements the above principle automatically in many cases, as observed in the comment - which caused me to delete an earlier example), I'll address the problem given in your question some more. It can also be sped up considerably by deferring the use of arbitrary precision (in this case the application of N[...,36] etc.) to the end:
{#, First@AbsoluteTiming[N[Sin[num], #];]} & /@ Range[32, 36]


{{32, 0.931845}, {33, 0.871302}, {34, 0.858584}, {35, 0.852693}, {36, 
    0.849243}}

All I did was to move the N outside the Sin, and the timing is an order of magnitude faster. 
"
Defining a non-linear optimization-problem,"
I'm not sure I fully understand the problem, but maybe this will give you some directions to try.
(*Exemplary data:*)
SeedRandom[11112222333];
WeeklyCapacity = Table[189*7.5, {t, 6}];
WeeklyDemand = Table[RandomInteger[{2000, 5000}], {i, 10}];
 CycleTimes = (1/#) & /@ Table[RandomInteger[{40, 125}], {i, 10}];

ProductionProgram = Table[Subscript[x, i, t], {i, 10}, {t, 6}];
CapaDemand = Transpose@ProductionProgram.CycleTimes;

ConstraintDemand = 
  Map[# == 0 &, Total /@ ProductionProgram - WeeklyDemand];
ConstraintCapa = Map[# <= 0 &, Total /@ CapaDemand - WeeklyCapacity];

constraints = Join[ConstraintDemand, ConstraintCapa];
vars = Flatten[ProductionProgram];

MinVarProductionProgram = 
  Simplify[Variance /@ ProductionProgram, 
   Assumptions -> Element[vars, Reals]];

Here I am not sure whether it is the total or total-of-squares (or something else entirely) to be minimized.
Timing[{min, vals} = 
  FindMinimum[{Total[MinVarProductionProgram], constraints}, vars]]

Out[294]= {0.1, {-8.53712*10^-11, {Subscript[x, 1, 1] -> 389.5, 
   Subscript[x, 1, 2] -> 389.5, Subscript[x, 1, 3] -> 389.5, 
   Subscript[x, 1, 4] -> 389.5, Subscript[x, 1, 5] -> 389.5, 
   Subscript[x, 1, 6] -> 389.5, Subscript[x, 2, 1] -> 549.167, 
   Subscript[x, 2, 2] -> 549.167, Subscript[x, 2, 3] -> 549.167, 
   Subscript[x, 2, 4] -> 549.167, Subscript[x, 2, 5] -> 549.167, 
   Subscript[x, 2, 6] -> 549.167, Subscript[x, 3, 1] -> 703.667, 
   Subscript[x, 3, 2] -> 703.667, Subscript[x, 3, 3] -> 703.667, 
   Subscript[x, 3, 4] -> 703.667, Subscript[x, 3, 5] -> 703.667, 
   Subscript[x, 3, 6] -> 703.667, Subscript[x, 4, 1] -> 495.167, 
   Subscript[x, 4, 2] -> 495.167, Subscript[x, 4, 3] -> 495.167, 
   Subscript[x, 4, 4] -> 495.167, Subscript[x, 4, 5] -> 495.167, 
   Subscript[x, 4, 6] -> 495.167, Subscript[x, 5, 1] -> 759.833, 
   Subscript[x, 5, 2] -> 759.833, Subscript[x, 5, 3] -> 759.833, 
   Subscript[x, 5, 4] -> 759.833, Subscript[x, 5, 5] -> 759.833, 
   Subscript[x, 5, 6] -> 759.833, Subscript[x, 6, 1] -> 764.167, 
   Subscript[x, 6, 2] -> 764.167, Subscript[x, 6, 3] -> 764.167, 
   Subscript[x, 6, 4] -> 764.167, Subscript[x, 6, 5] -> 764.167, 
   Subscript[x, 6, 6] -> 764.167, Subscript[x, 7, 1] -> 637.333, 
   Subscript[x, 7, 2] -> 637.333, Subscript[x, 7, 3] -> 637.333, 
   Subscript[x, 7, 4] -> 637.333, Subscript[x, 7, 5] -> 637.333, 
   Subscript[x, 7, 6] -> 637.333, Subscript[x, 8, 1] -> 476.5, 
   Subscript[x, 8, 2] -> 476.5, Subscript[x, 8, 3] -> 476.5, 
   Subscript[x, 8, 4] -> 476.5, Subscript[x, 8, 5] -> 476.5, 
   Subscript[x, 8, 6] -> 476.5, Subscript[x, 9, 1] -> 666.833, 
   Subscript[x, 9, 2] -> 666.833, Subscript[x, 9, 3] -> 666.833, 
   Subscript[x, 9, 4] -> 666.833, Subscript[x, 9, 5] -> 666.833, 
   Subscript[x, 9, 6] -> 666.833, Subscript[x, 10, 1] -> 511., 
   Subscript[x, 10, 2] -> 511., Subscript[x, 10, 3] -> 511., 
   Subscript[x, 10, 4] -> 511., Subscript[x, 10, 5] -> 511., 
   Subscript[x, 10, 6] -> 511.}}}

For sum of squares of variances:
Timing[{min2, vals2} = 
  FindMinimum[{MinVarProductionProgram.MinVarProductionProgram, 
    constraints}, vars]]

Out[296]= {2.28, {2.51657*10^8, {Subscript[x, 1, 1] -> 478.496, 
   Subscript[x, 1, 2] -> 373.593, Subscript[x, 1, 3] -> 373.593, 
   Subscript[x, 1, 4] -> 373.593, Subscript[x, 1, 5] -> 373.593, 
   Subscript[x, 1, 6] -> 364.134, Subscript[x, 2, 1] -> 686.262, 
   Subscript[x, 2, 2] -> 523.509, Subscript[x, 2, 3] -> 523.509, 
   Subscript[x, 2, 4] -> 523.509, Subscript[x, 2, 5] -> 523.509, 
   Subscript[x, 2, 6] -> 514.701, Subscript[x, 3, 1] -> 877.119, 
   Subscript[x, 3, 2] -> 668.976, Subscript[x, 3, 3] -> 668.976, 
   Subscript[x, 3, 4] -> 668.976, Subscript[x, 3, 5] -> 668.976, 
   Subscript[x, 3, 6] -> 668.979, Subscript[x, 4, 1] -> 346.338, 
   Subscript[x, 4, 2] -> 552.386, Subscript[x, 4, 3] -> 552.386, 
   Subscript[x, 4, 4] -> 552.386, Subscript[x, 4, 5] -> 552.386, 
   Subscript[x, 4, 6] -> 415.116, Subscript[x, 5, 1] -> 861.299, 
   Subscript[x, 5, 2] -> 743.336, Subscript[x, 5, 3] -> 743.336, 
   Subscript[x, 5, 4] -> 743.336, Subscript[x, 5, 5] -> 743.336, 
   Subscript[x, 5, 6] -> 724.357, Subscript[x, 6, 1] -> 937.424, 
   Subscript[x, 6, 2] -> 727.414, Subscript[x, 6, 3] -> 727.414, 
   Subscript[x, 6, 4] -> 727.414, Subscript[x, 6, 5] -> 727.414, 
   Subscript[x, 6, 6] -> 737.922, Subscript[x, 7, 1] -> 775.12, 
   Subscript[x, 7, 2] -> 611.552, Subscript[x, 7, 3] -> 611.552, 
   Subscript[x, 7, 4] -> 611.552, Subscript[x, 7, 5] -> 611.552, 
   Subscript[x, 7, 6] -> 602.671, Subscript[x, 8, 1] -> 612.536, 
   Subscript[x, 8, 2] -> 451.053, Subscript[x, 8, 3] -> 451.053, 
   Subscript[x, 8, 4] -> 451.053, Subscript[x, 8, 5] -> 451.053, 
   Subscript[x, 8, 6] -> 442.253, Subscript[x, 9, 1] -> 766.477, 
   Subscript[x, 9, 2] -> 650.705, Subscript[x, 9, 3] -> 650.705, 
   Subscript[x, 9, 4] -> 650.705, Subscript[x, 9, 5] -> 650.705, 
   Subscript[x, 9, 6] -> 631.703, Subscript[x, 10, 1] -> 523.304, 
   Subscript[x, 10, 2] -> 523.034, Subscript[x, 10, 3] -> 523.034, 
   Subscript[x, 10, 4] -> 523.034, Subscript[x, 10, 5] -> 523.034, 
   Subscript[x, 10, 6] -> 450.56}}}

Hope this gives some ideas for how to proceed.
--- edit ---
Since the objective is nonlinear Mathematica only has NMinimize to try to enforce integrality of variables. Here is the altered code for this situation. I start by rounding the result from FindMinimum, to be used as initial variable ranges for NMinimize.
In[35]:= Timing[{min2, vals2} = 
   FindMinimum[{MinVarProductionProgram.MinVarProductionProgram, 
     constraints}, vars];]

Out[35]= {2.16, Null}

In[39]:= firstGuess = Round[vars /. vals2];
delta = 50;
ranges = Transpose[{vars, firstGuess - delta, firstGuess + delta}];

I use these ranges in NMinimize.
Timing[{min3, vals3} = 
  NMinimize[{MinVarProductionProgram.MinVarProductionProgram, 
    Append[constraints, Element[vars, Integers]]}, ranges, 
   MaxIterations -> 1000]]

During evaluation of In[42]:= NMinimize::cvmit: Failed to converge to the requested accuracy or precision within 1000 iterations. >>

Out[42]= {153.86, {5.87444, {Subscript[x, 1, 1] -> 389, 
   Subscript[x, 1, 2] -> 390, Subscript[x, 1, 3] -> 390, 
   Subscript[x, 1, 4] -> 389, Subscript[x, 1, 5] -> 389, 
   Subscript[x, 1, 6] -> 390, Subscript[x, 2, 1] -> 548, 
   Subscript[x, 2, 2] -> 550, Subscript[x, 2, 3] -> 547, 
   Subscript[x, 2, 4] -> 550, Subscript[x, 2, 5] -> 550, 
   Subscript[x, 2, 6] -> 550, Subscript[x, 3, 1] -> 704, 
   Subscript[x, 3, 2] -> 704, Subscript[x, 3, 3] -> 704, 
   Subscript[x, 3, 4] -> 705, Subscript[x, 3, 5] -> 703, 
   Subscript[x, 3, 6] -> 702, Subscript[x, 4, 1] -> 495, 
   Subscript[x, 4, 2] -> 495, Subscript[x, 4, 3] -> 495, 
   Subscript[x, 4, 4] -> 496, Subscript[x, 4, 5] -> 495, 
   Subscript[x, 4, 6] -> 495, Subscript[x, 5, 1] -> 759, 
   Subscript[x, 5, 2] -> 759, Subscript[x, 5, 3] -> 761, 
   Subscript[x, 5, 4] -> 760, Subscript[x, 5, 5] -> 760, 
   Subscript[x, 5, 6] -> 760, Subscript[x, 6, 1] -> 764, 
   Subscript[x, 6, 2] -> 763, Subscript[x, 6, 3] -> 764, 
   Subscript[x, 6, 4] -> 765, Subscript[x, 6, 5] -> 765, 
   Subscript[x, 6, 6] -> 764, Subscript[x, 7, 1] -> 638, 
   Subscript[x, 7, 2] -> 638, Subscript[x, 7, 3] -> 636, 
   Subscript[x, 7, 4] -> 638, Subscript[x, 7, 5] -> 637, 
   Subscript[x, 7, 6] -> 637, Subscript[x, 8, 1] -> 477, 
   Subscript[x, 8, 2] -> 476, Subscript[x, 8, 3] -> 477, 
   Subscript[x, 8, 4] -> 476, Subscript[x, 8, 5] -> 476, 
   Subscript[x, 8, 6] -> 477, Subscript[x, 9, 1] -> 666, 
   Subscript[x, 9, 2] -> 666, Subscript[x, 9, 3] -> 667, 
   Subscript[x, 9, 4] -> 667, Subscript[x, 9, 5] -> 668, 
   Subscript[x, 9, 6] -> 667, Subscript[x, 10, 1] -> 511, 
   Subscript[x, 10, 2] -> 511, Subscript[x, 10, 3] -> 511, 
   Subscript[x, 10, 4] -> 511, Subscript[x, 10, 5] -> 511, 
   Subscript[x, 10, 6] -> 511}}}

As the message indicates, possibly one could do better. Notice though that the min is now considerably lower than what we had from FindMinimum, so progress has been made in the globval optimization effort. And of course we can keep going. This time I'll narrow the start range lengths.
nextGuess = vars /. vals3;
delta2 = 10;
ranges2 = Transpose[{vars, nextGuess - delta2, nextGuess + delta2}];

Timing[{min4, vals4} = 
  NMinimize[{MinVarProductionProgram.MinVarProductionProgram, 
    Append[constraints, Element[vars, Integers]]}, ranges2, 
   MaxIterations -> 1000]]

Out[66]= {135.86, {0.461111, {Subscript[x, 1, 1] -> 389, 
   Subscript[x, 1, 2] -> 389, Subscript[x, 1, 3] -> 390, 
   Subscript[x, 1, 4] -> 390, Subscript[x, 1, 5] -> 390, 
   Subscript[x, 1, 6] -> 389, Subscript[x, 2, 1] -> 549, 
   Subscript[x, 2, 2] -> 549, Subscript[x, 2, 3] -> 550, 
   Subscript[x, 2, 4] -> 549, Subscript[x, 2, 5] -> 549, 
   Subscript[x, 2, 6] -> 549, Subscript[x, 3, 1] -> 704, 
   Subscript[x, 3, 2] -> 704, Subscript[x, 3, 3] -> 704, 
   Subscript[x, 3, 4] -> 703, Subscript[x, 3, 5] -> 703, 
   Subscript[x, 3, 6] -> 704, Subscript[x, 4, 1] -> 496, 
   Subscript[x, 4, 2] -> 495, Subscript[x, 4, 3] -> 495, 
   Subscript[x, 4, 4] -> 495, Subscript[x, 4, 5] -> 495, 
   Subscript[x, 4, 6] -> 495, Subscript[x, 5, 1] -> 760, 
   Subscript[x, 5, 2] -> 760, Subscript[x, 5, 3] -> 760, 
   Subscript[x, 5, 4] -> 759, Subscript[x, 5, 5] -> 760, 
   Subscript[x, 5, 6] -> 760, Subscript[x, 6, 1] -> 764, 
   Subscript[x, 6, 2] -> 765, Subscript[x, 6, 3] -> 764, 
   Subscript[x, 6, 4] -> 764, Subscript[x, 6, 5] -> 764, 
   Subscript[x, 6, 6] -> 764, Subscript[x, 7, 1] -> 637, 
   Subscript[x, 7, 2] -> 638, Subscript[x, 7, 3] -> 638, 
   Subscript[x, 7, 4] -> 637, Subscript[x, 7, 5] -> 637, 
   Subscript[x, 7, 6] -> 637, Subscript[x, 8, 1] -> 477, 
   Subscript[x, 8, 2] -> 476, Subscript[x, 8, 3] -> 477, 
   Subscript[x, 8, 4] -> 476, Subscript[x, 8, 5] -> 477, 
   Subscript[x, 8, 6] -> 476, Subscript[x, 9, 1] -> 666, 
   Subscript[x, 9, 2] -> 667, Subscript[x, 9, 3] -> 667, 
   Subscript[x, 9, 4] -> 667, Subscript[x, 9, 5] -> 667, 
   Subscript[x, 9, 6] -> 667, Subscript[x, 10, 1] -> 511, 
   Subscript[x, 10, 2] -> 511, Subscript[x, 10, 3] -> 511, 
   Subscript[x, 10, 4] -> 511, Subscript[x, 10, 5] -> 511, 
   Subscript[x, 10, 6] -> 511}}}

Seems to be stabilizing.
--- end edit ---
"
databaselink - What format to use to store expressions in database?,"
It sounds like all you are looking for is a generic storage using MySQL. Then your translation of _String to TEXT makes sense, but I would consider _Real as a DOUBLE column, depending on your precision requirements. 
Additionally, I would probably separate the inner list:
{_String, {_String, _Real}, _Real}

into:
{_String, _String, _Real, _Real}

So that you would have four columns (TEXT, TEXT, DOUBLE, DOUBLE). You can translate back and forth with some patterns like:
{a_String, b_String, c_Real, d_Real} -> {a, {b, c}, d}

and 
{a_String, {b_String, c_Real}, d_Real} -> {a, b, c, d}

Before and after import. 
If you need to store MMA expressions, then the most portable way, I believe, is to store them as InputForm, as mentioned by FJRA in the comment to the question. To do so, you would need to do:
ToString[InputForm[expression]]

And then the reverse:
ToExpression[importedString,InputForm]

"
replacement - Replace expressions by self defined symbols,"
Let's represent your bracket expression using the head bb, so
bb[x, y] == x ** y - y ** x

Then we can just use a simple replace rule:
{{X00 ** X10 + X01 ** X10 - X10 ** X01 - X10 ** X00 }, 
 {X01 ** X10 - X10 ** X01 - X02 ** X10}, 
 {X00 ** X12 -  X12 ** X00}, {X01 ** X12 - X12 ** X01}, {X02 ** X13}} \
   //. x_ ** y_ - y_ ** x_ :> bb[x, y]

(* ==>
  {{bb[X00, X10] + bb[X01, X10]}, 
   {bb[X01, X10] - X02 ** X10}, 
   {bb[X00, X12]}, {bb[X01, X12]}, {X02 ** X13}}
*)

We can automate the conversion between the two representations using
toBracket[expr_] := expr //. x_ ** y_ - y_ ** x_ :> bb[x, y]
fromBracket[expr_] := expr /. bb[x_, y_] :> x ** y - y ** x

If you wish to have a prettier notiation, you could for example use AngleBracket instead of bb.  It is formatted like this:

You can enter the brackets using the key sequence Esc<Esc.
"
plotting - Why doesn't PlotMarker option None return no PlotMarkers?,"
The answer to your first question is that PlotMarkers doesn't really use a graphics primitive, but uses font based markers as a proxy for it. This can lead to errors in positioning on some OSes.
I'm guessing that PlotStyle has something of the form ToString@HoldForm[...] when the input is a list, which is why None and False or anything else get converted to strings. This might well be a bug/undesired behaviour, because AxesLabel -> None and AxesLabel -> {""x"", None} don't behave the same way. It does seem to work for Null though, although I wouldn't have guessed it at first.
For the second question, you can adapt Yu-Sung's answer and use CurrentValue[""Color""] to colour your markers. Here's your example modified to do this:
ListPlot[Table[n^(1/p), {p, 4}, {n, 10}], Joined -> True, PlotMarkers :> 
    {{Graphics[{Dynamic@EdgeForm[{CurrentValue[""Color""], Thick}], 
        FaceForm[White], Disk[{0, 0}, 1]}], 0.05}}
]


"
How to get FullSimplify to fully simplify my expression with custom complexity function?,"
We can confirm that the desired form never gets tried, by viewing the expressions sent to the ComplexityFunction with Sow and Reap:
vc := (Count[ToBoxes[Sow@#], Except["" "" | ""("" | "")"", _String], Infinity]) &

Union@Reap[FullSimplify[(-1 + a) (-1 + b), ComplexityFunction -> vc]][[2, 1]]
(*  {-1 + a, -1 + b, (-1 + a) (-1 + b), 1 - a + (-1 + a) b, 1 - a - b + a b}  *)

Therefore it seems that it will be essential to add to TransformationFunctions. First I tried generalising from the specific case given in your comment:
tf = {Automatic, # /. (x_ + a__) (y_ + b__) :> (-x - a) (-y - b) &};
SetOptions[FullSimplify, ComplexityFunction -> vc, TransformationFunctions -> tf];

FullSimplify[expr]
(*  (1 - a) (1 - b)  *)

Unfortunately this fails in certain cases, because ReplaceAll makes the first replacement it finds, which might happen to be one that doesn't decrease the complexity measure:
(* this doesn't work *)
FullSimplify[(a - b) (-1 + c) (-1 + d)]
(*  (a - b) (-1 + c) (-1 + d)  *)

(* but this does *)
FullSimplify[(-1 + c) (-1 + d) (e-f)]
(*  (1 - c) (1 - d) (e - f)  *)

Since it is problematic to find the correct pairs of terms to negate, my next approach was to convert all forms like (-1+a) into -(1-a), but in such a way that the complexity function would ignore the overall multiplier of -1 (and therefore prefer the latter form).
tf = {Automatic, $minusone (-#) &};
vc := (Count[ToBoxes[#], Except[""$minusone"" | "" "" | ""("" | "")"", _String], Infinity]) &
$minusone /: $minusone^2 = 1;
$minusone /: x_ + $minusone = x - 1;

specialSimplify[x_] := 
FullSimplify[x, ComplexityFunction -> vc, TransformationFunctions -> tf] /. $minusone -> -1

specialSimplify tries negating expressions and tests whether this decreases their complexity measure. The overall sign of the expression is kept correct by the symbol $minusone which is ignored by the complexity function. $minusone squared is converted to 1, and $minusone when it appears as part of a sum is converted back to -1. Any residual $minusone at the end of the simplification is converted back to -1.
This seems to well enough on toy examples, though I haven't tested it thoroughly. Note that in the last example specialSimplify prefers to have an overall minus sign than an expression like (-a+b)
specialSimplify[(-1 + a) (-1 + b)]
(*  (1 - a) (1 - b)  *)

specialSimplify[(a - b) (-1 + c) (-1 + d)]
(*  (a - b) (1 - c) (1 - d)  *)

specialSimplify[(b - a) (-1 + c) (-1 + d)]
(*  -(a - b) (1 - c) (1 - d)  *)

"
gui construction - Interdependent controls in Manipulate,"
Not sure if this is the best way, but you could consider something like this:
Manipulate[
 {x, y},
 {x, Manipulator[Dynamic[x, (x = #; y = 1/#) &], {.1, 10}] &},
 {y, Manipulator[Dynamic[y, (y = #; x = 1/#) &], {.1, 10}] &},
 Initialization :> ({x, y} = {1, 1})]

Edit V10
Since V10 one can use a shorter form:
Manipulate[
    {x, y}
  , {x, .1, 10, TrackingFunction :> ((x = #; y = 1/#) &)}
  , {y, .1, 10, TrackingFunction :> ((y = #; x = 1/#) &)}
  , Initialization :> ({x, y} = {1, 1})
]

"
front end - Running a package automatically when it's saved,"
This will assign a 'Save and Run` function to control-shift F:
FrontEndExecute[FrontEnd`AddMenuCommands[""Save"",
  {MenuItem[""Save and &Run"",
    FrontEnd`KernelExecute[NotebookSave[SelectedNotebook[]];
     Get[StringJoin[
       StringDrop[NotebookFileName[SelectedNotebook[]], -3], "".m""]]],
    MenuKey[""F"", Modifiers -> {""Control"", ""Shift""}],
    System`MenuEvaluator -> Automatic]}]]

To test, include the following as an initialisation cell in the working notebook (with auto-create package):
test := Print[""Change this text, then execute Save and Run and run test""]

By using AddMenuCommands the menu addition only appears when the procedure is run, so doesn't affect the standard setup.  It only needs to be run once, and the menu addition disappears upon restart.  The 'Save and Run' command is placed under Save on the File menu.
"
bugs - NExpectation behaves oddly with EmpiricalDistribution,"
This isn't perhaps exactly what you are looking for but here are some points worth noting.
In version 8 NExpectation uses numerical integration and summation methods whereas N[Expectation[...]] uses direct integration or summation and then approximates numerically after the fact. 
Though the idea is for data-distributions in M to behave just like regular distributions they are very different creatures under the hood. EmpiricalDistribution is perhaps the most different in that it is hard to categorize as discrete or continuous (whereas something like HistogramDistribution or SmoothKernelDistribution is continuous). 
Taking both of these into consideration, general NExpectation methods won't work for EmpiricalDistribution directly out of the box.
Expectations for EmpiricalDistribution are computed in the same way as those for raw lists of data.  For example...
Expectation[f[x], x \[Distributed] Range[10]] == Expectation[f[x], 
   x \[Distributed]EmpiricalDistribution[Range[10]]]

==> True

This is effectively accomplished by simply mapping the function f over the list and taking the mean. 
In my opinion there isn't a very good reason not to have a special case for NExpectation[EmpiricalDistribution[...]] that is effectively N[Expectation[EmpiricalDistribution[...]]]. It just isn't there in 8.
"
list manipulation - What is the cleanest way to prevent divide-by-zero warnings?,"
You could remove the zero from the denominator, and the corresponding entry from the numerator:
a = {1, 2, 3, 4};
b = {5, 6, 0, 8};

Pick[a, Positive[b]]/Pick[b, Positive[b]]

(*
==> {1/5, 1/3, 1/2}
*)

"
export - Support for Compressed Sparse Column sparse matrix representation,"
The first Google hit for ""compressed sparse column"" is this page, which explains that it's also called the Harwell-Boeing format.  If this is what you need, this format is supported by Mathematica.
"
graphics - Orthogonal Graph layout,"
=== UPDATE ===
Functionality and concept are updated and discussed here:
Orthogonal aka rectangular edge layout for Graph
=== OLDER ===
The main problem here I think is laying out edges along orthogonal lines. This can be addressed with splines. First define function that triples every element in the list to make a spline to pass sharply through the points. 
mlls[l_] := Flatten[Transpose[Table[l, {i, 3}]], 1];

In the function below I'll define a special EdgeRenderingFunction, a trick learned from @Yu-SungChang . Using LayeredGraphPlot:
OrthoLayer[x_] := LayeredGraphPlot[x, VertexLabeling -> True,
  PlotStyle -> Directive[Arrowheads[{{.02, .8}}], GrayLevel[.3]],

  EdgeRenderingFunction -> (Arrow@
      BezierCurve[
       mlls[{First[#1], {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, 
          First[#1][[2]]}, {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, 
          Last[#1][[2]]}, Last[#1]}]] &)]

Now I will use data from HERE and test the function 
OrthoLayer[g]


Or similarly using Graph function:
OrthoLayer[x_] := Graph[x,
   GraphLayout -> ""LayeredDrawing"",
  VertexLabels -> ""Name"", VertexSize -> .1, VertexStyle -> Red,
  EdgeStyle -> Directive[Arrowheads[{{.015, .8}}], GrayLevel[.3]],
  EdgeShapeFunction -> (Arrow@
      BezierCurve[
       mlls[{First[#1], {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, 
          First[#1][[2]]}, {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, 
          Last[#1][[2]]}, Last[#1]}]] &), 
  PlotRange -> {{-.1, 4.4}, {-.1, 2.5}}]

OrthoLayer[g]


Using splines allows us to take advantage of various GraphLayout settings and still keep orthogonal edges.
g = {""John"" -> ""plants"", ""lion"" -> ""John"", ""tiger"" -> ""John"", 
   ""tiger"" -> ""deer"", ""lion"" -> ""deer"", ""deer"" -> ""plants"", 
   ""mosquito"" -> ""lion"", ""frog"" -> ""mosquito"", ""mosquito"" -> ""tiger"", 
   ""John"" -> ""cow"", ""cow"" -> ""plants"", ""mosquito"" -> ""deer"", 
   ""mosquito"" -> ""John"", ""snake"" -> ""frog"", ""vulture"" -> ""snake""};

OrthoLayer[x_, st_] := 
 Graph[x, GraphLayout -> st, VertexLabels -> ""Name"", VertexSize -> .3,
   VertexStyle -> Red, 
  EdgeStyle -> Directive[Arrowheads[{{.015, .8}}], GrayLevel[.3]], 
  EdgeShapeFunction -> (Arrow@
      BezierCurve[
       mlls[{First[#1], {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, 
          First[#1][[2]]}, {(1 First[#1][[1]] + 2 Last[#1][[1]])/3, 
          Last[#1][[2]]}, Last[#1]}]] &), PlotRange -> All, 
  PlotRangePadding -> .2]

OrthoLayer[g, #] & /@ {""CircularEmbedding"", ""LayeredDrawing"", 
  ""RandomEmbedding"", ""SpiralEmbedding"", ""SpringElectricalEmbedding"", 
  ""SpringEmbedding""}


Not perfect, but a start. Many things can be adjusted to customize specific data.
"
Syntax for prefix mode with multiple arguments using @ shorthand,"
If you use Sequence instead of List for listing the multiple arguments, then @ also works: 
f@Sequence[x, y, z]
(* ==> f[x, y, z]  *)

or
f@({x, y, z}/.List->Sequence)

"
syntax - Using D to find a symbolic derivative,"
If you need to work with a set of variables symbolically, but you also need to substitute in values for them occasionally, a good approach is to use a rule list:
values = {a -> 0.04, L1 = 1, L0 -> 1}

If the symbols have no values assigned, you can use them normally in symbolic calculations:
L[s_, L0_, L1_, a_] := L1 + L0/(1 + s/a)

D[L[s, L0, L1, a], s]

(* ==>  -(L0/(a (1 + s/a)^2)) *)

When you need to substitute in numerical values, use ReplaceAll:
D[L[s, L0, L1, a], s] /. values

(* ==> -(25./(1 + 25. s)^2) *)

I wrote a bit more about using parameter list (rule lists) in this answer.
"
plotting - Real Size Image Printing,"
Quite redundant after the other answers and links, but I use something like this for vector-based technical drawings and CNC data (using mm as unit). This is not foolproof  as it might e.g. screw up with conflicting options and such, so make sure to check the output.
Important: SetPlotRange for your graphics explicitely: 
gfx = Graphics[Line[{{10, 10}, {110, 10}, {110, 110}}], 
  PlotRange -> {{0, 200}, {0, 200}}]

ExportScaled[filename_, gfx_, format_: {210, 297}, opts___?OptionQ] :=
  Module[{mm}, mm = 72/25.4;
  Export[filename, 
   Show[gfx, ImageSize -> format*mm, ImageMargins -> 0, 
    ImagePadding -> None, AspectRatio -> Automatic], opts]]

For proper scaling, your graphics´ PlotRange and the exported ImageSize need to correspond.
ExportScaled[""test.pdf"", gfx, -Subtract @@@ (PlotRange /. 
     Options[gfx, PlotRange])]

Below: Output measured in Acrobat (Again: It is usually a good idea to test a few cases by measuring them with Ghostview, Acrobat or such. Works just as well for EPS export).

"
"Is it possible to get the order of inputs when ""overloading"" an orderless function?","
Well, you can sort of do this, by creating something like a continuation. This requires playing games with the Stack, and I don't claim that it is robust, but it may represent some theoretical interest, particularly to those of us looking for ways to implement continuations in Mathematica. Here is the code  (edit please note that I had to add Update[matrix] to address some improper behavior noted in the comments end edit):
ClearAll[matrix, inMatrix];
matrix /: HoldPattern[Times[pre___, a_matrix, post___]] :=
  (
      Update[matrix];
      ReleaseHold[NonCommutativeMultiply @@@ $stack]
  );
matrix[args__] /; ! TrueQ[inMatrix] :=
  Block[{inMatrix = True},
    Update[matrix];
    $stack = Stack[_][[-5]];
    matrix[args]]

It combines UpValues, Villegas-Gayley trick to redefine a function, and manipuations with Stack. What happens is that first, of course, the attributes of Times are applied, I can't fight that. Then, the DownValues of matrix are applied, and at this point I record the relevant part of the Stack. Then, UpValues of matrix are applied, and at that point I communicate the recorded part of the stack, where the attributes of Times weren't yet applied, and Times gets replaced with NonCommutativeMultiply, after which I re-evaluate this, as if it was not evaluated before. The Update sommand is used to prevent caching the values for the $stack, as this is inappropriate here and resulted in some erroneous behavior noted in the comments. 
Here are some examples:
a = matrix[""a""];
b = matrix[""b""];

a*c*b


matrix[a]**c**matrix[b]

f[g[1 + c*a*d*b*e]]


f[g[1 + c ** matrix[""a""] ** d ** matrix[""b""] ** e]]

I would not probably recommend such tricks for serious use, it is just interesting that you can use them to divert evaluation sequence in ways which seem to be impossible otherwise.
"
export - How to save all data in all variables so that loading it is fast?,"
Assuming you haven't placed your variables in a non-standard context you can save them all at once using DumpSave's second syntax form, which saves everything in the indicated context.
Quit[] (* start a fresh kernel *)

x = 1; (* define some symbols *)
y = 2;
z[x_] := x^2

Names[""Global`*""] (* Check they're there *)

(* ==> {""x"", ""y"", ""z""}  *)

(* Save everything in the context *)
DumpSave[""C:\\Users\\Sjoerd\\Desktop\\dump.mx"", ""Global`""];    

Quit[] (* kill kernel to simulate a new start *)

Names[""Global`*""] (* Are we clean? *)
(* ==> {} *)

(* Get the save symbols *)
<< ""C:\\Users\\Sjoerd\\Desktop\\dump.mx""

(* Are they there? *)
Names[""Global`*""]    
(* ==> {""x"", ""y"", ""z""} *)

z[y]    
(* ==> 4 *)

"
Implementing bookmarks in the front end when editing a package,"
This answer implements Ajasja's suggestion from the comments to use comments (e.g., (* ::BOOKMARK::7:: *)  ) as bookmarks and simply finds them with NotebookFind. 
The following code (when inserted into KeyEventTranslations.tr) binds Ctrl-Alt-Numpad 1 to creating a (sequentially numbered) bookmark comment at the cursor location and Ctrl-Numpad 1 to cycling through the bookmark comments.
One could also modify this code to bind a number of named bookmarks to specific shortcuts. 
Item[KeyEvent[""Keypad1"", Modifiers -> {Control, Command}],
    FrontEndExecute[{
        NotebookWrite[InputNotebook[], "" (* ::BOOKMARK::"" <> 
            Block[{Inherited = 1}, 
                ToString[Increment[CurrentValue[InputNotebook[], {TaggingRules, 
                ""BookmarkCounter""}]]]] <> "":: *) "" ]
    }],
    MenuEvaluator->Automatic
],

Item[KeyEvent[""Keypad1"", Modifiers -> {Control}],
    FrontEndExecute[{
        FrontEnd`NotebookFind[FrontEnd`InputNotebook[], ""(* ::BOOKMARK:""]
    }]
], 

"
interoperability - How can I deploy DLL files created by a Fortran function and call them from Mathematica,"
Even the path is corrected, it still cannot run, since the argument type should {""double*"", ""double*""}.
Here is my memo on calling dll created by gfortran using NETLink:

Advantages of NETLink as compared to Mathlink:

Fortran functions and subroutines can be called using NETLink without writing an additional C wrapper which is necessary in Mathlink. 
NETLink can access all the functions and subroutines in the fortran code by calling the dll file, not only one.
And it seems to me NETLink is faster than Mathlink.

Calling a fortran function


Suppose we have a fortran code testfunction.f90
REAL(8) FUNCTION testfunction(x,y)
  REAL(8), DIMENSION(2) :: x
  REAL(8) :: y
  testfunction = (x(1)+x(2)) * y
END FUNCTION

We can compile it and build a dll
gfortran -c testfunction.f90
gfortran -shared -mrtd -o testfunction.dll testfunction.o

Now the function testfunction(x,y) in testfunction.dll can be called after loading the .NET/Link package
Needs[""NETLink`""]
ReinstallNET[""Force32Bit"" -> True]; (* or InstallNET[""Force32Bit""->True] *)

(* set to the directory of the notebook, and the dll file is in the same dir *)
SetDirectory[NotebookDirectory[]]; 
path = FileNameJoin[{Directory[], ""testfunction.dll""}];
TestFunction = DefineDLLFunction[""testfunction_"", path, ""double"", {""double[]"", ""double*""}];

TestFunction[{1.0, 2.0}, 3.0] gives the correct result 9.0.
Explanations:
DefineDLLFunction: the first argument is the function name to be called. It has changed from testfunction to testfunction_, and might be TESTFUNCTION or other depending on the fortran compiler. path is the complete path to the dll file. ""double"" is the return type. The last argument contains the types of the arguments. Note the presence of [] for an array and * for others. 
If * is missing, there will be an error message saying 
NET::netexcptn: A .NET exception occurred: 
System.AccessViolationException: Attempted to read or write protected memory. 
This is often an indication that other memory is corrupt. 
at Wolfram.NETLink.DynamicDLLNamespace.DLLWrapper...testfunction_(Double[],Double).

If [] is missing or written as * by mistake, the error message is
NET::methodargs: Improper arguments supplied for method named testfunction_.""

Before making revisions to the dll file, one should use ReinstallNET[""Force32Bit"" -> True] to quit and restart the .NET runtime

Calling a fortran subroutine

see also the post here
testsubroutine.f90
SUBROUTINE testsubroutine(x,y,z)
  REAL(8), DIMENSION(2), INTENT(in) :: x
  REAL(8), INTENT(in) :: y
  REAL(8), DIMENSION(2), INTENT(out) :: z
  z(1) = x(1) * y
  z(2) = x(2) * y
  RETURN
END SUBROUTINE

testsubroutine.dll can be built as before. In Mathematica, after loading NETLink and ReinstallNET[""Force32Bit"" -> True],
path2 = FileNameJoin[{Directory[], ""testsubroutine.dll""}]
TestSubroutine = DefineDLLFunction[""testsubroutine_"", path2, ""void"", 
{""Double[]"", ""Double*"", ""Double[]""}]

Now we should create a .NET object, which is to be sent to testsubroutine_ at the place of z to store the results
(* Any real or integer numbers can be put in the list. 
""System.Double[]"" is necessary if any of the numbers is an integer. *)  
res = MakeNETObject[{0, 0.}, ""System.Double[]""] 

Now let's test a case:
TestSubroutine[{1., 2.}, 3., res] (* res receives the calculated results *)

(* translate the .NET object results into a Mathematica expression  *)
NETObjectToExpression[res]  

The results are the desired {3., 6.}.
"
image processing - How to record the stream of data (PixelPosition) dynamically?,"
File Output
Use an output stream.
s = OpenWrite[""your_filename""];

Dynamic[With[{a = ImageKeypoints[EdgeDetect[CurrentImage[], 30], ""PixelPosition""]}, 
  Write[s, a]; a], Deinitialization :> Close[s]]

It will close the stream upon the deletion of the dynamic cell. It is not a bad idea to put time stamp with it.
Dynamic[With[{a = ImageKeypoints[EdgeDetect[CurrentImage[], 30], ""PixelPosition""]}, 
      Write[s, AbsoluteTime[] -> a]; a], Deinitialization :> Close[s]]

Notebook Output
Use NotebookWrite.
Dynamic[With[{a = ImageKeypoints[EdgeDetect[CurrentImage[], 30], ""PixelPosition""]}, 
  NotebookWrite[nb, Cell[RawBoxes[ToBoxes[a]]]]; a],
  Initialization :> (nb = CreateDocument[, WindowTitle -> ""PixelPosition""])]

Appending to List
Already answered by Mr. Sjoerd C. de Vries...
"
export - Exporting animations under duration constraints for viewing on an iPad,"
There exists no movie format on the iPad that can do a frame duration of .001 seconds. 30 frames per second (as for NTSC video) is the fastest you'll be able to do, corresponding to roughly .03 seconds per frame. This means your movies will be 100 seconds long if it has 3000 frames. 
It is easy to export a list of frames to Quicktime (Apple's own format) if you run Mathematica on the Mac:
Export[""movie.mov"", frameList]

should do it. 
For more control, you would follow these instructions:
After making the list of frames by creating a Table of Graphics and calling the output list frameList, execute the following line:
Map[Print, frameList]

This will create all the plots conveniently bracketed in a CellGroup which you can select with a single click. With this, QuickTime export can proceed by selecting in the Frontend menu the item Edit → Save Selection As.... Quicktime.
If you want even more control, e.g., to select a different display duration for each frame, just use (assuming you're on a Mac) the export function defined in the linked answer. To get a single constant frame duration d (in seconds), you'd invoke it as exportMov[""movie.mov"", frameList, {d}].
If this still doesn't satisfy you, it's always possible to export the individual movie frames and use an external program to make the final movie, as described in this answer.
"
Evaluating a function using arguments from a sliding window over a list,"
There is a function exactly for this: Developer`PartitionMap:
Developer`PartitionMap[f, {1, 2, 3, 4, 5, 6}, 3, 1]
(* {f[{1, 2, 3}], f[{2, 3, 4}], f[{3, 4, 5}], f[{4, 5, 6}]} *)

The first argument to Developer`PartitionMap is the function that's being used (f) and all successive arguments and options are exactly the same as in Partition. 
"
performance tuning - Speeding up random walk for many particles,"
This will give a modest improvement. I'm probably missing a few more though.
One other remark: this way of choosing a ""random"" direction is far from uniform.
numparticles = 10^4;
numsteps = 10^3;
radius = 1.;
particles = ConstantArray[{1.001, 0., 0.}, numparticles];
rnew = Map[#.# &, particles];
numcrossings = ConstantArray[0., numparticles];

In[120]:= 
runSim = Compile[{{numsteps, _Integer}, {radius, _Real}, \
{origparticles, _Real, 2}},
   Module[
    {numparticles, thetarand, phirand, rold, rnew, next, 
     particles = origparticles, isitoutside, switchsides, 
     numcrossings},
    numparticles = Length[particles];
    numcrossings = ConstantArray[0., numparticles];
    rnew = Map[#.# &, particles];
    Do[thetarand = RandomReal[{0., Pi}, numparticles]; 
     phirand = RandomReal[{0, 2.*Pi}, numparticles];
     rold = rnew;
     next = 
      Transpose[
       0.01*{Sin[thetarand]*Cos[phirand], Sin[thetarand]*Sin[phirand],
          Cos[thetarand]}];
     particles = particles + next;
     rnew = Map[#.# &, particles];
     isitoutside = (rold - radius)*(rnew - radius);
     switchsides = Clip[isitoutside, {0, 0}, {1, 0}];
     numcrossings = numcrossings + switchsides;
     , {numsteps}];
    Round[numcrossings]
    ], CompilationTarget -> ""C""];

In[121]:= Timing[nc = runSim[10^3, radius, particles];]

Out[121]= {1.53, Null}

"
symbolic - Representing a value in an output as a self defined variable,"
My solution below uses TagSetDelayed and associates the transformation rules with Power. Although I very much dislike using structural manipulations for such purposes, it might be a viable option here since the use case is narrow.
Unprotect[Power]
Power /: Power[-1, Rational[n_Integer, _]] := ρ^n
Protect[Power]



If you want to define it only for the cube roots of unity, you needn't use a general pattern like the above. Instead, restrict it by changing the _ to 3.
"
plotting - Why does the shape of my function change when plotted alongside another function?,"
All the plots are correct, but what may be catching you out is the windowing of the Y-axis and your tick specification. Adding PlotRange -> {{-4, 4}, {0, 2}} should help you see what is happening.
Plot[Cos[Cos[x]], {x, -4, 4}, Ticks -> {Table[x*Pi, {x, -2, 2, 1/2}]},
  AspectRatio -> .1, PlotRange -> {{-4, 4}, {0, 2}}]


Plot[Cos[Sin[x]], {x, -4, 4}, Ticks -> {Table[x*Pi, {x, -2, 2, 1/2}]},
  AspectRatio -> .1, PlotRange -> {{-4, 4}, {0, 2}}]


So for the combined plot you would get:
Plot[{Cos[Cos[x]], Cos[Sin[x]], Cos[Cos[x]] + Cos[Sin[x]]}, {x, -Pi, 
  Pi}, Ticks -> {Table[x*Pi, {x, -1, 1, 1/2}]}, AspectRatio -> 1/2, 
 PlotRange -> {{-4, 4}, {0, 2}}]


"
notebooks - NotebookFind and String Pattern Expressions,"
Ok so this is going to be a long one. This is definitely not a general purpose implementation, but It shows the general idea that one could use.
So you basicly want to be able to type out NotebookFind[""(.?foo\d.?)""], which would match to for example ""(something something foo4 dark side)"". However you only want it to highlight foo4, and not the rest. So the way to do this is to first search through the notebook and figure out that our pattern matches the entire string, and search only for the particular realized sub-expression ""foo4"" and figure out which of the potentially many search result for foo4 collides with the search for the entire pattern. 
So for the purpose of this implimentation I'll assume that you have a RegularExpression pattern, where the part you want to highlight the first matched subpattern (Which means you enclose it in parenthesis in the search string). So the above pattern would be: RegularExpression[""[(].?(foo[\d]+).?[)]""]. We then:

search through strings in the notebook expression for cases where this matches
then extract the subexpression matched, 
then sort out how many times we match the subexpression without matching the full.
Then call NotebookFind[] enough times to land on the correct match.

So here goes for the actual code. It doesn't work for matching notebook level expressions and only searches through strings. 
This function just creates a pattern for the actual substitution based on the search pattern.
StringPatternWrapper[stringpattern_]:=  
 (a_String/;StringMatchQ[a,stringpattern]):>StringCases[a,stringpattern:>""$1""]

This function finds the positions and cases of the matched pattern. The pattern provided for this function should first be sent through StringPatternWrapper[]-
 findPostionAndExactMatch[nbexp_,pattern_]:=
     {Position[nbexp,pattern[[1]],∞],
      Cases[nbexp,pattern,∞]}//ridiculousFormatingFunction

where ridiculousFormatingFunction is a messy function for reformating the output.
 ridiculousFormatingFunction[list_] := 
    Map[(a\[Function]Map[{a[[1]],#}&,a[[2]]]),Transpose[list]]//
    (Flatten[Table[{#[[1,1]],#[[1,2]],n},{n,1,#[[2]]}]&/@Tally[Flatten[#,1]],1])&

And then a function for finding all the matches to the matched subexpression
findAllExactMatches[nbexp_,exact_] := 
  Flatten[Map[Table[#, {Length@StringCases[nbexp[[Sequence@@#]],exact]}]&,
  Position[nbexp,a_String/;StringMatchQ[a,exact],∞]],1]

Because some stings might contain more then one match, we need some fixing of the numbers
repeatNumberForMatch[match_,nbexp_] := 
First@Position[
    findAllExactMatches[nbexp,RegularExpression["".*?""<>match[[2]]<>"".*?""]],match[[1]]
][[match[[3]]]]

And finally we have a nice little function which returns a list of all the matches, which expressions they apear in, and how many times you need to skip when using NotebookFind.
 matchTable[nbexp_,pattern_] := Prepend[#,repeatNumberForMatch[#,nbexp]]&/@
findPostionAndExactMatch[nbexp,pattern]

Here is an output example from Match table using the provided example notebook below:
  matchTable[NotebookGet[nb], 
   StringPatternWrapper[
    RegularExpression["".*?"" <> ""[(].*?(foo[\\d]+).*?[)]"" <> "".*?""]]] //
   Prepend[#, {""Repat find number"", ""Indices"", ""Exact Match"", 
     ""Number inside string""}] & // Grid


Here is a short usage example 
notebookFindN[nb_,find_,n_]:=
    (SelectionMove[nb,Before,Notebook];Do[NotebookFind[nb,find,Next],{n}])

clickerUI[nb_,pattern_]:=
    Button[#[[3]],notebookFindN[nb,#[[3]],#[[1]]]]&/@matchTable[NotebookGet[nb],pattern]

And some test code and a test notebook:
 nb = {
     Cell[""This is a direct match for the realised sub-pattern foo1 but not the full"", ""Text""], 
     Cell[""This is another match identical to the realised one foo2, and still not the full, however this one needs to be skiped when using NotebookFind"", ""Text""],
     Cell[""And finally ( we have a full match for foo2 the pattern ) (foo2) <- That's another one, and so is that -> (foo4)"", ""Text""],
     Cell[""Some times a single string can have more then one entry foo2 foo2, so we need to count how many and which ones we are looking for, which makes the code slightly messy."", ""Text""],
     Cell[""And finally ( we have one last full match for foo2 ) enclosed in parenthesis"", ""Text""]
     } // CreateDocument;

 clickerUI[nb, 
   StringPatternWrapper@
   RegularExpression["".*?"" <> ""[(].*?(foo[\\d]+).*?[)]"" <>"".*?""]
 ] // Row

Hope this can be of some help. Personally I'd like to have code that could equally well search though strings and notebook level expressions, however this requires a better structuring of the method I think. 
"
probability or statistics - Wald–Wolfowitz Runs Test,"
This is not built into the system as far as I can tell. However, it's a really good example of how to construct a fairly sophisticated function using just a few lines of code. I've taken the definition directly from the Wikipedia page, and applied it to Sign[data] on the assumption that if you are testing residuals from a regression, you are interested in runs of positive and negative values. 
runstest[x:{__?NumericQ}] := 
 Module[{n = Length[x], res = Sign[x], n1, n2, runs, mu, sig2, y},
  {n1, n2} = Last /@ Tally[res];
  runs = Split[res];
  mu = 2 n1 n2/n + 1;
  sig2 = (mu - 1) (mu - 2)/(n - 1);
  NProbability[y <= Length[runs], 
    y \[Distributed] NormalDistribution[N@mu, N@sig2]] ]

Some notable things about this code:

The pattern {__?NumericQ}. This ensures that the function only works on vectors of numeric data.
The use of local variables via Module, some of which can be set initially in the first argument of Module, while others can wait till later, perhaps because they depend on other local variables.
The use of Tally and Split, built-in functions that automatically divide lists into sublists of like elements.
The use of NProbability to work out the one-tailed test. Alternatively the last line could be something like N@CDF[NormalDistribution[mu, sig2], Length[runs]]: it gives the same answer except where the p-value is so tiny that numerical error creeps in (but seriously, who cares if it's $10^{-16}$ or $10^{-20}$?). It's possible that you want to express the test a different way, in which case that line is easy to modify.

Here is some test data that should definitely be rejected as random because of strong serial correlation: 
testdata1 = 
  FoldList[0.98 #1 + #2 &, RandomReal[], 
   RandomVariate[NormalDistribution[0, 0.5], 100]];

And here is some data that should probably pass the test.
testdata2 = RandomVariate[NormalDistribution[0, 0.5], 100];

Sure enough:
runstest[testdata1]

(* -7.90479*10^-14 *)

runstest[testdata2]

(* 0.451757 *)

"
Simplify an expression containing NonCommutativeMultiply,"
What you need here is actually expanding the expression (i.e. transforming all (a+b) ** c type expressions to a**c + b**c).  There's no built-in support for this kind of manipulation of non-commutative expressions.  You'd need to implement them yourself, which can be quite a bit of work.
However, instead of bothering with implementing all these simple operations yourself, I recommend using a dedicated package.  @gpap suggested the NCAlgebra package in an answer to your previous question.
After installing NCAlgebra by placing the NC directory in my $UserBaseDirectory/Applications directory, I could do this:
<< NC`
<< NCAlgebra`

expr = -a ** (b ** c - c ** b) + b ** (a ** c - c ** a) - 
  c ** (a ** b - b ** a) + (a ** b - b ** a) ** 
   c - (a ** c - c ** a) ** b + (b ** c - c ** b) ** a

NCExpand[expr]

(* ==> 0 *)

"
parallelization - Does parallel programming use up large quantities of memory in Mathematica?,"
First off, you shouldn't be worried that Mathematica hasn't returned the memory to the system. The memory may as well be (and is being) held onto by the process that last had it, and if some other program needed this memory it would be handed back to the system without a problem.
MaxMemoryUsed reports the maximum amount of memory used, but it is only interacting to the current kernel. If you wanted to interact with the other kernels, you would have to use ParallelEvaluate. This paper contains a nice example of a table displaying the max memory used on each processor, along with the processor ID and some other information. (You will have to update some of the commands though, it was written in 2004.)
When I have used ParallelTable commands in the past I always was sending the bulk of the data in my current application for processing through ParallelTable, and so an entire copy of the data often was transferred to the memory of each parallel kernel. The answer by acl points out that the memory sent to each parallel kernel is dependent on what you send to it, and it may not necessarily need to send the entire memory state from the main kernel.
What OS are you running Mathematica on? In Linux, pulling up the System Monitor (or a command like top) should show the kernels loading in real-time, and if you sort by memory you should get a very clear picture of what's happening.
I don't have any tips to avoid this - it's a trade off, if you want faster processing of data and you have the RAM to spare then use the ParallelTable command. If you don't have the RAM to spare then stick with the regular Table command and brew some coffee.
As a last ditch attempt to scrape up some spare RAM, you can try throwing the Share[] command in every once in a while, but I haven't seen significant improvements from this myself either. As long as you're not actually running out of RAM, however, it's nothing to worry about. The fact that Mathematica hangs on to that extra RAM even after it's done processing the data is standard procedure, and you shouldn't concern yourself with it. If you want to prove that another application can access that RAM if needed, just run some RAM intensive process and watch in real time using the System Monitor / top.

I was reminded by Albert Retey that you can use distributed contexts to reduce the amount of information transferred to each kernel. The effectiveness of this approach will vary with your particular application, i.e. if you have a lot of information in memory before you perform ParallelTable on a small subset of that data.
"
compile - How do I get Mathematica to recognize a C compiler on a 64-bit Windows machine?,"
First, be sure to read the Specific Compilers section of the CCompilerDriver User Guide.  This is the official place where the nuts and bolts of using external C compilers is discussed.
In that section, ""Visual Studio Express and 64-Bit Targets"" is where compilation on 64-bit Windows is discussed.
Some things to check when setting up:

Be sure to install .NET Framework 4 before Windows SDK 7.1.  Without this, the Windows SDK installer may (if you don't have it) give a warning about this, and the Visual C++ component will be grayed out.  
In the install wizard for the Windows SDK, be sure any components that say ""Visual C++"" are selected for installation.

If you're not sure if you have the .NET Framework 4, you can try running the Windows SDK 7.1 installer and look carefully for a warning dialog.  If you don't get a dialog warning that .NET Framework is not detected, and the Visual C++ component is selectable for installation, then you may proceed with installing just the Windows SDK.
I can confirm that you don't need to install Visual Studio Express first, you can get away with installing only the .NET Framework 4 (if needed) and then the Windows SDK.
Edited to add:
In answer to ""If the compiler is installed correctly, should Mathematica automatically recognize it, or do I have to point Mathematica to a very specific folder to find it?"", for Visual Studio it is automatically recognized through an environment variable or the registry.  Of the compilers that are directly supported, as opposed to a ""Generic"" C compiler, they are all automatically detected in some form, depending on the specifics of the compiler.
"
export - Converting a notebook to plain text programmatically,"
Saving is done by the front end, which you can exploit programatically by using FrontEndExecute. I think this is what you need:
nb=InputNotebook[];
fn=FileNameJoin[{""output.txt""}];
FrontEndExecute[FrontEndToken[nb,""Save"",{fn,""Text""}]]

Edit: Of course you can also save it as a package by replacing ""Text"" with ""Package"".
"
plotting - How do I plot Thomae's function in Mathematica?,"
I'd suggest producing a list of rational numbers and then plot the function there, like so:
maxq = 100;
fracs = Table[p/q, {q, 2, maxq}, {p, 2, q}] // Flatten // DeleteDuplicates;
pq = {#, 1/Denominator @ #} & /@ fracs;

ListPlot[pq, PlotRange -> {0, 1}]


"
plotting - Creating Marker (Tags) on Top of Plots,"
The interesting question is: how do we get labels into a plot without having the frame and/or axis range of that plot automatically adjust to enclose the labels. After all, you want labels on top of the plot, which means they will have to be ""hovering"" above the maximum vertical height of the axes. 
I think Overlay is really good for such tasks in principle. Let's say the y-axis is supposed to extend from $-5$ to $5$, then the first thing we have to do is create some empty space on top of that range. This can be done by setting PlotRegion. In the plot below, I want the extra height (in the coordinate system of the plot) to be up to yExtra = 8.5. 
The problem with Overlay is that it aligns two objects using scaled coordinates that are ""agnostic"" of the plot coordinates we're interested in (e.g., the center of the plot is always {0, 0} for Overlay). But we are trying to put labels at specific horizontal positions in the original plot coordinates.
To make the overlays align properly, especially in the horizontal direction where the placement has to be most accurate, I put the annotation into an invisible copy of the original plot. That guarantees that the overlays will fit together nicely:
g = With[{yMax = 5, yExtra = 8.5},
  p = Plot[
    {-.1 x, Tan[x]}, {x, 0, 3 Pi},
    PlotRange -> {-yMax, yMax},
    AxesLabel -> {x, y},
    ImageSize -> 400
    ];
  Overlay[{
    Show[p,
     PlotRegion -> {{0, 1}, {0, 2 yMax/(yMax + yExtra)}}],
    Show[p, 
     AspectRatio -> (AspectRatio /. 
         Options[p, AspectRatio]) (1 + yExtra/yMax)/2, 
     BaseStyle -> Opacity[0],
     PlotRange -> {-yMax, yExtra},
     Epilog -> {Opacity[1], 
       Table[{Arrow[{{(2 i + 1)/2 Pi, 6.5}, {(2 i + 1)/2 Pi, 
            5.5}}], 
         Text[Row[{x, "" = "", (2 i + 1)/(2 L) Pi}], {(2 i + 1)/
            2 Pi, 7.4}]}, {i, 0, 3}]}
     ]
    }
   ]
  ]


The invisible layer is created in Show[p, BaseStyle -> Opacity[0]... and the annotation is added to that layer as Epilog -> {Opacity[1],... (the specific annotation with text and arrows is created in the Table). 
For the original plot p, I use Show[p, PlotRegion ->...] to make sure it is shown with the empty space on top. That PlotRegion specification can't be added to the initial definition of p because then it would disappear when the plot is displayed inside Overlay.
The horizontal coordinates of the original plot and the overlay are identical, but the vertical coordinates are not. This is due to the axis label y that isn't contained in the spacing calculations.
However, you can now use the Epilog in the overlay to add annotations that overlap the plot any way you like - partly inside and outside of the coordinate frame. E.g., you could try changing the Arrow specification above to Arrow[{{(2 i + 1)/2 π, 6}, {(2 i + 1)/2 π, 4}}] to make the arrows reach deeper into the plot:

Edit: make it prettier
A separate issue is to make the arrows nicer:
With[{yMax = 5, yExtra = 7.5}, 
  p = Plot[{-.1 x, Tan[x]}, {x, 0, 3 Pi}, PlotRange -> {-yMax, yMax}, 
    AxesLabel -> {x, y}, ImageSize -> 400];
  Overlay[{Show[p, 
     PlotRegion -> {{0, 1}, {0, 2 yMax/(yMax + yExtra)}}], 
    Show[p, AspectRatio -> (AspectRatio /. 
         Options[p, AspectRatio]) (1 + yExtra/yMax)/2, 
     BaseStyle -> Opacity[0], PlotRange -> {-yMax, yExtra}, 
     Epilog -> {Opacity[1], 
       Table[{Arrow@
          BezierCurve[{{(2 i + 1)/2 Pi, 6.5}, {(2 i + 1)/2 Pi + 1, 
             5}, {(2 i + 1)/2 Pi, 3.5}}, SplineDegree -> 2], 
         Text[Row[{x, 
            "" = "", (2 i + 1)/(2 L) Pi}], {(2 i + 1)/2 Pi - .5, 
           6.5}]}, {i, 0, 3}]}]}]]


The arrows have been modified to have a curved appearance by using BezierCurve. All you have to do is replace Arrow by Arrow@BezierCurve and add one extra point in-between the start and end point of the original (straight) arrow. That point is the handle that pulls the curve to one side. 
"
"plotting - How can I turn off SingleLetterItalics in PlotLabel, etc, when the Options Inspector won't do it?","
I don't know if it qualifies as an answer to your question if I suggest to change the structure of the labeling in the first place. As you write it, the m is -- from the rendering point of view -- treated  as a symbol, if you inclose it with quotation marks it will be treated as a string and no auto-italic is performed at all. E.g.:
PlotLabel -> ""Test Label in k(\!\(\*SuperscriptBox[\(\""m\""\), \\(2\)]\))""

instead of
PlotLabel -> ""Test Label in k(\!\(\*SuperscriptBox[\(m\), \(2\)]\))""

another thing you should be aware of is that you can use arbitrary expressions as labels, e.g.:
PlotLabel -> Row[{""Test Label in k("", Superscript[""m"", 2], "")""}]

which I find much easier to automatically create and manipulate as well as manually maintain than those cryptic strings...
If, as your comments suggest, you don't have control over how these labels are created, the following could be the solution you are after:
ListLinePlot[fakedata101, Filling -> Axis, PlotStyle -> Red, 
  FillingStyle -> Red, 
  PlotLabel -> ""Test Label in k(\!\(\*SuperscriptBox[\(m\), \(2\)]\))"",
  FormatType -> (Style[TraditionalForm[##],SingleLetterItalics -> False] &)
]

"
linear algebra - Constructing a symbolic Hermitian matrix,"
By default, Mathematica assumes symbols to be complex. However the elements on the main diagonal of a Hermitian matrix are necessarily real. To force Mathematica to interpret the elements on diagonal of m to be real you could replace them by their real part, i.e.
m = {{Re[n], a, b, b}, {Conjugate[a], Re[n], b, b}, 
     {Conjugate[b], Conjugate[b], Re[c], d}, 
     {Conjugate[b], Conjugate[b], Conjugate[d], Re[e]}};

HermitianMatrixQ[m]

(* output: True *)

CholeskyDecomposition[m]

"
"plotting - Is it possible to use styled (e.g., colored) text in PlotLabel?","
Yeah, use Style and Column to format the PlotLabel:
PlotLabel -> Column[{Style[""Red curve: x^2"", Red], Style[""Blue curve: x^3"", Blue]}]]

Example:

"
manipulate - How to use Locators on a graphic in a tabview,"
Maybe something like
pltrng = {{-1, 1}, {-1, 1}};

Manipulate[pnts = LocatorPane[Dynamic[p], 
   Dynamic @ Graphics[Point[p], PlotRange -> pltrng], 
   LocatorAutoCreate -> True];
 tbl = Dynamic @ Grid[MapIndexed[{#2[[1]], #} &, p]];
 ln = Dynamic @  Graphics[{Red, Thick, Line[p]}, PlotRange -> pltrng]; 
 bzc = Dynamic @ Graphics[{Blue, BezierCurve[p]}, PlotRange -> pltrng];
 dsk = Dynamic @ Graphics[{Orange, Disk[#, .1] & /@ p}, PlotRange -> pltrng];
 plygn = Dynamic@ Graphics[{Green, Polygon[p]}, PlotRange -> pltrng];
 allviews =  Grid[{{pnts, tbl, dsk}, {ln, bzc, plygn}}, Dividers -> {All, All}];
 Dynamic @ TabView[{""locators"" -> pnts, ""table"" -> tbl, ""line"" -> ln, 
   ""beziercurve"" -> bzc, ""disks"" -> dsk, ""polygon"" -> plygn, ""all"" -> allviews}, 
   Alignment -> Center], 
 {{p, {{-.5, -0.5}, {-.25, .5}, {.6, 0.6}}}, None}]


"
cdf format - Mathematica Source-Code Control for CDF files in multi-user scenario,"
Short answers: 

it's very well possible to manage CDF-documents in a source control system, but you will loose some of the more attractive features of such systems.
most probably any system will do equally well (or bad).

Some elaboration:
I don't know TFS, but all source control systems I know basically do work line oriented with plain text documents (which is a very common format for source code after all). It could well be that some source control tools can handle other formats, e.g. office documents, but that I don't know and I'd be very surprised if any could handle notebook files. 
CDF documents basically are just notebook files with a signature, and notebook files are plain text, but unfortunately not line oriented but ""cell oriented"". That means that line breaks will be added and removed even when the content actually (or appearingly) has not changed. Notebooks also do contain formatting information which you might or might not want to be source controlled and they contain caching information which you probably never want to be source controlled. 
AFAIK there is no source control system which is aware of CDF-documents (or notebooks), but I think almost all of them will handle them correctly as ""binary files"". That means they can identify whether files have changed or not but can't provide you with useful information about what has changed or do automated merges in a meaningful way. So many of those features that a source control system makes really useful will not work. So the answer is that yes, you can manage notebooks and CDF-documents in probably any source control system you like, but you will loose much of its power, and I think there is not much difference between them concerning the handling of those files. 
There are some tools out there which will e.g. remove the caching information on checkin or remove the output cells of a notebook before checkin, which makes some sense for notebooks. But since the signature of a CDF document will become invalid with every change to the document, I don't think that is an option for CDF documents.
Another thing to have in mind is that the FrontEnd now handles package files reasonably well and there is also the Workbench, so interest in that direction has declined over the years, and most of those tools seem to be somewhat outdated.
Another tool which compensates for the fact the the source control systems can't handle notebook files is the notebook diff that newer versions of Mathematica (or the workbench?) do install under the hood and which pops up rather unexpectedly when using some version control systems and you try to compare two different versions of a notebook. I haven't investigated where that is stored and how you'd configure a source control system to use it if that isn't handled automatically, but you might want to get that working. That at least lets you compare notebook differences much more comfortable then any pure text utility. Another tool worth mentioning is the notebook diff tool in Workbench which lets you make a ""diff"" on the notebook expression of two notebooks and shows that in an extra view. But that view is rather something for a Mathematica programmer interested in the structure than for someone working on the layout of such a document.
One more thought: The best thing to do would actually be to generate those CDFs automatically, as WRI is suggesting e.g. in the CDF-Workshop (specifically here). You could then only put the generating code into source control and treat the generated CDF-documents as ""generated content"" like compiled binaries, which of course would not need to be stored within the version control system. But since that would probably be a huge change in how your users have to work, this might not be something you can inforce. Anyway I think it still should be in this answer in case someone is reading it who has the chance to make such a change...
"
Solving an equation and finding a couple of results given that they are integer,"
The following might be of use:
Reduce[x + y == y^2 && x^2 + y != 1, {x, y}, Integers]

To ease things, we consider the numerator and denominator separately. Here, we are asking Mathematica for conditions on integer x and y such that the numerator is zero, and the denominator isn't.
Solve[x + y == y^2 && x^2 + y != 1, {x, y}, Integers]

is useful as well.

If you need examples, you can use
FindInstance[x + y == y^2 && x^2 + y != 1, {x, y}, Integers, 10]

Change 10 to the number of examples you wish to generate.
"
output formatting - Question about evaluation control,"
This works nicely:
L[f_, a_, b_] := HoldForm[Integrate[#, {\[FormalX], a, b}]] &[f[\[FormalX]]]

Note that I used \[FormalX] to prevent conflicts with the usual x, which may have had a previous definition. Try L[E^-Sqrt[#] &, 0, 1] with this definition:

"
error trapping - Check does not interrupt evaluation of the expression when a Message is emitted,"
A simple method for accomplishing this is to have Message Throw an error when it is called, interrupting the current execution. Here is a replacement for Check which does that, with the same calling signature:
ClearAll[InterruptingCheck]
SetAttributes[InterruptingCheck, HoldAll]

InterruptingCheck[expr_, failexpr_, msgs : {___MessageName } : {}] :=
 Internal`InheritedBlock[{Message, $msgFlag},
      (* Module localizes tag while not polluting the global namespace *)
      Module[{ tag },
      Unprotect[Message];
      (* 
      Attach hook to message, where failexpr is thrown after the 
      first Message is raised. msgFlag is used to prevent recursion,
      so that when msg is called the original def is used.
      *)
      msg : Message[m_, ___] /; ! TrueQ[$msgFlag] := Block[{$msgFlag = True},
     msg;
     If[Length@msgs == 0 || MemberQ[msgs, m], Throw[failexpr, tag]]];
     Catch[expr, tag]
  ]
 ]

(* With Leonid's suggestion, this now works correctly. *)
InterruptingCheck[expr_, failexpr_, msgGroup_String] := 
 Hold[msgGroup] /. $MessageGroups /. 
  Hold[messages_List] :> InterruptingCheck[expr, failexpr, messages]

\begin{Edit}
My original code for the supplying a message group failed to work correctly. The fix is shown above.  It works by replacing msgGroup with the appropriate list of messages, but using Hold to prevent them from being replaced by their string equivalents. (That is part of the reason for the HoldAll attribute being used here, to begin with.) Then, the held messages are extracted from Hold and inserted into InterruptingCheck still held because of HoldAll.
\end{Edit}
When applied to the example in the question, 
res2 = {};
InterruptingCheck[
 MapIndexed[
  If[# < 0, 
    Message[Test::wrpt, #2[[1]]]; Unevaluated[Sequence[]], 
    res2 = {res2, #}; #] &,
  dat[[;; 10]]~Join~{-1}~Join~dat],
 $Failed,
     {Test::wrpt}
     ]
     (* Test::wrpt: Negative point at 11
     $Failed
 *)

and res2 is
{0.288047, 0.026642, 0.361008, 0.28977, 0.573743, 
0.272747, 0.937062, 0.330572, 0.192807, 0.916764}

showing that it did stop execution at after the tenth element in the data.
"
list manipulation - Populating and storing a very large array in Mathematica,"
The large data framework
Ok, here is a shameless plug for the  large-data framework, which I developed some time ago for similar purposes. While it is not a proper and / or final place to store it, I put its code (straight from the linked post) to this gist, so that it is easier to copy and paste as a single piece of code (note that this is not yet a package).Here, I will illustrate how and why to use it for your case. 
Why use it here?
Let us start with why. The short answer: because it was written to address exactly the (rather wide) class of use cases to which the case at hand seems to belong. 
These are the advantages of using it here:

Once you convert your array to the file-backed representation, you don't have to care any more about possible kernel crashes - you can always load things back, and load only those parts you need (so, you don't have to think much about the memory either)
You don't have to convert your list all at once, neither do you have to wait until you have constructed all its elements. In fact, you can even build the list already in the file-backed form, by using the framework's API (it has two - higher-level for typical operations on lists such as appending a list, and lower-level one for accessing and possibly modifying individual parts of a list).
The framework adds syntactic sugar, so that, when working with parts of your list, you use code which looks like it is a normal list. In other words: while the real data structure responsible for the file-backed list is more like a hash-table filled with class instances (with each class instance pointing at a specific file location where the appropriate part of the list is stored), it is hidden by an interface which overloads most list operations and implements the list abstraction in a rather complete way. So, you can work on a much higher, and familiar to most Mathematica users, level of abstraction, and not really be concerned with the details of how the parts of your list are actually backed by files, saved, loaded, etc (not that it is too complicated, but the whole point is in information hiding - these details are largely irrelevant from the point of view of the higher-level operations we perform on lists). For you, this will look just like a regular list, in most important respects.
You can release memory used by the loaded parts of your list selectively, and right after you used this part - so the memory used will only be as much as many parts of your list you have to keep in memory at the same time. In the case of writing to a disk, this is just one part.
You can set your writing-to-disk code up in such a way that a possible crash in the middle will only invalidate the last part being written, and you will be able to reload the kernel and start from where you stopped - and again, with minimal memory requirements.

How to use it here
First, run the code of the framework.
Then, run this initialization code, to switch to .mx files (which are very fast):
$fileNameFunction = mxFileName;
$importFunction = mxImport;
$exportFunction = mxExport;
$compressFunction = Identity;
$uncompressFunction = Identity;

Now, we create a test array:
myArray = RandomReal[10^6, {10000, 50, 15, 40}];

This took quite a bit of RAM, so you better have at least 5Gb of RAM available. Now, initialize the symbol used to represent your list in the framework:
ClearAll[test];
initList[test]

Now, convert your list to the file-backed list - this is the main operation (use the correct path on your machine. The directory must exist)
appendList[test,myArray,
   DestinationDirectory:>""C:\\Temp\\LargeData""
];//AbsoluteTiming


{327.4692831,Null}


Note that I have a very fast SSD (like 10x the usual HDD speed), so this part may be slower on your machine, if you have a regular HDD or SSD drive. In any case, several minutes for a file of a couple of Gb large is pretty decent I think.
Note also that, if you monitor the memory consumption, the additional memory used by this procedure is very little - below 50Mb according to what I saw.
Now, the last step: save the main symbol (again, use the correct path on your machine):
storeMainList[test,DestinationDirectory:>""C:\\Temp\\LargeData""]//AbsoluteTiming


{37.4501953,Null}


For the test list I generated, this file is about 7Mb. The write time is slow here because it is a normal .m file, not .mx file.
We can now quit the kernel:
Quit

On the fresh kernel, you have to execute the framework's code again. We can then reconstruct the top-level structure of our file-backed list:
retrieveMainList[test,
     DestinationDirectory:>""C:\\Temp\\LargeData""
]//AbsoluteTiming


{66.3115234,Null}


This does not take much memory - just a few extra Mb. You can now do a few tests:
Length[test]


10000


test[[1]]//Dimensions


{50,15,40}


Let us now write a few first elements to a disk, to illustrate how this is done. I will write the first 10 out of 10000 elements.
mp[x_] := NumberForm[SetPrecision[x, 16], 16, ExponentFunction -> (Null &)];

testLength = 10;
w=OpenWrite[""C:\\Temp\\myLargeArray.dat""];
time = 
  AbsoluteTiming[
    Do[
      Do[WriteString[w,mp[x],""\n""],
        {jrow,test[[irow]]},{krow,jrow},{x,krow}
      ];
      releasePart[test,irow],
      {irow,1,testLength}
    ]
  ];
Close[w];
time


{7.4648438,Null}


Note that I was sloppy with stream closing (in the sense that I don't always guarantee that the stream will be close in case of exception or Abort in the middle) - but this is not my main point here.
Note also that I use the lower-level API provided by the framework, to release the memory used by a given part of the file-backed list, right after it was used. This makes the memory use minimal.
From the timing, it will take about 2 hours for you to write the entire file. What is important is that you can arrange your code to stop at any time and resume later, without the need to load the full huge array into the kernel each time.
Taking yet more advantage of the framework
Note also, that you can, instead of transferring the array to file-backed form only at the end, do so as you build an array. You can use the appendList function to add any number of elements to the file-backed representation of your array, so you can, for example, call it on every new element (which is, 3D array in your case), or every 10 new elements, etc. 
One catch here is that, to be on the safe side, you will have to call the function storeMainList periodically as well, since those parts saved to disk can not be used by themselves, without this higher-level element. This takes time (for the final array it took about 40 sec. on my machine), but if your computation takes many hours, I think you can afford doing this every half an hour say. In this way, you will also protect your computation, so that, in the case of a crash, you will be able to resume from where you stopped, rather than starting from scratch.
"
export - Changing the speed of exported AVI videos,"
The trick is using a combination of ""FrameRate"", an option of Export, and AutorunSequencing, an option of Manipulate. The former determines the number of frames/second of the movie whereas the latter determines how long a sweep of the control takes. With one control, that will be the length of the movie. 
Export[""output.avi"", 
 Manipulate[
   Plot[Sin[k  x], {x, 0, 2 \[Pi]}], 
   {k, 1, 5}, 
   AutorunSequencing -> {{1, 10}}
 ], ""FrameRate"" -> 2
]


"
"gui construction - How to save data to a variable by clicking a button, using Widget Panel","
If GUIkit isn't really a prerequisite you could try the standard controls present in Mathematica in all versions as of 6:
Panel[
 Column[
  {
   ""Please provide the following coefficients:"",
   ""  Value for p1"",
   InputField[Dynamic[p1tf]],
   ""            "",
   Button[
    ""Submit"", (If[
       ImaginaryQ@p1tf == False, 
       {
         MessageDialog[""The provided value is not valid. You need to enter complex value""], 
         Exit[]
       }
     ];)]
   }
  ]
 ]


"
export - Issue with Grid command,"
You could try defining myGrid = Grid[..., ImageSize -> All]. Consider for example the following test data
headings = Range[20];
countryList = Cases[CountryData[""Countries""], 
   c_ /; CountryData[c, ""BorderingCountries""] =!= {}, 1, 8];
salesTrend[c_, p_] := 
 With[{t = CountryData[c, ""BorderingCountries""]},
  {t, RandomReal[1, {20, Length[t]}]}]

Then with 
myGrid = Grid[Partition[
    Column[{"""", Style[#, Bold, FontSize -> 36], """", 
        chartTrends[#, 0.9]}, Alignment -> Center] & /@ countryList, 
    4], Alignment -> Center, Frame -> All, 
   FrameStyle -> Directive[LightGray], ItemSize -> All];

Export[""myGrid2.pdf"",myGrid]

I get

compared to the original (Note the wrapping of Afghanistan plus the elongated legend)

"
plotting - Manipulate and ExclusionsStyle,"
You can give explicit lhs == rhs style exclusions to get dashed lines:
Manipulate[Plot[{1/(a - x), x/(x - b)}, {x, -10, 10}, 
    Exclusions -> {x == b, x == a}, 
    ExclusionsStyle -> Dashed], {{a, 0}, -10, 10}, {{b, 0}, -10, 10}]


"
graphics - Encoding format used by GraphicsData?,"
I found an example on the web.  Here is code that will convert the PICT data from the format stored in the notebook file into a .pict file that can be opened by an image viewer (e.g. Photoshop).
DecodePICT[data_String] := Module[
    {slash, backslash, zero, LF, CR, decode, codes, len, i},
    {slash, backslash, zero, LF, CR} = ToCharacterCode[""/\\0\n\r""];
    decode[char_] := If[char == slash, backslash-zero, char-zero];
    len = Length[codes = ToCharacterCode[data]];
    i = 1;
    Join[Table[0,{512}], Last@Last@Reap@While[i <= len-1,
        Which[
            codes[[i]] == LF || codes[[i]] == CR,
            i++,
            codes[[i]] == backslash,
            i += 4,
            True,
            Sow@BitAnd[BitOr[
                BitShiftLeft[decode[codes[[i]]], 2],
                BitShiftRight[decode[codes[[i+1]]], 4]
            ], 255];
            i++;
            If[i <= len-1,
                Sow@BitAnd[BitOr[
                    BitShiftLeft[decode[codes[[i]]], 4],
                    BitShiftRight[decode[codes[[i+1]]], 2]
                ], 255]
            ];
            i++;
            If[i <= len-1,
                Sow@BitAnd[BitOr[
                    BitShiftLeft[decode[codes[[i]]], 6],
                    BitShiftRight[decode[codes[[i+1]]], 0]
                ], 255]
            ];
            i += 2;
        ]
    ]]
];

str = ""0N801`0]05815@0A0_l<0?ooool0;@0000L0004E0000DP000000002Q0O@0hd=U
  K6aK8U`lG0eSKgEbHVEKM5mM83Xm80eLM51QLV5]IGAbJF=@K6md<dAKN`eLM2Pb
  :b1d84=_Le]fGBU3Kg=K<WIM;0eLM2Pb:b1d84=_Le]fGBUCJFiK<WIM;0eLM7@P
  DfU^FgIMOBakMR`P<2`P<R1@JGeM83]L3E`n8R`P8TU^L7Ed8R`=8219KF5WIE=Y
  NVD]?W/b<c8/83LeOB`=8219KF5WIDeQLVMYKW<]?W]k<2`P<7d/87/`;20`OGd/
  3B0PBFeQIfEBIFMYKfh]?W]k<2`P<Gd/87/`;20aOGeM000N01[oooooool00@0:
  00L0;@1B0AD0<@0602d0DP9203401`920582@P0J0000000002`01@R^0Te30003
  2:h0104000d0300^00@0o`0002/]4PiSKgEbHVEKM5mM83Xm8000:b0?4U1QLV5]
  IGAbJF=@K6md<dAKN`00:PlE:38[87@P@fmcFgIM:D=_Le/bMUd/000Z3aDX<R/P
  M213Kg=KMUdYDfU^Fc9fGB`002X?6G@PDfU^FgIMOBakMR`P<2`P<R1@JGeM83/0
  0?l"";

Export[""~/Desktop/foo.pict"", DecodePICT[str], ""Binary""]

"
differential equations - Starting NDSolve from intermediate time step?,"
You could integrate up to some intermediate time, tintermediate, and then feed the result as initial conditions to the solver to propagate from tintermediate to tmax, like so:
tmin = 0;
tintermediate = 2;
tmax = 5;
sol = NDSolve[{D[u[t, x], t] == D[u[t, x], x, x], u[0, x] == 0, 
    u[t, 0] == Sin[t], u[t, 5] == 0}, 
   u, {t, tmin, tintermediate}, {x, 0, 5}];
sol2 = NDSolve[{D[u[t, x], t] == D[u[t, x], x, x],
    u[tintermediate, x] \[Equal] First@(u[tintermediate, x] /. sol), 
    u[t, 0] == Sin[t], u[t, 5] == 0}, 
   u, {t, tintermediate, tmax}, {x, 0, 5}];

"
debugging - MUnit test debug breakpoints in Workbench not working,"
You have to set breakpoints in what is considered a source file, ie a .m package file. Breakpoints set within test or scrapbook files are not supported.
So you would have a test that executes a function defined in a package, set the breakpoint in the package, and when you debug the test, it will suspend.
"
front end - TextAlignment->Center in a notebook with WindowSize->All,"
There is no easy solution involving multi-cells.
I want to explain why it is a problem--you can call it a bug, but it is rather a tricky situation for Mathematica.
To determine the TextAlignment or TextJustification correctly, Mathematica needs to know the width of an enclosing window of the cell. Now, the problem is, the window width can be only determined when you know the width of the contents, since it is set to WindowSize->All. So we are in effect creating a circular argument: Mathematica can't decide one value because it depends on each other.
There are a number of similar situation. Try Pane[..., {Full, All}] for instance. In this case, the width of Pane should be determined by the enclosing cell, but works only when it is explicit (otherwise, the same circular argument). Compare these two cases:
CreateDialog[Framed[Pane[""A"", {Full, Full}], FrameMargins -> 0]];
CreateDialog[Framed[Pane[""A"", {Full, Full}], FrameMargins -> 0], WindowSize -> {100, All}];



You can easily tell which one is which (besides, the second image is correct. Full means that the pane should extend to the full width of the enclosing object--in this case, the notebook).
Anything involving undetermined object size which depends on the enclosed contents (WindowSize with All, or ImageSize with All, Automatic, Full) and the content properties (such as Scaled or ImageScaled size, coordinates, alignment, etc...) which depend on the size of the enclosing object (whether it is Notebook or Graphics, etc..), it is always very tricky to get a right solution. Mathematica tries its best to do a sensible thing, but like this case, sometimes it just can't handle it well... 
"
functions - How to load a package without naming conflicts?,"
Shadowing occurs only when there are two functions with the same name that are in $ContextPath. So right after you do <<Combinatorica`, do the following:
$ContextPath = Rest@$ContextPath;

What this does is that it removes Combinatorica (which is the package you just loaded). Now the only Graph function that's on the path is System`Graph and you can call it simply by the name, without the prefix. To access any functions from the package, use the prefix, as Combinatorica`Graph.
If Combinatorica` was loaded a while ago and you have loaded other packages in between, Rest@... is not going to be helpful. In that case, use:
$ContextPath = DeleteCases[$ContextPath, ""Combinatorica`""];

"
plotting - ImageCrop for vector graphics,"
Edit
Come to think of it, one case where I often want to crop the output is Graphics3D (one can do it with ViewAngle etc., but it's not always convenient - one could also convert to bitmap, but again that's not always desirable). So I decided to allow the cropGraphics function below to be used with any object, not just 2D Graphics. Here is an example:
q = Show[ExampleData[{""Geometry3D"", ""Cow""}], ImageSize -> 360, 
  Background -> Darker[Green]]


cg = cropGraphics[q, -0.8, -0.4, 200, 200]


In the simple form defined below, cropGraphics requires the input object to have an explicit ImageSize setting. But it works for a wide range of objects. It can even be used to convert Overlay objects to Graphics while at the same time cropping them.
Speaking of Overlay, here is a continuation of the above example:
plot = Overlay[{Plot[Sin[x], {x, 0, 2 Pi}, GridLines -> Automatic, 
    Frame -> True, ImageSize -> 360],
   Magnify[cg, .5]}, Alignment -> {.5, .5}]


This is an overlay with the cropped graphics created previously. Now crop this plot once again:
cropGraphics[plot, 0.5, 0, 300, 120]


End Edit
Here is the function that does the above. It is based on Inset, and it assumes for simplicity that the graphic you want to crop is going to be positioned in the crop window by placing the original coordinate {0,0} (in the coordinate system of the graphics) at a scaled position {x,y}. Here, x and y are between 0 and 1, with x = 0.5 corresponding to the center of the crop window. I'll explain this in an example:
cropGraphics[g_, x_, y_, w_, h_] := 
 Graphics[Inset[g, {x, y}, {0, 0}], PlotRange -> {{0, 1}, {0, 1}}, 
  ImageSize -> {w, h}, AspectRatio -> Full]

Here is a sample graphic; I would suggest always giving it a definite setting of ImageSize to begin with:
pl = Graphics[{{Red, Rectangle[{0, 0}, {.5, .5}]}, {Blue, 
    Disk[{1, 1}, .5]}}, PlotRange -> {{0, 1.5}, {0, 1.5}}, 
  ImageSize -> 400]


For reference, the bottom left corner of the square is at {0, 0}, and the graphics is 400 pixels wide and high.
Now we crop it:
cropGraphics[pl, 0, 0, 300, 300]


The coordinates 0, 0 mean that the bottom left corner of the square is still where it was before, but the new image width and height are 300. 
If we want to crop part of the square instead, all we have to do is move its lower left corner {0, 0} outside the crop window by giving it negative scaled coordinates:
cropGraphics[pl, -.25, -.1, 300, 300]


Finally, an example of a non-square crop area:
cropGraphics[pl, 0.5, -.24, 400, 300]


One could improve on this by changing the scaled coordinates x and y to something absolute in pixels, but I wanted to keep it simple for now, to focus on the main issue: use Inset with a variable position in a ""wrapper"" graphic whose coordinate system ranges from 0 to 1 to make the inset position a scaled coordinate, and whose ImageSize has the value desired for the crop.
"
probability or statistics - Some questions about random numbers,"
You can obtain discrete uniform or normally distributed numbers from random.org, which allows you to generate 200k bits/day.
Import[""http://www.random.org/cgi-bin/randbyte?nbytes=1024&format=f"", ""Binary""]

"
mathematical optimization - How to find all the local minima/maxima in a range,"
This can be done using event location within NDSolve. I start off as below (note f is slightly modified from what you have, mostly to rescale it).
GetRLine3[MMStdata_, IO_: 1][x_: x] := 
  ListInterpolation[#, InterpolationOrder -> IO, Method -> ""Spline""][
     x] & /@ (({{#[[1]]}, #[[2]]}) & /@ # & /@ MMStdata);
data = Transpose[{# + RandomReal[]*0.1 & /@ Range[-10, 30, 0.4], 
    Tanh[#] + (Sech[2 x - 0.5]/1.5 + 1.5) /. x -> # & /@ 
     Range[-4, 4, 0.08]}];

xLimits = {Min@#1, Max@#1} & @@ Transpose[data];
f = First[100*D[GetRLine3[{data}, 3][x], x]];

We'll recapture f using NDSolve, and locate the points where the derivative vanishes in the process.
vals = Reap[
    soln = y[x] /. 
      First[NDSolve[{y'[x] == Evaluate[D[f, x]], 
         y[-9.9] == (f /. x -> -9.9)}, y[x], {x, -9.9, 30}, 
        Method -> {""EventLocator"", ""Event"" -> y'[x], 
          ""EventAction"" :> Sow[{x, y[x]}]}]]][[2, 1]];

Visual check:
Plot[f, {x, -9.9, 30}, 
 Epilog -> {PointSize[Medium], Red, Point[vals]}]


"
manipulate - Question about making TabView remember what tab to open,"
I may have misunderstood your problem, but it looks like you just need to create a persistent local variable keeping the value of the tab which was last open. One way to do this:
DynamicModule[{tab},
   myCustomTab[] :=
      TabView[
       {
          {patt, ""Pattern"" -> 1},
          {motif, ""Motif"" -> 
             Column[{
               Button[""Type"", Print["" NOT IMPLEMENTED YET""], ImageSize -> 100],
               Button[""New shape"", Print["" NOT IMPLEMENTED YET""], ImageSize -> 100],
               Button[""Pixel"", Print["" NOT IMPLEMENTED YET""], ImageSize -> 100]}]}
       },
       Dynamic[tab]]
]

What matters is that you create a closure, so the variable tab is not local to the function myCustomTab (in the sense that it is not re-initialized on every function's invocation).
EDIT
Ok, it is probably a good time to explain what I mean by code generation, since I mentioned this technique many times already. Basically, I mean that you will be better off by creating your own DSL for UI. I will illustrate it here simplistically with rule application, but generally I would rather use recursion, which is more powerful. You can notice that your code is full of repeated elements, and this is true even for such a small code snippet. Here is one way to reduce the boilerplate:
This is a function written by @Szabolcs, which will be handy here
ClearAll[withRules]
SetAttributes[withRules, HoldAll]
withRules[rules_, expr_] :=
  First@PreemptProtect@Internal`InheritedBlock[
    {Rule, RuleDelayed},
    SetAttributes[{Rule, RuleDelayed}, HoldFirst];
    Hold[expr] /. rules
]

This is the starting point:
myTab = 
  myTabView[
   {""Pattern"" -> 1,
     ""Motif"" -> Column[{
         myButton[""Type"", noimpl[]],
         myButton[""New shape"", noimpl[]],
         myButton[""Pixel"", noimpl[]]}]
    }];

This is an auxiliary function:
Clear[dressTabView];
dressTabView[lrules_] :=
   t : myTabView[{__Rule}] :>
     DynamicModule[{tab},
        Append[
           Replace[t, e : (label_ -> w_) :> {withRules[lrules, label], e}, 2],
           Dynamic[tab]]];

This is a chain of transformations needed to generate your widget with tab memory:
myTab /. dressTabView[{""Motif"" :> motif, ""Pattern"" :> patt}] /.
    myButton[args__] :> Button[args, ImageSize -> 100] /.
       noimpl[] :> Print["" NOT IMPLEMENTED YET""] /.
          myTabView -> TabView

The main point is, as usual, to separate the specific from the general.          
"
